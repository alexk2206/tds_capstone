{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPa8jfl9Fr9CuN3DQ5/2pv5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "93a5db67155e47c5b7784e02d682f00a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8ed1a60f2e7d420b9087338906cd74af",
              "IPY_MODEL_91bc9606de7542a4ba572e8eceb7c261",
              "IPY_MODEL_77c4ea97c3d24a43980a06d7f457697b"
            ],
            "layout": "IPY_MODEL_823909baca8441a9bddb4c2d825be6ff"
          }
        },
        "8ed1a60f2e7d420b9087338906cd74af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c53250b753b04a24ab0a85f86a28ceb5",
            "placeholder": "​",
            "style": "IPY_MODEL_58aa2f61829c4a2292aa5f13967b9fa9",
            "value": "Casting to class labels: 100%"
          }
        },
        "91bc9606de7542a4ba572e8eceb7c261": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3e23e3b8b2a1467e941136b19fb52cd5",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e7acfc181fbb48c8b34c4fcebe066b73",
            "value": 1381
          }
        },
        "77c4ea97c3d24a43980a06d7f457697b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9cf7674a3db846c4bdd65563ef0fd8bb",
            "placeholder": "​",
            "style": "IPY_MODEL_26e30d1f3b2a4673a906115780ed086e",
            "value": " 1381/1381 [00:00&lt;00:00, 19622.13 examples/s]"
          }
        },
        "823909baca8441a9bddb4c2d825be6ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c53250b753b04a24ab0a85f86a28ceb5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58aa2f61829c4a2292aa5f13967b9fa9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3e23e3b8b2a1467e941136b19fb52cd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e7acfc181fbb48c8b34c4fcebe066b73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9cf7674a3db846c4bdd65563ef0fd8bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "26e30d1f3b2a4673a906115780ed086e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59044c8744854a1fb9feead203f8ab28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5d87ecc12c204399823d9becc2b5e850",
              "IPY_MODEL_e386a60c3a0749c0b0f3f7fc8733516d",
              "IPY_MODEL_fc0d81f19e23455cbb5dd12338fe1e27"
            ],
            "layout": "IPY_MODEL_cb407d065a124cfe94893c21b4467406"
          }
        },
        "5d87ecc12c204399823d9becc2b5e850": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_12a28748edf2413393bafaf643fa994f",
            "placeholder": "​",
            "style": "IPY_MODEL_db7abe09e1d44888abebb5a6cedf3401",
            "value": "Downloading builder script: 100%"
          }
        },
        "e386a60c3a0749c0b0f3f7fc8733516d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d8412d52ad94550a3c456b9bdb30475",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e9463f4e3ce043da9f2cdb16e7b10861",
            "value": 4203
          }
        },
        "fc0d81f19e23455cbb5dd12338fe1e27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a1272469e534174b3310f95b69d4123",
            "placeholder": "​",
            "style": "IPY_MODEL_9f511e0709394d449ee8caedcee4cd68",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 105kB/s]"
          }
        },
        "cb407d065a124cfe94893c21b4467406": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12a28748edf2413393bafaf643fa994f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db7abe09e1d44888abebb5a6cedf3401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d8412d52ad94550a3c456b9bdb30475": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e9463f4e3ce043da9f2cdb16e7b10861": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a1272469e534174b3310f95b69d4123": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f511e0709394d449ee8caedcee4cd68": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4b3b2436dab14560ade8908502a4fde3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15cf8b1942414b49b610eea5b051f50e",
              "IPY_MODEL_c9c512f1862440b682f0c850257ec833",
              "IPY_MODEL_b6bff98ef4294f6798bb6fd6d43abd6c"
            ],
            "layout": "IPY_MODEL_042ddbbc68974b289477ddea90fb4788"
          }
        },
        "15cf8b1942414b49b610eea5b051f50e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f533231358940ad9b29b702237a4374",
            "placeholder": "​",
            "style": "IPY_MODEL_bfc053516e084e0ea393d9fa76691c53",
            "value": "Downloading builder script: 100%"
          }
        },
        "c9c512f1862440b682f0c850257ec833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_476b3c9ab5a24ba8801a2998644871e8",
            "max": 6785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c12f0e1eaab149cea4e1c54b6c33d0d5",
            "value": 6785
          }
        },
        "b6bff98ef4294f6798bb6fd6d43abd6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf2d6f418d31490083af5228ff89c074",
            "placeholder": "​",
            "style": "IPY_MODEL_55d8f1b7bb944569982cf69a580ca541",
            "value": " 6.79k/6.79k [00:00&lt;00:00, 202kB/s]"
          }
        },
        "042ddbbc68974b289477ddea90fb4788": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f533231358940ad9b29b702237a4374": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfc053516e084e0ea393d9fa76691c53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "476b3c9ab5a24ba8801a2998644871e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c12f0e1eaab149cea4e1c54b6c33d0d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bf2d6f418d31490083af5228ff89c074": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "55d8f1b7bb944569982cf69a580ca541": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1274a62e96d449a391ba0ac43432897b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b8b67813d6f047cf9f5c9e28e8d0e672",
              "IPY_MODEL_5bb19898a6fc4c118b32d05553e48e97",
              "IPY_MODEL_9d9f2ce4ed1f42c2aad46a3a4ae6b208"
            ],
            "layout": "IPY_MODEL_7058d3c444994e64ad80d7d5e87aa294"
          }
        },
        "b8b67813d6f047cf9f5c9e28e8d0e672": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c63cd4cd6c5b4e3d8fa148b97b17d9fa",
            "placeholder": "​",
            "style": "IPY_MODEL_34b982e507b04e4889a81dcef2a22330",
            "value": "Downloading builder script: 100%"
          }
        },
        "5bb19898a6fc4c118b32d05553e48e97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fec9ca008dce44aa9bc915f17bb38bf4",
            "max": 7560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4c88a420328646aa80b65d41dad2b6d5",
            "value": 7560
          }
        },
        "9d9f2ce4ed1f42c2aad46a3a4ae6b208": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9808e01c8964a8293fb56df8c060af4",
            "placeholder": "​",
            "style": "IPY_MODEL_c66e1300994842768100b4cf1dbc37a4",
            "value": " 7.56k/7.56k [00:00&lt;00:00, 149kB/s]"
          }
        },
        "7058d3c444994e64ad80d7d5e87aa294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c63cd4cd6c5b4e3d8fa148b97b17d9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b982e507b04e4889a81dcef2a22330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fec9ca008dce44aa9bc915f17bb38bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c88a420328646aa80b65d41dad2b6d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9808e01c8964a8293fb56df8c060af4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c66e1300994842768100b4cf1dbc37a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "10d00df85e1e4c83ac9e908db63d6c26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3febdd5820c74dafa65d511a76fed480",
              "IPY_MODEL_43993b09d7c14f3e99b032d647ba9bb9",
              "IPY_MODEL_5eb7716c863d4d9da6df62c9c66470b9"
            ],
            "layout": "IPY_MODEL_6d025b2b9f5b42998a7c7e6014e0feec"
          }
        },
        "3febdd5820c74dafa65d511a76fed480": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0748a76db3cd4a5ea0269ac4c5055eab",
            "placeholder": "​",
            "style": "IPY_MODEL_dd4951eb191a419caba7a70d31e52f13",
            "value": "Downloading builder script: 100%"
          }
        },
        "43993b09d7c14f3e99b032d647ba9bb9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc9167f8b2ed4d469fb126cb34faa611",
            "max": 7377,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_82ed4394e8be4c7da9adae7f40c8345f",
            "value": 7377
          }
        },
        "5eb7716c863d4d9da6df62c9c66470b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8eedabcd99d6482e8f990348d16a061f",
            "placeholder": "​",
            "style": "IPY_MODEL_1b2822fcaa2a4bcfabba90b70be8bf7c",
            "value": " 7.38k/7.38k [00:00&lt;00:00, 303kB/s]"
          }
        },
        "6d025b2b9f5b42998a7c7e6014e0feec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0748a76db3cd4a5ea0269ac4c5055eab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd4951eb191a419caba7a70d31e52f13": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc9167f8b2ed4d469fb126cb34faa611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "82ed4394e8be4c7da9adae7f40c8345f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8eedabcd99d6482e8f990348d16a061f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b2822fcaa2a4bcfabba90b70be8bf7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7bb3fcc01032413eb2c6f0c501d4dd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f61d3fd3d7ec471481518077511dd049",
              "IPY_MODEL_e1a69486d9d148b0ace0d8218e065a50",
              "IPY_MODEL_2e00dd40066d4206bf1a507bcd13b355"
            ],
            "layout": "IPY_MODEL_c89b884b3d814baea55e86529b29b8a1"
          }
        },
        "f61d3fd3d7ec471481518077511dd049": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c81072ac31f434cb75a3b2f0c095478",
            "placeholder": "​",
            "style": "IPY_MODEL_a41d3bb104f4464bbb92c61329ec1b58",
            "value": "Downloading builder script: 100%"
          }
        },
        "e1a69486d9d148b0ace0d8218e065a50": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_314136a7957f43eca4120980d13cbf2b",
            "max": 5669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dc45f9388fc74965998e70d28ea4f826",
            "value": 5669
          }
        },
        "2e00dd40066d4206bf1a507bcd13b355": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f21533c5d4743aeb1e2bd554f3371e8",
            "placeholder": "​",
            "style": "IPY_MODEL_80346a59d2ea4b4f8b8f705c52fec3e5",
            "value": " 5.67k/5.67k [00:00&lt;00:00, 106kB/s]"
          }
        },
        "c89b884b3d814baea55e86529b29b8a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c81072ac31f434cb75a3b2f0c095478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41d3bb104f4464bbb92c61329ec1b58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "314136a7957f43eca4120980d13cbf2b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dc45f9388fc74965998e70d28ea4f826": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6f21533c5d4743aeb1e2bd554f3371e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80346a59d2ea4b4f8b8f705c52fec3e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "48e937a97261433d9cc6e7f0383cf40c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7f0901d13a184e8e89504775c8092d97",
              "IPY_MODEL_3bbe36de1dca48f99784408e545303b5",
              "IPY_MODEL_062a9dcb5aa54951a2e3b77d383f4552"
            ],
            "layout": "IPY_MODEL_63749ca00b394f67ba3a81f96ee1eb8f"
          }
        },
        "7f0901d13a184e8e89504775c8092d97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6980753b93a4cf9bfb446edfa50f440",
            "placeholder": "​",
            "style": "IPY_MODEL_4af8970fe4554e419e0a9e9fc1bfb201",
            "value": "config.json: 100%"
          }
        },
        "3bbe36de1dca48f99784408e545303b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34126c03aae049debb5ce1b8a9b87434",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f252110d65c64d158ef969b0e7744245",
            "value": 1206
          }
        },
        "062a9dcb5aa54951a2e3b77d383f4552": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_db4a2e33a5144b73a109fe1de0871af1",
            "placeholder": "​",
            "style": "IPY_MODEL_cb473c370b0b4420ae9509ea42143cf3",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 68.9kB/s]"
          }
        },
        "63749ca00b394f67ba3a81f96ee1eb8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6980753b93a4cf9bfb446edfa50f440": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4af8970fe4554e419e0a9e9fc1bfb201": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34126c03aae049debb5ce1b8a9b87434": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f252110d65c64d158ef969b0e7744245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "db4a2e33a5144b73a109fe1de0871af1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb473c370b0b4420ae9509ea42143cf3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "53f0e5f31c054232a9aa4e6f545b58f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e75c1cc060764f21a708b134d4c000e0",
              "IPY_MODEL_eb658a3b263c4a2eb8ecc59569dc75cb",
              "IPY_MODEL_c74a0fb700ff443094004257aa3b6204"
            ],
            "layout": "IPY_MODEL_21ba4b35cd4a4d12b91f67d03007087e"
          }
        },
        "e75c1cc060764f21a708b134d4c000e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_97c6e88e40c84dfeb0b0db0d6827b4af",
            "placeholder": "​",
            "style": "IPY_MODEL_71d98c8ab3534232b054933338b6e64b",
            "value": "model.safetensors: 100%"
          }
        },
        "eb658a3b263c4a2eb8ecc59569dc75cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e8bbc378cb7e4f2d9fc907cd2596228a",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e454fafeb5f94e0da6912565e79896fd",
            "value": 242043056
          }
        },
        "c74a0fb700ff443094004257aa3b6204": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0eb14b49919642c09417da326a26d1cd",
            "placeholder": "​",
            "style": "IPY_MODEL_42d5d26c5f924be08c1e94a88d27e567",
            "value": " 242M/242M [00:01&lt;00:00, 191MB/s]"
          }
        },
        "21ba4b35cd4a4d12b91f67d03007087e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "97c6e88e40c84dfeb0b0db0d6827b4af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71d98c8ab3534232b054933338b6e64b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e8bbc378cb7e4f2d9fc907cd2596228a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e454fafeb5f94e0da6912565e79896fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0eb14b49919642c09417da326a26d1cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "42d5d26c5f924be08c1e94a88d27e567": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "34c17d1f0d9b445fbc73a6c51ec72830": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a84217232a5d4c88a88e82f15af8370b",
              "IPY_MODEL_1a8b5f92ae6c4936b543f817194b82d8",
              "IPY_MODEL_8418d01c47f943d6a7fbaaf7806a42ce"
            ],
            "layout": "IPY_MODEL_d9ea2f137484493aaade56a912de2040"
          }
        },
        "a84217232a5d4c88a88e82f15af8370b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_125e93be67d540d6bf6388ab255095fb",
            "placeholder": "​",
            "style": "IPY_MODEL_1591b48c56b04a53a5a33fbd3ed14117",
            "value": "generation_config.json: 100%"
          }
        },
        "1a8b5f92ae6c4936b543f817194b82d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_06b132098dad4229afbef70fa9b29ba1",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b9ba2c1f8482455db4f4065da4cd2bdc",
            "value": 147
          }
        },
        "8418d01c47f943d6a7fbaaf7806a42ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ba804d065aa4798b59b726b2685a10e",
            "placeholder": "​",
            "style": "IPY_MODEL_7d0f0d77545c4491a156cf6ae92d70c5",
            "value": " 147/147 [00:00&lt;00:00, 4.34kB/s]"
          }
        },
        "d9ea2f137484493aaade56a912de2040": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "125e93be67d540d6bf6388ab255095fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1591b48c56b04a53a5a33fbd3ed14117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "06b132098dad4229afbef70fa9b29ba1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b9ba2c1f8482455db4f4065da4cd2bdc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ba804d065aa4798b59b726b2685a10e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7d0f0d77545c4491a156cf6ae92d70c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4844ef76a7bf4b0d8640e606341cbe81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8a04c3d943b049ccb757d0ab214a751e",
              "IPY_MODEL_4e93fcf8747542648bb27f960fb4a646",
              "IPY_MODEL_ad487a3822b84580ab26959b7e06a504"
            ],
            "layout": "IPY_MODEL_054190a8ba8f48fda3778b4052816507"
          }
        },
        "8a04c3d943b049ccb757d0ab214a751e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c71cbb2b23fc474588192f55a2564b87",
            "placeholder": "​",
            "style": "IPY_MODEL_3f598bade46a4f3e8ebc10e1b652bef4",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "4e93fcf8747542648bb27f960fb4a646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4c0a39e56e14d4d9d9331d01d94af1e",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52bb010f2b1c4a68a5c90fdcb311ef6f",
            "value": 2324
          }
        },
        "ad487a3822b84580ab26959b7e06a504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e7163f0be53e49bd967ed32d668001f3",
            "placeholder": "​",
            "style": "IPY_MODEL_49faeb14a5e94f4991ca035e57404ecf",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 117kB/s]"
          }
        },
        "054190a8ba8f48fda3778b4052816507": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71cbb2b23fc474588192f55a2564b87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f598bade46a4f3e8ebc10e1b652bef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4c0a39e56e14d4d9d9331d01d94af1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52bb010f2b1c4a68a5c90fdcb311ef6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e7163f0be53e49bd967ed32d668001f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49faeb14a5e94f4991ca035e57404ecf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df3a825c7b2e45dd9881ea18536d2d0c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c36bb59c2a07443195665b9e34f63bbc",
              "IPY_MODEL_6078bced7f5143b9a66aa6d24b3c5057",
              "IPY_MODEL_ec10760b362544edaa9eaa3294d19ef2"
            ],
            "layout": "IPY_MODEL_9de56b287a6646c39e4381a957de0ace"
          }
        },
        "c36bb59c2a07443195665b9e34f63bbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5700ca91c5845d198bd286758e621ec",
            "placeholder": "​",
            "style": "IPY_MODEL_72fd89542e57496cab9de10797504938",
            "value": "spiece.model: 100%"
          }
        },
        "6078bced7f5143b9a66aa6d24b3c5057": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ce5f083e5a7418b8692ecf884e6027c",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c3934f0069b74e91bc7de03997a61d53",
            "value": 791656
          }
        },
        "ec10760b362544edaa9eaa3294d19ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e74edb831954602a911a544604695ad",
            "placeholder": "​",
            "style": "IPY_MODEL_46710cb847574d7791a53e692cffbb2d",
            "value": " 792k/792k [00:00&lt;00:00, 3.22MB/s]"
          }
        },
        "9de56b287a6646c39e4381a957de0ace": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b5700ca91c5845d198bd286758e621ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "72fd89542e57496cab9de10797504938": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ce5f083e5a7418b8692ecf884e6027c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3934f0069b74e91bc7de03997a61d53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4e74edb831954602a911a544604695ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "46710cb847574d7791a53e692cffbb2d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b80abe0a7eaa48be810394645d660b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88a6d8091a8746d886bbb750786ccc53",
              "IPY_MODEL_617b1f62bd484b3d8826aa4db60d2854",
              "IPY_MODEL_2fc75246a50a49d4a72a751b52d6ecb1"
            ],
            "layout": "IPY_MODEL_eed83e0bd2d1464483cd622e5a9933bf"
          }
        },
        "88a6d8091a8746d886bbb750786ccc53": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb18e9f1d23f4ac08a4ec148ca1b2f30",
            "placeholder": "​",
            "style": "IPY_MODEL_6f47f77808ae4b2aba26ff3161874086",
            "value": "tokenizer.json: 100%"
          }
        },
        "617b1f62bd484b3d8826aa4db60d2854": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1294a0777af4d60806e14281d21ece1",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_12ca8d4f6ed44916b4ed4bf878152183",
            "value": 1389353
          }
        },
        "2fc75246a50a49d4a72a751b52d6ecb1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_41d252b5e3614207ac52d3911c1e690e",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9839c94ef747a3a776a5dd29e78072",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 4.24MB/s]"
          }
        },
        "eed83e0bd2d1464483cd622e5a9933bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb18e9f1d23f4ac08a4ec148ca1b2f30": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6f47f77808ae4b2aba26ff3161874086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d1294a0777af4d60806e14281d21ece1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "12ca8d4f6ed44916b4ed4bf878152183": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "41d252b5e3614207ac52d3911c1e690e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9839c94ef747a3a776a5dd29e78072": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de3e64c1e28c4fde94e6c67cad042623": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b25aaa3c01c44258a299b1e0c19bfae8",
              "IPY_MODEL_215f1e718f794b0a97ac40724bae0cd5",
              "IPY_MODEL_d47b1b3526164fdc85395f02231a34c2"
            ],
            "layout": "IPY_MODEL_5ca22f16658344d9aa6a3b37aa996b58"
          }
        },
        "b25aaa3c01c44258a299b1e0c19bfae8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d7b41d5b10d421e9cfed7dbd0e06c28",
            "placeholder": "​",
            "style": "IPY_MODEL_d8384107b53941a8805f7683b67fcd3b",
            "value": "config.json: 100%"
          }
        },
        "215f1e718f794b0a97ac40724bae0cd5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d703e1264c5641b38d65e407e5c210fd",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_000f9ed9a18d4fa18feb9ec32ce8ca97",
            "value": 570
          }
        },
        "d47b1b3526164fdc85395f02231a34c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d2f453c35a4c7ca837b26956fc3ed4",
            "placeholder": "​",
            "style": "IPY_MODEL_d8a6dd17cd6e4babb742db9c47668175",
            "value": " 570/570 [00:00&lt;00:00, 17.5kB/s]"
          }
        },
        "5ca22f16658344d9aa6a3b37aa996b58": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d7b41d5b10d421e9cfed7dbd0e06c28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8384107b53941a8805f7683b67fcd3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d703e1264c5641b38d65e407e5c210fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "000f9ed9a18d4fa18feb9ec32ce8ca97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5d2f453c35a4c7ca837b26956fc3ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8a6dd17cd6e4babb742db9c47668175": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a26ac8d668344fa89a3752777b345a20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_130378064923417caea03fc83c518021",
              "IPY_MODEL_418fefcc74884dc588f8dcc5428fd7ab",
              "IPY_MODEL_9a45fa39d39e4afdb667902ccc020f92"
            ],
            "layout": "IPY_MODEL_193cb982e8634a9a9962d6403fc47ca3"
          }
        },
        "130378064923417caea03fc83c518021": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_76be37e307b64e7ba2600709b8b45dab",
            "placeholder": "​",
            "style": "IPY_MODEL_cb9d3fce3045411dbda00ddc24f76dc6",
            "value": "model.safetensors: 100%"
          }
        },
        "418fefcc74884dc588f8dcc5428fd7ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a64aa05d13194640b5b965f619d15230",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2910a3d0afcb46d78fa8e96869d56de1",
            "value": 435755784
          }
        },
        "9a45fa39d39e4afdb667902ccc020f92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd2ff28b8ec1444799b18fe1156c127c",
            "placeholder": "​",
            "style": "IPY_MODEL_8951b6e73ca746118b797b86b13b2e91",
            "value": " 436M/436M [00:05&lt;00:00, 111MB/s]"
          }
        },
        "193cb982e8634a9a9962d6403fc47ca3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76be37e307b64e7ba2600709b8b45dab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb9d3fce3045411dbda00ddc24f76dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a64aa05d13194640b5b965f619d15230": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2910a3d0afcb46d78fa8e96869d56de1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dd2ff28b8ec1444799b18fe1156c127c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8951b6e73ca746118b797b86b13b2e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d53e9840097346d1b9a128165c3a556e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_725147d6ca0b452eba66bfe5ef15b22c",
              "IPY_MODEL_1888f14787ec4bae8d092aa682727e93",
              "IPY_MODEL_5825756e00a24393917b67b6949a02ac"
            ],
            "layout": "IPY_MODEL_b365a036697b4f83aab3afc59c92cd96"
          }
        },
        "725147d6ca0b452eba66bfe5ef15b22c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b6d4d384a6e6406d85bd8c545cd47fa1",
            "placeholder": "​",
            "style": "IPY_MODEL_2455fa29cf7b495f9d8d9a1fd6e3cac5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1888f14787ec4bae8d092aa682727e93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_629561ca99914abbbdf4c0f97b8ceec8",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28bf93ec9a6a44c6bf88683a07b124c9",
            "value": 49
          }
        },
        "5825756e00a24393917b67b6949a02ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_30d46d9fe2b94121816aebcce7be409e",
            "placeholder": "​",
            "style": "IPY_MODEL_675902fafb894dcbb711b9beadeedd20",
            "value": " 49.0/49.0 [00:00&lt;00:00, 1.23kB/s]"
          }
        },
        "b365a036697b4f83aab3afc59c92cd96": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6d4d384a6e6406d85bd8c545cd47fa1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2455fa29cf7b495f9d8d9a1fd6e3cac5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "629561ca99914abbbdf4c0f97b8ceec8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28bf93ec9a6a44c6bf88683a07b124c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "30d46d9fe2b94121816aebcce7be409e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "675902fafb894dcbb711b9beadeedd20": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "991aae395816463ebddf67a42961fd47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b485e8bf4f6940b889a0018846dc40c9",
              "IPY_MODEL_9ca3ce006f804e42821d406cb46a1c5b",
              "IPY_MODEL_ce9bb62504ac4993a2236ec456ffa554"
            ],
            "layout": "IPY_MODEL_c0f1c97910984fea95e37f692321300d"
          }
        },
        "b485e8bf4f6940b889a0018846dc40c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_68a92fc05f254f34a7fdd284e4963912",
            "placeholder": "​",
            "style": "IPY_MODEL_d75514b0bafd4810bf6c62adf9c01dde",
            "value": "vocab.txt: 100%"
          }
        },
        "9ca3ce006f804e42821d406cb46a1c5b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_857df7a5eb52490cae3054100f9c5b27",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9a224c58397d45a59deddf578d3334af",
            "value": 213450
          }
        },
        "ce9bb62504ac4993a2236ec456ffa554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d87738a0845d4f758b48261f7b954026",
            "placeholder": "​",
            "style": "IPY_MODEL_36b2bb1399b343e4b6129f4b4d53b78c",
            "value": " 213k/213k [00:00&lt;00:00, 4.88MB/s]"
          }
        },
        "c0f1c97910984fea95e37f692321300d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68a92fc05f254f34a7fdd284e4963912": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d75514b0bafd4810bf6c62adf9c01dde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "857df7a5eb52490cae3054100f9c5b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9a224c58397d45a59deddf578d3334af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d87738a0845d4f758b48261f7b954026": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b2bb1399b343e4b6129f4b4d53b78c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6fd8e0a53a843afa633def9510108d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a1b940b701a49fab872fc9fa26559f4",
              "IPY_MODEL_c7dfa73b13724b3e8fc08b2955ec30fb",
              "IPY_MODEL_3364df12fe2a4a5c98e1c7ce29e756cd"
            ],
            "layout": "IPY_MODEL_1392ed714d36446381160bb5f6cf84e5"
          }
        },
        "4a1b940b701a49fab872fc9fa26559f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1199afe26f3a4fffb88d15891afada68",
            "placeholder": "​",
            "style": "IPY_MODEL_92c44136cf2845219e42ed9830355af1",
            "value": "tokenizer.json: 100%"
          }
        },
        "c7dfa73b13724b3e8fc08b2955ec30fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d0e3a652f3d041199b1a10a2ab8022ff",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_15900a82a5874d3bb24e1687f423c18b",
            "value": 435797
          }
        },
        "3364df12fe2a4a5c98e1c7ce29e756cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_65e7a3f2aff8407fb64d2bc35edd0d6b",
            "placeholder": "​",
            "style": "IPY_MODEL_6ce10520f329468080370dd043d65b79",
            "value": " 436k/436k [00:00&lt;00:00, 1.23MB/s]"
          }
        },
        "1392ed714d36446381160bb5f6cf84e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1199afe26f3a4fffb88d15891afada68": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "92c44136cf2845219e42ed9830355af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d0e3a652f3d041199b1a10a2ab8022ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15900a82a5874d3bb24e1687f423c18b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "65e7a3f2aff8407fb64d2bc35edd0d6b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ce10520f329468080370dd043d65b79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f3a8f0cc8944c5fb094a71d863312dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b26de83e7cbe40aeb0f60373f161e059",
              "IPY_MODEL_ede00081592f49c28c9720c6c8610453",
              "IPY_MODEL_7bf1aa8808234ed0ad1a1ee48f4e593e"
            ],
            "layout": "IPY_MODEL_47dcb4a2489840de8ca02f1cb86c45d9"
          }
        },
        "b26de83e7cbe40aeb0f60373f161e059": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d02dc9522544dadb5b4524f45fe2526",
            "placeholder": "​",
            "style": "IPY_MODEL_53ff5bef6e114d45b7c7439b73835209",
            "value": "config.json: 100%"
          }
        },
        "ede00081592f49c28c9720c6c8610453": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96fd4a096c4942af86eb88cc58c009d9",
            "max": 451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1796f997784344299aed12f3da82fc73",
            "value": 451
          }
        },
        "7bf1aa8808234ed0ad1a1ee48f4e593e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_542d7a72732545fda19a9914dba0402b",
            "placeholder": "​",
            "style": "IPY_MODEL_43d0ad88d86b41adb40e8decb1d20240",
            "value": " 451/451 [00:00&lt;00:00, 33.1kB/s]"
          }
        },
        "47dcb4a2489840de8ca02f1cb86c45d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d02dc9522544dadb5b4524f45fe2526": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53ff5bef6e114d45b7c7439b73835209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "96fd4a096c4942af86eb88cc58c009d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1796f997784344299aed12f3da82fc73": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "542d7a72732545fda19a9914dba0402b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "43d0ad88d86b41adb40e8decb1d20240": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3a4affc5044449fb0e15ddf5b706260": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_030eefc9e2f84a6b9f0df6c281f014a7",
              "IPY_MODEL_f48e5ada65ff4aed83b12b617b1989e9",
              "IPY_MODEL_15d2cf2af5b7427c81200e4345487c99"
            ],
            "layout": "IPY_MODEL_b486709048a249a2aa4c777b09207679"
          }
        },
        "030eefc9e2f84a6b9f0df6c281f014a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_552063737d714ee4b394fd78cbcaa834",
            "placeholder": "​",
            "style": "IPY_MODEL_38752ebb03084e25a4daebc7831b81cf",
            "value": "model.safetensors: 100%"
          }
        },
        "f48e5ada65ff4aed83b12b617b1989e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e347f209f6624ded82db35a5c200677c",
            "max": 265470036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5d4d81e9da8a449aa6ef5e9cb7969ce4",
            "value": 265470036
          }
        },
        "15d2cf2af5b7427c81200e4345487c99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9226ff5f79534739809a30282193802e",
            "placeholder": "​",
            "style": "IPY_MODEL_69c6a3c0425b4818b39be61a7497e99d",
            "value": " 265M/265M [00:03&lt;00:00, 134MB/s]"
          }
        },
        "b486709048a249a2aa4c777b09207679": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "552063737d714ee4b394fd78cbcaa834": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38752ebb03084e25a4daebc7831b81cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e347f209f6624ded82db35a5c200677c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5d4d81e9da8a449aa6ef5e9cb7969ce4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9226ff5f79534739809a30282193802e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "69c6a3c0425b4818b39be61a7497e99d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "893decb20a564e8eb2c547ae93adebe2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d546523128404e94abf1ddfd7de3d32d",
              "IPY_MODEL_977d6573573a46eaa78f156538c70482",
              "IPY_MODEL_c2a9b6f4b25c4100b8a8784e398ddb7a"
            ],
            "layout": "IPY_MODEL_cba354970ec2426b93d91d8008fbe616"
          }
        },
        "d546523128404e94abf1ddfd7de3d32d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_23794d04100e40d091963cd8908b75f2",
            "placeholder": "​",
            "style": "IPY_MODEL_3f0fc167a84f417797aba312b7573535",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "977d6573573a46eaa78f156538c70482": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a729a430f0a34eada92b30bc9179c21a",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_59a7b91cc54142929fb81fe0368f6e5e",
            "value": 48
          }
        },
        "c2a9b6f4b25c4100b8a8784e398ddb7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d96e8fba4294eab9e4e604be2901101",
            "placeholder": "​",
            "style": "IPY_MODEL_416268ac1c3c48b4b8c5d9c498e7e13b",
            "value": " 48.0/48.0 [00:00&lt;00:00, 789B/s]"
          }
        },
        "cba354970ec2426b93d91d8008fbe616": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23794d04100e40d091963cd8908b75f2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3f0fc167a84f417797aba312b7573535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a729a430f0a34eada92b30bc9179c21a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "59a7b91cc54142929fb81fe0368f6e5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8d96e8fba4294eab9e4e604be2901101": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "416268ac1c3c48b4b8c5d9c498e7e13b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a3531d8add459d988c619ebc9f0bed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c9f74f64a004dba92741b6b7a6588c8",
              "IPY_MODEL_2770e86e93184848aa7ab8649d861d1b",
              "IPY_MODEL_6f7a852386c94fb2b87796bfd05eb42a"
            ],
            "layout": "IPY_MODEL_e0a13db292c348729674e5a66cb9a498"
          }
        },
        "7c9f74f64a004dba92741b6b7a6588c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5cf6eceb518470485b548f59e241771",
            "placeholder": "​",
            "style": "IPY_MODEL_06455f3325964be3b8a089cbc8f217c2",
            "value": "vocab.txt: 100%"
          }
        },
        "2770e86e93184848aa7ab8649d861d1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c4649ccda893422fabaa0a444f50edf5",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2bdb272bffaa40f4a3851cfad63e24cb",
            "value": 231508
          }
        },
        "6f7a852386c94fb2b87796bfd05eb42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f9d8a10561fc424ab44eb16831a578d4",
            "placeholder": "​",
            "style": "IPY_MODEL_c553e2d28c0d4258bf414aeec0cfa321",
            "value": " 232k/232k [00:00&lt;00:00, 3.80MB/s]"
          }
        },
        "e0a13db292c348729674e5a66cb9a498": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cf6eceb518470485b548f59e241771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "06455f3325964be3b8a089cbc8f217c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c4649ccda893422fabaa0a444f50edf5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bdb272bffaa40f4a3851cfad63e24cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f9d8a10561fc424ab44eb16831a578d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c553e2d28c0d4258bf414aeec0cfa321": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b8cfd7936a064b5387287337f530fc5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_776900c4d514492bb8d2b2b4f4b89301",
              "IPY_MODEL_6e8643d6fe2b4cbc8852e17d5041e841",
              "IPY_MODEL_03b1c0358c6748039ee531dc52a2b4f5"
            ],
            "layout": "IPY_MODEL_0b40c205dedb4a608538caa6af7bb607"
          }
        },
        "776900c4d514492bb8d2b2b4f4b89301": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_961c845cd0894c2a842bbe358ddea652",
            "placeholder": "​",
            "style": "IPY_MODEL_363d22bde50647599edae34f1b2b3648",
            "value": "tokenizer.json: 100%"
          }
        },
        "6e8643d6fe2b4cbc8852e17d5041e841": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4a462d3eac9c42f38bfb2e24a456aaa7",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38b43f339a7046d48b88d3cdeecb1bc5",
            "value": 466062
          }
        },
        "03b1c0358c6748039ee531dc52a2b4f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e53a54bd42045bdafd542ea7b83305f",
            "placeholder": "​",
            "style": "IPY_MODEL_b7fc1111de5d47c083f5c3eb3d80baf9",
            "value": " 466k/466k [00:00&lt;00:00, 5.80MB/s]"
          }
        },
        "0b40c205dedb4a608538caa6af7bb607": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "961c845cd0894c2a842bbe358ddea652": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "363d22bde50647599edae34f1b2b3648": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4a462d3eac9c42f38bfb2e24a456aaa7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38b43f339a7046d48b88d3cdeecb1bc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8e53a54bd42045bdafd542ea7b83305f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7fc1111de5d47c083f5c3eb3d80baf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0831d75191ed435b9bc8c5cab28f7718": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_af84a8d765714c2c8a18d152ed03fd37",
              "IPY_MODEL_ec8bd37565f8468a9dd0feae7da8cbad",
              "IPY_MODEL_ab3c5861897545a594a4c4e2c168318a"
            ],
            "layout": "IPY_MODEL_04465737c1d4423ca28be042c48db9ac"
          }
        },
        "af84a8d765714c2c8a18d152ed03fd37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_05eb159ae7cb429aa632598ca549b1c1",
            "placeholder": "​",
            "style": "IPY_MODEL_9fd07fe6937d49a88b4beaec4b7db37f",
            "value": "Filter: 100%"
          }
        },
        "ec8bd37565f8468a9dd0feae7da8cbad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_79350cdf11cb4a8f9059099ab55c546d",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08ea36fac1004090a5d56ac1bb43c114",
            "value": 1104
          }
        },
        "ab3c5861897545a594a4c4e2c168318a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ac1c48909cc4792a956818d4a2e62b6",
            "placeholder": "​",
            "style": "IPY_MODEL_a826edf595ea4119b52f5679d00e4661",
            "value": " 1104/1104 [00:00&lt;00:00, 11853.68 examples/s]"
          }
        },
        "04465737c1d4423ca28be042c48db9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "05eb159ae7cb429aa632598ca549b1c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9fd07fe6937d49a88b4beaec4b7db37f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "79350cdf11cb4a8f9059099ab55c546d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ea36fac1004090a5d56ac1bb43c114": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ac1c48909cc4792a956818d4a2e62b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a826edf595ea4119b52f5679d00e4661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc8f562343a742b9bdfec726834a5a02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5b07535240d43338dc151e7ffc38a62",
              "IPY_MODEL_82b0c7fc16da4b2fb145e7ea6eadf682",
              "IPY_MODEL_da1b8c647bad4eb9be7e96e7bdc68986"
            ],
            "layout": "IPY_MODEL_346002ad8f394988b36eedd8a16bf1bb"
          }
        },
        "f5b07535240d43338dc151e7ffc38a62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e5875a0ea8648e18248c84603699f35",
            "placeholder": "​",
            "style": "IPY_MODEL_a9a00c8eee56406aa22a4ff4c538da29",
            "value": "Filter: 100%"
          }
        },
        "82b0c7fc16da4b2fb145e7ea6eadf682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0043974a9d2840298a4ae531f33a7e32",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b4e093757f5d40e3afefc1ec16ee08fe",
            "value": 1104
          }
        },
        "da1b8c647bad4eb9be7e96e7bdc68986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ca37e689ce246118547c00d6d0049f9",
            "placeholder": "​",
            "style": "IPY_MODEL_1ced0c90a12045ce9135187b1fd17784",
            "value": " 1104/1104 [00:00&lt;00:00, 7958.54 examples/s]"
          }
        },
        "346002ad8f394988b36eedd8a16bf1bb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e5875a0ea8648e18248c84603699f35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9a00c8eee56406aa22a4ff4c538da29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0043974a9d2840298a4ae531f33a7e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4e093757f5d40e3afefc1ec16ee08fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ca37e689ce246118547c00d6d0049f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1ced0c90a12045ce9135187b1fd17784": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16df523eaf94f76b2ac1e07b44c1bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ac4b190935457e9a2208435dcac6ed",
              "IPY_MODEL_33b40819120b4ec6abf387d54b241e2e",
              "IPY_MODEL_30a7895eff374ccba813f0a6e7ee6412"
            ],
            "layout": "IPY_MODEL_f610fc7112f9417fbca1a5b40ab052fc"
          }
        },
        "63ac4b190935457e9a2208435dcac6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f118ae65c9d34c5b89688c56e7bc9d11",
            "placeholder": "​",
            "style": "IPY_MODEL_581fbefcc6234c3d9d85d0ccc7f44ecb",
            "value": "config.json: 100%"
          }
        },
        "33b40819120b4ec6abf387d54b241e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38616febf684434c99cd6e36c93086b6",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec9d849c33784b118e906435de5c20b0",
            "value": 684
          }
        },
        "30a7895eff374ccba813f0a6e7ee6412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9908716e59a349a282594e49e7a923cd",
            "placeholder": "​",
            "style": "IPY_MODEL_efcc6ff9f0b3407dbd9f7bc8b1439bcf",
            "value": " 684/684 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "f610fc7112f9417fbca1a5b40ab052fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f118ae65c9d34c5b89688c56e7bc9d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581fbefcc6234c3d9d85d0ccc7f44ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38616febf684434c99cd6e36c93086b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9d849c33784b118e906435de5c20b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9908716e59a349a282594e49e7a923cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efcc6ff9f0b3407dbd9f7bc8b1439bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f58c1164d1142478968257d7936123e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_866ebc4490c64d1d8e132bfa23b5449c",
              "IPY_MODEL_7d19a7184cb74e6fa3c1b302d11e3977",
              "IPY_MODEL_954c563eca1f49e89cc31ab1053a90ee"
            ],
            "layout": "IPY_MODEL_733972cc6fc645c4bde46213ce994139"
          }
        },
        "866ebc4490c64d1d8e132bfa23b5449c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c1dbeff9dff4225b10581622da91ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_50d3fd723e4f49c8ada234dcc7e41608",
            "value": "model.safetensors: 100%"
          }
        },
        "7d19a7184cb74e6fa3c1b302d11e3977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c49842ee1bde4670a7c5a30d44ebc785",
            "max": 47372894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cca4728d31f4bbe88250f62de0de2bf",
            "value": 47372894
          }
        },
        "954c563eca1f49e89cc31ab1053a90ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0409901b030c4b499dc27937d52b9216",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b3eb8f868749418a3643ee354a168c",
            "value": " 47.4M/47.4M [00:00&lt;00:00, 78.7MB/s]"
          }
        },
        "733972cc6fc645c4bde46213ce994139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1dbeff9dff4225b10581622da91ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d3fd723e4f49c8ada234dcc7e41608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49842ee1bde4670a7c5a30d44ebc785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cca4728d31f4bbe88250f62de0de2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0409901b030c4b499dc27937d52b9216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b3eb8f868749418a3643ee354a168c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9858c3d7d4584d3dbaf6e3fce07d6022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01ed020d255b4493b68909b4f68c3919",
              "IPY_MODEL_ea0abb6b4eec4052a6b29e7c2a820740",
              "IPY_MODEL_ef9e7f3990cf47ac813268ec18666845"
            ],
            "layout": "IPY_MODEL_1af9a5744f1d482db336a7ba7434b8e8"
          }
        },
        "01ed020d255b4493b68909b4f68c3919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40214daa9474f25a3485d8372ef6890",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7b70771e0f40b7bc2c80387e3e40b5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ea0abb6b4eec4052a6b29e7c2a820740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9491bcd4bd634d2da4eae5be751f883c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e80adcc785d4f91be7f7c5631922238",
            "value": 25
          }
        },
        "ef9e7f3990cf47ac813268ec18666845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202f2b58dba340848f6127e8e4135447",
            "placeholder": "​",
            "style": "IPY_MODEL_b642f48df26648699450f61b56af37ae",
            "value": " 25.0/25.0 [00:00&lt;00:00, 668B/s]"
          }
        },
        "1af9a5744f1d482db336a7ba7434b8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40214daa9474f25a3485d8372ef6890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7b70771e0f40b7bc2c80387e3e40b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9491bcd4bd634d2da4eae5be751f883c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e80adcc785d4f91be7f7c5631922238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "202f2b58dba340848f6127e8e4135447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b642f48df26648699450f61b56af37ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869473187683442ebe0ae6111bb8dc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70dce515a1c44780a3b3fce7177db3ec",
              "IPY_MODEL_3165b3ad4ab7405baedbd1a2a3d31be6",
              "IPY_MODEL_de49c1b6de0a4328992d59c951c4b754"
            ],
            "layout": "IPY_MODEL_3c75e550e7b74d37934bc2fff08b2cb8"
          }
        },
        "70dce515a1c44780a3b3fce7177db3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b23cecfd354ccf8548f8de6c3bc1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_925163e9ae1745fe9ad7167c09cf29cc",
            "value": "spiece.model: 100%"
          }
        },
        "3165b3ad4ab7405baedbd1a2a3d31be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bf97a9e3a84c94be32797a8ddd389b",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f534404ee49e46f8b1aee58911443255",
            "value": 760289
          }
        },
        "de49c1b6de0a4328992d59c951c4b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1277da6f76344ec8e3e13f89f938c10",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce1a17fbf2d4bbf86c087c591e53848",
            "value": " 760k/760k [00:00&lt;00:00, 5.67MB/s]"
          }
        },
        "3c75e550e7b74d37934bc2fff08b2cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b23cecfd354ccf8548f8de6c3bc1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925163e9ae1745fe9ad7167c09cf29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9bf97a9e3a84c94be32797a8ddd389b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f534404ee49e46f8b1aee58911443255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1277da6f76344ec8e3e13f89f938c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce1a17fbf2d4bbf86c087c591e53848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5333de9228684fcfa067d67443339d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_565fd76ff65249e284c69efa5ce62cc8",
              "IPY_MODEL_09cb3af7e3fe4f6db9c0e3eb4c23ddaf",
              "IPY_MODEL_f33286a085fa4c12a17ce40588e7e462"
            ],
            "layout": "IPY_MODEL_2b71f4d6c758424099e4ba0cbf6a9b54"
          }
        },
        "565fd76ff65249e284c69efa5ce62cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d6bc16da0f4e89aa9072b705a55684",
            "placeholder": "​",
            "style": "IPY_MODEL_9b56361ccd8246bb87b049414f646354",
            "value": "tokenizer.json: 100%"
          }
        },
        "09cb3af7e3fe4f6db9c0e3eb4c23ddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2072c72b679443b0aefe2fd109236464",
            "max": 1312669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3bd7434bc0c4d778beaa78bb2711401",
            "value": 1312669
          }
        },
        "f33286a085fa4c12a17ce40588e7e462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42b112574a347c7b6cfecc31b5821ca",
            "placeholder": "​",
            "style": "IPY_MODEL_ec59251d22ed4b12a2ec362b6f0fa27b",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 6.55MB/s]"
          }
        },
        "2b71f4d6c758424099e4ba0cbf6a9b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d6bc16da0f4e89aa9072b705a55684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b56361ccd8246bb87b049414f646354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2072c72b679443b0aefe2fd109236464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bd7434bc0c4d778beaa78bb2711401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42b112574a347c7b6cfecc31b5821ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec59251d22ed4b12a2ec362b6f0fa27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24c3cd3b73044820ab7729ffb51e53f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5fcbe55a1b79459d89c1e590677b33fb",
              "IPY_MODEL_5d9aee52a49e42c38b2a1bf2ea6a9661",
              "IPY_MODEL_653ec0da35a7430b806fc9cc5349429c"
            ],
            "layout": "IPY_MODEL_2f146d096fb8485c99048bd96ca843ee"
          }
        },
        "5fcbe55a1b79459d89c1e590677b33fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b62718e0f314e82aa65cd339d10bad1",
            "placeholder": "​",
            "style": "IPY_MODEL_1459ef83beda45c3a2ba350b5c7d40f1",
            "value": "Filter: 100%"
          }
        },
        "5d9aee52a49e42c38b2a1bf2ea6a9661": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_45069149fc1747118632af5e430bec57",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2c493580be134379b2422c319e7bbfae",
            "value": 1104
          }
        },
        "653ec0da35a7430b806fc9cc5349429c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3861bf8a39847e783ed666d963fedcb",
            "placeholder": "​",
            "style": "IPY_MODEL_d82fa0540ceb45e0a69531bd94c1f79d",
            "value": " 1104/1104 [00:00&lt;00:00, 4624.41 examples/s]"
          }
        },
        "2f146d096fb8485c99048bd96ca843ee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8b62718e0f314e82aa65cd339d10bad1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1459ef83beda45c3a2ba350b5c7d40f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45069149fc1747118632af5e430bec57": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c493580be134379b2422c319e7bbfae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3861bf8a39847e783ed666d963fedcb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d82fa0540ceb45e0a69531bd94c1f79d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ff8abba7b8d840ce9e1dc1a1b4986a93": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f4600fb96fd0420d98931be5d0dd1e35",
              "IPY_MODEL_c3a3c3cb59bc46b0b43e8f530ecc18f2",
              "IPY_MODEL_87501560ec434eb6a58c17bf42d4c31a"
            ],
            "layout": "IPY_MODEL_38af7788c16c479a810ddd23b9a66fa3"
          }
        },
        "f4600fb96fd0420d98931be5d0dd1e35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b495bdb8fac7465a9761209403d5ee11",
            "placeholder": "​",
            "style": "IPY_MODEL_6211010e464e4f979dddb911a06cad5a",
            "value": "Filter: 100%"
          }
        },
        "c3a3c3cb59bc46b0b43e8f530ecc18f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e621060517174440be94c586bd7fa980",
            "max": 277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c6a78016ce3f4280a7657b0d4e6d025c",
            "value": 277
          }
        },
        "87501560ec434eb6a58c17bf42d4c31a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_556254d0471549358804d5882e057be1",
            "placeholder": "​",
            "style": "IPY_MODEL_22f52adba8b2482882c6eb0205951f1b",
            "value": " 277/277 [00:00&lt;00:00, 1990.99 examples/s]"
          }
        },
        "38af7788c16c479a810ddd23b9a66fa3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b495bdb8fac7465a9761209403d5ee11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6211010e464e4f979dddb911a06cad5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e621060517174440be94c586bd7fa980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a78016ce3f4280a7657b0d4e6d025c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "556254d0471549358804d5882e057be1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "22f52adba8b2482882c6eb0205951f1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "26e5afd36d0b4aa8b2ceb2854999fe01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bcfaf0e172194f98af0c128c0c3f6dd8",
              "IPY_MODEL_2fa8f90b2e0144d6bb96701f59b2aac7",
              "IPY_MODEL_3fb069137e6d4af49e0ccfe5f7e03b3c"
            ],
            "layout": "IPY_MODEL_1dbf0ebf6f9a40e0b3605b856a48ef28"
          }
        },
        "bcfaf0e172194f98af0c128c0c3f6dd8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6dbf701059b4d2e8d0502d67847aeba",
            "placeholder": "​",
            "style": "IPY_MODEL_d3a3de3a21b74ddc9718a6e2d2725636",
            "value": "Filter: 100%"
          }
        },
        "2fa8f90b2e0144d6bb96701f59b2aac7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c69e2470ca714cc0b4908d3b5b62c007",
            "max": 937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_913a527a8c7b4f4688d7903163bf45ab",
            "value": 937
          }
        },
        "3fb069137e6d4af49e0ccfe5f7e03b3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bdc65a740d0247eda713fa0c6df1d1b5",
            "placeholder": "​",
            "style": "IPY_MODEL_6cbb8fe67da749528efe9e27e024877f",
            "value": " 937/937 [00:00&lt;00:00, 6150.15 examples/s]"
          }
        },
        "1dbf0ebf6f9a40e0b3605b856a48ef28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6dbf701059b4d2e8d0502d67847aeba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3a3de3a21b74ddc9718a6e2d2725636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c69e2470ca714cc0b4908d3b5b62c007": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "913a527a8c7b4f4688d7903163bf45ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bdc65a740d0247eda713fa0c6df1d1b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cbb8fe67da749528efe9e27e024877f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "697858837b734dc0b1da644602cd3787": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d244f1cf4f984fcd91a95df95a431e99",
              "IPY_MODEL_f053db6e69454c87a337b2d280247c0a",
              "IPY_MODEL_694bb480f12448c58ff328697c11bb18"
            ],
            "layout": "IPY_MODEL_66b5901275474e7face6c742e48ff398"
          }
        },
        "d244f1cf4f984fcd91a95df95a431e99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_af7ad24fb0844acd898846379bd7e89d",
            "placeholder": "​",
            "style": "IPY_MODEL_edeb69d18d0c4bc69708ff2b8c4dbd01",
            "value": "Filter: 100%"
          }
        },
        "f053db6e69454c87a337b2d280247c0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ee8b352922346e18fc549954b415b27",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c71068aef7994394a2ae8a1adb75dbba",
            "value": 235
          }
        },
        "694bb480f12448c58ff328697c11bb18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8265364ac9ec43e2a123d3116163a929",
            "placeholder": "​",
            "style": "IPY_MODEL_480c14d53ed5465b97303458601af4a2",
            "value": " 235/235 [00:00&lt;00:00, 2973.38 examples/s]"
          }
        },
        "66b5901275474e7face6c742e48ff398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af7ad24fb0844acd898846379bd7e89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "edeb69d18d0c4bc69708ff2b8c4dbd01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7ee8b352922346e18fc549954b415b27": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c71068aef7994394a2ae8a1adb75dbba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8265364ac9ec43e2a123d3116163a929": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "480c14d53ed5465b97303458601af4a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a9f92dacdd42aba2565cc688b26259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce751d3668641908a1eaba1e9617983",
              "IPY_MODEL_d383af551cc0451f81693b8a41c4baae",
              "IPY_MODEL_52d15a82a0da4475a97547a834e92472"
            ],
            "layout": "IPY_MODEL_8b2ae61c48ab432187bdb401d837bcba"
          }
        },
        "6ce751d3668641908a1eaba1e9617983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d93fd218bf14786b13ff071efb3e431",
            "placeholder": "​",
            "style": "IPY_MODEL_8fa0d2dd49454852a7064639922ce3a5",
            "value": "Map: 100%"
          }
        },
        "d383af551cc0451f81693b8a41c4baae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726587e2fbca49cf940ff1168911a32d",
            "max": 937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f0b4dda3e74241afbf00790567af79",
            "value": 937
          }
        },
        "52d15a82a0da4475a97547a834e92472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b407616052e46db9ed9ebd8a6a620b4",
            "placeholder": "​",
            "style": "IPY_MODEL_d7babf3b96cf4362ab1e013a170c90f0",
            "value": " 937/937 [00:01&lt;00:00, 491.83 examples/s]"
          }
        },
        "8b2ae61c48ab432187bdb401d837bcba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d93fd218bf14786b13ff071efb3e431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa0d2dd49454852a7064639922ce3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726587e2fbca49cf940ff1168911a32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f0b4dda3e74241afbf00790567af79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b407616052e46db9ed9ebd8a6a620b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7babf3b96cf4362ab1e013a170c90f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "052cc03567bd462fbb1f8c73d53a95e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16bfe78648c148f19397b2d478655dd3",
              "IPY_MODEL_2d46eaa1dc0542c49fa7e28f4739a9dd",
              "IPY_MODEL_b6dc0e5745a346208213ba88839b52ec"
            ],
            "layout": "IPY_MODEL_aad096bd72984f6faa700f6ccfe55bc8"
          }
        },
        "16bfe78648c148f19397b2d478655dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb27f854d8e4675917b5feeb77a9f49",
            "placeholder": "​",
            "style": "IPY_MODEL_3a019f9deb674dc9a06923f58a7f3015",
            "value": "Map: 100%"
          }
        },
        "2d46eaa1dc0542c49fa7e28f4739a9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05c3189060f4e71b6fb2f41b7b8dd08",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38effe6673584c05b1f930914caf0258",
            "value": 235
          }
        },
        "b6dc0e5745a346208213ba88839b52ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f621f287d15b4d3c88ad747fe4017678",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf306d1c34f4aa7b63d377593e46704",
            "value": " 235/235 [00:00&lt;00:00, 569.84 examples/s]"
          }
        },
        "aad096bd72984f6faa700f6ccfe55bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb27f854d8e4675917b5feeb77a9f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a019f9deb674dc9a06923f58a7f3015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d05c3189060f4e71b6fb2f41b7b8dd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38effe6673584c05b1f930914caf0258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f621f287d15b4d3c88ad747fe4017678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf306d1c34f4aa7b63d377593e46704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0615ce80df0f429db75363374f61cca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d00b1995ae645548bdbea00e6f8431e",
              "IPY_MODEL_3629e135de8c4176a4102d1d5f8e06d0",
              "IPY_MODEL_541150d14e5644cfa78897894d5afb91"
            ],
            "layout": "IPY_MODEL_c490762b2a5541949944eb4e8d97f05f"
          }
        },
        "3d00b1995ae645548bdbea00e6f8431e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca7a568149824cfe80b8c0ade733079f",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c992dd19904f76b609e53988b5fd67",
            "value": "Map: 100%"
          }
        },
        "3629e135de8c4176a4102d1d5f8e06d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54212caf83264951a60ca98b7b9f3819",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6dbe4d6195042debe70e0ed08e5d5d1",
            "value": 14
          }
        },
        "541150d14e5644cfa78897894d5afb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6de4b40e984107a374109491f2a21d",
            "placeholder": "​",
            "style": "IPY_MODEL_034e1a5b37b341ec9b6b164aeabb8428",
            "value": " 14/14 [00:00&lt;00:00, 159.02 examples/s]"
          }
        },
        "c490762b2a5541949944eb4e8d97f05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7a568149824cfe80b8c0ade733079f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c992dd19904f76b609e53988b5fd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54212caf83264951a60ca98b7b9f3819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6dbe4d6195042debe70e0ed08e5d5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c6de4b40e984107a374109491f2a21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034e1a5b37b341ec9b6b164aeabb8428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb7a71f0abeb49929cbf97579944383e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7492606e07b45d6a62b31f0dc777ee0",
              "IPY_MODEL_c0d2ed25aef64202a55a782eccfacefc",
              "IPY_MODEL_c660d50135ef479cac9265760eaeb1c6"
            ],
            "layout": "IPY_MODEL_d2238b001cf14759ad6118fad4fbafe4"
          }
        },
        "d7492606e07b45d6a62b31f0dc777ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e14b21c7414638b95fc6b0709c80ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4b48910f15844fe7bdae0f71df9c67ed",
            "value": "Map: 100%"
          }
        },
        "c0d2ed25aef64202a55a782eccfacefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fdbd68e4f0e41b19eb5fa3a3af9ee22",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dc8c9c96e62404ebfa11d59916ebef4",
            "value": 14
          }
        },
        "c660d50135ef479cac9265760eaeb1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a15c873cba65414aa3659fd8f6e1d0f0",
            "placeholder": "​",
            "style": "IPY_MODEL_099c7a2a1fb34513ba80006b38af592a",
            "value": " 14/14 [00:00&lt;00:00, 199.05 examples/s]"
          }
        },
        "d2238b001cf14759ad6118fad4fbafe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e14b21c7414638b95fc6b0709c80ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b48910f15844fe7bdae0f71df9c67ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fdbd68e4f0e41b19eb5fa3a3af9ee22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc8c9c96e62404ebfa11d59916ebef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a15c873cba65414aa3659fd8f6e1d0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "099c7a2a1fb34513ba80006b38af592a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexk2206/tds_capstone/blob/Domi-DEV/Productive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Choice, Fine-tuning and Evaluation**\n",
        "\n",
        "After having set up the QA-dataset, we are now capable of evaluating different models on the task that the dataset implicitly represents.\n",
        "For that, we have to create all corresponding functions that translates our dataset entries into model input and vice versa the model output to humanly understandable text.\n",
        "Therafter - or at the same time, as we will do it - the evaluation of that created output has to happen.\n",
        "\n",
        "On the basis of this data, we will decide which model we will fine-tune afterwards, to improve the model's performance even more.\n",
        "\n",
        "At last, we will test the newly fine-tuned model against the other models evaluated before\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "0mkPc0ZfHFc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But first things first, let's start with installing and importing all the necessary packages."
      ],
      "metadata": {
        "id": "bS3CxBr6mS7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install --upgrade sympy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLjPgWr_1-kF",
        "outputId": "cef1f673-11da-475c-a8b1-53ba8130a70a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import urllib\n",
        "from itertools import chain, combinations\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, AutoModelForQuestionAnswering, TrainingArguments, pipeline, Trainer, DataCollatorWithPadding, XLNetForMultipleChoice\n",
        "import torch\n",
        "import requests\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from datasets import Dataset\n",
        "from typing import Optional, Union\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "9KoU8tBBI45u"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preprocess dataset\n",
        "\n",
        "Here we split the previously created QA-dataset into train and validation dataset. For that, we load it from the public github account, where it was uploaded before.\n",
        "Additionnaly, we prepare the dataset to later be useful for response-generation and fine-tuning of a model"
      ],
      "metadata": {
        "id": "7zDNcgGRHOQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datset\n",
        "url = \"https://raw.githubusercontent.com/alexk2206/tds_capstone/refs/heads/main/datasets/combined_qa_dataset.json\"\n",
        "data = pd.read_json(url)\n",
        "# Convert to DataFrame for easy handling\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Map the intended answer to the index of the option\n",
        "df['label'] = df.apply(lambda x: np.array([1 if option in x['intended_answer'] else 0 for option in x['options']]) if x['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'] else np.array([0]), axis=1)\n",
        "df['stratify_key'] = df['difficulty'] + '_' + df['type']\n",
        "\n",
        "# Convert to Huggingface Dataset dataset\n",
        "qa_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "ykW3Lop-3ok5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train and validation (here called test) dataset with stratifying with question type and difficulty of context\n",
        "qa_dataset = qa_dataset.class_encode_column(\n",
        "    \"stratify_key\"\n",
        ").train_test_split(test_size=0.2, stratify_by_column=\"stratify_key\", seed=42).remove_columns(\"stratify_key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "93a5db67155e47c5b7784e02d682f00a",
            "8ed1a60f2e7d420b9087338906cd74af",
            "91bc9606de7542a4ba572e8eceb7c261",
            "77c4ea97c3d24a43980a06d7f457697b",
            "823909baca8441a9bddb4c2d825be6ff",
            "c53250b753b04a24ab0a85f86a28ceb5",
            "58aa2f61829c4a2292aa5f13967b9fa9",
            "3e23e3b8b2a1467e941136b19fb52cd5",
            "e7acfc181fbb48c8b34c4fcebe066b73",
            "9cf7674a3db846c4bdd65563ef0fd8bb",
            "26e30d1f3b2a4673a906115780ed086e"
          ]
        },
        "id": "W9tqK5cL4oyC",
        "outputId": "a28fcfa2-837f-4721-c3a6-6c3c1889b295"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/1381 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "93a5db67155e47c5b7784e02d682f00a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8YC0gsu4my2",
        "outputId": "c004680c-5258-4964-df41-7beae762504c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'type', 'options', 'intended_answer', 'context', 'difficulty', 'label'],\n",
              "        num_rows: 1104\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'type', 'options', 'intended_answer', 'context', 'difficulty', 'label'],\n",
              "        num_rows: 277\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label column: the intended_answer as list of binary variables for every option if question type is mc questions, list of entry 0 else\n",
        "qa_dataset[\"train\"][\"label\"][:5]"
      ],
      "metadata": {
        "id": "1gJAy5V8-2o-",
        "outputId": "c4894498-f6c3-44e4-d257-8d012cc044ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 0, 0, 0, 0, 0, 0], [0, 1], [0, 1, 0, 1, 0], [0], [1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate model output\n",
        "\n",
        "After the creation of the QA-dataset, it's time for generating model output for different Huggingface models."
      ],
      "metadata": {
        "id": "8iquDfG7gYdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example, tokenizer):\n",
        "    '''\n",
        "    Converts the string input, which is a question with its context and the given options for multi-/single-select questions, into IDs the model later can make sense of. Distinguishes between multi-/single-select and the other questions\n",
        "    parameters:\n",
        "    - expample: question of the QA-dataset with all its entries (question, context, options, type are urgently necessary)\n",
        "    - tokenizer: tokenizer of the model\n",
        "    output:\n",
        "    - tokenized: tokenized input example\n",
        "    '''\n",
        "    if example[\"type\"] == \"SINGLE_SELECT\" or example[\"type\"] == \"MULTI_SELECT\":\n",
        "      number_of_options = len(example[\"options\"])\n",
        "      first_sentence = [[example[\"context\"]] * number_of_options]  # Repeat context for each option\n",
        "      second_sentence = [[example[\"question\"] + \" \" + option] for option in example[\"options\"]]  # Pair with each option\n",
        "      tokenized = tokenizer(\n",
        "          sum(first_sentence, []),\n",
        "          sum(second_sentence, []),\n",
        "          padding=\"longest\",\n",
        "          truncation=True\n",
        "      )\n",
        "      # Un-flatten\n",
        "      return {k: [v[i:i+number_of_options] for i in range(0, len(v), number_of_options)] for k, v in tokenized.items()}\n",
        "\n",
        "    elif example['type'] == 'NUMBER':\n",
        "      tokenized = tokenizer(\n",
        "          example['context'],\n",
        "          example['question'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "    else:\n",
        "      tokenized = tokenizer(\n",
        "          example['question'],\n",
        "          example['context'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "hUzIIwagzO6P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, questions, sum_pipeline=None, mc_metric=None, oe_metric=None):\n",
        "    '''\n",
        "    model_output -> creates output for every question in the dataset and safes it in a list of dicts. One dic has keys 'answer', 'predicted_answer', 'type'\n",
        "    parameters:\n",
        "    - model: one hugging face model\n",
        "    - tokenizer: hugging face tokenizer\n",
        "    - questions: QA-dataset in json format\n",
        "    '''\n",
        "    answer_comparison = []\n",
        "    mc_answer_comparison = []\n",
        "    mc_model_name = mc_model.config._name_or_path\n",
        "    oe_model_name = oe_model.config._name_or_path\n",
        "\n",
        "    for index, question in questions.iterrows():\n",
        "        context = question['context']\n",
        "        question_text = question['question']\n",
        "        options = question['options']\n",
        "        question_type = question['type']\n",
        "        difficulty = question['difficulty']\n",
        "\n",
        "        mc_question_type = question_type in [\"MULTI_SELECT\", \"SINGLE_SELECT\"]\n",
        "\n",
        "        if question_type == \"MULTI_SELECT\":\n",
        "          intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = multi_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "        elif question_type == \"SINGLE_SELECT\":\n",
        "          intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = single_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "        elif question_type == \"TEXT\":\n",
        "          intended_answer, predicted_answer = text_model_output(question, sum_pipeline)\n",
        "          continue\n",
        "        elif question_type == \"NUMBER\":\n",
        "          intended_answer, predicted_answer = number_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "        elif question_type == \"DATE\":\n",
        "          intended_answer, predicted_answer = date_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "        else:\n",
        "          continue\n",
        "        if predicted_answer != intended_answer:\n",
        "          print('======= Wrong answer =======')\n",
        "          print(f\"Question: {question_text}\")\n",
        "          print(f\"Context: {context}\")\n",
        "          print(f\"The intended answer was: {intended_answer}\")\n",
        "          print(f\"The predicted answer was: {predicted_answer}\")\n",
        "          if mc_question_type:\n",
        "            print(f\"The intended answer in BINARY was: {intended_answer_binary}\")\n",
        "            print(f\"The predicted answer in BINARY was: {predicted_answer_binary}\\n\")\n",
        "          else:\n",
        "            print(\"\")\n",
        "        if mc_question_type:\n",
        "          mc_answer_comparison.append({'model': mc_model_name, 'intended_answer_binary': intended_answer_binary, 'predicted_answer_binary': predicted_answer_binary, 'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "        else:\n",
        "          answer_comparison.append({'model': oe_model_name, 'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "    if mc_metric is not None:\n",
        "      try:\n",
        "        mc_metric_result = mc_metric.compute()\n",
        "      except:\n",
        "        mc_metric_result = None\n",
        "    else:\n",
        "      mc_metric_result = None\n",
        "    if oe_metric is not None:\n",
        "      try:\n",
        "        oe_metric_result = oe_metric.compute()\n",
        "      except:\n",
        "        oe_metric_result = None\n",
        "    else:\n",
        "      oe_metric_result = None\n",
        "    return mc_answer_comparison, answer_comparison, mc_metric_result, oe_metric_result\n"
      ],
      "metadata": {
        "id": "tWqdWvQrgtle"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def map_model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, question, sum_pipeline=None, mc_metric=None, oe_metric=None):\n",
        "    '''\n",
        "    model_output -> creates output for every question in the dataset and safes it in a list of dicts. One dic has keys 'answer', 'predicted_answer', 'type'\n",
        "    parameters:\n",
        "    - model: one hugging face model\n",
        "    - tokenizer: hugging face tokenizer\n",
        "    - questions: QA-dataset in json format\n",
        "    '''\n",
        "    answer_comparison = []\n",
        "    mc_answer_comparison = []\n",
        "    context = question['context']\n",
        "    question_text = question['question']\n",
        "    options = question['options']\n",
        "    question_type = question['type']\n",
        "    difficulty = question['difficulty']\n",
        "\n",
        "    mc_question_type = question_type in [\"MULTI_SELECT\", \"SINGLE_SELECT\"]\n",
        "\n",
        "    if question_type == \"MULTI_SELECT\":\n",
        "      intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = multi_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "    elif question_type == \"SINGLE_SELECT\":\n",
        "      intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = single_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "    elif question_type == \"TEXT\":\n",
        "      intended_answer, predicted_answer = text_model_output(question, sum_pipeline)\n",
        "    elif question_type == \"NUMBER\":\n",
        "      intended_answer, predicted_answer = number_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "    elif question_type == \"DATE\":\n",
        "      intended_answer, predicted_answer = date_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "    else:\n",
        "      return None, None\n",
        "    if predicted_answer != intended_answer:\n",
        "      print('======= Wrong answer =======')\n",
        "      print(f\"Question: {question_text}\")\n",
        "      print(f\"Context: {context}\")\n",
        "      print(f\"The intended answer was: {intended_answer}\")\n",
        "      print(f\"The predicted answer was: {predicted_answer}\")\n",
        "      if mc_question_type:\n",
        "        print(f\"The intended answer in BINARY was: {intended_answer_binary}\")\n",
        "        print(f\"The predicted answer in BINARY was: {predicted_answer_binary}\\n\")\n",
        "      else:\n",
        "        print(\"\")\n",
        "    if mc_question_type:\n",
        "      mc_answer_comparison.append({'intended_answer_binary': intended_answer_binary, 'predicted_answer_binary': predicted_answer_binary, 'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "    else:\n",
        "      answer_comparison.append({'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "\n",
        "    return mc_answer_comparison, answer_comparison\n"
      ],
      "metadata": {
        "id": "baF5WYfzrdXP"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Single-select output"
      ],
      "metadata": {
        "id": "MwvDlSsVG3XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_select_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question, its context and its options for a single-select question and generates output\n",
        "    parameters:\n",
        "    - model: one hugging face model\n",
        "    - tokenizer: hugging face tokenizer\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    output:\n",
        "    - answer: the correct/intended answer as a list of a string\n",
        "    - predicted_answer: the predicted answer as a list of a string\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "    options = question['options']\n",
        "\n",
        "    # creating input ids by tokenizing the question\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    input_ids = {key: torch.tensor(array) for key, array in input_ids.items()}\n",
        "\n",
        "    # generating the output\n",
        "    outputs = model(**input_ids)\n",
        "    logits = outputs.logits  # Shape: [batch_size, num_choices]\n",
        "    print(logits)\n",
        "    # Predict the option with the highest score\n",
        "    predicted_option = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "    predicted_answer_binary = [0] * len(options)\n",
        "    predicted_answer_binary[predicted_option] = 1\n",
        "\n",
        "    intended_answer_binary = [1 if option == intended_answer else 0 for option in options]\n",
        "\n",
        "    if metric is not None:\n",
        "      metric.add_batch(predictions=predicted_answer_binary, references=intended_answer_binary)\n",
        "\n",
        "    return intended_answer, intended_answer_binary, predicted_answer_binary, options[predicted_option]\n"
      ],
      "metadata": {
        "id": "KgWVBNWlGkrC"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Multi-select output"
      ],
      "metadata": {
        "id": "4XwAHnUIGy-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_select_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question, its context and its options for a multi-select question and generates output as a list of indices of the predicted answers. Ticks every option whose probability is at least 90% of the best option (softmax)\n",
        "    parameters:\n",
        "    - model: one hugging face model\n",
        "    - tokenizer: hugging face tokenizer\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    output:\n",
        "    - answer: the correct/intended answers as a list of strings\n",
        "    - predicted_answer: the predicted answers as a list of strings\n",
        "    '''\n",
        "    intended_answer = question['intended_answer']\n",
        "    options = question['options']\n",
        "\n",
        "    # creating input ids by tokenizing the question\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    input_ids = {key: torch.tensor(array) for key, array in input_ids.items()}\n",
        "\n",
        "    # generating the output\n",
        "    outputs = model(**input_ids)\n",
        "    logits = outputs.logits  # Shape: [batch_size, num_choices]\n",
        "    print(logits)\n",
        "    # Find all indices to have at least 80% of the max score\n",
        "    # probabilities = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
        "    # print(probabilities)\n",
        "    # max_score = probabilities.max().item()  # Use max probability\n",
        "    #### better approach: using min_score\n",
        "    #min_score = logits.min().item()\n",
        "    #threshold = 2 * min_score  # Compute threshold based on probabilities\n",
        "\n",
        "    ### next approach: using a threshold from deviation\n",
        "    mean_score = logits.mean().item()\n",
        "    std_dev = logits.std().item()\n",
        "\n",
        "    # Define a threshold based on deviation from the mean\n",
        "    threshold = mean_score + (0.4 * std_dev)\n",
        "    high_score_options = (logits >= threshold).nonzero(as_tuple=True)[1]  # Get the indices of valid options\n",
        "    # high_score_options = (probabilities >= threshold).nonzero(as_tuple=True)[1]  # Get the indices of valid options\n",
        "\n",
        "    # List the corresponding options\n",
        "    high_score_answers = [options[idx] for idx in high_score_options.tolist()]\n",
        "    intended_answer_binary = [1 if option in intended_answer else 0 for option in options]\n",
        "\n",
        "    predicted_answer_binary = [1 if option in high_score_answers else 0 for option in options]\n",
        "\n",
        "    if metric is not None:\n",
        "        metric.add_batch(predictions=predicted_answer_binary, references=intended_answer_binary)\n",
        "\n",
        "    return intended_answer, intended_answer_binary, predicted_answer_binary, high_score_answers\n",
        "\n"
      ],
      "metadata": {
        "id": "V52Kz-lNGqca"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text output"
      ],
      "metadata": {
        "id": "UXc_BEivG7nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_model_output(question, pipeline):\n",
        "    '''\n",
        "    Handles an open text question and summarizes it\n",
        "    parameter:\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    output:\n",
        "    - answer: the full context of the question as a string\n",
        "    - summary: the generated summary as a string\n",
        "    '''\n",
        "    intended_answer = question['context']\n",
        "    summary = pipeline(intended_answer, max_length=len(intended_answer), do_sample=False)\n",
        "    return intended_answer, summary[0]['summary_text']\n",
        "\n"
      ],
      "metadata": {
        "id": "D7dedyjuGwXb"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Phone Number output"
      ],
      "metadata": {
        "id": "XhVsQSw7G-G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question where the context should contain a phone number and generates an answer to that question\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    output = model(**input_ids)\n",
        "    start_logits, end_logits = output.start_logits, output.end_logits\n",
        "\n",
        "    # Get most probable start and end index\n",
        "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "    end_idx = torch.argmax(end_logits, dim=1).item() + 1  # Include last token\n",
        "\n",
        "    # Convert token IDs to text\n",
        "    predicted_tokens = input_ids[\"input_ids\"][0][start_idx:end_idx]\n",
        "    predicted_number = tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "\n",
        "    if metric is not None:\n",
        "        metric.add(predictions=predicted_number, references=intended_answer)\n",
        "\n",
        "    return intended_answer, predicted_number\n",
        "\n"
      ],
      "metadata": {
        "id": "7h0RxjaPGvXO"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Date output"
      ],
      "metadata": {
        "id": "9UZp9MuGHCoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_date_format(date_str):\n",
        "  try:\n",
        "    parsed_date = parser.parse(date_str)\n",
        "    return parsed_date.strftime('%Y-%m-%d')\n",
        "  except Exception as e:\n",
        "    return date_str\n",
        "\n",
        "def find_date_and_convert(input_string):\n",
        "  date_regex = r'\\b(?:\\d{1,2}(?:st|nd|rd|th)?\\s+[A-Za-z]+\\s+\\d{4}|\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}|\\b[A-Za-z]+\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s+\\d{4})\\b'\n",
        "  match = re.search(date_regex, input_string)\n",
        "  if match:\n",
        "    extracted_date = match.group(0)\n",
        "    formatted_date = convert_date_format(extracted_date)\n",
        "    return formatted_date\n",
        "  else:\n",
        "    return input_string\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Du-hjdJCSKPk"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question where the context should contain a date and generates an answer to that question\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    output = model(**input_ids)\n",
        "    start_logits, end_logits = output.start_logits, output.end_logits\n",
        "    # Get most probable start and end index\n",
        "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "    end_idx = torch.argmax(end_logits, dim=1).item() + 1  # Include last token\n",
        "\n",
        "    # Convert token IDs to text\n",
        "    predicted_tokens = input_ids[\"input_ids\"][0][start_idx:end_idx]\n",
        "    predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "    formatted_predicted_answer = find_date_and_convert(predicted_answer)\n",
        "\n",
        "    if metric is not None:\n",
        "        metric.add(predictions=formatted_predicted_answer, references=intended_answer)\n",
        "\n",
        "    return intended_answer, formatted_predicted_answer\n",
        "\n"
      ],
      "metadata": {
        "id": "0trBt0BSGuQ4"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection"
      ],
      "metadata": {
        "id": "qBzA_tYRHFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
        "exact_match = evaluate.load(\"exact_match\")"
      ],
      "metadata": {
        "id": "2IlwKlBCkbq1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "59044c8744854a1fb9feead203f8ab28",
            "5d87ecc12c204399823d9becc2b5e850",
            "e386a60c3a0749c0b0f3f7fc8733516d",
            "fc0d81f19e23455cbb5dd12338fe1e27",
            "cb407d065a124cfe94893c21b4467406",
            "12a28748edf2413393bafaf643fa994f",
            "db7abe09e1d44888abebb5a6cedf3401",
            "2d8412d52ad94550a3c456b9bdb30475",
            "e9463f4e3ce043da9f2cdb16e7b10861",
            "3a1272469e534174b3310f95b69d4123",
            "9f511e0709394d449ee8caedcee4cd68",
            "4b3b2436dab14560ade8908502a4fde3",
            "15cf8b1942414b49b610eea5b051f50e",
            "c9c512f1862440b682f0c850257ec833",
            "b6bff98ef4294f6798bb6fd6d43abd6c",
            "042ddbbc68974b289477ddea90fb4788",
            "4f533231358940ad9b29b702237a4374",
            "bfc053516e084e0ea393d9fa76691c53",
            "476b3c9ab5a24ba8801a2998644871e8",
            "c12f0e1eaab149cea4e1c54b6c33d0d5",
            "bf2d6f418d31490083af5228ff89c074",
            "55d8f1b7bb944569982cf69a580ca541",
            "1274a62e96d449a391ba0ac43432897b",
            "b8b67813d6f047cf9f5c9e28e8d0e672",
            "5bb19898a6fc4c118b32d05553e48e97",
            "9d9f2ce4ed1f42c2aad46a3a4ae6b208",
            "7058d3c444994e64ad80d7d5e87aa294",
            "c63cd4cd6c5b4e3d8fa148b97b17d9fa",
            "34b982e507b04e4889a81dcef2a22330",
            "fec9ca008dce44aa9bc915f17bb38bf4",
            "4c88a420328646aa80b65d41dad2b6d5",
            "e9808e01c8964a8293fb56df8c060af4",
            "c66e1300994842768100b4cf1dbc37a4",
            "10d00df85e1e4c83ac9e908db63d6c26",
            "3febdd5820c74dafa65d511a76fed480",
            "43993b09d7c14f3e99b032d647ba9bb9",
            "5eb7716c863d4d9da6df62c9c66470b9",
            "6d025b2b9f5b42998a7c7e6014e0feec",
            "0748a76db3cd4a5ea0269ac4c5055eab",
            "dd4951eb191a419caba7a70d31e52f13",
            "cc9167f8b2ed4d469fb126cb34faa611",
            "82ed4394e8be4c7da9adae7f40c8345f",
            "8eedabcd99d6482e8f990348d16a061f",
            "1b2822fcaa2a4bcfabba90b70be8bf7c",
            "7bb3fcc01032413eb2c6f0c501d4dd47",
            "f61d3fd3d7ec471481518077511dd049",
            "e1a69486d9d148b0ace0d8218e065a50",
            "2e00dd40066d4206bf1a507bcd13b355",
            "c89b884b3d814baea55e86529b29b8a1",
            "6c81072ac31f434cb75a3b2f0c095478",
            "a41d3bb104f4464bbb92c61329ec1b58",
            "314136a7957f43eca4120980d13cbf2b",
            "dc45f9388fc74965998e70d28ea4f826",
            "6f21533c5d4743aeb1e2bd554f3371e8",
            "80346a59d2ea4b4f8b8f705c52fec3e5"
          ]
        },
        "outputId": "f02f0697-a748-47fc-8cdc-c1dc69898898"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59044c8744854a1fb9feead203f8ab28"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4b3b2436dab14560ade8908502a4fde3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1274a62e96d449a391ba0ac43432897b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "10d00df85e1e4c83ac9e908db63d6c26"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7bb3fcc01032413eb2c6f0c501d4dd47"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "summarization_pipeline = pipeline(\"summarization\", model=\"t5-small\")"
      ],
      "metadata": {
        "id": "OqjZCcSen3B3",
        "outputId": "a9b8c340-8802-41a0-c5c6-67d040aa9dc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354,
          "referenced_widgets": [
            "48e937a97261433d9cc6e7f0383cf40c",
            "7f0901d13a184e8e89504775c8092d97",
            "3bbe36de1dca48f99784408e545303b5",
            "062a9dcb5aa54951a2e3b77d383f4552",
            "63749ca00b394f67ba3a81f96ee1eb8f",
            "f6980753b93a4cf9bfb446edfa50f440",
            "4af8970fe4554e419e0a9e9fc1bfb201",
            "34126c03aae049debb5ce1b8a9b87434",
            "f252110d65c64d158ef969b0e7744245",
            "db4a2e33a5144b73a109fe1de0871af1",
            "cb473c370b0b4420ae9509ea42143cf3",
            "53f0e5f31c054232a9aa4e6f545b58f7",
            "e75c1cc060764f21a708b134d4c000e0",
            "eb658a3b263c4a2eb8ecc59569dc75cb",
            "c74a0fb700ff443094004257aa3b6204",
            "21ba4b35cd4a4d12b91f67d03007087e",
            "97c6e88e40c84dfeb0b0db0d6827b4af",
            "71d98c8ab3534232b054933338b6e64b",
            "e8bbc378cb7e4f2d9fc907cd2596228a",
            "e454fafeb5f94e0da6912565e79896fd",
            "0eb14b49919642c09417da326a26d1cd",
            "42d5d26c5f924be08c1e94a88d27e567",
            "34c17d1f0d9b445fbc73a6c51ec72830",
            "a84217232a5d4c88a88e82f15af8370b",
            "1a8b5f92ae6c4936b543f817194b82d8",
            "8418d01c47f943d6a7fbaaf7806a42ce",
            "d9ea2f137484493aaade56a912de2040",
            "125e93be67d540d6bf6388ab255095fb",
            "1591b48c56b04a53a5a33fbd3ed14117",
            "06b132098dad4229afbef70fa9b29ba1",
            "b9ba2c1f8482455db4f4065da4cd2bdc",
            "5ba804d065aa4798b59b726b2685a10e",
            "7d0f0d77545c4491a156cf6ae92d70c5",
            "4844ef76a7bf4b0d8640e606341cbe81",
            "8a04c3d943b049ccb757d0ab214a751e",
            "4e93fcf8747542648bb27f960fb4a646",
            "ad487a3822b84580ab26959b7e06a504",
            "054190a8ba8f48fda3778b4052816507",
            "c71cbb2b23fc474588192f55a2564b87",
            "3f598bade46a4f3e8ebc10e1b652bef4",
            "c4c0a39e56e14d4d9d9331d01d94af1e",
            "52bb010f2b1c4a68a5c90fdcb311ef6f",
            "e7163f0be53e49bd967ed32d668001f3",
            "49faeb14a5e94f4991ca035e57404ecf",
            "df3a825c7b2e45dd9881ea18536d2d0c",
            "c36bb59c2a07443195665b9e34f63bbc",
            "6078bced7f5143b9a66aa6d24b3c5057",
            "ec10760b362544edaa9eaa3294d19ef2",
            "9de56b287a6646c39e4381a957de0ace",
            "b5700ca91c5845d198bd286758e621ec",
            "72fd89542e57496cab9de10797504938",
            "6ce5f083e5a7418b8692ecf884e6027c",
            "c3934f0069b74e91bc7de03997a61d53",
            "4e74edb831954602a911a544604695ad",
            "46710cb847574d7791a53e692cffbb2d",
            "b80abe0a7eaa48be810394645d660b06",
            "88a6d8091a8746d886bbb750786ccc53",
            "617b1f62bd484b3d8826aa4db60d2854",
            "2fc75246a50a49d4a72a751b52d6ecb1",
            "eed83e0bd2d1464483cd622e5a9933bf",
            "cb18e9f1d23f4ac08a4ec148ca1b2f30",
            "6f47f77808ae4b2aba26ff3161874086",
            "d1294a0777af4d60806e14281d21ece1",
            "12ca8d4f6ed44916b4ed4bf878152183",
            "41d252b5e3614207ac52d3911c1e690e",
            "8d9839c94ef747a3a776a5dd29e78072"
          ]
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "48e937a97261433d9cc6e7f0383cf40c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "53f0e5f31c054232a9aa4e6f545b58f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "34c17d1f0d9b445fbc73a6c51ec72830"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4844ef76a7bf4b0d8640e606341cbe81"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "df3a825c7b2e45dd9881ea18536d2d0c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b80abe0a7eaa48be810394645d660b06"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "q95bFIxx1X8E",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "de3e64c1e28c4fde94e6c67cad042623",
            "b25aaa3c01c44258a299b1e0c19bfae8",
            "215f1e718f794b0a97ac40724bae0cd5",
            "d47b1b3526164fdc85395f02231a34c2",
            "5ca22f16658344d9aa6a3b37aa996b58",
            "1d7b41d5b10d421e9cfed7dbd0e06c28",
            "d8384107b53941a8805f7683b67fcd3b",
            "d703e1264c5641b38d65e407e5c210fd",
            "000f9ed9a18d4fa18feb9ec32ce8ca97",
            "c5d2f453c35a4c7ca837b26956fc3ed4",
            "d8a6dd17cd6e4babb742db9c47668175",
            "a26ac8d668344fa89a3752777b345a20",
            "130378064923417caea03fc83c518021",
            "418fefcc74884dc588f8dcc5428fd7ab",
            "9a45fa39d39e4afdb667902ccc020f92",
            "193cb982e8634a9a9962d6403fc47ca3",
            "76be37e307b64e7ba2600709b8b45dab",
            "cb9d3fce3045411dbda00ddc24f76dc6",
            "a64aa05d13194640b5b965f619d15230",
            "2910a3d0afcb46d78fa8e96869d56de1",
            "dd2ff28b8ec1444799b18fe1156c127c",
            "8951b6e73ca746118b797b86b13b2e91",
            "d53e9840097346d1b9a128165c3a556e",
            "725147d6ca0b452eba66bfe5ef15b22c",
            "1888f14787ec4bae8d092aa682727e93",
            "5825756e00a24393917b67b6949a02ac",
            "b365a036697b4f83aab3afc59c92cd96",
            "b6d4d384a6e6406d85bd8c545cd47fa1",
            "2455fa29cf7b495f9d8d9a1fd6e3cac5",
            "629561ca99914abbbdf4c0f97b8ceec8",
            "28bf93ec9a6a44c6bf88683a07b124c9",
            "30d46d9fe2b94121816aebcce7be409e",
            "675902fafb894dcbb711b9beadeedd20",
            "991aae395816463ebddf67a42961fd47",
            "b485e8bf4f6940b889a0018846dc40c9",
            "9ca3ce006f804e42821d406cb46a1c5b",
            "ce9bb62504ac4993a2236ec456ffa554",
            "c0f1c97910984fea95e37f692321300d",
            "68a92fc05f254f34a7fdd284e4963912",
            "d75514b0bafd4810bf6c62adf9c01dde",
            "857df7a5eb52490cae3054100f9c5b27",
            "9a224c58397d45a59deddf578d3334af",
            "d87738a0845d4f758b48261f7b954026",
            "36b2bb1399b343e4b6129f4b4d53b78c",
            "f6fd8e0a53a843afa633def9510108d9",
            "4a1b940b701a49fab872fc9fa26559f4",
            "c7dfa73b13724b3e8fc08b2955ec30fb",
            "3364df12fe2a4a5c98e1c7ce29e756cd",
            "1392ed714d36446381160bb5f6cf84e5",
            "1199afe26f3a4fffb88d15891afada68",
            "92c44136cf2845219e42ed9830355af1",
            "d0e3a652f3d041199b1a10a2ab8022ff",
            "15900a82a5874d3bb24e1687f423c18b",
            "65e7a3f2aff8407fb64d2bc35edd0d6b",
            "6ce10520f329468080370dd043d65b79"
          ]
        },
        "outputId": "f8fc73f4-d783-497f-b0df-a0f6b0a50537"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de3e64c1e28c4fde94e6c67cad042623"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a26ac8d668344fa89a3752777b345a20"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d53e9840097346d1b9a128165c3a556e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "991aae395816463ebddf67a42961fd47"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f6fd8e0a53a843afa633def9510108d9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oe_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")\n",
        "oe_tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")"
      ],
      "metadata": {
        "id": "AwK34z3JFMic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "7f3a8f0cc8944c5fb094a71d863312dd",
            "b26de83e7cbe40aeb0f60373f161e059",
            "ede00081592f49c28c9720c6c8610453",
            "7bf1aa8808234ed0ad1a1ee48f4e593e",
            "47dcb4a2489840de8ca02f1cb86c45d9",
            "1d02dc9522544dadb5b4524f45fe2526",
            "53ff5bef6e114d45b7c7439b73835209",
            "96fd4a096c4942af86eb88cc58c009d9",
            "1796f997784344299aed12f3da82fc73",
            "542d7a72732545fda19a9914dba0402b",
            "43d0ad88d86b41adb40e8decb1d20240",
            "b3a4affc5044449fb0e15ddf5b706260",
            "030eefc9e2f84a6b9f0df6c281f014a7",
            "f48e5ada65ff4aed83b12b617b1989e9",
            "15d2cf2af5b7427c81200e4345487c99",
            "b486709048a249a2aa4c777b09207679",
            "552063737d714ee4b394fd78cbcaa834",
            "38752ebb03084e25a4daebc7831b81cf",
            "e347f209f6624ded82db35a5c200677c",
            "5d4d81e9da8a449aa6ef5e9cb7969ce4",
            "9226ff5f79534739809a30282193802e",
            "69c6a3c0425b4818b39be61a7497e99d",
            "893decb20a564e8eb2c547ae93adebe2",
            "d546523128404e94abf1ddfd7de3d32d",
            "977d6573573a46eaa78f156538c70482",
            "c2a9b6f4b25c4100b8a8784e398ddb7a",
            "cba354970ec2426b93d91d8008fbe616",
            "23794d04100e40d091963cd8908b75f2",
            "3f0fc167a84f417797aba312b7573535",
            "a729a430f0a34eada92b30bc9179c21a",
            "59a7b91cc54142929fb81fe0368f6e5e",
            "8d96e8fba4294eab9e4e604be2901101",
            "416268ac1c3c48b4b8c5d9c498e7e13b",
            "e5a3531d8add459d988c619ebc9f0bed",
            "7c9f74f64a004dba92741b6b7a6588c8",
            "2770e86e93184848aa7ab8649d861d1b",
            "6f7a852386c94fb2b87796bfd05eb42a",
            "e0a13db292c348729674e5a66cb9a498",
            "e5cf6eceb518470485b548f59e241771",
            "06455f3325964be3b8a089cbc8f217c2",
            "c4649ccda893422fabaa0a444f50edf5",
            "2bdb272bffaa40f4a3851cfad63e24cb",
            "f9d8a10561fc424ab44eb16831a578d4",
            "c553e2d28c0d4258bf414aeec0cfa321",
            "b8cfd7936a064b5387287337f530fc5d",
            "776900c4d514492bb8d2b2b4f4b89301",
            "6e8643d6fe2b4cbc8852e17d5041e841",
            "03b1c0358c6748039ee531dc52a2b4f5",
            "0b40c205dedb4a608538caa6af7bb607",
            "961c845cd0894c2a842bbe358ddea652",
            "363d22bde50647599edae34f1b2b3648",
            "4a462d3eac9c42f38bfb2e24a456aaa7",
            "38b43f339a7046d48b88d3cdeecb1bc5",
            "8e53a54bd42045bdafd542ea7b83305f",
            "b7fc1111de5d47c083f5c3eb3d80baf9"
          ]
        },
        "outputId": "c898d0ac-10b8-4d50-aa02-5a575439221e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f3a8f0cc8944c5fb094a71d863312dd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3a4affc5044449fb0e15ddf5b706260"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "893decb20a564e8eb2c547ae93adebe2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a3531d8add459d988c619ebc9f0bed"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b8cfd7936a064b5387287337f530fc5d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We look how accurate the model is for the open-ended questions. Is there a need to look for other models?\n",
        "\n",
        "We test everything on the train dataset (Doesn't matter, because we do not fine-tune at this stage)"
      ],
      "metadata": {
        "id": "uw1EcrEMldG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "oe_qa_train_dataset = pd.DataFrame(qa_dataset['train'].filter(lambda example: example['type'] in ['DATE', 'NUMBER']))\n",
        "oe_qa_train_dataset.shape"
      ],
      "metadata": {
        "id": "meA0KR7mlS3b",
        "outputId": "117c16e4-e494-4f3e-e53c-f235dd9466ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "0831d75191ed435b9bc8c5cab28f7718",
            "af84a8d765714c2c8a18d152ed03fd37",
            "ec8bd37565f8468a9dd0feae7da8cbad",
            "ab3c5861897545a594a4c4e2c168318a",
            "04465737c1d4423ca28be042c48db9ac",
            "05eb159ae7cb429aa632598ca549b1c1",
            "9fd07fe6937d49a88b4beaec4b7db37f",
            "79350cdf11cb4a8f9059099ab55c546d",
            "08ea36fac1004090a5d56ac1bb43c114",
            "0ac1c48909cc4792a956818d4a2e62b6",
            "a826edf595ea4119b52f5679d00e4661"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0831d75191ed435b9bc8c5cab28f7718"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 8)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, oe_qa_train_dataset, mc_metric=clf_metrics, oe_metric=exact_match)\n",
        "print(f\"The exact_match metric for all open-ended questions in the train dataset: {oe_metric_result['exact_match']}\")"
      ],
      "metadata": {
        "id": "JfiuSgE5m75C",
        "outputId": "c9f37764-7e91-4147-9586-7eac791d21e7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we touch base again on January 15th?  That works for me.\n",
            "The intended answer was: 2025-01-15\n",
            "The predicted answer was: january 15th\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we connect again on January 17th?  That works for me.\n",
            "The intended answer was: 2025-01-17\n",
            "The predicted answer was: january 17th\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we follow up around January 22nd of 2025? That should work nicely.\n",
            "The intended answer was: 2025-01-22\n",
            "The predicted answer was: 22nd of 2025\n",
            "\n",
            "The exact_match metric for all open-ended questions in the train dataset: 0.9651162790697675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is there a possibility to write a map function? Insert it here!!"
      ],
      "metadata": {
        "id": "ic-fXdrms97t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No need of searching for another model here, we can concentrate on the mc questions"
      ],
      "metadata": {
        "id": "k99_LAIpqupY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_train_qa_dataset = pd.DataFrame(qa_dataset['train'].filter(lambda example: example['type'] in ['MULTI_SELECT', 'SINGLE_SELECT']))\n",
        "mc_train_qa_dataset.shape\n",
        "\n",
        "model_results = []"
      ],
      "metadata": {
        "id": "jlMX2rCjtMi3",
        "outputId": "693a801e-0ae0-44b0-f548-ffd15298b858",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "cc8f562343a742b9bdfec726834a5a02",
            "f5b07535240d43338dc151e7ffc38a62",
            "82b0c7fc16da4b2fb145e7ea6eadf682",
            "da1b8c647bad4eb9be7e96e7bdc68986",
            "346002ad8f394988b36eedd8a16bf1bb",
            "0e5875a0ea8648e18248c84603699f35",
            "a9a00c8eee56406aa22a4ff4c538da29",
            "0043974a9d2840298a4ae531f33a7e32",
            "b4e093757f5d40e3afefc1ec16ee08fe",
            "5ca37e689ce246118547c00d6d0049f9",
            "1ced0c90a12045ce9135187b1fd17784"
          ]
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "cc8f562343a742b9bdfec726834a5a02"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### BERT base model (cased)\n",
        "Trained from scratch"
      ],
      "metadata": {
        "id": "EwsbEfOhX892"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "id": "xvWK_VxTq6By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3968da8-f343-4897-b6a7-583e0fc658c5"
      },
      "execution_count": 25,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7140, -0.7189, -0.7236, -0.7183, -0.7252, -0.7269, -0.7186, -0.7242,\n",
            "         -0.7153, -0.7232, -0.7220, -0.7312, -0.7133]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7229, -0.7253, -0.7389, -0.7482, -0.7273, -0.7265, -0.7366, -0.7389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7331, -0.6442, -0.6257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think we should have a meeting next.  That seems like the best way to move forward.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7991, -0.7888]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7381, -0.7457, -0.7329, -0.7564, -0.7414, -0.7624]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7062, -0.7132, -0.7315, -0.7412, -0.7285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, we are larger than 2000. That's how big we are!\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7430, -0.7273, -0.7259, -0.7225, -0.7421, -0.7569, -0.7270, -0.7481,\n",
            "         -0.7397, -0.7397, -0.7403, -0.7331, -0.7204]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7202, -0.7198, -0.7194, -0.7180, -0.7175, -0.7174, -0.7128]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7152, -0.7193, -0.7203, -0.7192, -0.7201, -0.7203, -0.7187, -0.7135,\n",
            "         -0.7193, -0.7212, -0.7176, -0.7231, -0.7135]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Jessica Hanke', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6488, -0.6149, -0.6550, -0.6692]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7310, -0.7324, -0.7378, -0.8003, -0.7264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7209, -0.7253, -0.7174, -0.7377, -0.7495, -0.7368]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7264, -0.7258, -0.7981, -0.7218, -0.7221]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7445, -0.7447]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7940, -0.7205, -0.7250, -0.7277, -0.7152]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7136, -0.7230, -0.7160, -0.7124, -0.7221, -0.7169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6751, -0.7165, -0.6955, -0.7125, -0.6664, -0.7171, -0.7178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7122, -0.7197, -0.7163, -0.7140, -0.7068, -0.7158, -0.7100, -0.7198,\n",
            "         -0.7157, -0.7174]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6804, -0.6665, -0.6707, -0.6750, -0.6570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7183, -0.7241, -0.7151, -0.7250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6617, -0.7140, -0.6816, -0.6648, -0.6600, -0.6800, -0.6643, -0.7215,\n",
            "         -0.6799, -0.6997]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7136, -0.7151]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7008, -0.7125, -0.7132, -0.7090, -0.7239]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7110, -0.7508, -0.6783, -0.7293, -0.6745, -0.7308, -0.6749, -0.7546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7002, -0.7003, -0.7005, -0.7021, -0.7015]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3159, -0.2826, -0.3412, -0.4175, -0.7128, -0.3424, -0.6063]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7536, -0.7979, -0.7207, -0.7254, -0.7391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7157, -0.7151, -0.7160, -0.7244, -0.7123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7113, -0.7092, -0.7298, -0.7246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7100, -0.6801, -0.7079, -0.7099, -0.7067]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6960, -0.7241, -0.7151, -0.7122, -0.7214, -0.7214]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7084, -0.7387, -0.7815, -0.7383]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7251, -0.7166, -0.7159]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 3 weeks sounds good, that's when I'd like a follow up.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.6930, -0.7070, -0.6882, -0.6685, -0.6777]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.8156, -0.7023, -0.7028, -0.7254, -0.7247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7790, -0.7106]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7318, -0.7275, -0.7250, -0.7430, -0.7310, -0.7107, -0.7260, -0.7354,\n",
            "         -0.7282, -0.7200, -0.7239, -0.7750, -0.7190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Marisa Peng', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7263, -0.7309, -0.7315, -0.7318, -0.7315, -0.7339, -0.7294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7232, -0.7167, -0.7189]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7218, -0.7292, -0.7299, -0.7391, -0.7128, -0.7300, -0.7203, -0.7196]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7239, -0.7234, -0.7263, -0.7280, -0.7178, -0.7220, -0.7208, -0.7233,\n",
            "         -0.7184, -0.7252, -0.7130, -0.7263, -0.7285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7160, -0.7235, -0.7173, -0.7145, -0.7237, -0.7156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7372, -0.7288, -0.7315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7138, -0.7093, -0.6896, -0.7177, -0.7016, -0.6991, -0.7195]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm I guess the customer group would be end user then, that seems about right.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7201, -0.7209, -0.7232, -0.7165, -0.7152, -0.7200, -0.7168, -0.7228,\n",
            "         -0.7212, -0.7208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7225, -0.7173, -0.7244, -0.7187, -0.7247, -0.7262, -0.7171, -0.7151,\n",
            "         -0.7167, -0.7241, -0.7111, -0.7321, -0.7346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7248, -0.7243, -0.7442, -0.7504, -0.7381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7067, -0.7085, -0.7164, -0.7184, -0.7213]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh I'm not really sure about the company size, but I'd guess it's around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7238, -0.7210, -0.7035, -0.7130, -0.6909, -0.7139, -0.7262, -0.7251,\n",
            "         -0.6889, -0.7226, -0.6813, -0.7299, -0.7062]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7407, -0.7419, -0.7469, -0.7305, -0.7391, -0.7505]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7481, -0.7391, -0.7456, -0.7544, -0.7352, -0.7371, -0.7469, -0.7186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7045, -0.6781, -0.7078, -0.6811]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, well, I guess I'd say I'm very satisfied, if that's an option, it's definitely my answer.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6780, -0.6866, -0.6785, -0.6683, -0.6885]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm I'd probably go with Spanish. I don't know what else there is.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7207, -0.7532, -0.7286, -0.7250, -0.7483]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7342, -0.7417, -0.8130, -0.7303, -0.7105]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7239, -0.7087, -0.7093, -0.6898, -0.7176, -0.7065]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6684, -0.6640, -0.7074, -0.7125, -0.7075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7326, -0.7309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7158, -0.7236, -0.7209, -0.7247, -0.7120, -0.7662]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7611, -0.6918, -0.7456, -0.7210, -0.7366]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7084, -0.7006, -0.7060, -0.7087, -0.7069]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7008, -0.7128, -0.7165, -0.7633, -0.7474]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6977, -0.6397, -0.6806]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess the next thing I would do is call, seems right to me.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7009, -0.7003, -0.7090, -0.7101]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7171, -0.7134, -0.7148]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7126, -0.6315, -0.7060, -0.7176]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I think, I'd have to say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7029, -0.6902, -0.6930, -0.6787, -0.6670]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I'm not sure about languages but I guess I'd choose German then.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7102, -0.7155, -0.7135, -0.7049, -0.7131, -0.7107]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7240, -0.7185, -0.7170]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7260, -0.7283, -0.7308, -0.7262, -0.7219, -0.7288, -0.7237, -0.7311,\n",
            "         -0.7291, -0.7283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7142, -0.7526, -0.7035, -0.7115, -0.7225, -0.7163]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7204, -0.6640, -0.4756, -0.5481, -0.5277, -0.7661, -0.7279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7207, -0.7198, -0.7191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6793, -0.7233, -0.6703, -0.7181, -0.6698, -0.6823, -0.7182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7765, -0.7795, -0.7416, -0.7944, -0.7301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7182, -0.7120, -0.7154, -0.7277]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7147, -0.7153, -0.7137, -0.7187, -0.7119, -0.7136, -0.7146, -0.7117,\n",
            "         -0.7128, -0.7128, -0.7134, -0.7188, -0.7222]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6923, -0.7088, -0.7182, -0.6913, -0.6847, -0.7092, -0.6959, -0.7061,\n",
            "         -0.7118, -0.7115]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3263, -0.5470, -0.4600, -0.3629, -0.5787, -0.5442, -0.1830, -0.7358]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6465, -0.7286]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know, but I guess No. I'm not sure what the options are.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.6926, -0.6982, -0.6958, -0.6749, -0.6882, -0.7156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's an education company, I guess.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6889, -0.6925, -0.7306, -0.7480]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6995, -0.7113, -0.7223, -0.7019, -0.7107, -0.7204, -0.7032, -0.7066,\n",
            "         -0.7185, -0.7222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7344, -0.7460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think I want to.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.6786, -0.6740, -0.6615, -0.6973, -0.7142, -0.6657, -0.7084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7226, -0.7241, -0.7278, -0.7197, -0.7181, -0.7266, -0.7207, -0.7263,\n",
            "         -0.7243, -0.7255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6703, -0.6571, -0.6998, -0.6789, -0.7037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in high-speed interconnect testing, because that sounds like a really important field.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5132, -0.4716, -0.5331, -0.5215, -0.7257, -0.7504, -0.7652]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7203, -0.7310, -0.7300, -0.7735, -0.7285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7017, -0.6847, -0.6853, -0.6969]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7737, -0.7337, -0.7284, -0.7460, -0.7268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6865, -0.5890, -0.6350]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so the next step is to just call. That's the only thing it says.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7147, -0.7096, -0.7169, -0.7204]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7166, -0.7270, -0.7051, -0.7223, -0.7220, -0.7248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['JTS']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7081, -0.6974, -0.6908, -0.6802, -0.6714]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh umm, I guess I'd prefer German then, if that's an option. I'm not sure what other choices there are.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7132, -0.7218, -0.6915, -0.7059, -0.7193, -0.7120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7108, -0.7125, -0.7134, -0.7106, -0.7135, -0.7151]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5361, -0.5547]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess I'd say no, since that's the only option there.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.3223, -0.3125, -0.4726, -0.3515, -0.2714, -0.1867, -0.4873]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 12, I don't really know exactly.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6854, -0.6861, -0.7122, -0.6765, -0.6451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7439, -0.6343, -0.6440]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7134, -0.7258, -0.7087, -0.7011, -0.7198, -0.7157]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7263, -0.7272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7111, -0.7098, -0.7167, -0.7236, -0.7221]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6384, -0.7155, -0.6500, -0.6343, -0.6442, -0.6343]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6886, -0.7203, -0.7034, -0.6887, -0.6773, -0.7078, -0.6911, -0.7249,\n",
            "         -0.7049, -0.7156]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7228, -0.7123, -0.7327, -0.7974, -0.7376]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Supplier']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7206, -0.7318, -0.7336, -0.7290, -0.7221, -0.7316, -0.7292, -0.7217,\n",
            "         -0.7269, -0.7226, -0.7186, -0.7417, -0.7324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7157, -0.6952, -0.7192, -0.6980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.4648, -0.4846]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not really sure about the options, but I think I would say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7205, -0.7161, -0.7172]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they'd like a follow up in about 1 week.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6885, -0.6869, -0.7154, -0.6990]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6585, -0.6657, -0.7022, -0.6930]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7691, -0.7736, -0.7287, -0.7343, -0.6829, -0.7571, -0.7883]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7154, -0.7123, -0.7137, -0.7032, -0.7150, -0.7074]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it must be a construction company. That makes the most sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6670, -0.6567, -0.7253, -0.7245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7342, -0.7214, -0.7413, -0.7243, -0.7058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7264, -0.7222, -0.7267, -0.7168, -0.7165, -0.7242, -0.7197, -0.7228,\n",
            "         -0.7234, -0.7258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in Aerospace? It's the only option provided.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6982, -0.7116, -0.6953, -0.6724, -0.6785]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I suppose Italian is what I want to use. I guess that's it.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7090, -0.6997, -0.7077, -0.7028, -0.7162]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, um, I think our company size is probably somewhere between 1 and 10 people. Yeah, I'd guess that.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7264, -0.7414, -0.7499, -0.7482, -0.7345, -0.7391, -0.7358, -0.7491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7048, -0.7001, -0.7217, -0.7307, -0.7262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7875, -0.7641, -0.7884, -0.7228, -0.7290]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7397, -0.7238, -0.7239, -0.7322, -0.7081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7158, -0.7162]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7236, -0.7229, -0.7219, -0.7214, -0.7173, -0.7085, -0.7223, -0.7153,\n",
            "         -0.7157, -0.7243, -0.7134, -0.7328, -0.7193]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7209, -0.7242, -0.7261, -0.7166, -0.7137, -0.7233, -0.7181, -0.7250,\n",
            "         -0.7279, -0.7200]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4873, -0.4939, -0.4034, -0.4042, -0.5290, -0.4820, -0.2088, -0.7294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, gosh I am not really sure about those options but I'm guessing the one I'd use is Adito, is that right?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7537, -0.7564, -0.7484, -0.7471, -0.7419, -0.7415, -0.7264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7180, -0.7071, -0.7186, -0.7224, -0.7230]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7429, -0.6456, -0.6427]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7228, -0.7255, -0.7446, -0.7557, -0.7373]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7218, -0.7231]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7359, -0.7189, -0.7428, -0.7238, -0.6944]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7390, -0.7239, -0.7123, -0.7251, -0.7594]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6612, -0.6610, -0.6939, -0.6602]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7116, -0.6307, -0.6368]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess my next step would be offer.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7177, -0.7197, -0.7207, -0.7143, -0.7099, -0.7559]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7302, -0.7074, -0.7004]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6851, -0.7056, -0.6324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7043, -0.6675, -0.6901, -0.7397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7150, -0.7213, -0.7319, -0.7204, -0.7186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6922, -0.6955, -0.6966, -0.6865, -0.7013]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7684, -0.7562, -0.7141, -0.7554, -0.7545, -0.7559, -0.7755]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7098, -0.7023, -0.7086, -0.6767, -0.7049]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7295, -0.7284]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7246, -0.7192, -0.7260, -0.7343, -0.7294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7243, -0.7226, -0.7253, -0.7911, -0.7600]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6997, -0.6980, -0.6997, -0.6888, -0.7247, -0.7034]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7165, -0.7170]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7232, -0.7301, -0.7108]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7481, -0.7393, -0.7464, -0.7578, -0.7339, -0.7257, -0.7395, -0.7501]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7227, -0.7237, -0.7242, -0.7224, -0.7223, -0.7240, -0.7189]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7415, -0.7609, -0.7226, -0.7488, -0.6827]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6929, -0.7109, -0.7036, -0.7500, -0.7145, -0.6960, -0.7231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7155, -0.7380, -0.7297, -0.7695, -0.7366, -0.7483, -0.7556]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7893, -0.7297, -0.7279, -0.7230, -0.7145]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6204, -0.6165, -0.7573, -0.6909]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6946, -0.6996, -0.7027, -0.6918, -0.7178, -0.7031]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6776, -0.7088, -0.6924, -0.7069]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7293, -0.7243, -0.7223, -0.7219, -0.7156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7739, -0.7252, -0.7859, -0.8114, -0.7598, -0.7707, -0.8007, -0.8196]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7252, -0.7215, -0.7244, -0.7162, -0.7256, -0.7207]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6798, -0.6287, -0.6257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.3982, -0.4156, -0.6448, -0.7074]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm very unsatisfied, actually.  I didn't get what I wanted, and the whole experience was frustrating.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7138, -0.7065, -0.7098, -0.7046]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7283, -0.7272, -0.7258, -0.7240, -0.7240, -0.7242, -0.7164]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7310, -0.7290, -0.7297, -0.7128, -0.7127, -0.7231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7246, -0.7267]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think so.  I prefer not to receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7815, -0.7738, -0.7632, -0.7872, -0.7335, -0.7311, -0.7966]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7206, -0.7236, -0.7270, -0.7187, -0.7288, -0.7672]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7072, -0.7090, -0.7140, -0.6885, -0.7077, -0.7074]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6816, -0.6840, -0.7074, -0.6987, -0.7240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5813, -0.5632]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I guess I'd say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7235, -0.7154, -0.7143]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm, I think they want a follow up in 3 weeks, sounds about right to me.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.7040, -0.6686]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7126, -0.7210, -0.7145, -0.7110, -0.7109, -0.7138, -0.7104, -0.7204,\n",
            "         -0.7162, -0.7160]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7147, -0.7124, -0.7125, -0.7173, -0.7195, -0.7203]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7182, -0.7279, -0.7239, -0.7157, -0.7277, -0.7673]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7233, -0.7204, -0.7225, -0.7220, -0.7232, -0.7255, -0.7192]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6997, -0.6860, -0.6374]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7237, -0.7159, -0.7258, -0.7290, -0.7168, -0.7086, -0.7231, -0.7397]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I'd probably go with HubSpot, since that seems to be the only option listed right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7263, -0.7272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7228, -0.7535, -0.7358, -0.6916, -0.7332]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6655, -0.7002, -0.6639, -0.6444, -0.6519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, Italian, I think Italian sounds good. I'm going with that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7278, -0.7268]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7041, -0.6898, -0.6649, -0.6786]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7219, -0.7206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7231, -0.7258, -0.7243, -0.7192, -0.7188, -0.7261, -0.7174, -0.7259,\n",
            "         -0.7268, -0.7281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7292, -0.7190, -0.7259, -0.7356, -0.7291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7085, -0.7109, -0.7128, -0.6945, -0.7077, -0.7046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7088, -0.6440, -0.6504]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'll offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7193, -0.7456, -0.7267, -0.8028, -0.7547]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7101, -0.7151, -0.7660, -0.7280]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7116, -0.7226, -0.7110, -0.7150, -0.7213, -0.7092]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7447, -0.7276, -0.7323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7300, -0.7259, -0.7201, -0.7162, -0.7190, -0.7236, -0.7182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7392, -0.7421, -0.7407, -0.7270, -0.7215, -0.7581]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7401, -0.7278, -0.7301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7118, -0.7009, -0.6359]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess a meeting is what's next then. I think that is the only thing on the list anyway.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7159, -0.7334, -0.7230, -0.7231, -0.7224, -0.7300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7430, -0.7415, -0.7387, -0.7352, -0.7298, -0.7330, -0.7262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7158, -0.7173]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7097, -0.7130, -0.7118, -0.7082, -0.7125, -0.7101]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6958, -0.7047, -0.7103, -0.7550, -0.6954, -0.6983, -0.7287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7138, -0.6958, -0.7248, -0.7057]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.8173, -0.8446, -0.8106, -0.8018, -0.7748]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7196, -0.7542, -0.7621, -0.7468, -0.7241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7238, -0.7269, -0.7176, -0.7209, -0.7382, -0.7599]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6947, -0.7688, -0.7574, -0.7124, -0.7450, -0.7085, -0.7227, -0.7860,\n",
            "         -0.6761, -0.6838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6910, -0.6257, -0.6473]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would say I'll call then.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7112, -0.7255, -0.7080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6944, -0.7546, -0.7161, -0.7134, -0.7209, -0.7169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7384, -0.7252, -0.7271, -0.7265, -0.7120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7397, -0.7263, -0.7911, -0.7022, -0.7181]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7146, -0.7139, -0.7223, -0.7179]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.8064, -0.7233, -0.8109, -0.7127, -0.7264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6868, -0.6611]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7399, -0.6839, -0.7631, -0.7357, -0.7125, -0.6541, -0.7386, -0.6936,\n",
            "         -0.6792, -0.7195]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7875, -0.7014, -0.6905, -0.7182, -0.7674]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6369, -0.6254, -0.7023, -0.7111]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6849, -0.6578, -0.7162, -0.5477, -0.6712, -0.6665, -0.5079, -0.6287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't know all the options but I guess it's Close.io. I've heard good things about it.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7140, -0.7309, -0.7744, -0.7309]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7285, -0.7867, -0.7891, -0.7658, -0.7190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7252, -0.7265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7189, -0.7194]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7144, -0.7209, -0.7183, -0.7247, -0.7164, -0.7137, -0.7195, -0.7199,\n",
            "         -0.7201, -0.7214, -0.7157, -0.7209, -0.7229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Marisa Peng', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6863, -0.6931, -0.7164, -0.6937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7266, -0.7078, -0.7378, -0.7596, -0.6907]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7276, -0.7264, -0.7259, -0.7235, -0.7224, -0.7233, -0.7205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6844, -0.7095, -0.7012, -0.7082, -0.7212, -0.7144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7219, -0.7226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.6811, -0.7065, -0.7118, -0.7020, -0.7059]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, well, I think I'm interested in both Noise figure measurements and Double-Pulse Testing. Those sound like things I could explore more.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7152, -0.7243, -0.7254, -0.7312, -0.7180, -0.7145, -0.7247, -0.7230,\n",
            "         -0.7166, -0.7187, -0.7138, -0.7530, -0.7272]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7111, -0.7160, -0.7097, -0.7165]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7279, -0.7299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't want marketing emails; I prefer not to receive them.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.8144, -0.7382, -0.7271, -0.7345, -0.7258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7320, -0.7179, -0.7144]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7154, -0.7034, -0.7533, -0.7002]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7336, -0.6691, -0.6654]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6801, -0.7249, -0.7141, -0.7141, -0.7202, -0.7156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7249, -0.7069, -0.7250, -0.7799, -0.6967]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7130, -0.7178, -0.7073, -0.7097]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. I'm going with very unsatisfied I think. Yeah, that's what I would say.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7251, -0.7242, -0.7237, -0.7214, -0.7213, -0.7238, -0.7204]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6752, -0.6816, -0.6957, -0.7264, -0.7111]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7253, -0.7234, -0.7213, -0.7160, -0.7202, -0.7234, -0.7190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7159, -0.8028, -0.7188, -0.7142, -0.7201, -0.7167]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7355, -0.7510, -0.7202, -0.7181, -0.6986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7199, -0.7071, -0.7015]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so next steps, hmmm... I guess my only option here is to make an Offer, then.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7192, -0.7204]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6792, -0.6853, -0.6989, -0.6975, -0.7207]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6914, -0.7256, -0.7540, -0.6879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7429, -0.7277, -0.7139, -0.7196]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7674, -0.7113, -0.7636, -0.7666, -0.7208, -0.6947, -0.7628, -0.7441,\n",
            "         -0.7076, -0.7233]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6287, -0.6367, -0.6321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.7266, -0.7240, -0.7288, -0.7159, -0.7190, -0.7244, -0.7162, -0.7210,\n",
            "         -0.7253, -0.7257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7086, -0.6967, -0.7080, -0.7167]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, I think I'm very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7225, -0.7097, -0.7150, -0.7055, -0.7096, -0.7184, -0.7037, -0.7058,\n",
            "         -0.7066, -0.7183]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7298, -0.6490, -0.6476]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.4928, -0.5543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess no is the only option available, so I choose no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7817, -0.7733]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7109, -0.6436, -0.7093, -0.6574, -0.7079]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7133, -0.7086, -0.7264, -0.7124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7091, -0.6976, -0.7087, -0.7096, -0.7044]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7191, -0.6597]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7017, -0.7000, -0.7140, -0.7120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6384, -0.6293, -0.7094, -0.6612]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7270, -0.7257, -0.7297, -0.7254, -0.7189]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7316, -0.7359, -0.7377, -0.7274, -0.7367]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1368, -0.0738, -0.1493, -0.1094, -0.1265, -0.1895, -0.7126]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6752, -0.6866, -0.6754, -0.6731, -0.6945]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6701, -0.6942, -0.7185, -0.7370]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess it's Partner, since that's the only option I have.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7844, -0.7282, -0.7942, -0.7330, -0.7179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7066, -0.7028, -0.7102, -0.7015, -0.7143, -0.7026]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7180, -0.7181, -0.7223, -0.7284, -0.7143, -0.7296]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6776, -0.7088, -0.6924, -0.7069]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7056, -0.7007, -0.6958, -0.6977, -0.7036, -0.7060, -0.7208]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7316, -0.7337, -0.7527, -0.7890, -0.7249, -0.7347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7257, -0.7196, -0.7184]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.4806, -0.5389, -0.6595, -0.7015]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6823, -0.6686, -0.6995, -0.7462, -0.6844]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7198, -0.7207, -0.7232, -0.7240, -0.7292, -0.7249, -0.7187, -0.7190,\n",
            "         -0.7191, -0.7376, -0.7149, -0.7273, -0.7260]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7282, -0.7339, -0.7363, -0.7266, -0.7260, -0.7590, -0.7292, -0.7208,\n",
            "         -0.7248, -0.7381, -0.7155, -0.7374, -0.7202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6967, -0.6608, -0.7008, -0.7438]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7130, -0.7170, -0.7091, -0.7187, -0.6877, -0.7069, -0.7194, -0.6817,\n",
            "         -0.6865, -0.7149, -0.6738, -0.7014, -0.7118]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7166, -0.7187, -0.7237, -0.7225, -0.7131, -0.7548]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7200, -0.7216, -0.7227, -0.7205, -0.7206, -0.7264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a production company. That's the type I think it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7225, -0.7256, -0.7307, -0.7361, -0.7256, -0.7254, -0.7290, -0.7288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7218, -0.7206, -0.7232, -0.7161, -0.7131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6937, -0.6968, -0.6969, -0.6955, -0.6985]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7332, -0.7303, -0.7269, -0.7275, -0.7291, -0.7363, -0.7333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7121, -0.7158, -0.7239, -0.7277]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7086, -0.7149, -0.7129, -0.7148, -0.7131, -0.7102]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I'm not really sure. I think it might be a trading company.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7126, -0.7092, -0.7233, -0.7219]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6929, -0.6910, -0.7010, -0.7130]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, the customer type is an 'Applicant'. That seems straightforward. I guess there weren't any other options.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7121, -0.7091, -0.7093]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.6817, -0.6805, -0.7105, -0.7101, -0.7020]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7642, -0.7459, -0.7281, -0.7356, -0.7103, -0.7234, -0.7631, -0.7258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7205, -0.7189, -0.7183, -0.7158, -0.7153, -0.7127, -0.7137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7147, -0.7253, -0.7152, -0.7208, -0.7199, -0.7226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5936, -0.5394]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, I guess I would say yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.7199, -0.7174, -0.7214, -0.7185, -0.7163, -0.7217, -0.7157, -0.7172,\n",
            "         -0.7191, -0.7194]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3191, -0.4822, -0.4191, -0.2776, -0.1839, -0.0974, -0.4972]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7679, -0.6976, -0.7729, -0.7203, -0.6722]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6710, -0.6746, -0.7001, -0.7158, -0.7215]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, that's a good question. I guess we are larger than 2000, it is what feels right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7409, -0.7052, -0.7637, -0.6998, -0.7127]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6884, -0.7032, -0.7323, -0.7111, -0.7114, -0.7092, -0.7284, -0.7292]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7100, -0.6861, -0.7087, -0.6692, -0.7027]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6938, -0.6891, -0.7146, -0.7121, -0.7081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6757, -0.6790, -0.7055, -0.6755, -0.6702]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess you're looking for me to use Japanese. That's the only option, so Japanese it is!\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7377, -0.7254, -0.7705, -0.7308, -0.7230]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7112, -0.7103, -0.7189, -0.7122, -0.7201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd guess we have around 1000 employees.  I don't know the exact breakdown of sizes, like  201-2000 or any other ranges\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5060, -0.5317, -0.6889, -0.7120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm very unsatisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6562, -0.6469, -0.6681, -0.6438, -0.6552, -0.6802, -0.6587, -0.6602,\n",
            "         -0.7188, -0.7124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7175, -0.7276, -0.7404, -0.7241, -0.7385, -0.7520, -0.7271, -0.7457,\n",
            "         -0.7400, -0.7367, -0.7168, -0.8041, -0.7653]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7267, -0.6945, -0.7153]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7114, -0.7813, -0.8021, -0.7247, -0.7223, -0.7864, -0.7319, -0.8037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it would be SAP Sales Cloud, I think I've heard of that one.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7246, -0.7943, -0.7697, -0.7367, -0.7197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6752, -0.6810, -0.7056, -0.7103, -0.7078]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7151, -0.7160]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7166, -0.7122, -0.7223, -0.7226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7262, -0.7137, -0.6870, -0.7226, -0.6809]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7337, -0.7277, -0.7280]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.7158, -0.6960, -0.7872, -0.7860]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4964, -0.5226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7094, -0.7012, -0.7037, -0.7097, -0.7066]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6168, -0.7011, -0.7102, -0.6849, -0.7178, -0.7041, -0.5631, -0.7036]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7067, -0.6475, -0.6976, -0.6686, -0.7036]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6258, -0.5224, -0.6902, -0.7150]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I'm very unsatisfied, not thrilled at all to be honest.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7081, -0.6424, -0.6152]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7072, -0.7058, -0.7086, -0.7075]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6816, -0.7266, -0.7099, -0.7126, -0.7225, -0.7169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7238, -0.7140]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7032, -0.7201, -0.7104, -0.7043, -0.6940, -0.7112, -0.7015, -0.7230,\n",
            "         -0.7097, -0.7146]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7231, -0.7224]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7393, -0.7254, -0.7193, -0.7148, -0.7084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7112, -0.7184, -0.7085, -0.7150, -0.7132, -0.7105]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7199, -0.7178, -0.7185, -0.7198, -0.7119, -0.7141]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7480, -0.7206, -0.7276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7447, -0.7376, -0.7395]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6939, -0.7266, -0.7133, -0.7153, -0.7201, -0.7225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7242, -0.7168, -0.7161]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.7227, -0.7217, -0.7276, -0.7207, -0.7186, -0.7255, -0.7179, -0.7216,\n",
            "         -0.7250, -0.7241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7155, -0.7229, -0.7254, -0.7237, -0.7189, -0.7094, -0.7223, -0.7134,\n",
            "         -0.7074, -0.7183, -0.7086, -0.7294, -0.7164]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Marisa Peng', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7304, -0.7223, -0.7291, -0.7164, -0.7195, -0.7205, -0.7320, -0.7328]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7438, -0.7365, -0.7472, -0.7825, -0.7129]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6958, -0.7086, -0.7083, -0.7128]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7203, -0.7180, -0.7181, -0.7050, -0.7186, -0.7203]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6977, -0.7028, -0.7353, -0.7442, -0.6944]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7074, -0.6916, -0.7491, -0.7826]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6972, -0.6975, -0.6984, -0.7000, -0.6928]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking about language, I'd prefer to communicate in English. It's the only language option available, so English it is!\n",
            "The intended answer was: English\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6664, -0.7000, -0.6643, -0.6454]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7208, -0.7098, -0.7245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6567, -0.6461, -0.7168, -0.6851]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6818, -0.7684, -0.7154, -0.7119, -0.7258, -0.7261]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7447, -0.7421, -0.7180, -0.7496, -0.7224, -0.7178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6934, -0.6978, -0.7198, -0.7135, -0.7076]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7224, -0.7230, -0.7234, -0.7248, -0.7165]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6953, -0.6604, -0.6388, -0.6327, -0.6393, -0.6281, -0.7423]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7370, -0.7270, -0.7271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.8175, -0.8390, -0.8082, -0.8325, -0.7860]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7145, -0.7206, -0.7154, -0.7113, -0.7157, -0.7417]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7382, -0.7356, -0.7256, -0.7118]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7335, -0.7253, -0.7375, -0.7475, -0.7261, -0.7324, -0.7390, -0.7437]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7689, -0.7231, -0.7251, -0.7245, -0.7171]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6563, -0.6603, -0.6538, -0.6456, -0.6768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7261, -0.7266, -0.7292, -0.7248, -0.7232, -0.7251, -0.7236, -0.7283,\n",
            "         -0.7250, -0.7228]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7460, -0.7349, -0.7454, -0.7535, -0.7322, -0.7238, -0.7457, -0.7339]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7262, -0.7177, -0.7013]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6832, -0.7028, -0.6972, -0.7093, -0.6932, -0.6866]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7150, -0.7199, -0.7188, -0.7213, -0.7185]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6969, -0.7334, -0.7204, -0.7266, -0.7216, -0.7037, -0.7261]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6584, -0.6533, -0.7348, -0.7425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6965, -0.6789, -0.6829, -0.6671, -0.6590]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'm not sure which one but German sounds like the right choice for me, I guess.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7463, -0.7368, -0.7403]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.5875, -0.6356]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I'm not sure what the options are. I guess I'll just say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7281, -0.7308, -0.7330, -0.7575, -0.7232]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7079, -0.6602, -0.6557]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7833, -0.7531, -0.7664, -0.7843, -0.7174, -0.7783, -0.7855]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7473, -0.7521, -0.7502, -0.7605, -0.7279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.8000, -0.7844]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7086, -0.6847, -0.6925, -0.7105, -0.6950]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, and also display port debugging and compliance. I think those two are interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7881, -0.7058, -0.7811, -0.7128, -0.7187]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6687, -0.7239, -0.7036, -0.7092, -0.7382, -0.7158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7168, -0.7221, -0.7260, -0.7201, -0.7225, -0.7248, -0.7206, -0.7162,\n",
            "         -0.7215, -0.7177, -0.7203, -0.7271, -0.7151]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7262, -0.7288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what options there are. I would say no for the data processing consent.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.6905, -0.7151, -0.6928, -0.7742, -0.7142, -0.6902, -0.7180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7201, -0.7213, -0.7247, -0.7154, -0.7266, -0.7551]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7126, -0.7714, -0.7158, -0.7486, -0.7194, -0.7149]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7282, -0.7301]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6853, -0.7331, -0.6986, -0.7638, -0.6818, -0.6860, -0.7681]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6936, -0.6139, -0.6340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7134, -0.7142, -0.7232, -0.7139]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7055, -0.7178, -0.7221, -0.7224, -0.7096, -0.7220, -0.7112, -0.7771,\n",
            "         -0.7228, -0.7241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7196, -0.5673, -0.5399, -0.6879, -0.7042, -0.7135, -0.7243]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7172, -0.7196, -0.6886, -0.7029, -0.6723, -0.7185, -0.7163, -0.7163,\n",
            "         -0.7151, -0.7031, -0.7133, -0.7052, -0.7176]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7120, -0.7502, -0.7137, -0.7131, -0.6812, -0.7390, -0.7050, -0.7729,\n",
            "         -0.7354, -0.7503]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7267, -0.7220, -0.7293, -0.7147, -0.7146, -0.7246, -0.7162, -0.7221,\n",
            "         -0.7275, -0.7261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7147, -0.7119, -0.7157, -0.7110, -0.7091, -0.7157]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7219, -0.7206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.6982, -0.7038, -0.6863, -0.7839, -0.6937, -0.7007, -0.7262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7214, -0.7257, -0.7283, -0.7334, -0.7238, -0.7247, -0.7276, -0.7276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6939, -0.6553, -0.6496]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7165, -0.7171, -0.7207, -0.7225]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction? I'd say, I guess, I'm satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7061, -0.6505, -0.6976, -0.6566, -0.7023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6222, -0.6334, -0.6938, -0.6543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7291, -0.7267, -0.7338, -0.8205, -0.7230]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7237, -0.7231, -0.7340, -0.7219]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7361, -0.7187, -0.7120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7068, -0.6463, -0.6772, -0.7083, -0.6770]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6739, -0.6779, -0.7118, -0.6778, -0.7096]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7008, -0.7137, -0.7077, -0.6935, -0.7050, -0.6994]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I guess it must be craft enterprises then, since that's the only one I know.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6936, -0.6363, -0.6197]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7304, -0.7492, -0.7319, -0.7695, -0.7521]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6775, -0.7036, -0.6893, -0.7098, -0.6899]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7115, -0.6956, -0.6959, -0.6986, -0.7173, -0.7281, -0.7328]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7259, -0.7259]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7151, -0.7258, -0.7173, -0.7130, -0.7036, -0.7146, -0.7114, -0.7234,\n",
            "         -0.7155, -0.7214]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7372, -0.7153, -0.7658, -0.7287, -0.7856]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6932, -0.7201, -0.7067, -0.6860, -0.6805, -0.7042, -0.6983, -0.7218,\n",
            "         -0.7026, -0.7183]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7251, -0.7163, -0.7209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6776, -0.7184, -0.6821, -0.6673, -0.6517, -0.6794, -0.6736, -0.7207,\n",
            "         -0.6785, -0.7067]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7103, -0.7010, -0.7001, -0.6827, -0.6955]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7176, -0.7207, -0.7225, -0.7167, -0.7254, -0.7685]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7266, -0.7363, -0.7739, -0.7242, -0.7250]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7243, -0.7588]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7099, -0.6915, -0.6794, -0.7005, -0.6778, -0.6992, -0.7154]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, huh. I guess that would be End User then.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7074, -0.6999, -0.6910, -0.7061, -0.7075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7202, -0.7091, -0.7283, -0.8042, -0.7186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7245, -0.7251]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7128, -0.7210, -0.7091, -0.7146, -0.7171, -0.7114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JTS', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7150, -0.7150, -0.7192, -0.7141, -0.7130]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6921, -0.7134, -0.6925, -0.6818, -0.6967, -0.6871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm I think it's a craft enterprise company, I don't know all the options available though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5225, -0.5093]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.6955, -0.7205, -0.6943, -0.7120, -0.6797, -0.7083, -0.7216]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7213, -0.7196, -0.7189, -0.7202, -0.7231, -0.7254, -0.7237]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7219, -0.7218]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7209, -0.7220, -0.7239, -0.7366, -0.7311, -0.7110, -0.7246, -0.7249,\n",
            "         -0.7225, -0.7211, -0.7221, -0.7270, -0.7307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Marisa Peng', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7249, -0.7166, -0.7241, -0.7341, -0.7423, -0.7642]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6977, -0.7285, -0.7241, -0.7139, -0.7336, -0.7536]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6964, -0.7205, -0.7083, -0.6924, -0.6788, -0.7088, -0.6977, -0.7234,\n",
            "         -0.6992, -0.7176]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7234, -0.7017, -0.7745, -0.7558]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, well I suppose I'd say a new customer then. I really have no other information about this.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7149, -0.7189, -0.7186, -0.7174, -0.7199, -0.7178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7854, -0.8146, -0.7693, -0.7997, -0.7725]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6649, -0.7047, -0.7118, -0.7094, -0.7087]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7370, -0.7347, -0.7480, -0.7475, -0.7334, -0.7346, -0.7270, -0.7440]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6639, -0.6723, -0.6793, -0.6742, -0.6975]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7191, -0.7177, -0.7190, -0.7230, -0.7188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7173, -0.7319, -0.7262, -0.7292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7420, -0.7347, -0.7365]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in a week, I think.  I don't know what other options there are.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6341, -0.6499, -0.6815, -0.7246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7720, -0.7097, -0.6930, -0.7173, -0.7611]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7053, -0.7010, -0.7275, -0.7353, -0.7298]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6634, -0.6398, -0.6604, -0.6606, -0.6865, -0.6702, -0.7368]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7270, -0.7213, -0.7235, -0.7124, -0.7288, -0.7228]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7441, -0.7353, -0.7367]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.7239, -0.7227, -0.7314, -0.7436, -0.7128, -0.7152, -0.7306, -0.7393]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7077, -0.6889, -0.7000, -0.6834, -0.7128]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I'm not sure of the exact options but I'd guess our company is between 1 and 10 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7153, -0.7222, -0.7143, -0.7133, -0.7242, -0.7155]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7053, -0.6940, -0.7170, -0.7460]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7123, -0.7541, -0.7521, -0.7042]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6166, -0.6042, -0.7114, -0.7124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6745, -0.6158, -0.6277]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step should be offer, yeah that sounds about right.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7255, -0.7187, -0.7219, -0.7225, -0.6916]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7335, -0.7247, -0.7592, -0.7225, -0.7183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I think I would search for a solution to clean up the CRM or maybe to improve CRM data quality.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6993, -0.7228, -0.7245, -0.7244, -0.7214]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7080, -0.6945, -0.6869, -0.6790, -0.6671]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7858, -0.7697, -0.7714, -0.7067, -0.6995]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7736, -0.7521, -0.7901, -0.7844, -0.7332]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7094, -0.6988, -0.7185, -0.7188]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7359, -0.7277, -0.7302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.6844, -0.6791, -0.7077, -0.7094, -0.7053]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6770, -0.6967, -0.6783, -0.6594, -0.6629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6555, -0.6261, -0.7031, -0.7254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7837, -0.7924, -0.7864, -0.7266, -0.7519, -0.7790, -0.8050, -0.7990]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7118, -0.7153, -0.7149, -0.7205]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7073, -0.6977, -0.7254, -0.6964]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7070, -0.7145, -0.6922, -0.7169, -0.6865, -0.6995, -0.7357]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7142, -0.7140, -0.7161, -0.7104, -0.7151, -0.7183, -0.7081, -0.7352,\n",
            "         -0.7168, -0.7191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7354, -0.7263, -0.7314, -0.7420, -0.7233, -0.7251, -0.7357, -0.7488]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I've heard of Pipedrive, which is supposed to be good. Is there anything else, though?\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7195, -0.7162, -0.7215, -0.7212]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7171, -0.7137, -0.7174, -0.7212, -0.7193, -0.7047, -0.7142, -0.7193,\n",
            "         -0.7134, -0.7134, -0.7147, -0.7243, -0.7255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7298, -0.7158, -0.7327, -0.7355, -0.7124]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6818, -0.6856, -0.7113, -0.7000, -0.7172]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7106, -0.6980, -0.7150, -0.7660, -0.7182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7272, -0.7195, -0.7235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7047, -0.7063, -0.7097, -0.7115, -0.7181]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7212, -0.7223]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, about data processing consent? Hmm, it looks like the only option is \"No\". So, I'm saying no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7114, -0.7404, -0.7267, -0.7272, -0.7330]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6995, -0.6995, -0.7120, -0.7099, -0.6983, -0.6290, -0.7629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I really dont know but if i had to guess it's probably around 12 people on average, it could also be in the 11-15 range I suppose.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6960, -0.6863, -0.7005, -0.7016, -0.7133]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6735, -0.6783, -0.6991, -0.7100, -0.6966]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question. I'm honestly not sure of the exact number. I think we have somewhere around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7193, -0.7388, -0.7222, -0.7247, -0.7314, -0.7362, -0.7372, -0.7182,\n",
            "         -0.7316, -0.7208, -0.7143, -0.7530, -0.7392]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7526, -0.7744, -0.7910, -0.7133, -0.7206]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6767, -0.6360, -0.6896, -0.6954, -0.6739]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7051, -0.6821, -0.7008, -0.7325]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3368, -0.2523, -0.0625, -0.2732, -0.1860, -0.2773, -0.7183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it is R&D because it makes the most sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7148, -0.7186, -0.7232, -0.7264, -0.7224, -0.7191, -0.7192, -0.7187,\n",
            "         -0.7176, -0.7163, -0.7190, -0.7234, -0.7151]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7353, -0.7455, -0.7386, -0.7386, -0.7494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7158, -0.7225, -0.7252, -0.7126, -0.7171, -0.7229, -0.7137, -0.7284,\n",
            "         -0.7241, -0.7252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7371, -0.7303, -0.7829, -0.7318, -0.7179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7260, -0.7146, -0.7130]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.7328, -0.7260, -0.7208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7353, -0.7293, -0.7324, -0.7462, -0.7155, -0.7132, -0.7353, -0.7403]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Well, for a CRM system, I'd recommend HubSpot, it’s a popular choice.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7310, -0.7173, -0.7195]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7082, -0.7008, -0.7050, -0.6777, -0.7049]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7118, -0.7197, -0.7147, -0.7134, -0.7109]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7139, -0.7185, -0.7174, -0.7141, -0.7112]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7599, -0.8329, -0.7767, -0.7797, -0.7173]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7045, -0.7040, -0.7057, -0.6976, -0.7164, -0.7041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7153, -0.7128, -0.7109, -0.7002, -0.7146, -0.7110]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, well I believe it's a construction company. Yeah, that makes sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7157, -0.7491, -0.7074, -0.7159, -0.7202, -0.7170]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JTS']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7361, -0.7035, -0.7231, -0.7616, -0.7526, -0.7536, -0.7651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5586, -0.6337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd have to choose \"No\". So, yeah, \"No\" is the option I'm going with.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.8053, -0.7309, -0.7207, -0.7385, -0.7212]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7274, -0.7265, -0.7335, -0.7386, -0.7181, -0.7254, -0.7327, -0.7384]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7143, -0.6930]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.6790, -0.6997, -0.7063, -0.6726, -0.7041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7180, -0.7193]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.7123, -0.6733, -0.7445, -0.7496, -0.7341, -0.7796, -0.8044]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7170, -0.7279, -0.6914, -0.7089, -0.6981, -0.6951, -0.6943, -0.6433,\n",
            "         -0.7020, -0.7551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7327, -0.7753, -0.7431, -0.7877, -0.7512]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6736, -0.6789, -0.6948, -0.7057, -0.7141]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6672, -0.6952, -0.6975, -0.7090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7450, -0.7193, -0.7295, -0.7281, -0.7159]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7428, -0.6607, -0.5949, -0.6978, -0.7027, -0.7480, -0.7592]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6855, -0.7014, -0.6903, -0.7100, -0.6872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6581, -0.6942, -0.6678, -0.6654, -0.6640, -0.6667, -0.7110, -0.6756,\n",
            "         -0.6801, -0.6895]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7105, -0.6709, -0.6617]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6954, -0.6943, -0.6786, -0.7231, -0.6763, -0.6827, -0.7190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7121, -0.7060, -0.7139, -0.7174]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6792, -0.6824, -0.7092, -0.7337, -0.7204]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I really don't know the exact size. Hmm, is it like larger than 2000? I'm guessing that might be right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7235, -0.7535, -0.7616, -0.8002, -0.7169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6864, -0.6549, -0.6379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, I guess I could **offer** something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7070, -0.6992, -0.6953, -0.7080, -0.6941]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6692, -0.6777, -0.7654, -0.7668]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, hmm, I guess I would be an existing customer. I think that's the option that makes the most sense for me.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7200, -0.7167, -0.7278, -0.7232]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7730, -0.7267, -0.7148, -0.7068, -0.6987]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7226, -0.7199, -0.7198, -0.7158, -0.7262, -0.7413]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7121, -0.7130, -0.7135, -0.7122, -0.7141, -0.7166]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7222, -0.6830, -0.6844, -0.7463, -0.7017, -0.7019, -0.7422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh I think it would be distributor, that sounds right for this.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7222, -0.7415, -0.7921, -0.7383, -0.7241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7103, -0.7145, -0.7182, -0.7250, -0.7271]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, our company size is 51-200 people. That's the only size range I'm aware of, so we must fit into that category.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7374, -0.7183, -0.6886]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.7491, -0.7499, -0.7454, -0.7487, -0.7279, -0.7151, -0.7512, -0.7274,\n",
            "         -0.7441, -0.7250, -0.7422, -0.7325, -0.7544]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6822, -0.7235, -0.6960, -0.6835, -0.6729, -0.6837, -0.6882, -0.7191,\n",
            "         -0.6834, -0.7108]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7261, -0.7243, -0.7235, -0.7209, -0.7214, -0.7221, -0.7202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7097, -0.7131, -0.7098, -0.7125]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7167, -0.7140, -0.7193, -0.7272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7426, -0.7335, -0.7472, -0.7489, -0.7609, -0.7458]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2191, -0.4638, -0.4381, -0.0652, -0.5266, -0.5011,  0.1304, -0.7431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6811, -0.7257, -0.7070, -0.7152, -0.7191, -0.7158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7986, -0.7269, -0.7938, -0.7326, -0.7124]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6722, -0.7029, -0.7065, -0.7106, -0.7045]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7442, -0.7614, -0.7239, -0.7300, -0.7147]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.6716, -0.7060, -0.7126, -0.7128, -0.7093]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7155, -0.7178, -0.7237, -0.7251, -0.7221, -0.7252, -0.7167, -0.7141,\n",
            "         -0.7239, -0.7209, -0.7119, -0.7330, -0.7309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7790, -0.7492, -0.7472, -0.7383, -0.7211, -0.7172]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7172, -0.7202, -0.7190, -0.7221, -0.7099]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7076, -0.6718, -0.6611, -0.7040]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7465, -0.7369, -0.7405, -0.7617, -0.7347, -0.7401, -0.7488, -0.7295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6665, -0.6873, -0.7277, -0.7273]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7103, -0.6683, -0.6180]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh um, I guess the next step would probably be meeting, yeah.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.6819, -0.7214, -0.6967, -0.6883, -0.6858, -0.7017, -0.6907, -0.7175,\n",
            "         -0.6931, -0.7119]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7224, -0.6717, -0.7365, -0.6652, -0.7095]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7453, -0.7421, -0.6996, -0.7397, -0.7269, -0.7323, -0.7376, -0.7782,\n",
            "         -0.6951, -0.7383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7051, -0.7232, -0.7216, -0.7244, -0.7254, -0.7193]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7143, -0.7141, -0.7141, -0.7186, -0.7155]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7318, -0.7271, -0.7325, -0.7207, -0.7258, -0.7276, -0.7344, -0.7373]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6975, -0.7332, -0.7228, -0.7683, -0.6956, -0.7082, -0.7487]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7174, -0.7259, -0.7257, -0.7201, -0.7261, -0.7087, -0.7259, -0.7179,\n",
            "         -0.7237, -0.7268, -0.7224, -0.7241, -0.7144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Marisa Peng', 'Jessica Hanke', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7221, -0.7271, -0.7266, -0.7212, -0.7278]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7107, -0.7183, -0.7228, -0.7231, -0.7161]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7198, -0.7212, -0.7211, -0.7181, -0.7162, -0.7165, -0.7162, -0.7213,\n",
            "         -0.7204, -0.7201]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7071, -0.7439, -0.7170, -0.7094, -0.7201, -0.7120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.7421, -0.7254, -0.7046, -0.7144, -0.7784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.7209, -0.7196, -0.7184, -0.7154, -0.7152, -0.7173, -0.7183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7324, -0.7323, -0.7381, -0.7813, -0.7277]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7161, -0.7173, -0.7254, -0.7177, -0.7164]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7528, -0.6620, -0.6671]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I think the next step should be to offer, I suppose.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7151, -0.7127, -0.7176, -0.7163, -0.7168, -0.7180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7220, -0.7254, -0.7260, -0.7232, -0.7232]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.7231, -0.7272, -0.7267, -0.7162, -0.7116, -0.7252, -0.7168, -0.7246,\n",
            "         -0.7231, -0.7260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7086, -0.6901, -0.6806, -0.6387, -0.7129, -0.6945, -0.7208, -0.6030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.7029, -0.7071, -0.7101, -0.7016, -0.7070, -0.7153]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7028, -0.7129, -0.7084, -0.7087, -0.7251, -0.7235]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6447, -0.6145, -0.6158]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.7100, -0.7120, -0.7148, -0.7063, -0.7102, -0.7083]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, a company, hmm. I guess it must be a scaffolding company. I'm not really sure though, sorry.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7025, -0.6928, -0.6825, -0.7031, -0.7144, -0.7032, -0.7352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.7232, -0.7249]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7154, -0.7140, -0.7217, -0.7274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7444, -0.7751, -0.7276, -0.7437, -0.7187]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "The metrics for all open-ended questions in the train dataset:\\m{'accuracy': 0.651180797522261, 'f1': 0.4153147306943543, 'precision': 0.4497540407589599, 'recall': 0.3857745629897529}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "id": "9Ss0cdN_Y1tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### XLNet base model (cased)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gDwuXt2qX176"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"xlnet/xlnet-base-cased\"\n",
        "mc_model = XLNetForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fT6kyrCMOsx",
        "outputId": "1676316b-af15-48a7-832b-27a369e808f2"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForMultipleChoice were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)\n",
        "print(f\"The metrics for all open-ended questions in the train dataset:\\n{mc_metric_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vhm6x-iPd6n",
        "outputId": "705b5e73-cb14-4acb-fec0-70ffede2e79d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1831, 0.1568]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2677,  0.1753,  0.1103, -0.0263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, I can either call you, *phone*, or we can *schedule a visit*. If neither is needed, we'll take *no action*.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0766, -0.0440,  0.0239,  0.0230,  0.1300,  0.0417,  0.1068]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2129, -0.2678,  0.2089,  0.0660,  0.1731,  0.2041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in JTS, AKW100, and AX100. I'm not really sure what other options there are.\n",
            "The intended answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0762, 0.2540, 0.0423, 0.2119]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, the customer type is an **Applicant**. That's the only option available, so it must be who we're dealing with.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2408, -0.0395, -0.1318,  0.2164,  0.0197, -0.0852,  0.2389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1286, 0.1937, 0.2265, 0.2276, 0.1452]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1576, 0.3916, 0.1349, 0.2387, 0.3354, 0.2769]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0691, 0.1697]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0031, 0.1256]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3861, -0.2598, -0.0588, -0.1346, -0.1169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something, like, to clean up CRM or extract data from emails. I might also improve CRM data quality or maybe even capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1875, 0.0458, 0.0645, 0.2393, 0.2864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, well, maybe scan business cards or, I could clean up the CRM, or capture trade fair contacts, yeah. I would choose all of them I guess.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0746, -0.0148,  0.0461,  0.0274, -0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in English, since that's the language I know best.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0977, -0.1147,  0.0110,  0.1277, -0.0155, -0.0354,  0.0803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1446, 0.2430, 0.2213, 0.1569, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1564, -0.0400, -0.0821,  0.0426,  0.0592,  0.1307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation, maybe something around joining systems for large components, or possibly additive manufacturing;  I'm not sure, it could even be advanced manufacturing or something else entirely.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0660, 0.1997]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0144, 0.0515, 0.1085, 0.0710, 0.0891, 0.1615, 0.0906]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say more than 40 people, I don't really have an exact number, though.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1891, 0.4119]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3617, -0.2818, -0.4025, -0.3491, -0.3612]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'd be interested in noise figure measurements, double-pulse testing and high-speed interconnect testing, those seem like good things to explore.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2374, 0.1258, 0.0395, 0.2658, 0.2024, 0.3016, 0.2897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I'm not sure about all the options, but I guess the customer group is R and D, so I'll just say R and D.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2238,  0.1670, -0.1410,  0.0553,  0.0391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess, searching for a solution for this seems like it's probably empty. I really don't know what else it could be.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0530,  0.1887,  0.2107, -0.0867,  0.1275,  0.0838, -0.0162,  0.0708]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I think a CRM system? Hmm, I guess maybe Pipedrive would be it.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0232, 0.1831, 0.2221, 0.2149]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1354, -0.2726, -0.0557, -0.1638, -0.3178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in Double-Pulse Testing,  because it sounds interesting, and Display port debugging and compliance, as I'd like to learn more about that.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2159, -0.1426, -0.2600, -0.2019, -0.2238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the specific count but if I had to guess, maybe around 500 employees? It feels like a mid size company to me.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3086, -0.0777, -0.0072,  0.0973,  0.0953]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in BusinessCards, also DataEnrichment, Data Cleansing and definitely DataQuality, I guess those are the main things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0700,  0.1106,  0.1988, -0.0274,  0.1450,  0.1964,  0.0197,  0.2114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not sure which CRM system that is. Maybe CAS, I don't know, I'd choose that.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0911,  0.0145, -0.2220, -0.0787,  0.0007,  0.0636]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well, I like MY-SYSTEM, and also Notion, plus AKW100, and finally AX100, those are what I am interested in I guess.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0670, 0.1758, 0.0216, 0.1758, 0.2917]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier, or even someone from the press or media, I'm really not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2102, 0.1719, 0.1585, 0.1374]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think they're an existing customer,  I don't know what other options there are.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0985, 0.2461, 0.1055, 0.1162, 0.1576, 0.2761, 0.1901, 0.0833, 0.1712,\n",
            "         0.2671, 0.1192, 0.1952, 0.2491]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for the follow up, I guess I should copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Domiki Stein, and also Tim Persson then.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0313,  0.1129,  0.1137,  0.1200]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Okay, so when it comes to customer satisfaction, I guess I'd say I'm likely just, well, 'Satisfied'. That's all they provided as an option.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1820, 0.2268]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1830, -0.0821,  0.0300, -0.0153, -0.1668]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get the information, or maybe extract data from emails if there's relevant information there.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2199,  0.2082, -0.0385]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3405, -0.2621, -0.2757, -0.4071, -0.3895]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because they're useful for networking.  Data enrichment and cleansing also sound important to me, for keeping information accurate and complete.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.2323, 0.1241, 0.1572]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess the customer type would be an Applicant.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0133, -0.0910, -0.1888,  0.0929,  0.1307, -0.1044]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2091, 0.2326, 0.2568, 0.1902, 0.1364, 0.0706]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I think it must be a craft enterprise then.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0399,  0.0851,  0.1128,  0.2477]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied, that's how I feel about my experience.  I don't know what other options there might be.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1094,  0.1543, -0.0002,  0.0265, -0.0081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess a solution could be cleaning up the CRM, extracting data from emails, or even capturing trade fair contacts. I am not really sure which of those it could be.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1331,  0.0190,  0.0424, -0.1111,  0.2764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1071, 0.1388, 0.1123, 0.1826, 0.1129]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh umm, I guess Japanese is what you're looking for.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0092, 0.1134]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent? I guess the only option here is 'Yes', so, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2036, 0.2392]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I think yes, I'd like to receive emails.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1360, 0.1532, 0.1321, 0.0101, 0.0217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, if you're asking about which language I should use, then it's **Spanish**. I only know to speak that one right now.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1641, -0.1756, -0.2749, -0.2429, -0.3231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I am interested in automotive radar target simulation and also display port debugging and compliance. Those seem like interesting things to learn about.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0735, 0.1091, 0.1446, 0.1336, 0.1297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I suppose English is the language that would work best.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0377,  0.0617, -0.1036,  0.1836, -0.0980]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I'm trying to find something that will either let me scan business cards or improve CRM data quality. Either of those would be really helpful.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0967,  0.1241,  0.1629,  0.0859, -0.0209]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0302,  0.1740,  0.0737, -0.0178,  0.2245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1039,  0.2376, -0.0557,  0.0887,  0.1492]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. I guess it's either an existing customer or press media, probably something along those lines.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5072, -0.3117, -0.3911, -0.3531, -0.4866, -0.3704, -0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess it would be Wholesaler. That seems like the best fit.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2419,  0.0204, -0.1264, -0.0767, -0.0898, -0.3844, -0.0445, -0.2439,\n",
            "         -0.1945, -0.0456, -0.2229, -0.3349, -0.0719]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Erik Schneider, Angelina Haug, Johannes Wagner, Jens Roschmann, Domiki Stein, and Tim Persson;  I think they all need to be kept in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0158,  0.1290,  0.0050,  0.1788, -0.0710,  0.1912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2432, 0.2466, 0.3895, 0.1494, 0.2213, 0.2013, 0.1790, 0.2661]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not really sure which CRM system that is. I guess I'd say HubSpot.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1648, -0.0322,  0.0631,  0.2920]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think it will be an email. Maybe no action is the other option, but I am not sure.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0441, -0.0136,  0.0231, -0.0461,  0.0012,  0.0074,  0.1155]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I really don't know but maybe about 35 people, that's a guess.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0836, 0.1202, 0.0691, 0.0445, 0.0213, 0.2128]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1158, 0.1533, 0.2497, 0.1458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh I guess it would be existing customer, if that's the only option. I mean, is that what you're asking?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2594, 0.1007, 0.1902]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, next steps, hmm... I guess I could *Call*. That seems like a reasonable thing to do next.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2567,  0.1069, -0.0441,  0.1965,  0.1186, -0.1220,  0.0703,  0.1572,\n",
            "         -0.0913, -0.0758]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm operating in the industrial area then, that's the one I know of.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1139, 0.0954, 0.1196]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0412, -0.0943, -0.0487,  0.1957,  0.1670, -0.2280]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's a production company. That means they probably make movies, TV shows, or something similar.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2414, -0.2773, -0.1064, -0.0044]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1831, -0.0996, -0.0878, -0.3240, -0.1170]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and high-speed interconnect testing. Those seem pretty cool, I think.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 1.2738e-01, -2.0918e-01,  3.3855e-05,  2.5425e-01,  2.7241e-01,\n",
            "          2.8750e-01]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0023, -0.1960, -0.0194, -0.1411, -0.0711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0097,  0.1399,  0.0556, -0.0176,  0.1333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0439,  0.0073,  0.2669, -0.0055,  0.1286,  0.2396,  0.0423,  0.1397]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0722, 0.0036]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.  I don't want my inbox cluttered.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0863,  0.1231, -0.1016,  0.1042, -0.1062]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess I'd pick \"Clean up CRM\" and \"Capture trade fair contacts\", if those are the only options available. I don't know the other ones.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2283, -0.2227, -0.1763, -0.2191, -0.3420]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so for communication, I see we could use German. That's the only language option available.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2479, 0.1864, 0.1842, 0.2254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I think the customer type is Partner, I'm not sure what else there could be.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2055, 0.2262, 0.2343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, so for the follow up, I think either **2 weeks** or **3 weeks** would work; they seem to be the options I have to choose from.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1399, 0.2356, 0.0424, 0.2110, 0.2975]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a supplier, maybe even press or media.  I'm not sure,  it could be either one.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2099,  0.0292,  0.0848,  0.0045,  0.0146]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1321, -0.0526,  0.0172,  0.0501, -0.2199,  0.2461]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1497, -0.1832, -0.0651,  0.2628,  0.3321,  0.2515]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.1543,  0.0110, -0.0151,  0.0173,  0.1329]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer,  but it could also be a new customer or prospect, or maybe even press or media; I really don't know.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1519,  0.0146]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1504,  0.0345, -0.3943, -0.2806, -0.2593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation. Also double-pulse testing seems intriguing. I would explore display port debugging and compliance too, plus high-speed interconnect testing is definitely up my alley.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1323, -0.0442, -0.2953, -0.0598, -0.0373, -0.0158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and JS EcoLine, those are the ones I like.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1157, 0.1007]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0555,  0.0536,  0.0456,  0.0717, -0.0516]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1705, -0.0963,  0.0901, -0.0423,  0.1246]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I think I am interested in high-speed interconnect testing, if that's an option.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0457, -0.0405, -0.0994,  0.1204, -0.1491,  0.0230,  0.0311, -0.0755,\n",
            "          0.1082, -0.0073, -0.0802, -0.0072,  0.0651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1053, -0.0472,  0.0754, -0.0650, -0.0314,  0.0464, -0.0727, -0.0068]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0515, -0.1470,  0.1086]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think we should have a meeting next.  That seems like the best way to move forward.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0289, -0.0539]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like that actually.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2532, -0.3074,  0.1772,  0.0863,  0.2679,  0.1422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0083,  0.0710, -0.0714,  0.0442,  0.2781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3970, 0.3062, 0.4327, 0.3721, 0.1592, 0.3737, 0.4064, 0.3946, 0.3050,\n",
            "         0.3002, 0.3404, 0.3390, 0.4222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0821, -0.0872,  0.0081, -0.0187, -0.0361, -0.0959,  0.0058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0267, -0.0574, -0.2140, -0.0012, -0.1556, -0.2334, -0.0499, -0.0629,\n",
            "          0.0003,  0.0905, -0.1260, -0.1723, -0.0401]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0833, -0.0184, -0.0980,  0.0012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1827,  0.2686,  0.1261, -0.0795,  0.3963]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2852, 0.0685, 0.3333, 0.1760, 0.1002, 0.1794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2095, -0.0739, -0.2720,  0.0004, -0.0622]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0509,  0.1544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, hmm, yes I guess I would, sure.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3526, -0.3964, -0.3046, -0.1413, -0.1422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0895, -0.0676, -0.2448, -0.2056, -0.3095, -0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0337,  0.0832, -0.1116,  0.1931,  0.0323,  0.2524,  0.2400]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0517,  0.1024,  0.2517,  0.2409,  0.1353,  0.1605,  0.1583,  0.0989,\n",
            "         -0.0879,  0.1629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1156, 0.1245, 0.1311, 0.0234, 0.0352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1287, 0.0092, 0.1418, 0.0729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1387, -0.0108, -0.0771,  0.1546, -0.1297,  0.0900,  0.0410, -0.0399,\n",
            "         -0.1364, -0.0236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2366, 0.2021]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0644,  0.1234,  0.0074, -0.1216,  0.0161]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2693, -0.2439, -0.2066, -0.1333, -0.2367,  0.1816, -0.3005, -0.2197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1369, 0.1464, 0.2357, 0.0879, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0034,  0.1084,  0.1241,  0.0724,  0.2959,  0.0720,  0.1460]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1433, 0.2438, 0.2471, 0.3882, 0.2307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0192,  0.3552,  0.0197, -0.2763,  0.3421]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1088, -0.0143, -0.0584, -0.0379]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1771, -0.0167, -0.3909, -0.3232, -0.2608]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0190, -0.5048, -0.4236, -0.2770, -0.0673, -0.0822]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2095, -0.0796, -0.4788, -0.2838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer. I guess that's what I would be.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1689, 0.1527, 0.1880]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1845, 0.3375, 0.2527, 0.2456, 0.1738]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1665, -0.4551,  0.0431, -0.0455,  0.0543]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1515, 0.2518]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3725,  0.3515, -0.0989, -0.2279, -0.1899,  0.1359,  0.0337, -0.2427,\n",
            "         -0.0588,  0.1709, -0.1554, -0.0581, -0.0179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1249, -0.1426, -0.1277, -0.1215, -0.1322, -0.1270, -0.0607]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1674, 0.1139, 0.0882]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.3520, -0.2523, -0.1131, -0.3067, -0.1179, -0.1488, -0.5742,  0.1037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1514,  0.1529, -0.1055,  0.0670, -0.1292,  0.0167, -0.1325, -0.0404,\n",
            "         -0.0373,  0.1342, -0.1426,  0.0715,  0.0120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0008, -0.1073, -0.2458,  0.0753, -0.0280,  0.0650]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0008, -0.0635,  0.0235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0765, -0.2042, -0.1317, -0.0952, -0.0060, -0.2002,  0.0760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1042,  0.1013,  0.1380,  0.2217,  0.0484,  0.1794,  0.0433,  0.1056,\n",
            "         -0.1326,  0.0729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0201, -0.0774, -0.0888, -0.0675, -0.0304,  0.0172,  0.0852, -0.1618,\n",
            "         -0.1638,  0.0736, -0.0899, -0.0161, -0.0905]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1955, -0.0203, -0.1694, -0.2142,  0.0820]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2363, 0.3272, 0.2074, 0.1586, 0.2575]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh I'm not really sure about the company size, but I'd guess it's around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2261, 0.1402, 0.0552, 0.1994, 0.0097, 0.0979, 0.0903, 0.1210, 0.0766,\n",
            "         0.1083, 0.3608, 0.1130, 0.1099]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0542, -0.2153, -0.0932,  0.1319,  0.1180,  0.1824]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1019,  0.0950,  0.2315,  0.1671, -0.0140,  0.2346,  0.0131,  0.3686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1505, 0.0624, 0.1201, 0.2437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, well, I guess I'd say I'm very satisfied, if that's an option, it's definitely my answer.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0357,  0.0839,  0.0974,  0.0880,  0.1156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0339, -0.0045, -0.1572, -0.0425,  0.1219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0626, 0.0122, 0.1935, 0.1152, 0.0105]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2498,  0.1206,  0.0049,  0.1308,  0.0518, -0.0949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3048, -0.1701, -0.2304, -0.1820, -0.2272]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1872, 0.1660]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2903, -0.3018,  0.1233, -0.0126,  0.1277,  0.2268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0438,  0.1152, -0.1129,  0.2474,  0.0704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1356,  0.0415, -0.3501, -0.2696, -0.1027]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1446, -0.0740, -0.2488, -0.0755, -0.2197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0658, -0.1386, -0.0357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1259, 0.1884, 0.2003, 0.2129]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2603, 0.2303, 0.2442]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1675,  0.1239,  0.2476,  0.2444]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I think, I'd have to say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2139, 0.1922, 0.1730, 0.1292, 0.1932]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1466,  0.1895,  0.1603,  0.2424, -0.0703,  0.1389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1774, 0.1218, 0.1670]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2337,  0.1912,  0.0426,  0.1719,  0.0376, -0.0556,  0.0348,  0.1274,\n",
            "          0.0493,  0.1982]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3658, -0.0278,  0.0947,  0.1314,  0.2300,  0.2567]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1033, -0.1463,  0.1062,  0.0651,  0.0492,  0.1052,  0.1360]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1537, 0.1276, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1653, 0.1719, 0.0634, 0.3095, 0.1664, 0.3160, 0.3003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0940, -0.4606, -0.3329, -0.3222, -0.4016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0188, -0.0178, -0.0778,  0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0139, -0.1347, -0.0891, -0.0212, -0.1379,  0.0457, -0.0431, -0.1875,\n",
            "         -0.0995, -0.0753,  0.0954, -0.0357, -0.1888]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2350,  0.1116,  0.0358, -0.1287,  0.1176,  0.0607,  0.1203,  0.0212,\n",
            "         -0.3073, -0.1695]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1417, -0.0635, -0.0534, -0.2142, -0.0609, -0.1611, -0.1633,  0.1258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0068, 0.2355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1778, -0.2789, -0.1748, -0.2455, -0.3215, -0.1571]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0920, -0.1276,  0.0888,  0.1681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2022, -0.0922,  0.1182,  0.1729,  0.0989,  0.1347,  0.1104,  0.0297,\n",
            "          0.0141,  0.0190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1997, -0.0930]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0149, -0.0891,  0.0408,  0.0496,  0.0340,  0.0229,  0.0415]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1857,  0.1383,  0.1391,  0.3452,  0.2202,  0.0480,  0.2143,  0.1375,\n",
            "          0.0028, -0.0674]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3267, -0.2442, -0.2369, -0.2395, -0.1120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1381,  0.1478, -0.0360,  0.0689,  0.1165,  0.1874,  0.1547]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1765, -0.0390, -0.1419, -0.0892,  0.2693]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1876, 0.0386, 0.2522, 0.2792]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 6.0263e-02,  2.6899e-01, -2.5292e-02,  2.6579e-02,  1.7972e-04]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1904, -0.2642, -0.1097]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0389, -0.0509, -0.0134,  0.0264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, customer type. I guess that would be existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2308, -0.0356, -0.1336, -0.1711,  0.0902, -0.0279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0065,  0.1110,  0.0546, -0.0131,  0.0252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh umm, I guess I'd prefer German then, if that's an option. I'm not sure what other choices there are.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0622, -0.0097, -0.1505, -0.0884, -0.1237, -0.1400]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1107,  0.1217, -0.0309, -0.0250, -0.2529, -0.0477]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1811, 0.3615]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2153, 0.2363, 0.3202, 0.2714, 0.2921, 0.2332, 0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1286, 0.1937, 0.2265, 0.2276, 0.1452]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1457, -0.4437, -0.0443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0619, -0.1235, -0.1078, -0.1369, -0.0245, -0.0375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0198,  0.1035, -0.0553, -0.0225,  0.2138]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0166,  0.1818, -0.0863,  0.0568,  0.0585, -0.1588]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2707, -0.0996,  0.1022,  0.2386, -0.0514,  0.0983,  0.1115, -0.0252,\n",
            "         -0.1812, -0.0623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1525,  0.0523,  0.0778, -0.0280,  0.3731]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0324,  0.0802, -0.0676, -0.0637,  0.0255, -0.0822,  0.0128, -0.0556,\n",
            "         -0.0533, -0.1101, -0.0967, -0.0534, -0.0674]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1618, -0.1736, -0.2899,  0.1032]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0207, 0.3861]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2623, 0.1512, 0.1975]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1650, 0.2576, 0.1154, 0.2542]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0556,  0.0022,  0.0669,  0.0660]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1686, -0.1015, -0.1172, -0.0361, -0.0166,  0.0362,  0.1003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1223, -0.0973, -0.1906, -0.0477, -0.0005, -0.3108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0437, -0.1988, -0.0497,  0.1150]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1142,  0.0087, -0.0331, -0.0105,  0.1825]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2616, -0.0779,  0.0521, -0.0050,  0.0794, -0.0100,  0.1269,  0.0652,\n",
            "         -0.3471,  0.0165]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1615, 0.3714, 0.2063, 0.2286, 0.0985]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2422, 0.1786, 0.0250, 0.0089, 0.1522]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2464, 0.1419, 0.3500, 0.2700, 0.0960, 0.2609, 0.2342, 0.1893]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1680, -0.0259, -0.1622,  0.0609,  0.2405]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2239, 0.2112, 0.2777, 0.2078, 0.3574]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1472, 0.0671, 0.2528, 0.2091, 0.2492]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1194, 0.2090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0130,  0.2199,  0.1280,  0.0784, -0.0745,  0.1152,  0.1273, -0.0575,\n",
            "          0.0611,  0.1369,  0.1953,  0.1273,  0.1095]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2757,  0.0727,  0.1425,  0.0542,  0.0371, -0.0929, -0.0943,  0.0415,\n",
            "         -0.1202, -0.0360]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0074,  0.0662, -0.0567, -0.2108,  0.0746, -0.0529, -0.0629,  0.1666]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0709, -0.0980,  0.0497, -0.0266,  0.0059, -0.0483,  0.0403]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0326, -0.0684, -0.0469, -0.0043,  0.1931]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0937, -0.1220,  0.0052]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1228, -0.0969, -0.1746, -0.1103,  0.0465]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1003, -0.0912]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0585, -0.1061, -0.0931, -0.0503,  0.3546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3398, -0.1947,  0.0070, -0.0358, -0.3704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1764, -0.1522,  0.1094,  0.0098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4458, -0.5197, -0.3438]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess my next step would be offer.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1603, -0.0308, -0.0059,  0.0282,  0.1692,  0.2326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0711,  0.1532,  0.0325]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1376, 0.0124, 0.2681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2418, -0.1004,  0.0916,  0.0696]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1235,  0.2207, -0.0798,  0.1568,  0.3687]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0139,  0.1453,  0.1393,  0.1909,  0.1837]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1200, -0.2495,  0.1185, -0.0580,  0.0333,  0.0114, -0.0420]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1205, -0.1080, -0.1294, -0.2247, -0.1593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0185, 0.1401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2449, 0.2931, 0.2488, 0.0976, 0.1033]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1632, -0.0657, -0.0441, -0.1551,  0.2081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2637, 0.0745, 0.0609, 0.2613, 0.3004, 0.1257]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2199, 0.2587]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1555, 0.1590, 0.2145]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.2024, -0.0772, -0.2332, -0.2433, -0.2002, -0.0529, -0.2070, -0.1196]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0033, 0.0020, 0.0065, 0.0142, 0.0259, 0.0624, 0.0949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3156, -0.3887, -0.2997, -0.2157, -0.1814]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0923, 0.2712, 0.1977, 0.1848, 0.1540, 0.0839, 0.1491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1363, 0.0819, 0.1267, 0.3406, 0.3474, 0.1942, 0.0940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0990, -0.1002, -0.0666,  0.0547,  0.0871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3160, -0.3149, -0.0690, -0.2769]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1370, 0.2142, 0.1310, 0.2435, 0.1677, 0.1736]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0739, -0.1077,  0.0937,  0.2248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0413, -0.3195, -0.0839,  0.1194,  0.1225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0237,  0.1937, -0.0553, -0.1167, -0.1457, -0.0153, -0.0161,  0.0381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1644, -0.2161,  0.2432,  0.2781,  0.2105,  0.2435]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1851, -0.0496,  0.2189]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1019, 0.1339, 0.1832, 0.1853]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2310, 0.2330, 0.0022, 0.1562]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0137, 0.0735, 0.1224, 0.1221, 0.1202, 0.1944, 0.2760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0053, -0.2722, -0.3749,  0.3885,  0.2323,  0.2308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.0572, 0.1085]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1013,  0.0104,  0.1375,  0.0471, -0.0374, -0.0880,  0.0234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3539, 0.1713, 0.1986, 0.2605, 0.2101, 0.2144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1042,  0.1057,  0.1760,  0.1547,  0.0412, -0.1846]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0243, 0.1381, 0.0603, 0.0053, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1238, 0.1101]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0625, 0.0431, 0.0752]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1384, 0.1913]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0736,  0.3032,  0.1106,  0.1870,  0.0727,  0.0412,  0.0206,  0.2092,\n",
            "          0.0426,  0.2022]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2180, -0.0789,  0.1289,  0.1138,  0.0144, -0.0063]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3035, -0.1353,  0.1465,  0.2725,  0.2112,  0.2191]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0864,  0.0547, -0.0608, -0.0226,  0.0306,  0.0424,  0.0823]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0880, -0.0201,  0.0122]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1895, -0.3490,  0.0148, -0.0959,  0.1784, -0.0200, -0.3769, -0.0947]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0237, -0.0500,  0.0265,  0.0743,  0.1724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1162, 0.3072, 0.2063, 0.1644, 0.1220]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2300, 0.3285]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1121,  0.0295,  0.2445,  0.2626]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1039, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1145,  0.0439, -0.0385,  0.0583,  0.0689, -0.1037, -0.1554,  0.0456,\n",
            "          0.1208, -0.0888]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2244,  0.3337,  0.0771,  0.0806, -0.0045]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2969,  0.0587,  0.2996,  0.2165,  0.1118, -0.0624]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0778, -0.3470, -0.0460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'll offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0781, 0.0427, 0.1671, 0.0996, 0.1408]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1249,  0.1093,  0.2690,  0.3558]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I am very satisfied, that seems like the best choice I guess.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1189, -0.1811, -0.2295,  0.0552, -0.2883, -0.2595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0642, -0.0876, -0.0396]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0955, 0.0336, 0.0485, 0.0262, 0.0233, 0.0498, 0.1934]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0581, -0.1050, -0.2081,  0.1128,  0.1697,  0.1729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2984, 0.2934, 0.2738]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.0269, 0.1677, 0.3616]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess a meeting is what's next then. I think that is the only thing on the list anyway.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1887, -0.3429, -0.4527, -0.2196, -0.3209, -0.3255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1479, -0.2432, -0.1866, -0.1110, -0.1804, -0.1667, -0.0601]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1273, 0.0838]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0675,  0.1183,  0.1689,  0.1940, -0.0971, -0.0609]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2060, 0.1387, 0.1690, 0.3206, 0.2819, 0.1765, 0.2264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0847, -0.1634, -0.1201, -0.0155]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1713, -0.0893,  0.1211,  0.1524,  0.1302]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0776, -0.1014, -0.1882, -0.0631, -0.0725]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2150, -0.0059,  0.2406, -0.0023, -0.0632, -0.0150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4293, -0.0636, -0.0188, -0.1440, -0.1289, -0.1031,  0.0314, -0.0334,\n",
            "         -0.2441, -0.1640]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0696, -0.1888,  0.0951]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0605, 0.1486, 0.2012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1958, -0.3739, -0.1351,  0.0906, -0.1180, -0.0381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2036, 0.0676, 0.0247, 0.0207, 0.0662]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1629, 0.0957, 0.1069, 0.0651, 0.1620]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2068, 0.1045, 0.0903, 0.0136]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0610, -0.2848, -0.0287, -0.0762, -0.1500]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.2293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.2818, -0.0760,  0.0089,  0.1314, -0.0763, -0.0260, -0.0680, -0.2078,\n",
            "         -0.2237, -0.1166]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0649, -0.2401,  0.0778,  0.0075, -0.1586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1449, 0.2012, 0.1949, 0.2750]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2409, 0.2154, 0.4675, 0.2396, 0.2664, 0.2227, 0.3207, 0.3014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0748, 0.2246, 0.2943, 0.3485]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0432, 0.1727, 0.1745, 0.1764, 0.1073]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1651, 0.2510]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3554, 0.4501]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1624,  0.0011, -0.0087, -0.1642, -0.0890, -0.1130, -0.0658, -0.2440,\n",
            "         -0.1378,  0.0343, -0.2223, -0.1986, -0.1802]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1075, 0.2237, 0.1620, 0.1865]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2838, -0.1145, -0.0867, -0.1380, -0.2375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0950, -0.1580, -0.0810, -0.1221, -0.1204, -0.0912,  0.0433]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1791, -0.0271,  0.2080,  0.2086,  0.3296,  0.2282]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0736, 0.0491]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.4193, -0.0619,  0.0637, -0.3117, -0.3437]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1349, -0.0379, -0.2938, -0.2758, -0.1438, -0.0748, -0.0248, -0.3626,\n",
            "         -0.1719, -0.0819, -0.0789, -0.1063, -0.3375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0719,  0.0011,  0.0603,  0.0371]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1094, 0.1606]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0004,  0.0715, -0.0349,  0.0522,  0.0847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2222, 0.2593, 0.2535]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2478, 0.1321, 0.2889, 0.3936]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1803, 0.1153, 0.2617]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0354, -0.0052,  0.2238, -0.0104, -0.0147, -0.1859]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JTS']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1766,  0.1908,  0.1028, -0.1352,  0.3550]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1609, 0.2307, 0.2360, 0.2677]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1553, 0.1602, 0.1885, 0.1544, 0.1607, 0.1300, 0.2663]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0474,  0.0434,  0.0836, -0.0068,  0.1782]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1402, -0.0675,  0.0038,  0.1000,  0.0174,  0.0083,  0.0546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1229, -0.2724, -0.1549, -0.1102,  0.0245,  0.1136]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1842, -0.1127,  0.1295,  0.1383, -0.0214]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0492, -0.1446, -0.0099]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so next steps, hmmm... I guess my only option here is to make an Offer, then.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2297, 0.3322]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent. I guess yes? I really don't know all the options.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1054, -0.0574, -0.1620, -0.2366, -0.1755]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1289, -0.2397, -0.4245,  0.0262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1128, 0.2379, 0.2195, 0.1677]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2279, -0.1158,  0.0297,  0.1985, -0.0523, -0.0635,  0.0788, -0.0471,\n",
            "         -0.1572, -0.0063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0567, -0.3738, -0.1684]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1589,  0.2097, -0.0025,  0.1174,  0.0703, -0.0187,  0.0609,  0.1764,\n",
            "          0.1581,  0.1200]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2863, 0.4018, 0.4456, 0.4601]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0286,  0.1073,  0.1730,  0.3805,  0.2199,  0.2372,  0.2003,  0.0847,\n",
            "          0.0765,  0.3216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3166, -0.1647, -0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0013,  0.2546]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1017, -0.0648]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0620, -0.1353, -0.0975, -0.2843, -0.0316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0397, -0.0341,  0.0213,  0.0090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2195, -0.2259, -0.3537, -0.2665, -0.4758]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0221,  0.1762]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2245, 0.2656, 0.0215, 0.3678]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1841, -0.1883, -0.0612,  0.0794]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3412, 0.3451, 0.3311, 0.3509, 0.3433]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1275,  0.1000, -0.0472,  0.0729,  0.1126]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0792, 0.1087, 0.2659, 0.2085, 0.2499, 0.2519, 0.1415]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0866, 0.1714, 0.1652, 0.1693, 0.1372]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0706, 0.0071, 0.2143, 0.0041]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2007, -0.0516, -0.2182, -0.1629, -0.1144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2586, 0.1413, 0.1826, 0.1575, 0.1957, 0.1876]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1404, -0.1772, -0.1991, -0.3546,  0.2665,  0.2961]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0739, -0.1077,  0.0937,  0.2248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0351, -0.0633, -0.0152, -0.0985, -0.0923, -0.1451,  0.0451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0163, -0.1772, -0.3120,  0.0084, -0.0197,  0.0278]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1987, 0.2184, 0.2181]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.0948,  0.0263, -0.0407,  0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0486, -0.1159, -0.2007, -0.2323,  0.0517]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1021, -0.0365, -0.0155, -0.1074, -0.0829, -0.0728, -0.0401, -0.0479,\n",
            "         -0.0815, -0.0193, -0.1428, -0.1357, -0.1317]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0617,  0.1741, -0.1675,  0.0449, -0.0187,  0.1276,  0.0066, -0.0093,\n",
            "          0.0474,  0.1029,  0.0837,  0.0754,  0.0843]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.1382,  0.1555, -0.0037,  0.3134]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1259, 0.2869, 0.2747, 0.2031, 0.1685, 0.0351, 0.2878, 0.0957, 0.2182,\n",
            "         0.0786, 0.1438, 0.0618, 0.1690]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0791, -0.0967, -0.1965, -0.2317, -0.0508,  0.2029]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0236, -0.0306, -0.0847,  0.0875,  0.0896, -0.1680]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2491, -0.1424, -0.1672, -0.0367, -0.1604, -0.1304, -0.1384, -0.1852]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1998,  0.1808, -0.0424,  0.3454,  0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0096,  0.0219,  0.0258, -0.0485, -0.0553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0772, -0.0844, -0.0065, -0.0625, -0.0602, -0.0414, -0.0184]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1755, 0.2763, 0.2887, 0.3321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0557, -0.0035, -0.0427,  0.2498,  0.0928, -0.0262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0791, 0.0878, 0.1201, 0.1696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I guess the customer type is an 'Existing customer'.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2984, 0.2734, 0.3453, 0.4433]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0689, 0.0846, 0.0486]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.4475, -0.3654, -0.4099, -0.1411, -0.4809]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3439, -0.1585, -0.1074, -0.2153, -0.0729, -0.2233, -0.2168, -0.1033]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1608, 0.2450, 0.3113, 0.2981, 0.3404, 0.3919, 0.3614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1501,  0.1023,  0.1441,  0.0459, -0.0548,  0.0841]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0426, -0.0476]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0719,  0.0917,  0.0152,  0.2355,  0.0614, -0.0097, -0.0171,  0.2094,\n",
            "          0.1147,  0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0733, 0.2271, 0.2066, 0.1196, 0.1346, 0.1726, 0.1041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5046, -0.3543, -0.4483, -0.4292, -0.4021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0047,  0.0371, -0.0944, -0.0259,  0.1621]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1552, -0.0943, -0.3897, -0.0098, -0.0546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0376,  0.1688, -0.2268, -0.1812,  0.1218, -0.1818, -0.1474,  0.0022]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Pipedrive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2072, -0.0083,  0.2288,  0.2483,  0.1379]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2114, -0.1254,  0.2065,  0.1275,  0.2193]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0875, 0.2078, 0.2209, 0.0991, 0.0623]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0147, -0.1141, -0.1970, -0.1162, -0.1150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0831, -0.0150, -0.0919,  0.0435, -0.1294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1224,  0.0913,  0.0441,  0.2219]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-6.6145e-02,  1.1137e-01,  3.2680e-01,  3.7495e-01,  1.0932e-01,\n",
            "          1.5980e-01,  1.5561e-01, -6.4522e-05,  1.7808e-01,  2.4826e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1954,  0.1777,  0.0099,  0.1002, -0.1518, -0.0705,  0.1628, -0.0962,\n",
            "          0.0857,  0.0327,  0.0612,  0.0589,  0.0946]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0629,  0.0587,  0.0226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.2559, -0.6972, -0.5280, -0.3614, -0.4442, -0.3239,  0.1368, -0.5729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0644, -0.0794, -0.0307,  0.1192,  0.0384]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0159,  0.1270,  0.0371, -0.0029,  0.0871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0350, 0.1658]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1638, 0.2418, 0.1420, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3129, -0.3209, -0.3259, -0.2658, -0.3697]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0829, 0.0888, 0.0864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.0716, -0.1027, -0.3877, -0.3210]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess I am an existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1044, 0.4391]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0303, -0.0725, -0.1164, -0.0029,  0.1903]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0727,  0.0661,  0.1751, -0.0444,  0.2094,  0.3381,  0.0574, -0.0569]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2479, -0.1491, -0.2076, -0.3964, -0.0554]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1922, 0.1981, 0.3902, 0.3113]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I'm very unsatisfied, not thrilled at all to be honest.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0754, -0.2846,  0.0458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2107, 0.1512, 0.2058, 0.3369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0822, -0.0570, -0.1890,  0.1452,  0.0518,  0.0801]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0879,  0.2567]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2989, -0.0042,  0.1012,  0.1894,  0.1762, -0.1345,  0.1266,  0.0251,\n",
            "         -0.0066, -0.0487]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1452, 0.2636]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0005, -0.2218, -0.0166, -0.0559, -0.1861]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0345, -0.2250,  0.0603, -0.2424, -0.0025,  0.0479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1349, -0.0580, -0.0190, -0.2325,  0.0097, -0.1111]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0911, 0.1398, 0.1426]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1058, 0.1148, 0.1459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0272, -0.0699, -0.1531, -0.1525,  0.0737,  0.1580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2942, 0.2330, 0.2691]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.0489,  0.1420,  0.1498,  0.2977,  0.2324,  0.2197,  0.1157,  0.1524,\n",
            "          0.1156,  0.4059]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0782,  0.0217, -0.0328,  0.1053,  0.2008, -0.0828,  0.0324, -0.1656,\n",
            "         -0.0551, -0.0102,  0.1656,  0.1080,  0.0940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0560, -0.2060,  0.0721,  0.2015, -0.3016,  0.0094, -0.2671, -0.1792]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0544,  0.0135, -0.0825, -0.1631,  0.1096]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2301, 0.2702, 0.2780, 0.2500]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2056, -0.0234,  0.0015,  0.1601,  0.0854,  0.0202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0246, -0.0205,  0.0140, -0.0502,  0.1117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1296, -0.1051, -0.3404, -0.2045]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0558,  0.0418, -0.0636,  0.0192, -0.0619]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking about language, I'd prefer to communicate in English. It's the only language option available, so English it is!\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0663, -0.0915,  0.0570,  0.1838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0482, 0.0196, 0.2857]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1296, -0.2523, -0.0608, -0.0707]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2516, -0.3325, -0.1267, -0.0506,  0.0351, -0.0354]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0652,  0.1659,  0.0403, -0.1988,  0.0814,  0.0349]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0519, -0.1146,  0.1518,  0.0483,  0.2598]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0465,  0.0813, -0.0438, -0.0412,  0.1536]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1128, 0.1041, 0.1632, 0.1265, 0.1338, 0.1502, 0.1768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0612, 0.0118, 0.0561]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0116, -0.1818, -0.0819, -0.2317,  0.0233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2801, 0.2341, 0.3501, 0.3172, 0.2732, 0.3211]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0542, 0.2577, 0.0587, 0.0330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'd say Applicant, I'm not really sure what other kinds there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0472,  0.2147,  0.2042,  0.0206,  0.1623,  0.1458,  0.0237,  0.2234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0292, -0.1258, -0.0323, -0.0179, -0.0494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0122, -0.0094,  0.0276, -0.0322,  0.0360]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2616,  0.0621,  0.0421,  0.2547,  0.0744, -0.3039,  0.0437,  0.0412,\n",
            "         -0.0010,  0.0316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in the Physical Security industry. That's the only one listed.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1979, -0.0581, -0.2156, -0.0941, -0.3701,  0.0237, -0.1503,  0.0775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1575, 0.0269, 0.0935]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.0695, -0.0532, -0.1565,  0.0767, -0.2326, -0.1431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2517,  0.2568,  0.2726, -0.1819,  0.4424]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0880, -0.0757,  0.1200,  0.0598,  0.1017,  0.2020, -0.0760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1462, 0.2890, 0.1310, 0.1751]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2987, 0.1913, 0.2287, 0.1912, 0.1560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1702, 0.1722, 0.1429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.2253, 0.3045]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1700,  0.0897,  0.0842, -0.0601,  0.2816]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0527, -0.2332, -0.0084]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.4536, -0.0904, -0.1416, -0.3362, -0.3826, -0.3545, -0.2192]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3100, -0.1229, -0.1803, -0.1699,  0.2603]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1749, 0.1109]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Well, I would like to say, I prefer not to, so I'll choose **No**.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0775, -0.0782, -0.1749,  0.0263, -0.3600]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, and also display port debugging and compliance. I think those two are interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3116, -0.2258, -0.3064, -0.1303, -0.2109]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1734, 0.1675, 0.0536, 0.1490, 0.0454, 0.0158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0165,  0.0140, -0.1802,  0.0644, -0.2104, -0.0616,  0.0567,  0.0063,\n",
            "         -0.0963, -0.0691, -0.0233,  0.0531,  0.0218]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2158, 0.2602]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0043,  0.0620, -0.0186,  0.1039,  0.0240,  0.0963,  0.1500]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2163,  0.0296,  0.0412,  0.1794, -0.0004,  0.0720]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0505, -0.0284, -0.2088, -0.0384, -0.0044, -0.1921]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1909, 0.3013]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2383, 0.2515, 0.0764, 0.1462, 0.0619, 0.2074, 0.1840]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1708, -0.0229, -0.0968]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2573, -0.2702, -0.3283, -0.1780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0675,  0.0566,  0.1947,  0.1172,  0.1599,  0.1691,  0.1634, -0.0799,\n",
            "         -0.1637, -0.0281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0189, -0.2124,  0.0032, -0.0363, -0.0990, -0.0935, -0.0803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0486, -0.1047, -0.0126, -0.0007, -0.1434,  0.1013, -0.1396, -0.2160,\n",
            "         -0.0501,  0.0230, -0.0439,  0.0918,  0.0241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1863, -0.1492, -0.0555,  0.0964, -0.0685, -0.0407, -0.0665,  0.0200,\n",
            "         -0.3360, -0.3095]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2373,  0.2366,  0.0409,  0.1540,  0.0886,  0.2032,  0.1004,  0.1969,\n",
            "          0.1415,  0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0625, -0.3629,  0.0338,  0.0030,  0.2120,  0.2422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1039, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1864, 0.1716, 0.0842, 0.2992, 0.1650, 0.1954, 0.2300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0188, -0.1105, -0.0808, -0.0913, -0.1254, -0.0301, -0.2104, -0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0496, -0.2117,  0.0869]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0456, 0.1492, 0.1352, 0.1054]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3619, -0.2440, -0.4064, -0.6674, -0.1466]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1370, -0.0044,  0.1493,  0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0004,  0.1318, -0.0954, -0.1680,  0.2229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1685, -0.3739, -0.0424, -0.1968]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2577, 0.2584, 0.2464]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1479, -0.1084, -0.2617, -0.1255, -0.2858]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1100, -0.0431,  0.1937,  0.0130,  0.2710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1773, 0.2113, 0.1164, 0.0717, 0.1150, 0.1028]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2487, -0.0315,  0.0137]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1169, -0.0603, -0.2258, -0.0744, -0.1604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2619, -0.0276, -0.0928, -0.2349, -0.1552]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2308, -0.2381, -0.1776, -0.1911, -0.1372, -0.1546,  0.0293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0010, -0.0188]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.1552,  0.0411,  0.0551,  0.3102,  0.1360,  0.2202,  0.1475,  0.1083,\n",
            "          0.0032,  0.2517]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1711,  0.0693, -0.1865, -0.2680,  0.0394]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1723,  0.0389, -0.0477,  0.0531, -0.0717,  0.0026, -0.1930, -0.0742,\n",
            "         -0.1045, -0.0703]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0012,  0.0006,  0.0494]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0168,  0.0752,  0.1267,  0.3236,  0.1633,  0.1873,  0.1292,  0.1121,\n",
            "         -0.0348,  0.1422]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0610,  0.0741, -0.0872, -0.2194, -0.3549]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2745, 0.2040, 0.2895, 0.2722, 0.1609, 0.2927]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0592, -0.6220, -0.5354, -0.3276, -0.5475]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0882, 0.1620]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2280, -0.0861,  0.0207,  0.1345,  0.1052,  0.0261,  0.0768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3630, -0.2583, -0.5577, -0.4745, -0.4413]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1954,  0.1733,  0.0957, -0.1008,  0.1708]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1542, 0.1685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to data processing.  I don't know what other options there might be.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.1271, -0.0690, -0.0965, -0.1236, -0.0363, -0.0425]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0571, -0.0024,  0.0091,  0.0504, -0.0156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1687, 0.3077, 0.1976, 0.1866, 0.0878, 0.1986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0489, 0.1686]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1541, 0.0899, 0.1280, 0.1738, 0.1181, 0.1910, 0.2326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0634, 0.0653, 0.1245, 0.0925, 0.0842, 0.0845, 0.1645]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1542, 0.1429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I'd rather not receive any marketing emails, so no, please. That's the only option you gave me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.2577,  0.1154, -0.0851, -0.0939, -0.1364,  0.0175, -0.0513, -0.2454,\n",
            "         -0.0451, -0.1888, -0.2619,  0.0448, -0.0613]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0062,  0.0432, -0.0324, -0.0358, -0.0350, -0.1117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0013,  0.0965,  0.1007,  0.2046,  0.0783, -0.0081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0829,  0.0163,  0.1293,  0.2541,  0.1123,  0.1399,  0.1393,  0.1812,\n",
            "          0.0039,  0.0321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1133,  0.0260, -0.0315, -0.0243]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1135,  0.1620,  0.0723,  0.3444,  0.1505, -0.0897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2315, 0.1835, 0.4069, 0.3325, 0.3221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2268, -0.2756, -0.3145, -0.1412, -0.0893]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2227, -0.3658, -0.3450, -0.1377, -0.2863, -0.3128, -0.0582, -0.2439]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1108,  0.2111,  0.0925,  0.1660, -0.0541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0263,  0.0600, -0.1312, -0.0749,  0.0147]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1158,  0.0599,  0.0919,  0.0566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2490, 0.2269, 0.2367]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0803, 0.1013, 0.0311, 0.0131]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0706, -0.4319,  0.0709, -0.0251, -0.1190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1063,  0.0439, -0.0367, -0.0547,  0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1927, 0.0775, 0.1995, 0.2271, 0.1724, 0.1687, 0.2616]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1107,  0.1619,  0.0689, -0.1279, -0.0946,  0.0035]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0771, 0.0277, 0.0869]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1]\n",
            "\n",
            "tensor([[-0.0061, -0.1146,  0.1524,  0.0078,  0.2486,  0.0426, -0.1866,  0.0957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1978, -0.0617,  0.0330, -0.1547,  0.1727]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0734, -0.3206, -0.1506,  0.0563, -0.0275,  0.0096]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0009,  0.0267,  0.0943,  0.1817]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1653, 0.2175, 0.2684, 0.3576]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0941, 0.2574, 0.2455, 0.1642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3452, -0.3026, -0.3455]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step should be offer, yeah that sounds about right.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.0513, 0.1344, 0.0992, 0.1258, 0.2065]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0053,  0.0550,  0.0281,  0.0428, -0.0750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0848,  0.0506, -0.1877, -0.2206,  0.2442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1102, 0.2488, 0.2453, 0.1494, 0.0694]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0184, -0.4906, -0.0559, -0.3143, -0.3777]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0250, 0.1412, 0.0474, 0.1342, 0.2122]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0236, -0.0757, -0.1482,  0.0756]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1876, 0.1550, 0.2164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.3289, -0.1872, -0.1923, -0.1865, -0.1925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.1498, -0.1401, -0.1131, -0.1571, -0.2286]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0578,  0.0151, -0.0070, -0.0038]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0444,  0.0437,  0.1628,  0.1518, -0.0101,  0.0398, -0.0794,  0.0733]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2418, 0.2230, 0.2966, 0.3960]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction. I'd say, like, I am very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0278,  0.1159, -0.0060,  0.1667]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1847, -0.0608, -0.0939,  0.2847, -0.0104, -0.0344,  0.2711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0323,  0.0783,  0.2333,  0.5639,  0.2190,  0.3253,  0.2263,  0.1263,\n",
            "          0.1484,  0.2019]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0209,  0.2979,  0.1182, -0.2752,  0.0490, -0.0433, -0.4209,  0.0908]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2910, -0.3204, -0.3929, -0.1017]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0192, -0.0081, -0.1202,  0.0289, -0.0517,  0.0126,  0.1016, -0.0273,\n",
            "         -0.0384,  0.0125,  0.0987,  0.0490, -0.1011]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0979,  0.0752, -0.1855, -0.0611,  0.1293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0296,  0.1441,  0.0820, -0.0426,  0.1202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1189, -0.0526,  0.0215,  0.1926, -0.0195]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3134, 0.2760, 0.2746]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1705, 0.2215, 0.1496, 0.1480, 0.0053]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0763, -0.0192]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0200, 0.0210, 0.0588, 0.1278, 0.3284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0345, 0.0777, 0.4104, 0.1584, 0.2062, 0.1106, 0.0943]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1508,  0.0450, -0.0432, -0.0304,  0.1793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0817, -0.0203, -0.0226, -0.0178, -0.0787]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question. I'm honestly not sure of the exact number. I think we have somewhere around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0441,  0.1696, -0.0187,  0.1099, -0.0077,  0.0515,  0.0211,  0.0581,\n",
            "          0.0257,  0.1435,  0.0734,  0.0583, -0.1074]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0531, -0.1547, -0.0310, -0.1434,  0.1870]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1846, -0.0130, -0.0952, -0.0725,  0.2206]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1477, 0.0739, 0.0986, 0.1898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0074, 0.1144, 0.0080, 0.1314, 0.0372, 0.0558, 0.1912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0159, -0.0860, -0.2822, -0.0820, -0.1863, -0.0992, -0.0348, -0.1316,\n",
            "          0.0363, -0.1566, -0.1174, -0.0306, -0.0986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1749, -0.0380, -0.2649, -0.2200,  0.0519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0686,  0.1704,  0.0410,  0.2858,  0.1280, -0.0908,  0.0139,  0.0664,\n",
            "          0.1102, -0.0035]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2964, -0.3741, -0.2133, -0.1430, -0.2484]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1804, 0.1735, 0.1774]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2675, 0.3013, 0.3402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0335, -0.0338,  0.0935,  0.0546,  0.1702,  0.1008, -0.0879, -0.0387]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1384, 0.1803, 0.1958]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'm happy to follow up! It could be in **2 weeks** or maybe in **3 weeks**. Which timing is best for you?\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0077, -0.1685,  0.1751, -0.0901,  0.1375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.2293, 0.1649, 0.1382, 0.3946]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0572, 0.2121, 0.0546, 0.0233, 0.1634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1740, 0.0967, 0.1570, 0.2029, 0.0837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0630, -0.0215, -0.0119,  0.2145,  0.2037, -0.1925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1412,  0.0024, -0.0773,  0.0401,  0.1336, -0.1902]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0634, -0.1476, -0.2377,  0.0760, -0.0137,  0.0617]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0701, 0.1115, 0.2391, 0.1700, 0.1231, 0.1447, 0.1537]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what groups there are but I think it's probably a wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0471,  0.0149]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1276,  0.1126,  0.0614, -0.0590,  0.1038]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3456, -0.1158,  0.0744, -0.2391,  0.3036,  0.0161, -0.3839,  0.0322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0376,  0.0265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.2765, -0.1226, -0.3433, -0.2763, -0.2522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2442, 0.2208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0643, -0.3319, -0.0763, -0.1024, -0.0974, -0.3017, -0.2634]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2050,  0.1969,  0.0605,  0.4133,  0.3035,  0.2079,  0.1598,  0.2332,\n",
            "         -0.0576,  0.1673]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0734, -0.2588, -0.0694, -0.1127, -0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0188,  0.1531,  0.0424, -0.1239,  0.0212]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0931,  0.1614,  0.0677,  0.1042]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0046, -0.0307, -0.1814,  0.0115, -0.0930]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2782, -0.1496, -0.1661, -0.0464, -0.1498, -0.1468, -0.0684]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2814, -0.0408, -0.1657, -0.1570, -0.4184]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1975,  0.0499,  0.0175,  0.1899, -0.0868,  0.1308,  0.0252,  0.0575,\n",
            "         -0.0343,  0.1956]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0301, -0.0577,  0.0226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0853, -0.1781, -0.1099, -0.0535, -0.0302,  0.0004,  0.1960]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0095,  0.1103, -0.0290,  0.0896]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0439, -0.0564, -0.1368, -0.0641,  0.0674]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1311, -0.2249, -0.1421, -0.1798, -0.1551]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0648, -0.2410, -0.1810]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0261, -0.0017,  0.0180,  0.0688, -0.4108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0186,  0.0391, -0.0409, -0.0022]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1055,  0.0192, -0.0749,  0.0190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0076, -0.0517,  0.0442, -0.0152, -0.0595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1942, 0.2280, 0.2531, 0.2518, 0.2140, 0.1808]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2062,  0.0766,  0.0418,  0.1026, -0.2100, -0.1293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0020, -0.0300,  0.0338, -0.2048, -0.0903, -0.1797, -0.1406]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2987, 0.1925, 0.0315, 0.1418, 0.2348]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0898,  0.0519,  0.1088, -0.0132, -0.1252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1306, -0.2062, -0.0363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0027, -0.0061, -0.1607, -0.1680,  0.0169, -0.0011, -0.0526, -0.0966,\n",
            "         -0.0813, -0.0028, -0.1385,  0.0484, -0.1717]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2002,  0.1006,  0.0239,  0.3060,  0.1719,  0.1410,  0.0677, -0.0004,\n",
            "         -0.0151,  0.1760]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0866, 0.0276, 0.1497, 0.1456, 0.1246, 0.1769, 0.3614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1124, 0.2632, 0.3317, 0.2938]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1379, 0.1137, 0.2226, 0.1169]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0287, -0.4235, -0.2805,  0.0731, -0.2042,  0.1381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2683, -0.1899, -0.0650, -0.2957, -0.0560, -0.1213, -0.1952, -0.0835]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0571, -0.1016, -0.1760,  0.0213, -0.0652, -0.0734]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2031, -0.1694, -0.3067, -0.1853, -0.1123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0682, -0.1930, -0.2488, -0.2658, -0.1654]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0065, -0.1708,  0.0411, -0.0182,  0.0021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3815, -0.2120, -0.1981, -0.0852, -0.0693]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0325, -0.1024, -0.0140,  0.0463, -0.0061,  0.0569,  0.0099, -0.1364,\n",
            "         -0.0102,  0.0178, -0.1334,  0.0477, -0.0724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0591, -0.3126, -0.3526,  0.0805,  0.4220,  0.1183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2266, -0.2475, -0.2485, -0.1633, -0.4038]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1412, -0.0547,  0.0587,  0.2937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0396,  0.1057,  0.2162,  0.1548, -0.0077,  0.0874, -0.0169,  0.2030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1182, 0.1189, 0.1468, 0.1395]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0716, -0.0483, -0.0528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2139,  0.3097,  0.1582,  0.2863,  0.2010,  0.1407,  0.1406,  0.1694,\n",
            "          0.0686,  0.0911]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2160, -0.4218, -0.3895, -0.3025, -0.3548]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2605, -0.0608, -0.0779, -0.0914, -0.0719, -0.0351, -0.1786, -0.0646,\n",
            "         -0.2182, -0.2642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0735, -0.1219, -0.1211, -0.3709, -0.0060, -0.0176]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0430,  0.0996, -0.0194,  0.0881,  0.1775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1602, -0.1074, -0.0472,  0.0822, -0.1080, -0.0711, -0.2762, -0.0924]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2327, -0.0735,  0.0751,  0.1924,  0.2501,  0.3738,  0.1748]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1451,  0.2301,  0.0206,  0.1732,  0.0776,  0.0331,  0.1868,  0.0717,\n",
            "          0.2081,  0.2393, -0.0015, -0.0091,  0.1350]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3138, 0.2175, 0.1003, 0.1832, 0.2780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0785,  0.3069,  0.0595, -0.1176,  0.2471]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2587, -0.2338, -0.1221,  0.0399, -0.0384, -0.2622, -0.1019, -0.1734,\n",
            "         -0.3082, -0.2858]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1010, -0.1513, -0.2206,  0.2558,  0.0241,  0.0452]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3972, -0.2897, -0.3215, -0.1311, -0.3847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1274, -0.1395, -0.0613, -0.0245, -0.0558, -0.0388,  0.0690]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 25 people.  I don't know what the other options are, but that's my best estimate for the average size of a trade fair team.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1454, 0.1010, 0.1749, 0.0929, 0.2745]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2599,  0.1134,  0.2992, -0.0113,  0.1565]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1473, 0.0124, 0.1152]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1243, 0.1020, 0.1282, 0.2061, 0.0867, 0.2447]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1735, 0.0970, 0.0390, 0.1382, 0.3727]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3223,  0.0906,  0.0160,  0.0914, -0.0023,  0.0998,  0.0218,  0.1984,\n",
            "          0.1757,  0.1284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2134, -0.2891, -0.1565, -0.1624,  0.1259, -0.2846, -0.3241, -0.0391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0969,  0.0954, -0.0215,  0.0771,  0.0833,  0.2028]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1985, -0.1583, -0.0533,  0.3706,  0.0072,  0.0883]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0864, -0.4556, -0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2396,  0.1212,  0.2025,  0.1430,  0.0774, -0.2201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, a company, hmm. I guess it must be a scaffolding company. I'm not really sure though, sorry.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0835, -0.1118, -0.0198,  0.0188, -0.0075, -0.0319,  0.1766]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0423,  0.0855]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, for data processing consent, it looks like the only option here is 'Yes'. So, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.0770, 0.1304, 0.3735, 0.3475]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2390, -0.0304,  0.1395,  0.1649,  0.0326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "The metrics for all open-ended questions in the train dataset:\n",
            "{'accuracy': 0.7078977932636469, 'f1': 0.5054080629301868, 'precision': 0.5538793103448276, 'recall': 0.46473779385171793}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDF1GH7FZHvK",
        "outputId": "99aaf6a1-b01a-4a2f-bd8b-e32dc99118fc"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "xlnet/xlnet-base-cased: {'accuracy': 0.7078977932636469, 'f1': 0.5054080629301868, 'precision': 0.5538793103448276, 'recall': 0.46473779385171793}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### RoBERTa base model of FacebookAI\n",
        "Roberta models are using the hyperparameters of underlying bert model -> less fine-tuning necessary"
      ],
      "metadata": {
        "id": "eaZn2ZLgXlw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"FacebookAI/roberta-base\"\n",
        "mc_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whjdVgK4Wnsz",
        "outputId": "2744daf0-a34b-4f44-d59c-e0a38aa8eed7"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yCT4MxbXkcL",
        "outputId": "ac99c647-95a4-49b5-ac59-eab3329b2936"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "tensor([[0.1364, 0.1373, 0.1391, 0.1375, 0.1388, 0.1386, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1324, 0.1339, 0.1312, 0.1301, 0.1254, 0.1323, 0.1301, 0.1338,\n",
            "         0.1336, 0.1323, 0.1329, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1320, 0.1326, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1251, 0.1226, 0.1232, 0.1259, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1281, 0.1268, 0.1239, 0.1216, 0.1226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1262, 0.1237, 0.1247, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1400, 0.1407]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, hmm, yes I guess I would, sure.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1325, 0.1338, 0.1309, 0.1320, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1229, 0.1240, 0.1216, 0.1256, 0.1232, 0.1240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1263, 0.1247, 0.1289, 0.1274, 0.1255, 0.1295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1236, 0.1231, 0.1201, 0.1248, 0.1255, 0.1254, 0.1232, 0.1221, 0.1223,\n",
            "         0.1244]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1283, 0.1254, 0.1287, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1342, 0.1332, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1252, 0.1248, 0.1230, 0.1267, 0.1279, 0.1275, 0.1249, 0.1238, 0.1241,\n",
            "         0.1269]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1380, 0.1389]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yeah I would like to get emails about marketing information.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1362, 0.1379, 0.1422, 0.1391, 0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1301, 0.1290, 0.1299, 0.1307, 0.1269, 0.1283, 0.1309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1335, 0.1314, 0.1287, 0.1334, 0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1370, 0.1395, 0.1387, 0.1393, 0.1402, 0.1369]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1317, 0.1287, 0.1303, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1205, 0.1184, 0.1188, 0.1209, 0.1185]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1333, 0.1332, 0.1338, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1236, 0.1194, 0.1243, 0.1233, 0.1239]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1266, 0.1294, 0.1284, 0.1310, 0.1284, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1313, 0.1286, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer. I guess that's what I would be.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1305, 0.1311, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 3 weeks sounds good, that's when I'd like a follow up.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1314, 0.1304, 0.1317, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1268, 0.1310, 0.1263, 0.1279, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1353, 0.1370]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1314, 0.1320, 0.1310, 0.1301, 0.1293, 0.1278, 0.1322, 0.1300, 0.1324,\n",
            "         0.1319, 0.1323, 0.1313, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1335, 0.1346, 0.1336, 0.1343, 0.1348, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1257, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1339, 0.1290, 0.1305, 0.1319, 0.1318, 0.1299, 0.1318, 0.1306]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1346, 0.1347, 0.1325, 0.1312, 0.1275, 0.1337, 0.1319, 0.1328,\n",
            "         0.1355, 0.1317, 0.1336, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1294, 0.1267, 0.1297, 0.1288, 0.1294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1297, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1288, 0.1281, 0.1264, 0.1309, 0.1285, 0.1264, 0.1311]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm I guess the customer group would be end user then, that seems about right.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1303, 0.1291, 0.1294, 0.1323, 0.1328, 0.1325, 0.1298, 0.1274, 0.1282,\n",
            "         0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1298, 0.1298, 0.1311, 0.1290, 0.1274, 0.1247, 0.1318, 0.1280, 0.1299,\n",
            "         0.1309, 0.1278, 0.1299, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1295, 0.1352, 0.1310, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1352, 0.1370, 0.1429, 0.1399, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1294, 0.1288, 0.1301, 0.1280, 0.1272, 0.1261, 0.1292, 0.1276, 0.1307,\n",
            "         0.1308, 0.1296, 0.1280, 0.1300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Erik Schneider', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1220, 0.1178, 0.1199, 0.1158, 0.1143, 0.1172]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1254, 0.1269, 0.1261, 0.1257, 0.1239, 0.1263, 0.1247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I'm not sure which CRM system you mean, is it maybe Adito?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1376, 0.1369, 0.1361, 0.1389]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, well, I guess I'd say I'm very satisfied, if that's an option, it's definitely my answer.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1337, 0.1323, 0.1303, 0.1326, 0.1325]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm I'd probably go with Spanish. I don't know what else there is.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1207, 0.1262, 0.1236, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1367, 0.1327, 0.1334, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1184, 0.1195, 0.1188, 0.1167, 0.1204, 0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1222, 0.1281, 0.1239, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1239, 0.1277, 0.1262, 0.1227, 0.1243, 0.1252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1257, 0.1300, 0.1264, 0.1276, 0.1266]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1235, 0.1259, 0.1236, 0.1236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1272, 0.1220, 0.1307, 0.1227, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1325, 0.1338, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess the next thing I would do is call, seems right to me.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1390, 0.1388, 0.1390, 0.1416]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1257, 0.1268, 0.1273]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1426, 0.1408, 0.1389, 0.1431]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1323, 0.1313, 0.1294, 0.1328, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I'm not sure about languages but I guess I'd choose German then.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1265, 0.1279, 0.1253, 0.1294, 0.1284]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1237, 0.1248, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1247, 0.1239, 0.1238, 0.1261, 0.1273, 0.1272, 0.1248, 0.1235, 0.1235,\n",
            "         0.1254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1298, 0.1288, 0.1279, 0.1289, 0.1300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1304, 0.1294, 0.1283, 0.1308, 0.1311, 0.1277, 0.1288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1264, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1256, 0.1235, 0.1273, 0.1280, 0.1250, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1332, 0.1298, 0.1309, 0.1297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1285, 0.1292, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1358, 0.1364, 0.1354, 0.1342, 0.1341, 0.1283, 0.1383, 0.1340, 0.1365,\n",
            "         0.1373, 0.1359, 0.1359, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1270, 0.1260, 0.1244, 0.1288, 0.1292, 0.1282, 0.1265, 0.1250, 0.1258,\n",
            "         0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1355, 0.1327, 0.1322, 0.1339, 0.1341, 0.1323, 0.1330, 0.1313]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1347, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1241, 0.1253, 0.1241, 0.1220, 0.1265, 0.1232]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's an education company, I guess.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1386, 0.1388, 0.1386, 0.1407]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1234, 0.1231, 0.1228, 0.1251, 0.1255, 0.1248, 0.1229, 0.1225, 0.1218,\n",
            "         0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1295, 0.1276, 0.1262, 0.1300, 0.1291, 0.1252, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1269, 0.1265, 0.1303, 0.1299, 0.1313, 0.1283, 0.1265, 0.1260,\n",
            "         0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1189, 0.1263, 0.1223, 0.1229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in high-speed interconnect testing, because that sounds like a really important field.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1280, 0.1292, 0.1283, 0.1286, 0.1284, 0.1277]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1244, 0.1244, 0.1259, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1290, 0.1291, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1278, 0.1261, 0.1268, 0.1289, 0.1264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1292, 0.1295]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1299, 0.1289, 0.1286, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, customer type. I guess that would be existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1285, 0.1262, 0.1268, 0.1271, 0.1281]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1315, 0.1297, 0.1291, 0.1313, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1217, 0.1229, 0.1212, 0.1215, 0.1227, 0.1249]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1261, 0.1255, 0.1267, 0.1240, 0.1288, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1352, 0.1358, 0.1382, 0.1366, 0.1376, 0.1382, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1292, 0.1256, 0.1288, 0.1280, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1332, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1277, 0.1296, 0.1278, 0.1271, 0.1266, 0.1288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1392, 0.1410, 0.1471, 0.1436, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1276, 0.1269, 0.1263, 0.1288, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1245, 0.1236, 0.1225, 0.1262, 0.1268, 0.1265, 0.1241, 0.1222, 0.1236,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1240, 0.1212, 0.1216, 0.1237, 0.1210]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1337, 0.1341, 0.1318, 0.1310, 0.1271, 0.1333, 0.1311, 0.1340,\n",
            "         0.1342, 0.1326, 0.1329, 0.1334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1308, 0.1300, 0.1311, 0.1276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1373, 0.1381]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1276, 0.1289, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they'd like a follow up in about 1 week.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1319, 0.1295, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1318, 0.1319, 0.1286]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1232, 0.1211, 0.1269, 0.1280, 0.1232, 0.1244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1227, 0.1227, 0.1223, 0.1209, 0.1239, 0.1223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it must be a construction company. That makes the most sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1282, 0.1263, 0.1263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1271, 0.1274, 0.1276, 0.1274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1298, 0.1299, 0.1336, 0.1332, 0.1333, 0.1314, 0.1292, 0.1296,\n",
            "         0.1326]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in Aerospace? It's the only option provided.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1305, 0.1302, 0.1309, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I suppose Italian is what I want to use. I guess that's it.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1354, 0.1363, 0.1454, 0.1383, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, um, I think our company size is probably somewhere between 1 and 10 people. Yeah, I'd guess that.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1291, 0.1289, 0.1297, 0.1305, 0.1293, 0.1287, 0.1329]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1335, 0.1394, 0.1365, 0.1305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1229, 0.1290, 0.1225, 0.1252, 0.1230]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1345, 0.1317, 0.1328, 0.1340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1384, 0.1390]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1336, 0.1357, 0.1345, 0.1336, 0.1314, 0.1299, 0.1350, 0.1325, 0.1354,\n",
            "         0.1344, 0.1337, 0.1353, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1253, 0.1229, 0.1234, 0.1267, 0.1269, 0.1267, 0.1244, 0.1224, 0.1226,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1275, 0.1257, 0.1271, 0.1276, 0.1268, 0.1251, 0.1267, 0.1248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, gosh I am not really sure about those options but I'm guessing the one I'd use is Adito, is that right?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1300, 0.1328, 0.1311, 0.1328, 0.1327, 0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1214, 0.1229, 0.1213, 0.1217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1308, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1303, 0.1313, 0.1363, 0.1328, 0.1289]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1361, 0.1365]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1246, 0.1231, 0.1240, 0.1237, 0.1240]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1298, 0.1341, 0.1296, 0.1316, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1292, 0.1256, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1378, 0.1371]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1263, 0.1267, 0.1267, 0.1254, 0.1247, 0.1270]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1324, 0.1312, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1399, 0.1371, 0.1410]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1333, 0.1339, 0.1311, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1195, 0.1157, 0.1185, 0.1180, 0.1153]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1308, 0.1287, 0.1311, 0.1303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1313, 0.1293, 0.1307, 0.1330, 0.1290, 0.1318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1281, 0.1270, 0.1268, 0.1248, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1364, 0.1362]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1349, 0.1356, 0.1418, 0.1401, 0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, the size of my company? I think we're around 11 to 50 people; it is definitely in that range.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1227, 0.1183, 0.1214, 0.1236, 0.1191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1193, 0.1213, 0.1198, 0.1185, 0.1203, 0.1197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1382]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1268, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1347, 0.1310, 0.1308, 0.1321, 0.1335, 0.1314, 0.1326, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with CAS,  I don't know what other CRM systems are out there.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1368, 0.1374, 0.1389, 0.1378, 0.1388, 0.1396, 0.1359]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1332, 0.1314, 0.1305, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1327, 0.1322, 0.1315, 0.1337, 0.1340, 0.1326, 0.1342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1263, 0.1247, 0.1242, 0.1274, 0.1271, 0.1247, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1326, 0.1326, 0.1340, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1287, 0.1291, 0.1256, 0.1262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1184, 0.1205, 0.1193, 0.1173, 0.1196, 0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1373, 0.1365, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1304, 0.1266, 0.1274, 0.1254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1296, 0.1287, 0.1300, 0.1296, 0.1283, 0.1284, 0.1309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh gosh, I'm not sure. Maybe it's Pipedrive? I'm not very knowledgeable about those types of systems.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1261, 0.1251, 0.1233, 0.1216, 0.1229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1288, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1370, 0.1368, 0.1358, 0.1393]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1315, 0.1306, 0.1283, 0.1295]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1318, 0.1325, 0.1342, 0.1327, 0.1338, 0.1337, 0.1280]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average the trade fair team is usually more than 40 people, it seems. That's the only size I know about for now.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1245, 0.1230, 0.1213, 0.1216, 0.1219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1361]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1309, 0.1269, 0.1248, 0.1305, 0.1317, 0.1292, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1272, 0.1268, 0.1248, 0.1220, 0.1245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1245, 0.1248, 0.1246, 0.1230, 0.1261, 0.1238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1354, 0.1380, 0.1372, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1395, 0.1405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I guess I'd say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1310, 0.1313, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm, I think they want a follow up in 3 weeks, sounds about right to me.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1375, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.1249, 0.1228, 0.1268, 0.1274, 0.1273, 0.1251, 0.1240, 0.1240,\n",
            "         0.1263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1343, 0.1337, 0.1319, 0.1306, 0.1294, 0.1321]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1216, 0.1243, 0.1236, 0.1208, 0.1211, 0.1212]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1321, 0.1349, 0.1339, 0.1358, 0.1361, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1290, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1288, 0.1301, 0.1319, 0.1331, 0.1304, 0.1307, 0.1331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1331, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1304, 0.1274, 0.1275, 0.1317, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1317, 0.1290, 0.1315, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, Italian, I think Italian sounds good. I'm going with that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1365]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1339, 0.1339, 0.1343, 0.1380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1351]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1269, 0.1244, 0.1254, 0.1286, 0.1290, 0.1290, 0.1264, 0.1237, 0.1252,\n",
            "         0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1384, 0.1373, 0.1445, 0.1440, 0.1391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, the size of my company? It's in the 11-50 range, so not too big, but definitely not a tiny operation either.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1209, 0.1220, 0.1204, 0.1188, 0.1222, 0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1378, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1251, 0.1222, 0.1225, 0.1251, 0.1216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1354, 0.1337, 0.1345, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I am very satisfied, that seems like the best choice I guess.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1247, 0.1261, 0.1249, 0.1276, 0.1252, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1290, 0.1298, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1401, 0.1407, 0.1423, 0.1411, 0.1425, 0.1430, 0.1393]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1255, 0.1237, 0.1216, 0.1205, 0.1226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1320, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1257, 0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess a meeting is what's next then. I think that is the only thing on the list anyway.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1257, 0.1247, 0.1273, 0.1259, 0.1262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1368, 0.1374, 0.1385, 0.1375, 0.1383, 0.1387, 0.1356]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1385, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Yes, I would like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1276, 0.1273, 0.1272, 0.1255, 0.1290, 0.1273]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1319, 0.1303, 0.1328, 0.1328, 0.1304, 0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1310, 0.1317, 0.1320, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1331, 0.1282, 0.1300, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1312, 0.1256, 0.1287, 0.1247]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1377, 0.1368, 0.1345, 0.1333, 0.1302, 0.1351]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1299, 0.1290, 0.1293, 0.1319, 0.1315, 0.1320, 0.1296, 0.1284, 0.1283,\n",
            "         0.1310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1343, 0.1355, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would say I'll call then.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1301, 0.1282, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1281, 0.1298, 0.1299, 0.1325, 0.1312, 0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1340, 0.1348, 0.1335, 0.1353, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1355, 0.1358, 0.1340, 0.1378, 0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1336, 0.1346, 0.1329, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1289, 0.1304, 0.1278, 0.1299, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1238, 0.1235, 0.1232, 0.1260, 0.1257, 0.1258, 0.1239, 0.1238, 0.1238,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1307, 0.1354, 0.1312, 0.1321, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1385, 0.1395, 0.1385, 0.1425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1328, 0.1304, 0.1281, 0.1310, 0.1314, 0.1296, 0.1306, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't know all the options but I guess it's Close.io. I've heard good things about it.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1314, 0.1320, 0.1337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1303, 0.1245, 0.1279, 0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1364, 0.1365, 0.1355, 0.1340, 0.1335, 0.1307, 0.1371, 0.1334, 0.1360,\n",
            "         0.1364, 0.1353, 0.1347, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1318, 0.1283, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1359, 0.1291, 0.1318, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1394, 0.1412, 0.1402, 0.1414, 0.1417, 0.1383]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 45 people,  I don't know what the other options are but that sounds about right for a trade fair team.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1293, 0.1286, 0.1304, 0.1306, 0.1305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1339, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1271, 0.1275, 0.1272, 0.1239, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1333, 0.1332, 0.1352, 0.1322, 0.1314, 0.1281, 0.1355, 0.1326, 0.1336,\n",
            "         0.1341, 0.1320, 0.1343, 0.1341]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1393, 0.1372, 0.1369, 0.1402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1362, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1275, 0.1255, 0.1265, 0.1292, 0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1296, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1396, 0.1383, 0.1378, 0.1418]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1302, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1309, 0.1230, 0.1260, 0.1250, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1238, 0.1215, 0.1202, 0.1241, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1397, 0.1384, 0.1385, 0.1409]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1339, 0.1349, 0.1360, 0.1346, 0.1355, 0.1360, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1351, 0.1400, 0.1382, 0.1333]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1338, 0.1350, 0.1326, 0.1348, 0.1355, 0.1326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is usually around 16-20 people, give or take. That seems to be the typical amount.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1289, 0.1280, 0.1276, 0.1310, 0.1298, 0.1302]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1321, 0.1337, 0.1297, 0.1325, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1378, 0.1357, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1346, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent. I guess yes? I really don't know all the options.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1326, 0.1333, 0.1373, 0.1355, 0.1341]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1309, 0.1278, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1441, 0.1411, 0.1404, 0.1439]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1224, 0.1218, 0.1209, 0.1243, 0.1246, 0.1240, 0.1222, 0.1220, 0.1219,\n",
            "         0.1225]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1323, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1233, 0.1248, 0.1261, 0.1267, 0.1267, 0.1250, 0.1231, 0.1236,\n",
            "         0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1408, 0.1392, 0.1377, 0.1413]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1257, 0.1246, 0.1265, 0.1265, 0.1276, 0.1280, 0.1264, 0.1240, 0.1253,\n",
            "         0.1266]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1318, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1368, 0.1380]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1387, 0.1393]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1296, 0.1246, 0.1294, 0.1253, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1301, 0.1315, 0.1309, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1216, 0.1243, 0.1230, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1358, 0.1375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1319, 0.1301, 0.1289, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1275, 0.1263, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1229, 0.1251, 0.1254, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1223, 0.1244, 0.1224, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1380, 0.1390, 0.1410, 0.1396, 0.1406, 0.1402, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1264, 0.1270, 0.1286, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1309, 0.1314, 0.1278, 0.1279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess it's Partner, since that's the only option I have.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1352, 0.1337, 0.1335, 0.1365, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1270, 0.1289, 0.1277, 0.1254, 0.1281, 0.1274]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1287, 0.1278, 0.1259, 0.1274, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1373, 0.1365, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1354, 0.1359, 0.1378, 0.1365, 0.1379, 0.1382, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1283, 0.1271, 0.1268, 0.1269, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1261, 0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1360, 0.1357, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1355, 0.1386, 0.1365, 0.1331]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1337, 0.1352, 0.1339, 0.1336, 0.1323, 0.1302, 0.1367, 0.1330, 0.1360,\n",
            "         0.1344, 0.1352, 0.1342, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1329, 0.1331, 0.1312, 0.1298, 0.1275, 0.1329, 0.1305, 0.1333,\n",
            "         0.1327, 0.1304, 0.1328, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1312, 0.1295, 0.1305]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1360, 0.1351, 0.1357, 0.1340, 0.1328, 0.1299, 0.1354, 0.1332, 0.1356,\n",
            "         0.1356, 0.1349, 0.1342, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1275, 0.1265, 0.1236, 0.1256, 0.1256]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1216, 0.1236, 0.1221, 0.1208, 0.1229, 0.1220]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a production company. That's the type I think it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1258, 0.1293, 0.1272, 0.1290, 0.1282, 0.1271, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1283, 0.1270, 0.1275, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1340, 0.1311, 0.1284, 0.1342, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1379, 0.1384, 0.1399, 0.1388, 0.1401, 0.1406, 0.1382]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1373, 0.1361, 0.1365, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1239, 0.1252, 0.1244, 0.1245, 0.1258, 0.1239]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I'm not really sure. I think it might be a trading company.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1266, 0.1252, 0.1256]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1277, 0.1266, 0.1268, 0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, the customer type is an 'Applicant'. That seems straightforward. I guess there weren't any other options.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1262, 0.1264, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1201, 0.1160, 0.1204, 0.1181, 0.1209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1358, 0.1326, 0.1341, 0.1346, 0.1356, 0.1327, 0.1331, 0.1349]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've used HubSpot before.  It seemed pretty good to me.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1372, 0.1388, 0.1370, 0.1379, 0.1363, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team is usually around 31-40 people, that's the average size I'd say.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1277, 0.1254, 0.1245, 0.1255, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1371, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, I guess I would say yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1242, 0.1236, 0.1234, 0.1260, 0.1263, 0.1271, 0.1242, 0.1235, 0.1229,\n",
            "         0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1361, 0.1355, 0.1386, 0.1378, 0.1388, 0.1392, 0.1367]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1338, 0.1300, 0.1339, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1303, 0.1376, 0.1352, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, that's a good question. I guess we are larger than 2000, it is what feels right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1310, 0.1303, 0.1318, 0.1301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1334, 0.1305, 0.1312, 0.1324, 0.1326, 0.1310, 0.1296, 0.1331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1286, 0.1248, 0.1276, 0.1236, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1206, 0.1257, 0.1241, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1223, 0.1240, 0.1246, 0.1235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess you're looking for me to use Japanese. That's the only option, so Japanese it is!\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1296, 0.1292, 0.1284, 0.1294, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1303, 0.1346, 0.1284, 0.1289]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd guess we have around 1000 employees.  I don't know the exact breakdown of sizes, like  201-2000 or any other ranges\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1380, 0.1368, 0.1361, 0.1397]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1271, 0.1268, 0.1265, 0.1286, 0.1288, 0.1284, 0.1267, 0.1263, 0.1254,\n",
            "         0.1284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1347, 0.1351, 0.1335, 0.1322, 0.1291, 0.1352, 0.1331, 0.1342,\n",
            "         0.1348, 0.1333, 0.1341, 0.1338]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1299, 0.1308, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1336, 0.1323, 0.1310, 0.1329, 0.1326, 0.1309, 0.1325, 0.1328]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it would be SAP Sales Cloud, I think I've heard of that one.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1331, 0.1335, 0.1312, 0.1348, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1345, 0.1358, 0.1385, 0.1394, 0.1336]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1388, 0.1397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1337, 0.1347, 0.1350]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1301, 0.1326, 0.1287, 0.1285, 0.1287]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1300, 0.1304]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1303, 0.1307, 0.1269, 0.1277]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1376, 0.1375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1241, 0.1261, 0.1232, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1331, 0.1310, 0.1271, 0.1322, 0.1320, 0.1300, 0.1310, 0.1305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1200, 0.1274, 0.1231, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1452, 0.1431, 0.1422, 0.1464]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1327, 0.1298, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1397, 0.1388, 0.1376, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1262, 0.1240, 0.1264, 0.1259, 0.1258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1315, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1249, 0.1234, 0.1219, 0.1256, 0.1271, 0.1272, 0.1241, 0.1217, 0.1230,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1358, 0.1364]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1376, 0.1386, 0.1378, 0.1386, 0.1376]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1293, 0.1278, 0.1282, 0.1285, 0.1304]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1280, 0.1274, 0.1265, 0.1228, 0.1266, 0.1260]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1324, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1285, 0.1288, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1244, 0.1272, 0.1250, 0.1248, 0.1262, 0.1256]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1319, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1253, 0.1238, 0.1252, 0.1264, 0.1274, 0.1283, 0.1260, 0.1236, 0.1248,\n",
            "         0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1341, 0.1350, 0.1339, 0.1317, 0.1300, 0.1354, 0.1325, 0.1342,\n",
            "         0.1346, 0.1332, 0.1332, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1297, 0.1274, 0.1267, 0.1276, 0.1297, 0.1268, 0.1276, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what CRM systems are available, but I'd guess Microsoft Dynamics, since I've heard of that one.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1240, 0.1242, 0.1229, 0.1266, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1450, 0.1416, 0.1418, 0.1460]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1205, 0.1208, 0.1213, 0.1185, 0.1225, 0.1200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1367, 0.1377, 0.1451, 0.1422, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1285, 0.1258, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1295, 0.1272, 0.1248, 0.1303, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1354, 0.1362, 0.1359, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1301, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1320, 0.1295, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1270, 0.1263, 0.1253, 0.1264, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1296, 0.1287, 0.1270, 0.1293, 0.1297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1397, 0.1405, 0.1402, 0.1436, 0.1386]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1217, 0.1222, 0.1220, 0.1223]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1383, 0.1386, 0.1409, 0.1397, 0.1409, 0.1411, 0.1376]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1309, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1250, 0.1260, 0.1257, 0.1266, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1274, 0.1263, 0.1257, 0.1235, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1354, 0.1350, 0.1306, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'd say Applicant, I'm not really sure what other kinds there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1315, 0.1292, 0.1316, 0.1318, 0.1306, 0.1305, 0.1337]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1322, 0.1326, 0.1318, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1338, 0.1313, 0.1282, 0.1329, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1238, 0.1232, 0.1262, 0.1262, 0.1266, 0.1245, 0.1242, 0.1236,\n",
            "         0.1255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in the Physical Security industry. That's the only one listed.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1235, 0.1241, 0.1254, 0.1263, 0.1225, 0.1251, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1304, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1217, 0.1238, 0.1227, 0.1221, 0.1242, 0.1231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1233, 0.1202, 0.1205, 0.1238, 0.1216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1275, 0.1272, 0.1298, 0.1288, 0.1263, 0.1303]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1312, 0.1315, 0.1301, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1329, 0.1309, 0.1295, 0.1327, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1308, 0.1310, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1367, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1220, 0.1198, 0.1195, 0.1227, 0.1195]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1275, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1289, 0.1291, 0.1318, 0.1327, 0.1297, 0.1316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1339, 0.1376, 0.1368, 0.1322]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1387]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1192, 0.1165, 0.1220, 0.1193, 0.1218]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, and also display port debugging and compliance. I think those two are interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1309, 0.1271, 0.1270, 0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1301, 0.1287, 0.1302, 0.1284, 0.1295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1342, 0.1354, 0.1353, 0.1333, 0.1324, 0.1284, 0.1349, 0.1320, 0.1357,\n",
            "         0.1353, 0.1338, 0.1341, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what options there are. I would say no for the data processing consent.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1271, 0.1261, 0.1249, 0.1280, 0.1276, 0.1268, 0.1292]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1261, 0.1275, 0.1277, 0.1256, 0.1212, 0.1255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1237, 0.1250, 0.1237, 0.1236, 0.1239, 0.1240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1346, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.1229, 0.1202, 0.1249, 0.1240, 0.1242, 0.1248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1304, 0.1302, 0.1282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1315, 0.1329, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1279, 0.1280, 0.1303, 0.1309, 0.1314, 0.1295, 0.1269, 0.1269,\n",
            "         0.1300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1293, 0.1283, 0.1304, 0.1285, 0.1262, 0.1306]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1354, 0.1368, 0.1346, 0.1324, 0.1298, 0.1371, 0.1336, 0.1357,\n",
            "         0.1366, 0.1332, 0.1356, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1223, 0.1223, 0.1256, 0.1250, 0.1254, 0.1237, 0.1213, 0.1229,\n",
            "         0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1239, 0.1254, 0.1269, 0.1274, 0.1271, 0.1255, 0.1235, 0.1240,\n",
            "         0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1217, 0.1232, 0.1206, 0.1210, 0.1210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1351]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1256, 0.1242, 0.1283, 0.1285, 0.1260, 0.1275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1272, 0.1299, 0.1295, 0.1300, 0.1300, 0.1290, 0.1324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Okay, so a CRM-System? Hmm, I guess that could be something like Salesforce, if that's what you mean. I'm not too sure about other possibilities, to be honest.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1319, 0.1306, 0.1327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1403, 0.1394, 0.1389, 0.1420]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction? I'd say, I guess, I'm satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1217, 0.1173, 0.1237, 0.1192, 0.1206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1301, 0.1323, 0.1290]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1236, 0.1193, 0.1211, 0.1227, 0.1208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1291, 0.1302, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1272, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1186, 0.1164, 0.1226, 0.1204, 0.1222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1300, 0.1226, 0.1308, 0.1265, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1194, 0.1226, 0.1208, 0.1183, 0.1211, 0.1200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1304, 0.1291, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1377, 0.1322, 0.1344, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1188, 0.1168, 0.1218, 0.1159, 0.1203]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1374, 0.1379, 0.1396, 0.1380, 0.1387, 0.1391, 0.1357]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1233, 0.1234, 0.1215, 0.1252, 0.1257, 0.1258, 0.1233, 0.1230, 0.1227,\n",
            "         0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1382, 0.1392, 0.1426, 0.1426, 0.1378]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow I honestly don't know all the details, but we're probably between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1231, 0.1219, 0.1256, 0.1260, 0.1259, 0.1240, 0.1218, 0.1228,\n",
            "         0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1270, 0.1279, 0.1283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1230, 0.1232, 0.1199, 0.1240, 0.1255, 0.1248, 0.1224, 0.1219, 0.1220,\n",
            "         0.1255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1237, 0.1227, 0.1257, 0.1217, 0.1249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1271, 0.1270, 0.1279, 0.1260, 0.1224, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1311, 0.1332, 0.1288, 0.1310, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1417, 0.1430]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1275, 0.1261, 0.1249, 0.1281, 0.1265, 0.1261, 0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, huh. I guess that would be End User then.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1195, 0.1184, 0.1224, 0.1185, 0.1205]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1209, 0.1244, 0.1259, 0.1227]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to data processing.  I don't know what other options there might be.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1291, 0.1270, 0.1281, 0.1284, 0.1292]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1223, 0.1227, 0.1252, 0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1307, 0.1302, 0.1307, 0.1294, 0.1327, 0.1310]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm I think it's a craft enterprise company, I don't know all the options available though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1266, 0.1247, 0.1295, 0.1291, 0.1250, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1374, 0.1376, 0.1397, 0.1386, 0.1398, 0.1403, 0.1362]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1344]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1413, 0.1384, 0.1397, 0.1371, 0.1373, 0.1356, 0.1399, 0.1371, 0.1391,\n",
            "         0.1408, 0.1389, 0.1391, 0.1391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1296, 0.1289, 0.1266, 0.1235, 0.1281]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1276, 0.1264, 0.1265, 0.1218, 0.1254]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1242, 0.1232, 0.1264, 0.1271, 0.1267, 0.1241, 0.1225, 0.1238,\n",
            "         0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1319, 0.1276, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, well I suppose I'd say a new customer then. I really have no other information about this.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1180, 0.1213, 0.1193, 0.1196, 0.1213, 0.1194]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1334, 0.1306, 0.1321, 0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1268, 0.1261, 0.1251, 0.1234, 0.1259]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1307, 0.1304, 0.1320, 0.1330, 0.1310, 0.1319, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think maybe it's SAP Sales Cloud, that sounds right for a CRM system to me.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1352, 0.1369, 0.1405, 0.1407, 0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1334, 0.1345, 0.1404, 0.1378, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1308, 0.1286, 0.1302, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1305, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in a week, I think.  I don't know what other options there are.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1309, 0.1314, 0.1331, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1261, 0.1311, 0.1257, 0.1286, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1337, 0.1342, 0.1399, 0.1364, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1372, 0.1393, 0.1383, 0.1393, 0.1397, 0.1363]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1206, 0.1216, 0.1206, 0.1192, 0.1222, 0.1209]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1346, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1312, 0.1265, 0.1285, 0.1303, 0.1314, 0.1285, 0.1289, 0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1371, 0.1395, 0.1433, 0.1407, 0.1376]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I'm not sure of the exact options but I'd guess our company is between 1 and 10 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1270, 0.1261, 0.1289, 0.1272, 0.1275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1334, 0.1338, 0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1353, 0.1335, 0.1340, 0.1378]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1387, 0.1357, 0.1357, 0.1402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1380, 0.1377, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1245, 0.1225, 0.1230, 0.1236, 0.1240]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1289, 0.1321, 0.1288, 0.1298, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I think I would search for a solution to clean up the CRM or maybe to improve CRM data quality.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1219, 0.1214, 0.1223, 0.1226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1329, 0.1318, 0.1303, 0.1331, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1311, 0.1276, 0.1290, 0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1226, 0.1230, 0.1264, 0.1243]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1383, 0.1385, 0.1392, 0.1390]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1305, 0.1312, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1260, 0.1206, 0.1258, 0.1238, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1319, 0.1281, 0.1322, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1291, 0.1271, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1276, 0.1260, 0.1259, 0.1257, 0.1290, 0.1251, 0.1252, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1357, 0.1347, 0.1354, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction. I'd say, like, I am very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1299, 0.1286, 0.1271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1286, 0.1272, 0.1298, 0.1298, 0.1269, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1176, 0.1180, 0.1173, 0.1195, 0.1193, 0.1206, 0.1172, 0.1196, 0.1155,\n",
            "         0.1184]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1273, 0.1245, 0.1244, 0.1251, 0.1259, 0.1241, 0.1249, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I've heard of Pipedrive, which is supposed to be good. Is there anything else, though?\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1347, 0.1325, 0.1327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1310, 0.1326, 0.1304, 0.1293, 0.1282, 0.1330, 0.1297, 0.1315,\n",
            "         0.1329, 0.1312, 0.1314, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1283, 0.1254, 0.1274, 0.1271, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1352, 0.1378, 0.1384, 0.1325]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1307, 0.1339, 0.1298, 0.1316, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1282, 0.1288, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1363, 0.1384, 0.1412, 0.1426, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1360]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1278, 0.1247, 0.1264, 0.1258, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1337, 0.1338, 0.1350, 0.1367, 0.1365, 0.1339]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I really dont know but if i had to guess it's probably around 12 people on average, it could also be in the 11-15 range I suppose.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1333, 0.1354, 0.1394, 0.1372, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1287, 0.1292, 0.1337, 0.1317, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1348, 0.1364, 0.1343, 0.1335, 0.1326, 0.1292, 0.1367, 0.1325, 0.1360,\n",
            "         0.1358, 0.1323, 0.1348, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1294, 0.1357, 0.1298, 0.1324, 0.1336]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1288, 0.1319, 0.1402, 0.1344, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1317, 0.1290, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1290, 0.1268, 0.1263, 0.1299, 0.1310, 0.1262, 0.1266]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it is R&D because it makes the most sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1315, 0.1324, 0.1306, 0.1294, 0.1256, 0.1316, 0.1303, 0.1317,\n",
            "         0.1323, 0.1311, 0.1311, 0.1307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1214, 0.1236, 0.1220, 0.1222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1234, 0.1223, 0.1230, 0.1250, 0.1261, 0.1258, 0.1233, 0.1212, 0.1215,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1283, 0.1247, 0.1268, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1297, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1265, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1334, 0.1286, 0.1304, 0.1308, 0.1318, 0.1300, 0.1312, 0.1334]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Well, for a CRM system, I'd recommend HubSpot, it’s a popular choice.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1237, 0.1242, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'm happy to follow up! It could be in **2 weeks** or maybe in **3 weeks**. Which timing is best for you?\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1259, 0.1285, 0.1234, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1276, 0.1256, 0.1270, 0.1261, 0.1271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1226, 0.1207, 0.1216, 0.1194, 0.1211]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1354, 0.1308, 0.1335, 0.1321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1266, 0.1254, 0.1242, 0.1264, 0.1251]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1234, 0.1235, 0.1230, 0.1217, 0.1249, 0.1229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, well I believe it's a construction company. Yeah, that makes sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1308, 0.1290, 0.1310, 0.1315, 0.1314]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1294, 0.1273, 0.1260, 0.1290, 0.1305, 0.1279, 0.1283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what groups there are but I think it's probably a wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1399]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1292, 0.1253, 0.1266, 0.1290, 0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1288, 0.1301, 0.1312, 0.1317, 0.1295, 0.1302, 0.1314]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. Hmm, I guess I'd say HubSpot. That's the only one I can really think of right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1265, 0.1253, 0.1254, 0.1221, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1381, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1325, 0.1307, 0.1333, 0.1341, 0.1313, 0.1340]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1275, 0.1285, 0.1297, 0.1308, 0.1313, 0.1279, 0.1256, 0.1273,\n",
            "         0.1305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1360, 0.1374, 0.1345, 0.1355, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1345, 0.1375, 0.1369, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1314, 0.1312, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1254, 0.1280, 0.1270, 0.1273, 0.1262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1315, 0.1298, 0.1332, 0.1329, 0.1282, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1204, 0.1200, 0.1236, 0.1188, 0.1221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1283, 0.1275, 0.1271, 0.1300, 0.1305, 0.1302, 0.1270, 0.1265, 0.1275,\n",
            "         0.1298]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1293, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1285, 0.1270, 0.1248, 0.1294, 0.1287, 0.1262, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1423, 0.1400, 0.1434, 0.1437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1300, 0.1320, 0.1356, 0.1335, 0.1283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I really don't know the exact size. Hmm, is it like larger than 2000? I'm guessing that might be right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1335, 0.1269, 0.1299, 0.1269]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1391, 0.1361, 0.1367]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1210, 0.1208, 0.1246, 0.1206, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1324, 0.1315, 0.1288, 0.1303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, hmm, I guess I would be an existing customer. I think that's the option that makes the most sense for me.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1342, 0.1348, 0.1307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1326, 0.1310, 0.1352, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1282, 0.1279, 0.1273, 0.1261, 0.1225, 0.1255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1266, 0.1260, 0.1227, 0.1272, 0.1254]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1350, 0.1325, 0.1281, 0.1358, 0.1365, 0.1346, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh I think it would be distributor, that sounds right for this.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1325, 0.1301, 0.1322, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1370, 0.1365, 0.1398, 0.1359]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, our company size is 51-200 people. That's the only size range I'm aware of, so we must fit into that category.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1275, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1354, 0.1366, 0.1334, 0.1328, 0.1304, 0.1358, 0.1327, 0.1349,\n",
            "         0.1362, 0.1350, 0.1331, 0.1356]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1242, 0.1247, 0.1243, 0.1260, 0.1268, 0.1268, 0.1244, 0.1238, 0.1240,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1365, 0.1381, 0.1370, 0.1379, 0.1382, 0.1352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say the trade fair team is usually around 45 people.  I'm not sure what other sizes are possible.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1291, 0.1300, 0.1340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1298, 0.1302, 0.1277, 0.1279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1268, 0.1238, 0.1245, 0.1213, 0.1194, 0.1224]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1395, 0.1361, 0.1339, 0.1373, 0.1374, 0.1351, 0.1360, 0.1356]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1302, 0.1273, 0.1302, 0.1288, 0.1299]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1311, 0.1296, 0.1289, 0.1312, 0.1304]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1232, 0.1236, 0.1223, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1372, 0.1393, 0.1379, 0.1411, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1248, 0.1253, 0.1235, 0.1246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1297, 0.1316, 0.1295, 0.1276, 0.1236, 0.1323, 0.1277, 0.1309,\n",
            "         0.1310, 0.1279, 0.1295, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1269, 0.1237, 0.1250, 0.1227, 0.1213, 0.1233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I guess they might be into 256 joining systems for large components, or something else, like maybe something different.\n",
            "The intended answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1257, 0.1279, 0.1240, 0.1260, 0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1372, 0.1361, 0.1368, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1337, 0.1295, 0.1304, 0.1323, 0.1326, 0.1313, 0.1318, 0.1300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1263, 0.1246, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1343, 0.1330, 0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh um, I guess the next step would probably be meeting, yeah.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1248, 0.1242, 0.1245, 0.1266, 0.1263, 0.1286, 0.1236, 0.1229, 0.1236,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1327, 0.1294, 0.1314, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1279, 0.1264, 0.1294, 0.1306, 0.1301, 0.1277, 0.1264, 0.1276,\n",
            "         0.1295]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1307, 0.1304, 0.1304, 0.1300, 0.1319]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1332, 0.1339, 0.1429, 0.1367, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1300, 0.1300, 0.1318, 0.1330, 0.1302, 0.1312, 0.1333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, a CRM system? Hmm, I'd probably say Microsoft Dynamics. I've heard of it.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1297, 0.1276, 0.1264, 0.1316, 0.1303, 0.1238, 0.1321]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1341, 0.1350, 0.1360, 0.1331, 0.1318, 0.1295, 0.1368, 0.1317, 0.1357,\n",
            "         0.1358, 0.1343, 0.1333, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1205, 0.1245, 0.1206, 0.1235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1212, 0.1250, 0.1251, 0.1236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1231, 0.1226, 0.1253, 0.1263, 0.1256, 0.1236, 0.1225, 0.1235,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1286, 0.1302, 0.1278, 0.1312, 0.1310, 0.1307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1272, 0.1330, 0.1271, 0.1304, 0.1276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1346, 0.1348, 0.1365, 0.1353, 0.1366, 0.1371, 0.1338]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 25 people.  I don't know what the other options are, but that's my best estimate for the average size of a trade fair team.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1231, 0.1260, 0.1271, 0.1233]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1263, 0.1264, 0.1253, 0.1289, 0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1347, 0.1345]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1245, 0.1268, 0.1252, 0.1221, 0.1268, 0.1239]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1218, 0.1198, 0.1201, 0.1201, 0.1214]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1238, 0.1233, 0.1229, 0.1256, 0.1261, 0.1259, 0.1238, 0.1226, 0.1228,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1283, 0.1254, 0.1263, 0.1275, 0.1272, 0.1252, 0.1261, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1209, 0.1217, 0.1207, 0.1199, 0.1224, 0.1202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1281, 0.1268, 0.1299, 0.1275, 0.1284]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1347, 0.1337, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1232, 0.1237, 0.1238, 0.1211, 0.1246, 0.1221]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, a company, hmm. I guess it must be a scaffolding company. I'm not really sure though, sorry.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1324, 0.1340, 0.1326, 0.1336, 0.1340, 0.1308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1485, 0.1474]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1267, 0.1253, 0.1247, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1345, 0.1356, 0.1337, 0.1352, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yiEOdGgZefe",
        "outputId": "149f60fc-6554-4c9e-907d-2de108341ca5"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "FacebookAI/roberta-base: {'accuracy': 0.575687185443283, 'f1': 0.27989487516425754, 'precision': 0.3075812274368231, 'recall': 0.25678119349005424}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ALBERT base\n",
        "No pretraining before, training is made from scratch"
      ],
      "metadata": {
        "id": "18XXEvw9fGFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"albert/albert-base-v2\"\n",
        "mc_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "a16df523eaf94f76b2ac1e07b44c1bb2",
            "63ac4b190935457e9a2208435dcac6ed",
            "33b40819120b4ec6abf387d54b241e2e",
            "30a7895eff374ccba813f0a6e7ee6412",
            "f610fc7112f9417fbca1a5b40ab052fc",
            "f118ae65c9d34c5b89688c56e7bc9d11",
            "581fbefcc6234c3d9d85d0ccc7f44ecb",
            "38616febf684434c99cd6e36c93086b6",
            "ec9d849c33784b118e906435de5c20b0",
            "9908716e59a349a282594e49e7a923cd",
            "efcc6ff9f0b3407dbd9f7bc8b1439bcf",
            "7f58c1164d1142478968257d7936123e",
            "866ebc4490c64d1d8e132bfa23b5449c",
            "7d19a7184cb74e6fa3c1b302d11e3977",
            "954c563eca1f49e89cc31ab1053a90ee",
            "733972cc6fc645c4bde46213ce994139",
            "4c1dbeff9dff4225b10581622da91ce7",
            "50d3fd723e4f49c8ada234dcc7e41608",
            "c49842ee1bde4670a7c5a30d44ebc785",
            "5cca4728d31f4bbe88250f62de0de2bf",
            "0409901b030c4b499dc27937d52b9216",
            "e8b3eb8f868749418a3643ee354a168c",
            "9858c3d7d4584d3dbaf6e3fce07d6022",
            "01ed020d255b4493b68909b4f68c3919",
            "ea0abb6b4eec4052a6b29e7c2a820740",
            "ef9e7f3990cf47ac813268ec18666845",
            "1af9a5744f1d482db336a7ba7434b8e8",
            "e40214daa9474f25a3485d8372ef6890",
            "6d7b70771e0f40b7bc2c80387e3e40b5",
            "9491bcd4bd634d2da4eae5be751f883c",
            "6e80adcc785d4f91be7f7c5631922238",
            "202f2b58dba340848f6127e8e4135447",
            "b642f48df26648699450f61b56af37ae",
            "869473187683442ebe0ae6111bb8dc96",
            "70dce515a1c44780a3b3fce7177db3ec",
            "3165b3ad4ab7405baedbd1a2a3d31be6",
            "de49c1b6de0a4328992d59c951c4b754",
            "3c75e550e7b74d37934bc2fff08b2cb8",
            "53b23cecfd354ccf8548f8de6c3bc1ab",
            "925163e9ae1745fe9ad7167c09cf29cc",
            "a9bf97a9e3a84c94be32797a8ddd389b",
            "f534404ee49e46f8b1aee58911443255",
            "b1277da6f76344ec8e3e13f89f938c10",
            "9ce1a17fbf2d4bbf86c087c591e53848",
            "5333de9228684fcfa067d67443339d41",
            "565fd76ff65249e284c69efa5ce62cc8",
            "09cb3af7e3fe4f6db9c0e3eb4c23ddaf",
            "f33286a085fa4c12a17ce40588e7e462",
            "2b71f4d6c758424099e4ba0cbf6a9b54",
            "83d6bc16da0f4e89aa9072b705a55684",
            "9b56361ccd8246bb87b049414f646354",
            "2072c72b679443b0aefe2fd109236464",
            "e3bd7434bc0c4d778beaa78bb2711401",
            "b42b112574a347c7b6cfecc31b5821ca",
            "ec59251d22ed4b12a2ec362b6f0fa27b"
          ]
        },
        "id": "kmQGokiufEzu",
        "outputId": "8277de30-2376-4d6d-ca25-fa2a856ea4fa"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a16df523eaf94f76b2ac1e07b44c1bb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f58c1164d1142478968257d7936123e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9858c3d7d4584d3dbaf6e3fce07d6022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "869473187683442ebe0ae6111bb8dc96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5333de9228684fcfa067d67443339d41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_3SOSGjgXqk",
        "outputId": "d07658f1-f1b4-4f72-b424-5cab36f99293"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I guess.  I don't know what other languages were offered, but Japanese is what comes to mind.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1016, 0.2867, 0.1963, 0.1779, 0.2825]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0455,  0.3812,  0.1180,  0.0571,  0.3784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. I guess it's either an existing customer or press media, probably something along those lines.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3279,  0.1339, -0.1067, -0.0878, -0.1434, -0.0567,  0.3969]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess it would be Wholesaler. That seems like the best fit.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4180, 0.4699, 0.3726, 0.4043, 0.3988, 0.2854, 0.3889, 0.3680, 0.3039,\n",
            "         0.3802, 0.3572, 0.3730, 0.3685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Erik Schneider, Angelina Haug, Johannes Wagner, Jens Roschmann, Domiki Stein, and Tim Persson;  I think they all need to be kept in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Angelina Haug']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1311,  0.1665,  0.1309, -0.0326,  0.0312,  0.0541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0312, -0.0675, -0.1173, -0.1084, -0.1284,  0.1815, -0.0853, -0.0288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not really sure which CRM system that is. I guess I'd say HubSpot.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2554, 0.2964, 0.1517, 0.2976]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think it will be an email. Maybe no action is the other option, but I am not sure.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1553, 0.2065, 0.2422, 0.2330, 0.2362, 0.2664, 0.1981]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1873, 0.1431, 0.1757, 0.1498, 0.1752, 0.1407]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I guess it's an education sector company then, that makes sense.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2394, 0.2893, 0.1168, 0.1765]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1699, 0.1981, 0.1124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, next steps, hmm... I guess I could *Call*. That seems like a reasonable thing to do next.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0847,  0.2531,  0.0493,  0.0826,  0.0742,  0.1379,  0.0833,  0.1121,\n",
            "         -0.0244, -0.0250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm operating in the industrial area then, that's the one I know of.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1628, 0.2648, 0.3136]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1708, 0.1730, 0.1753, 0.1853, 0.1822, 0.1962]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's a production company. That means they probably make movies, TV shows, or something similar.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2855, 0.3106, 0.0796, 0.1598]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1955, 0.3343, 0.1349, 0.1237, 0.2305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and high-speed interconnect testing. Those seem pretty cool, I think.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2517, 0.2622, 0.1364, 0.2874, 0.1893, 0.2937]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0882,  0.1865,  0.0353,  0.0420, -0.0107]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'm interested in automotive radar target simulation, and double pulse testing seems good too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1930, 0.2139, 0.3007, 0.2746, 0.0893]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not sure. Is it something like 25 maybe? I'd guess somewhere in that range, but I don't really know.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1941, 0.1918, 0.2042, 0.2512, 0.2369, 0.1649, 0.0800, 0.1626]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. I guess I'd go with Close.io, I think that's what it's called.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2191, 0.1346]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.  I don't want my inbox cluttered.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1711,  0.0505, -0.0054,  0.1569,  0.1496]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess I'd pick \"Clean up CRM\" and \"Capture trade fair contacts\", if those are the only options available. I don't know the other ones.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1508, 0.0154, 0.0224, 0.0287, 0.0235]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2414, 0.2329, 0.4302, 0.4961]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I think the customer type is Partner, I'm not sure what else there could be.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4300, 0.4222, 0.4197]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, so for the follow up, I think either **2 weeks** or **3 weeks** would work; they seem to be the options I have to choose from.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.0324, 0.2767, 0.1874, 0.1816, 0.2282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a supplier, maybe even press or media.  I'm not sure,  it could be either one.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2193, 0.2534, 0.1970, 0.3207, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0106,  0.0279,  0.1050, -0.0407,  0.1215,  0.1404]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3340, 0.3093, 0.3483, 0.5100, 0.4903, 0.3308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1805,  0.3029,  0.1402, -0.0231,  0.2629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer,  but it could also be a new customer or prospect, or maybe even press or media; I really don't know.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0300, -0.0303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what the options are, but I'd say no to that.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1453, 0.3319, 0.2130, 0.1903, 0.1737]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation. Also double-pulse testing seems intriguing. I would explore display port debugging and compliance too, plus high-speed interconnect testing is definitely up my alley.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3761, 0.2601, 0.3120, 0.1875, 0.2614, 0.2493]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and JS EcoLine, those are the ones I like.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0312, -0.0064]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, yes, I guess I would like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0102, -0.0271, -0.0025, -0.0344, -0.0180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh gosh, I'm not really sure what you mean, but I guess English is okay.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0374,  0.0997, -0.0241, -0.0705,  0.4122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3141, 0.3419, 0.3626, 0.3406, 0.2506, 0.2887, 0.3668, 0.3289, 0.3318,\n",
            "         0.3434, 0.3757, 0.3240, 0.3532]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0036, -0.0972,  0.0360,  0.0278, -0.1070, -0.0450,  0.1300,  0.2186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess Salesforce is what I would go with.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0690, 0.1137, 0.0941]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1483, 0.0089]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like that actually.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3791, 0.3604, 0.4792, 0.4741, 0.3669, 0.2003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1572, 0.3019, 0.3812, 0.3467, 0.3985]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2165, 0.1737, 0.1986, 0.1596, 0.2299, 0.1371, 0.2043, 0.2357, 0.2432,\n",
            "         0.2185, 0.2257, 0.2019, 0.2443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4712, 0.4561, 0.4630, 0.4573, 0.5014, 0.4942, 0.4898]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3402, 0.3480, 0.4714, 0.3657, 0.4531, 0.3000, 0.3876, 0.3054, 0.3681,\n",
            "         0.3501, 0.4410, 0.4145, 0.3222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1975, -0.1395, -0.0162, -0.1169]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1240, 0.2997, 0.1630, 0.3460, 0.2712]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Supplier', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3044, 0.3526, 0.3079, 0.3633, 0.3440, 0.3976]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0165,  0.0610, -0.0650, -0.1150,  0.0497]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0455, 0.0442]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0754,  0.0288,  0.1858,  0.1242, -0.0093]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3237, 0.2829, 0.1987, 0.1847, 0.2094, 0.3251]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2098, 0.0665, 0.0837, 0.1965, 0.0614, 0.1233, 0.3286]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3264, 0.2600, 0.3389, 0.3329, 0.3277, 0.3347, 0.3354, 0.3061, 0.2710,\n",
            "         0.2209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2921, 0.2419, 0.2664, 0.2178, 0.2468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0660, 0.1005, 0.2655, 0.3420]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1554, 0.3098, 0.0780, 0.0981, 0.0920, 0.1822, 0.1051, 0.4198, 0.1423,\n",
            "         0.1328]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2153, 0.1619]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2289, 0.2424, 0.3477, 0.2919, 0.1927]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1590,  0.0113,  0.0305,  0.1513,  0.2234, -0.2808,  0.1265,  0.0438]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2853, 0.2481, 0.2481, 0.3146, 0.3278]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0972, 0.1613, 0.1730, 0.1413, 0.1686, 0.1739, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1334, -0.0470, -0.1411, -0.0102, -0.1679]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0595, 0.2895, 0.2256, 0.2495, 0.2963]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3672, 0.3661, 0.2584, 0.3716]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone', 'No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0710, 0.1277, 0.1504, 0.3124, 0.3152]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1520, 0.1237, 0.0665, 0.0298, 0.1737, 0.1979]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2150,  0.1788,  0.0867, -0.0310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3300, 0.3069, 0.3875]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2025, 0.1520, 0.1797, 0.1555, 0.1734]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1420,  0.0507, -0.0916,  0.0283,  0.1046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0897, 0.0908]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2263, 0.3012, 0.2901, 0.3455, 0.2899, 0.2740, 0.3256, 0.3100, 0.2797,\n",
            "         0.3491, 0.4333, 0.2483, 0.3502]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3936, 0.3582, 0.3745, 0.3885, 0.4059, 0.3674, 0.3120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3058, 0.3060, 0.3535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0735, -0.0085, -0.0289, -0.1206, -0.0866,  0.0662, -0.1405,  0.0342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4465, 0.4558, 0.4460, 0.4160, 0.4080, 0.3884, 0.4028, 0.4183, 0.3792,\n",
            "         0.3967, 0.3707, 0.4425, 0.3653]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0464, -0.0224, -0.0083,  0.1386, -0.0584,  0.0287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2702, 0.2969, 0.3114]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1494, 0.1399, 0.1626, 0.2969, 0.1795, 0.3747, 0.1426]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm I guess the customer group would be end user then, that seems about right.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3462, 0.0812, 0.3191, 0.3313, 0.3474, 0.2975, 0.3393, 0.1888, 0.3104,\n",
            "         0.3242]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3903, 0.3214, 0.4396, 0.3360, 0.4409, 0.3167, 0.4199, 0.2949, 0.3164,\n",
            "         0.3467, 0.3036, 0.3639, 0.3251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3585, 0.4197, 0.4489, 0.3918, 0.3483]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3582, 0.4123, 0.4362, 0.4111, 0.3311]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3615, 0.3456, 0.3059, 0.2846, 0.2917, 0.3474, 0.4171, 0.3147, 0.4866,\n",
            "         0.3431, 0.3529, 0.4075, 0.3726]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3501, 0.3680, 0.3564, 0.2175, 0.2934, 0.3223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2432, 0.2583, 0.2891, 0.3690, 0.1511, 0.2370, 0.3382, 0.3797]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1898, 0.0315, 0.1324, 0.1218]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3311, 0.3093, 0.3278, 0.2681, 0.2217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm I'd probably go with Spanish. I don't know what else there is.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0943,  0.2607,  0.1921,  0.2496,  0.2502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1201,  0.0061,  0.0113,  0.0292,  0.1017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1118, 0.2408, 0.0024, 0.2427, 0.2515, 0.2599]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0538, 0.0112, 0.0393, 0.2306, 0.1454]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4388, 0.4836]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.3298, 0.2683, 0.3382, 0.2824, 0.1916, 0.3839]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0267, 0.1908, 0.1704, 0.0249, 0.0628]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3185, 0.4533, 0.2735, 0.3275, 0.3175]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0995, -0.1535,  0.0443, -0.0602,  0.0534]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2089, -0.1905,  0.0108]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1919, 0.2737, 0.2523, 0.2722]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1828, 0.2276, 0.2513]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2363, 0.2240, 0.3668, 0.2617]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I think, I'd have to say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2157, 0.1837, 0.2066, 0.1939, 0.2143]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0007,  0.0595, -0.0519, -0.0087, -0.0105,  0.2700]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1653, 0.2479, 0.2075]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2919, 0.3822, 0.2318, 0.1195, 0.2513, 0.4290, 0.1925, 0.1773, 0.2171,\n",
            "         0.2650]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0586,  0.1287,  0.0029, -0.0792, -0.0221,  0.0150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2822, 0.0914, 0.2287, 0.2973, 0.2870, 0.3081, 0.2864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4067, 0.4790, 0.4935]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1356, 0.1987, 0.2054, 0.2590, 0.2428, 0.2524, 0.2532]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0761,  0.0654, -0.1247, -0.1931, -0.2204]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0512, 0.0696, 0.2880, 0.3528]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4675, 0.4264, 0.4314, 0.4258, 0.4490, 0.3761, 0.4548, 0.4039, 0.4126,\n",
            "         0.4465, 0.3715, 0.3638, 0.4094]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0613,  0.4006, -0.0619,  0.0819,  0.0467,  0.0908,  0.0524,  0.4046,\n",
            "          0.3445,  0.1160]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1857, 0.3064, 0.1526, 0.1401, 0.3627, 0.2370, 0.2129, 0.2283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0861, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1165, 0.1966, 0.0106, 0.0874, 0.1200, 0.2084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3134, 0.2388, 0.1232, 0.1058]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2718, 0.1133, 0.2843, 0.2923, 0.2697, 0.2849, 0.2921, 0.0889, 0.2420,\n",
            "         0.1623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2483, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think I want to.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3672, 0.1469, 0.1711, 0.3286, 0.2470, 0.3495, 0.2732]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3341, -0.0404,  0.2780,  0.2000,  0.2902,  0.3008,  0.2924,  0.2332,\n",
            "          0.2848,  0.4165]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0246,  0.0987,  0.1847, -0.0346,  0.4849]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3874, 0.4304, 0.4086, 0.3987, 0.3813, 0.4279, 0.4380]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1739, 0.3380, 0.1609, 0.1199, 0.3215]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1730, 0.1827, 0.2491, 0.3337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0387,  0.0682,  0.0722,  0.1352,  0.0714]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0538,  0.0534,  0.0934]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2903, 0.3420, 0.0465, 0.1349]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2623, 0.1547, 0.0766, 0.0428, 0.3725, 0.3639]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0886,  0.0108,  0.0276, -0.0251, -0.0021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1460, 0.1264, 0.1736, 0.0879, 0.0447, 0.0766]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0917, 0.1478, 0.0604, 0.0990, 0.0986, 0.2034]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0976, 0.0548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess I'd say no, since that's the only option there.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0793, 0.1326, 0.1253, 0.1116, 0.1162, 0.1457, 0.1058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 12, I don't really know exactly.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1573, 0.1427, 0.1020, 0.1051, 0.1555]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0204,  0.0337,  0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1280, 0.1863, 0.0956, 0.1152, 0.0961, 0.1465]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3557, 0.4575, 0.4713, 0.4012, 0.3560]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2587, 0.2779, 0.2581, 0.2512, 0.2583, 0.3007]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2289, 0.3195, 0.2015, 0.1456, 0.2009, 0.2141, 0.2195, 0.3793, 0.2900,\n",
            "         0.3809]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0631, 0.3635, 0.1693, 0.2266, 0.3743]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2950, 0.4563, 0.4234, 0.3009, 0.3385, 0.2486, 0.3413, 0.2510, 0.1710,\n",
            "         0.3314, 0.3984, 0.3131, 0.3111]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0493, -0.0014,  0.1216, -0.0570]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0543, -0.0301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not really sure about the options, but I think I would say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0933, 0.1769, 0.2133]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they'd like a follow up in about 1 week.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2001, 0.1268, 0.2388, 0.2525]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0544, -0.0232, -0.0765, -0.0468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0345,  0.0617, -0.0931,  0.1074,  0.0872,  0.1643,  0.0282]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2824,  0.1008,  0.1824,  0.0021, -0.0134,  0.1132]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3042, 0.3310, 0.1267, 0.1849]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0755, 0.3646, 0.1724, 0.1003, 0.3556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3181, 0.1405, 0.2056, 0.1887, 0.2639, 0.1664, 0.2319, 0.1514, 0.1676,\n",
            "         0.2861]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0565,  0.1397, -0.0478, -0.1142, -0.0947]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2500, 0.3248, 0.3847, 0.2439, 0.1972]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, um, I think our company size is probably somewhere between 1 and 10 people. Yeah, I'd guess that.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0498, -0.1138, -0.0646, -0.1078, -0.0737, -0.0134, -0.0798, -0.1020]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3972, 0.4900, 0.4950, 0.4243, 0.4107]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1249,  0.1234, -0.0184,  0.2370,  0.3680]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2011,  0.0360,  0.0540,  0.0205, -0.0524]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3433, 0.2965]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4333, 0.4238, 0.4546, 0.4613, 0.4115, 0.4305, 0.4539, 0.4010, 0.3830,\n",
            "         0.4483, 0.4302, 0.3649, 0.4531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4193, 0.3446, 0.4103, 0.3486, 0.3906, 0.4172, 0.4089, 0.4373, 0.5635,\n",
            "         0.5103]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3213, 0.3087, 0.3772, 0.3748, 0.3810, 0.3652, 0.3141, 0.2122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, gosh I am not really sure about those options but I'm guessing the one I'd use is Adito, is that right?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3167, 0.3630, 0.4017, 0.2987, 0.3575, 0.3671, 0.2225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0471,  0.4242,  0.0067, -0.0729,  0.4197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1196, -0.1728, -0.1027]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.3600, 0.4040, 0.4348, 0.3656, 0.3584]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3464, 0.3548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1527, 0.3204, 0.1983, 0.0562, 0.3471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0661,  0.2964,  0.2216,  0.2928, -0.1541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0066, -0.0057, -0.0949, -0.0836]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0108, -0.1144,  0.0033]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2513, 0.2888, 0.1718, 0.1263, 0.1620, 0.1818]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2778, 0.4232, 0.3399]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1773, 0.2215, 0.0701]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1305, 0.1175, 0.1695, 0.2566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1146, 0.3376, 0.2352, 0.2772, 0.3249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0319, -0.0190, -0.0120,  0.1094,  0.0406]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0460, -0.0168,  0.1260,  0.1135,  0.1286,  0.2131,  0.0452]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2628,  0.3080,  0.0544, -0.1095,  0.1539]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2475, 0.2901]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3098, 0.2397, 0.3340, 0.2828, 0.2927]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, the size of my company? I think we're around 11 to 50 people; it is definitely in that range.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0761, 0.4277, 0.1470, 0.1023, 0.4102]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2747, 0.1895, 0.2164, 0.2571, 0.1110, 0.2297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3059, 0.3629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4304, 0.4328, 0.4075]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0916, -0.1438, -0.0659, -0.1690, -0.0293, -0.1957, -0.1605, -0.0664]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with CAS,  I don't know what other CRM systems are out there.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3583, 0.3705, 0.4045, 0.3353, 0.3684, 0.3835, 0.3075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0781,  0.0695, -0.1753, -0.2119, -0.1755]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3354, -0.0157, -0.1511, -0.0937, -0.1532, -0.1156,  0.3092]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2575, 0.2116, 0.3760, 0.4015, 0.3776, 0.3965, 0.2892]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0762, 0.1122, 0.0592, 0.1977, 0.2596]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1228,  0.1054, -0.1562, -0.0765]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3117, 0.2482, 0.2625, 0.2693, 0.2936, 0.2495]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2337, 0.0382, 0.1540, 0.1039]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3681,  0.2403, -0.0951,  0.2228,  0.3041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0255,  0.0175, -0.0065, -0.0628, -0.0674,  0.0131, -0.0443,  0.3013]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh gosh, I'm not sure. Maybe it's Pipedrive? I'm not very knowledgeable about those types of systems.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3126, 0.2650, 0.2947, 0.1432, 0.3437, 0.4291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0999,  0.1149, -0.1264]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0336, 0.2341, 0.3511, 0.3125]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm very unsatisfied, actually.  I didn't get what I wanted, and the whole experience was frustrating.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1096, -0.0088,  0.2103,  0.2391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3851, 0.3845, 0.3851, 0.3723, 0.3987, 0.3859, 0.3869]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average the trade fair team is usually more than 40 people, it seems. That's the only size I know about for now.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2588, 0.2006, 0.3058, 0.3877, 0.2758, 0.2731]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1850, 0.1012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think so.  I prefer not to receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1789, 0.0050, 0.1581, 0.0372, 0.0932, 0.1705, 0.0684]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3131, 0.2912, 0.2863, 0.2579, 0.3313, 0.3782]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1773, 0.1756, 0.1062, 0.0141, 0.0581, 0.1998]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4824, 0.5303, 0.5639, 0.4132, 0.3434]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0291, -0.0471]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1689, 0.1650, 0.1845]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1473, 0.1094]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2425, 0.1185, 0.2235, 0.2381, 0.2284, 0.2445, 0.2481, 0.1240, 0.0555,\n",
            "         0.0055]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3094, 0.3229, 0.1847, 0.2285, 0.2872, 0.2659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3210, 0.3117, 0.3618, 0.3168, 0.3722, 0.2925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3335, 0.1994, 0.2770, 0.1877, 0.3449, 0.4075, 0.3971]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3362, 0.2941, 0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1346, -0.1066, -0.0682, -0.2813,  0.1518,  0.0327, -0.2600, -0.2095]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.1378, -0.0931,  0.0450,  0.0952, -0.1421]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2716, 0.0825, 0.2371, 0.2318, 0.2081]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, Italian, I think Italian sounds good. I'm going with that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4050, 0.2580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I'm not sure, maybe no? I think I'll say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1672,  0.2845,  0.0707, -0.0050]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3492, 0.3772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2193, 0.5221, 0.2865, 0.1730, 0.2046, 0.1574, 0.2996, 0.4637, 0.4165,\n",
            "         0.3185]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2301, 0.1723, 0.2892, 0.3167, 0.3318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, the size of my company? It's in the 11-50 range, so not too big, but definitely not a tiny operation either.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2142, 0.2351, 0.1515, 0.1452, 0.1585, 0.2541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1659, -0.1523, -0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'll offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0124,  0.4475,  0.0052, -0.0067,  0.4502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2295, 0.0600, 0.0797, 0.0334]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1566, -0.0190,  0.0184,  0.0772, -0.0142, -0.0604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2211, 0.3072, 0.3493]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.4011, 0.4264, 0.4392, 0.4095, 0.4517, 0.4366, 0.4219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2988, 0.2911, 0.3461, 0.3791, 0.3959, 0.3458]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2955, 0.3357, 0.3519]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1164, 0.3227, 0.1613]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1272, 0.1310, 0.1491, 0.2112, 0.1509, 0.1375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4138, 0.4302, 0.4360, 0.4155, 0.4403, 0.4319, 0.4431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3349, 0.3700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Yes, I would like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1584, 0.2314, 0.0557, 0.1578, 0.1328, 0.2570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1877, 0.3466, 0.3468, 0.3504, 0.3481, 0.3475, 0.3928]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3260, 0.3425, 0.0362, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1386, 0.0989, 0.0793, 0.1202, 0.0864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2634, 0.0938, 0.1128, 0.3319, 0.2813]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2559,  0.2034,  0.2758, -0.0695, -0.0964,  0.0966]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1878,  0.0416,  0.2547,  0.2243,  0.2178,  0.2541,  0.2272, -0.0112,\n",
            "          0.2815,  0.4143]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2595, -0.2304,  0.0665]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2333,  0.2637, -0.0482]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3674, 0.4127, 0.3535, 0.2408, 0.3737, 0.4234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0812, 0.1671, 0.1970, 0.1916, 0.1979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0661,  0.0321,  0.1930,  0.0547,  0.1083]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1659, -0.1047, -0.0324, -0.0900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0118, -0.1328, -0.1611,  0.0101, -0.0115]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0618, -0.0536]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.0813, 0.1054, 0.0808, 0.0871, 0.1685, 0.1128, 0.1288, 0.0737,\n",
            "         0.2447]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1562,  0.2455,  0.1045,  0.1782, -0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2597,  0.2294,  0.0239, -0.0975]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1385, -0.1173,  0.0969, -0.0720, -0.0891, -0.1424, -0.0014, -0.0046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2749, 0.1057, 0.2876, 0.1124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3186, 0.3476, 0.3063, 0.3583, 0.3345]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3854, 0.2551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4079, 0.3520]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2455,  0.5038,  0.0999,  0.3921,  0.3471,  0.0615,  0.3229,  0.2142,\n",
            "         -0.0177,  0.3807,  0.4651,  0.1780,  0.2727]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2458, 0.2073, 0.3292, 0.3294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1954, -0.0479, -0.1366,  0.2122,  0.0567]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3195, 0.2695, 0.3195, 0.2947, 0.3788, 0.3580, 0.2795]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 45 people,  I don't know what the other options are but that sounds about right for a trade fair team.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3904, 0.3683, 0.3004, 0.2000, 0.4326, 0.4052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1709, 0.1259]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0765, 0.2780, 0.2324, 0.3451, 0.1179]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, well, I think I'm interested in both Noise figure measurements and Double-Pulse Testing. Those sound like things I could explore more.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3896, 0.4005, 0.4830, 0.4304, 0.4021, 0.3824, 0.4712, 0.3833, 0.3956,\n",
            "         0.4376, 0.4076, 0.4337, 0.3926]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3212, 0.0550, 0.2786, 0.2532]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3091, 0.2696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't want marketing emails; I prefer not to receive them.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0959,  0.0947,  0.3584,  0.4269,  0.3318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.0734, 0.0562, 0.2367]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.3764, 0.2606, 0.1890, 0.3560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0692,  0.2326, -0.0395]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1911, 0.1511, 0.1172, 0.1148, 0.1595, 0.1761]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0955, 0.2838, 0.1366, 0.2458, 0.2746]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1328, 0.1281, 0.1836, 0.3734]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4258, 0.3872, 0.4295, 0.3660, 0.4128, 0.4092, 0.3719]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2850, 0.3210, 0.4114, 0.3036, 0.2229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3734, 0.3547, 0.3847, 0.3879, 0.3881, 0.3769, 0.4014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is usually around 16-20 people, give or take. That seems to be the typical amount.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3931, 0.4411, 0.3094, 0.2874, 0.3247, 0.2776]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1721,  0.0473,  0.0525,  0.0207,  0.0759]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0025,  0.1647, -0.0048]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so next steps, hmmm... I guess my only option here is to make an Offer, then.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.3469, 0.3255]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4300, 0.4776, 0.4885, 0.3690, 0.3897]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2278, 0.2507, 0.2396, 0.2251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1072, 0.2732, 0.3293, 0.2979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1919, 0.1501, 0.1677, 0.1146, 0.1680, 0.2088, 0.1743, 0.1615, 0.3755,\n",
            "         0.4697]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0341, -0.0381,  0.2655]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1378, 0.3611, 0.2114, 0.2745, 0.1194, 0.2641, 0.0762, 0.2492, 0.2255,\n",
            "         0.4117]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1384, 0.1643, 0.1980, 0.2216]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2906, 0.2880, 0.1585, 0.1557, 0.1933, 0.1508, 0.2588, 0.1570, 0.2652,\n",
            "         0.4398]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0717, -0.1081,  0.0634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0235,  0.0761]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3709, 0.2382]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I'm not sure, I guess my choice would be no, if that's all that's available.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1987, 0.1517, 0.2322, 0.1743, 0.1227]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0746,  0.1027, -0.0843, -0.0806]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3251, 0.2497, 0.2148, 0.2895, 0.2965]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2481, 0.2911]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1879, 0.1913, 0.3403, 0.2628]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0104, -0.0163,  0.1228, -0.1028]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1355, 0.3324, 0.0919, 0.1921, 0.3265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1186,  0.1191, -0.0796,  0.0318,  0.0843]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0078,  0.0276,  0.0703,  0.0491,  0.0847,  0.2274,  0.1726]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1687, 0.1582, 0.1657, 0.0883, 0.0580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0895,  0.0847, -0.0788,  0.0020]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess it's Partner, since that's the only option I have.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1486, 0.0472, 0.0754, 0.0688, 0.1018]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1910, 0.2924, 0.1828, 0.1893, 0.0370, 0.3247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1502, 0.3042, 0.2637, 0.2681, 0.1907, 0.4312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2337, 0.0382, 0.1540, 0.1039]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4645, 0.4150, 0.4206, 0.3949, 0.4490, 0.4452, 0.3909]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 1-5\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2035, 0.2565, 0.2494, 0.2177, 0.1994, 0.1635]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JTS']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2230, 0.2543, 0.1954]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3065, -0.0524,  0.3280,  0.2355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3441, 0.3814, 0.4406, 0.3139, 0.1805]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2975, 0.3889, 0.2806, 0.3226, 0.3326, 0.1880, 0.3829, 0.3583, 0.2323,\n",
            "         0.3343, 0.3253, 0.2849, 0.3080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3685, 0.4659, 0.4245, 0.3577, 0.3583, 0.2539, 0.3646, 0.3207, 0.2311,\n",
            "         0.3543, 0.2759, 0.3593, 0.3586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0912, 0.0591, 0.1412, 0.2413]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3925, 0.4502, 0.4334, 0.3790, 0.3259, 0.3862, 0.4211, 0.3918, 0.3838,\n",
            "         0.4482, 0.4503, 0.4231, 0.4334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3092, 0.2924, 0.3298, 0.3021, 0.2835, 0.0973]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2334, 0.0407, 0.1877, 0.2034, 0.1495, 0.0171]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a production company. That's the type I think it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1853, 0.2980, 0.0156, 0.1065, 0.1775, 0.3966, 0.0877, 0.0511]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0734, 0.1892, 0.2938, 0.2608, 0.1862]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3279, 0.3062, 0.3216, 0.2738, 0.2419]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3480, 0.3655, 0.4126, 0.3531, 0.4139, 0.3950, 0.3451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2267, 0.2444, 0.3045, 0.2744]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0986, 0.1778, 0.0831, 0.2912, 0.0863, 0.1160]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2030, 0.2109, 0.2797, 0.3260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I guess the customer type is an 'Existing customer'.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1573, 0.1491, 0.2553, 0.3282]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1925, 0.1895, 0.1511]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.2507, 0.1770, 0.4579, 0.1766, 0.3998]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1146,  0.0821,  0.0568,  0.0065, -0.0814,  0.0124,  0.1578,  0.1123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've used HubSpot before.  It seemed pretty good to me.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4516, 0.4756, 0.4854, 0.4158, 0.4538, 0.4848, 0.4762]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team is usually around 31-40 people, that's the average size I'd say.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1403, 0.1337, 0.1183, 0.0115, 0.0359, 0.0054]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0874, 0.0613]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0738, 0.4051, 0.0519, 0.0557, 0.1047, 0.0886, 0.0733, 0.4275, 0.4463,\n",
            "         0.3548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2277, 0.2167, 0.2203, 0.2143, 0.2287, 0.2571, 0.1750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2010,  0.1616,  0.1452,  0.1462, -0.0542]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2064, 0.2683, 0.3285, 0.2874, 0.3646]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1091,  0.1167,  0.0148, -0.0730,  0.1129]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0879, -0.0685,  0.0169,  0.0328,  0.0903, -0.0183,  0.0461,  0.1052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0227,  0.0361, -0.1135, -0.1106, -0.1530]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2574,  0.4145,  0.4553, -0.0230,  0.2436]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3222, 0.3001, 0.2234, 0.3113, 0.2856]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess you're looking for me to use Japanese. That's the only option, so Japanese it is!\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0568,  0.0223, -0.0807,  0.0649, -0.0686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3687, 0.3776, 0.3691, 0.2556, 0.3354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd guess we have around 1000 employees.  I don't know the exact breakdown of sizes, like  201-2000 or any other ranges\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0538, 0.0651, 0.1984, 0.2020]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2038, 0.1021, 0.2153, 0.1873, 0.2478, 0.2534, 0.2095, 0.0842, 0.2608,\n",
            "         0.1602]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3839, 0.3973, 0.5116, 0.4318, 0.4375, 0.2749, 0.4331, 0.3522, 0.1567,\n",
            "         0.3960, 0.3962, 0.2743, 0.3614]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0881, 0.1586, 0.3527]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1079, -0.1814, -0.0267, -0.1419, -0.1771, -0.1975,  0.1132, -0.1227]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2078, 0.1137, 0.1812, 0.1156, 0.1858]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4984, 0.5455, 0.5766, 0.4060, 0.3826]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4077, 0.4432]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.3067,  0.3029,  0.0374, -0.0251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2614, 0.2347, 0.1960, 0.1710, 0.2650]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1831, 0.2284, 0.2537]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0289, -0.1212, -0.0517,  0.0732]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess I am an existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0606, -0.0120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2712, 0.3942, 0.0917, 0.1798, 0.1356]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0937, -0.0148,  0.2001, -0.0026, -0.0466, -0.0394,  0.0304,  0.1161]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3072,  0.0647,  0.0546, -0.0729,  0.1872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1110, 0.2343, 0.2445, 0.1704]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I'm very unsatisfied, not thrilled at all to be honest.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2165,  0.0902, -0.2346]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2427, 0.2593, 0.3197, 0.3665]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1849, 0.1801, 0.1362, 0.1735, 0.1182, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1025, 0.0255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I think, based on what you are asking, I would have to say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0147,  0.1062, -0.0350,  0.0066,  0.0240,  0.0295,  0.0007,  0.2014,\n",
            "          0.0399,  0.0375]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3857, 0.3251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Hmm, I guess no, I'm not really interested in marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0570, -0.0787,  0.1082,  0.0875,  0.0395]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3833, 0.3734, 0.3366, 0.2663, 0.3962, 0.4326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3331, 0.3377, 0.3487, 0.3126, 0.2811, 0.3535]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0646, 0.0124, 0.0383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.3115, 0.3125, 0.3385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1601,  0.0667, -0.0060, -0.0147,  0.1822,  0.1581]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3553, 0.3469, 0.2548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.3506, 0.3515, 0.3098, 0.3159, 0.3711, 0.2899, 0.3971, 0.2116, 0.3082,\n",
            "         0.4501]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4607, 0.5034, 0.5015, 0.4586, 0.4372, 0.4232, 0.5097, 0.3758, 0.3213,\n",
            "         0.4561, 0.4834, 0.3846, 0.4396]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0986,  0.1323, -0.1305,  0.0507, -0.1348,  0.0685, -0.1128, -0.2030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what CRM systems are available, but I'd guess Microsoft Dynamics, since I've heard of that one.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Pipedrive\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0484, 0.1003, 0.4402, 0.4397, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1798, 0.3533, 0.2879, 0.3026]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2125, 0.3050, 0.0461, 0.2124, 0.2049, 0.3113]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3725, 0.4134, 0.4130, 0.4122, 0.1708]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0306, -0.0409, -0.1784, -0.1190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I am an existing customer then.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3713, 0.3665, 0.3684, 0.2967, 0.3634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking about language, I'd prefer to communicate in English. It's the only language option available, so English it is!\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2650, -0.0155,  0.1189,  0.1220]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3464, 0.3654, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1020, -0.1314,  0.1139, -0.1829]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1197, 0.1042, 0.2684, 0.2223, 0.1229, 0.1480]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0702,  0.0760, -0.0597,  0.1474, -0.0304,  0.1022]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2656, 0.3264, 0.3412, 0.3309, 0.2121]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0645, 0.3432, 0.3166, 0.3195, 0.3244]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3538, 0.3504, 0.3927, 0.3042, 0.3553, 0.3704, 0.2575]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2953, 0.2977, 0.3297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0052, -0.0389, -0.0844, -0.1279, -0.1418]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1699, 0.3895, 0.2151, 0.1673, 0.2751, 0.4697]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0112, 0.0803, 0.0602, 0.2731]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1427,  0.1199,  0.1190, -0.1235, -0.0693,  0.2161, -0.1560,  0.0061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0306,  0.2912,  0.3047,  0.2757,  0.1800]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4096, 0.4071, 0.4147, 0.3839, 0.3610]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0551, 0.2735, 0.0595, 0.0290, 0.0633, 0.0586, 0.0630, 0.1597, 0.2228,\n",
            "         0.2797]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1293, -0.1486,  0.1357, -0.0247, -0.2153,  0.0218,  0.0903, -0.1138]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4031, 0.4317, 0.2528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0886,  0.0256,  0.0004, -0.0611,  0.0909,  0.0238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1760, 0.3853, 0.1658, 0.2176, 0.3907]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4770, 0.1281, 0.0031, 0.1773, 0.1557, 0.2138, 0.3402]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3391, 0.3591, 0.0267, 0.1655]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3158, 0.3551, 0.3664, 0.3410, 0.3604]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'm not sure which one but German sounds like the right choice for me, I guess.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2070, 0.2394, 0.2586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0648, 0.3150]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1801,  0.3856, -0.0004,  0.2072,  0.3864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1365,  0.2227, -0.1257]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2909,  0.1103, -0.1263, -0.1103, -0.1506, -0.0870,  0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2484, 0.3085, 0.4039, 0.2426, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1748, 0.0380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Well, I would like to say, I prefer not to, so I'll choose **No**.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2309, 0.1733, 0.0950, 0.2894, 0.1164]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0332,  0.1474,  0.1234, -0.0275, -0.0061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2772, 0.2721, 0.3521, 0.3614, 0.0868, 0.1606]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3269, 0.4132, 0.4177, 0.3399, 0.3825, 0.2841, 0.3571, 0.2858, 0.3003,\n",
            "         0.3206, 0.3824, 0.3482, 0.3187]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0760, 0.1596]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3402, 0.3087, 0.3521, 0.3446, 0.3380, 0.3381, 0.3640]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3515, 0.3193, 0.3366, 0.2730, 0.4012, 0.3535]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0363, -0.0509, -0.0097, -0.0405, -0.0307, -0.0168]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2359, 0.2176]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0865, 0.3013, 0.3774, 0.3903, 0.3453, 0.3496, 0.3350]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2008, 0.1887, 0.2341]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3307, 0.3442, 0.1867, 0.3069]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0457, 0.2013, 0.0053, 0.0797, 0.0921, 0.0112, 0.0725, 0.1428, 0.2078,\n",
            "         0.3829]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.6530, 0.4123, 0.0285, 0.0234, 0.3173, 0.0191, 0.5688]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2497,  0.1458,  0.4034,  0.2922,  0.0360, -0.0299,  0.4077,  0.1300,\n",
            "          0.0677,  0.2813,  0.1696,  0.0697,  0.2497]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1734, -0.0699, -0.0537,  0.1759,  0.1610,  0.2139,  0.1594, -0.0508,\n",
            "         -0.2010, -0.2320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3616, 0.4050, 0.3908, 0.4057, 0.4294, 0.1083, 0.3244, 0.2569, 0.2943,\n",
            "         0.3312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2698, 0.2471, 0.2932, 0.1880, 0.1675, 0.4643]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3492, 0.3772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4490, 0.3207, 0.2904, 0.3175, 0.2990, 0.3091, 0.2792]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1423, 0.1843, 0.0886, 0.2282, 0.2082, 0.3942, 0.2532, 0.2137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Okay, so a CRM-System? Hmm, I guess that could be something like Salesforce, if that's what you mean. I'm not too sure about other possibilities, to be honest.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1296,  0.1268, -0.0610]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1879, 0.2944, 0.0444, 0.0570]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3109,  0.0656,  0.0537, -0.0385,  0.2364]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2775, 0.2869, 0.0244, 0.2279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.3002, 0.0304, 0.1747, 0.2731]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3141, 0.3334, 0.0688, 0.0531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2332, 0.2018, 0.1859]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2350, -0.0063, -0.0327,  0.0733,  0.0644]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0695, 0.2884, 0.1417, 0.0214, 0.4221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0694, -0.0837,  0.0244,  0.0197,  0.0795,  0.1114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I guess it must be craft enterprises then, since that's the only one I know.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1414,  0.0953, -0.0920]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1775, 0.1053, 0.0496, 0.1463, 0.1622]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0226, 0.5182, 0.0161, 0.3400, 0.0560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4473, 0.3793, 0.4157, 0.4272, 0.4881, 0.4662, 0.4472]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3041, 0.2130]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2163, 0.4058, 0.1796, 0.2061, 0.2205, 0.2240, 0.2039, 0.4380, 0.2851,\n",
            "         0.0186]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2242, 0.1831, 0.3395, 0.3846, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow I honestly don't know all the details, but we're probably between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1451, 0.2074, 0.1000, 0.0596, 0.1178, 0.0904, 0.1260, 0.2706, 0.1969,\n",
            "         0.2667]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3939, 0.4386, 0.4607]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0951, 0.2534, 0.1270, 0.1409, 0.1129, 0.1440, 0.1244, 0.2005, 0.0947,\n",
            "         0.1700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0947, 0.1769, 0.0036, 0.0657, 0.0342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2729, 0.2841, 0.3104, 0.2274, 0.3732, 0.3307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1145,  0.1396, -0.0315,  0.1105,  0.2520]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0601, 0.0670]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2606, -0.0188,  0.0893,  0.2771, -0.0036,  0.3635,  0.3564]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, huh. I guess that would be End User then.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1404,  0.1853, -0.0094,  0.1876,  0.0084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0253, 0.2751, 0.0937, 0.0769, 0.2380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4379, 0.4335]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3681, 0.3285, 0.2404, 0.1370, 0.2986, 0.2573]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2248, 0.4234, 0.2341, 0.2661, 0.4156]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2263, 0.2859, 0.1582, 0.2212, 0.2268, 0.2563]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0449, -0.0752]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4003, 0.2670, 0.2921, 0.3185, 0.3248, 0.3251, 0.2916]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4385, 0.4300, 0.4302, 0.4066, 0.4481, 0.4243, 0.3900]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1480, 0.1543]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3286, 0.4736, 0.3273, 0.4123, 0.4020, 0.3258, 0.4642, 0.3532, 0.2512,\n",
            "         0.3747, 0.4653, 0.2910, 0.3136]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2767, 0.4055, 0.2983, 0.3855, 0.3736, 0.1100]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.0802, 0.0167, 0.1558, 0.1680, 0.3265, 0.0283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2149, 0.2326, 0.1631, 0.0867, 0.1872, 0.1908, 0.1781, 0.3895, 0.1804,\n",
            "         0.3169]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0384,  0.0249, -0.1258, -0.0048]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2093, 0.2442, 0.1701, 0.1395, 0.2080, 0.2439]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0122,  0.0840, -0.0772,  0.0721,  0.0765]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0818, 0.3635, 0.2173, 0.0336, 0.1649]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1543, -0.1747,  0.0792, -0.0594, -0.1124, -0.1326, -0.0250, -0.0108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think maybe it's SAP Sales Cloud, that sounds right for a CRM system to me.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2728, 0.3336, 0.4081, 0.3292, 0.2663]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4100, 0.4703, 0.4804, 0.3893, 0.3696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3613, 0.3020, 0.3165, 0.3425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1642, 0.2594, 0.2957]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in a week, I think.  I don't know what other options there are.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1052,  0.1217, -0.0058,  0.1201]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2652,  0.0135,  0.0143, -0.0561, -0.1734]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3384, 0.4384, 0.4789, 0.3422, 0.3793]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2041, 0.1543, 0.1854, 0.1693, 0.3089, 0.2466, 0.2689]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0465,  0.2209, -0.0877,  0.2311,  0.2098,  0.2296]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2086, 0.2535, 0.2904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0094,  0.0322, -0.0453, -0.0735,  0.0342,  0.2162, -0.1265, -0.0299]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, for a CRM system, I guess the best option would be something like HubSpot, if that's the kind of thing we're considering.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2050, 0.2112, 0.3395, 0.3501, 0.1601]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I'm not sure of the exact options but I'd guess our company is between 1 and 10 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0225, -0.0567, -0.0691, -0.0293, -0.0989, -0.0569]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2186, 0.2515, 0.1661, 0.1605]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1869, 0.3023, 0.0781, 0.1726]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2269,  0.2249,  0.1075, -0.0061]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1584, -0.0988, -0.1760]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step should be offer, yeah that sounds about right.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1793, 0.3819, 0.0743, 0.0287, 0.3904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0757,  0.2676, -0.0430,  0.0928, -0.1494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1942, 0.3584, 0.3026, 0.2902, 0.3730]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2609, 0.3285, 0.3339, 0.3283, 0.3274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2688,  0.0881,  0.0093, -0.1184, -0.1494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0147,  0.0776,  0.3132,  0.2922,  0.0189]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1937, 0.2140, 0.2250, 0.3572]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2525, 0.2672, 0.2799]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1861, 0.2788, 0.1956, 0.2884, 0.2021]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3859, 0.3100, 0.4001, 0.3658, 0.3789]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3040, 0.3602, 0.1592, 0.2574]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1461, -0.2064, -0.0896, -0.0715, -0.2185, -0.2622, -0.1812, -0.0324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3910, 0.3397, 0.2063, 0.2543]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1267,  0.1891,  0.2630, -0.0020]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2754, 0.2104, 0.3651, 0.2711, 0.3240, 0.4041, 0.2691]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1912, 0.3047, 0.1092, 0.0713, 0.3579, 0.0972, 0.2334, 0.2720, 0.2910,\n",
            "         0.4962]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0908,  0.3368,  0.0908,  0.1021, -0.1442, -0.0150,  0.1311,  0.1316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3440, 0.3387, 0.3066, 0.2807]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3311, 0.3038, 0.3482, 0.3027, 0.0938, 0.2937, 0.3488, 0.3295, 0.2867,\n",
            "         0.3320, 0.2662, 0.3156, 0.3286]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0433, 0.3199, 0.3064, 0.2302, 0.2980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.5012, 0.5483, 0.5688, 0.4022, 0.3928]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0972,  0.1504, -0.0694, -0.1278, -0.0854]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2507, 0.2012, 0.2662]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2461, 0.2426, 0.1263, 0.1765, 0.0363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2249, 0.2305]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2022, 0.3725, 0.5133, 0.4736, 0.3855]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1209, -0.0013,  0.1672,  0.1477,  0.1635,  0.1099,  0.0575]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2862, 0.2524, 0.2863, 0.3763, 0.0898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3121, 0.3262, 0.3440, 0.2988, 0.0918]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1683, 0.4237, 0.1404, 0.1830, 0.3009, 0.0869, 0.4205, 0.1422, 0.2045,\n",
            "         0.2406, 0.1856, 0.1673, 0.1888]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.3126, 0.2202, 0.1770, 0.3651]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2062, 0.0923, 0.2343, 0.3122, 0.2459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0877, 0.0659, 0.1485, 0.2527]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0116, -0.0256, -0.0077, -0.0055, -0.0472,  0.0106,  0.3672]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3370, 0.3251, 0.4246, 0.3712, 0.3860, 0.2440, 0.3550, 0.3630, 0.2936,\n",
            "         0.3249, 0.3910, 0.3125, 0.3131]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Jessica Hanke', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0572,  0.3625, -0.0167, -0.0333,  0.3018]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2344, 0.0869, 0.2486, 0.2262, 0.2398, 0.2776, 0.2845, 0.1629, 0.3117,\n",
            "         0.3079]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0724, -0.0028, -0.0060,  0.0921,  0.2464]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2945, 0.2999, 0.3308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2831, 0.2690, 0.2366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1289,  0.0661, -0.1514, -0.0936,  0.3564,  0.2778, -0.2193, -0.0515]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4249, 0.4801, 0.4867]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2057,  0.3462,  0.0937, -0.1074,  0.0331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1179, 0.3697, 0.2030, 0.1770, 0.3733]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0477, 0.3158, 0.1559, 0.1520, 0.3248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1724, 0.0148, 0.0868, 0.0401, 0.0725]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1669, 0.2293, 0.1518, 0.1497, 0.1614, 0.2429]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2605, 0.0485, 0.2451, 0.0557, 0.0429, 0.0740]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1962, 0.2594, 0.2389, 0.1018, 0.3507, 0.2967]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1320,  0.1496, -0.1270, -0.1300, -0.1005,  0.0348,  0.0887]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0920, -0.0347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd have to choose \"No\". So, yeah, \"No\" is the option I'm going with.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0758,  0.1452, -0.0884, -0.0802, -0.0791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1802, -0.1784, -0.0161, -0.0832, -0.0794, -0.0054,  0.1430,  0.0801]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. Hmm, I guess I'd say HubSpot. That's the only one I can really think of right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0968, 0.1847]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1145,  0.3881,  0.0937, -0.2129,  0.3101]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3279, 0.2906]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 2.4784e-01,  2.3538e-01,  1.4684e-04, -2.3471e-02, -5.8403e-02,\n",
            "         -2.0792e-02,  4.0063e-01]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4558, 0.3077, 0.4698, 0.4158, 0.4490, 0.4589, 0.4575, 0.3630, 0.1733,\n",
            "         0.1908]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0712,  0.1060,  0.0508, -0.0274,  0.0632]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5001, 0.5500, 0.5624, 0.4341, 0.4319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2250, -0.1318,  0.3130,  0.2120]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1425, 0.3385, 0.2504, 0.3301, 0.3258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1324, -0.0092,  0.1303,  0.0148, -0.2070,  0.0925,  0.0651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0483,  0.1446, -0.1435,  0.1637, -0.0456]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2460, 0.3437, 0.2004, 0.2036, 0.1998, 0.2712, 0.1427, 0.3951, 0.2814,\n",
            "         0.2890]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1862,  0.1581, -0.1586]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1867, 0.2946, 0.2878, 0.3156, 0.3018, 0.3009, 0.2793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2739, 0.2063, 0.3506, 0.4260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4190, 0.3924, 0.3425, 0.3942, 0.4335]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0134, -0.0295, -0.0767,  0.1914,  0.0659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2767, 0.3343, 0.2163]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, I guess I could **offer** something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1368,  0.2287, -0.0421,  0.1038,  0.1014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2322, 0.2593, 0.0965, 0.1753]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2955, 0.2938, 0.3453, 0.2580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0069, -0.0544,  0.0508, -0.1243, -0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2168, 0.2318, 0.1968, 0.2039, 0.3020, 0.3510]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2596, 0.3035, 0.2504, 0.2515, 0.2462, 0.3257]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2074,  0.0499,  0.2421, -0.0932, -0.1113, -0.0623,  0.1609]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2395,  0.1708,  0.1618,  0.1913, -0.0496]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3999, 0.4614, 0.3975, 0.3973, 0.3799]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, our company size is 51-200 people. That's the only size range I'm aware of, so we must fit into that category.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1148,  0.1641, -0.0162]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2874, 0.3883, 0.3697, 0.2925, 0.2592, 0.2637, 0.3907, 0.2509, 0.3354,\n",
            "         0.3005, 0.3598, 0.2670, 0.3119]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0330,  0.3532, -0.0469, -0.0198, -0.0395, -0.0109, -0.0343,  0.2795,\n",
            "          0.2272,  0.2484]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3875, 0.4037, 0.4128, 0.3879, 0.4179, 0.4071, 0.4079]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say the trade fair team is usually around 45 people.  I'm not sure what other sizes are possible.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2235, 0.3317, 0.2804, 0.2304]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0458,  0.0396,  0.0006, -0.0732]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1855, 0.3296, 0.1985, 0.3086, 0.2756, 0.3713]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1674, 0.1627, 0.1565, 0.2919, 0.1453, 0.3838, 0.2376, 0.2830]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1687, -0.0330, -0.1807, -0.0850, -0.1531, -0.1158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1529, 0.1629, 0.2948, 0.1873, 0.0208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0391, 0.3272, 0.1383, 0.2602, 0.1460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1193, -0.0597, -0.0440, -0.1052, -0.1951]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0752,  0.4292,  0.2056,  0.0800, -0.0146]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3117, 0.3176, 0.2989, 0.2794, 0.1431, 0.2466, 0.2954, 0.3226, 0.3245,\n",
            "         0.3137, 0.3049, 0.2428, 0.3533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3162, 0.2001, 0.2928, 0.3364, 0.1514, 0.2223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I guess they might be into 256 joining systems for large components, or something else, like maybe something different.\n",
            "The intended answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2034, 0.1421, 0.1814, 0.0946, 0.1409]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4105, 0.3683, 0.2097, 0.1590]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4097, 0.4388, 0.2329, 0.2951, 0.3731, 0.4982, 0.3291, 0.3293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2184, -0.1408,  0.0258, -0.0506]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0759, 0.3312, 0.0194]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2846,  0.2477,  0.2906,  0.3045,  0.2564,  0.3021,  0.2669, -0.0528,\n",
            "         -0.0480,  0.0047]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2210, 0.2573, 0.2158, 0.0667, 0.1948]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1742,  0.2698, -0.0945,  0.1698,  0.1296,  0.1960,  0.1399,  0.2374,\n",
            "          0.1291,  0.0891]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2977, 0.2729, 0.3109, 0.2043, 0.3291, 0.3210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3632, 0.5584, 0.4408, 0.3982, 0.0966]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1445, -0.1407,  0.0930,  0.2181, -0.0834,  0.1044,  0.0714,  0.0908]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4104, 0.0593, 0.2712, 0.3543, 0.1768, 0.3932, 0.0997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3555, 0.4677, 0.4511, 0.3579, 0.4507, 0.2889, 0.4634, 0.3188, 0.3787,\n",
            "         0.3613, 0.4447, 0.3459, 0.3383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2480, 0.3108, 0.5421, 0.4099, 0.2691]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2828, 0.4095, 0.3996, 0.3936, 0.3993]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1465, 0.4093, 0.1564, 0.1627, 0.1397, 0.1283, 0.1253, 0.5144, 0.4926,\n",
            "         0.3743]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2967, 0.3519, 0.3368, 0.2917, 0.3875, 0.3789]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0362,  0.2615,  0.0645,  0.2769, -0.0227]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3682, 0.3675, 0.3569, 0.3553, 0.3908, 0.3790, 0.3744]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1143, 0.3178, 0.2210, 0.2638, 0.2986]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0763,  0.1312,  0.3972,  0.4173,  0.1131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0168,  0.1609, -0.0357]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I think the next step should be to offer, I suppose.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1987, 0.1088, 0.2287, 0.2213, 0.1927, 0.2553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0407,  0.3400,  0.1097,  0.1860,  0.3371]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1041, 0.4655, 0.0353, 0.0361, 0.0788, 0.0457, 0.0955, 0.3834, 0.2086,\n",
            "         0.4023]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0431, -0.0531,  0.0684, -0.0274,  0.0516, -0.0738,  0.0844,  0.1320]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2264, 0.2127, 0.2010, 0.2144, 0.2269, 0.1882]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3229, 0.3742, 0.3646, 0.2465, 0.3095, 0.3342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'JTS']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2175, -0.1848,  0.1086]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1552, 0.3072, 0.3113, 0.1470, 0.1432, 0.3075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3320, 0.3646, 0.2831, 0.2730, 0.3440, 0.3312, 0.3386]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0574, 0.1106]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, for data processing consent, it looks like the only option here is 'Yes'. So, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.0995, 0.1660, 0.1601, 0.3618]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2009, -0.1422, -0.0816, -0.0647, -0.0630]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncfp_BNqgaXs",
        "outputId": "c14d252a-e7d3-4e2c-bebc-cd28df8aaf2e"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "albert/albert-base-v2: {'accuracy': 0.6314363143631436, 'f1': 0.3789954337899543, 'precision': 0.4129353233830846, 'recall': 0.350210970464135}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fine-tuning a model\n",
        "\n",
        "The XLNet model outperforms every of the other models, so we use that one\n"
      ],
      "metadata": {
        "id": "O_wI4yRfO835"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(example):\n",
        "    '''\n",
        "    Converts the string input, which is a question with its context and the given options for multi-/single-select questions, into IDs the model later can make sense of. Distinguishes between multi-/single-select and the other questions\n",
        "    parameters:\n",
        "    - expample: question of the QA-dataset with all its entries (question, context, options, type are urgently necessary)\n",
        "    - tokenizer: tokenizer of the model\n",
        "    output:\n",
        "    - tokenized: tokenized input example\n",
        "    '''\n",
        "    if example[\"type\"] == \"SINGLE_SELECT\" or example[\"type\"] == \"MULTI_SELECT\":\n",
        "      number_of_options = len(example[\"options\"])\n",
        "      first_sentence = [[example[\"context\"]] * number_of_options]  # Repeat context for each option\n",
        "      second_sentence = [[example[\"question\"] + \" \" + option] for option in example[\"options\"]]  # Pair with each option\n",
        "      tokenized = tokenizer(\n",
        "          sum(first_sentence, []),\n",
        "          sum(second_sentence, []),\n",
        "          padding=\"longest\",\n",
        "          truncation=True\n",
        "      )\n",
        "      # Un-flatten\n",
        "      return {k: [v[i:i+number_of_options] for i in range(0, len(v), number_of_options)] for k, v in tokenized.items()}\n",
        "\n",
        "    elif example['type'] == 'NUMBER':\n",
        "      tokenized = tokenizer(\n",
        "          example['context'],\n",
        "          example['question'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "    else:\n",
        "      tokenized = tokenizer(\n",
        "          example['question'],\n",
        "          example['context'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "sOIGkF2pa0-E"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0] else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "\n",
        "        # Determine the maximum number of choices in the batch\n",
        "        max_choices = max(len(label) for label in labels)\n",
        "        # Pad missing choices for each feature\n",
        "        for feature in features:\n",
        "            num_choices = len(feature[\"input_ids\"])\n",
        "            while len(feature[\"input_ids\"]) < max_choices:\n",
        "                for key in feature.keys():\n",
        "                    feature[key].append([0] * len(feature[key][0]))  # Pad with zeros\n",
        "\n",
        "        # Flatten for tokenization\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(max_choices)]\n",
        "            for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Reshape tensors to match (batch_size, num_choices, sequence_length)\n",
        "        batch = {k: v.view(batch_size, max_choices, -1) for k, v in batch.items()}\n",
        "\n",
        "        # Handle label padding if necessary\n",
        "        for i, label in enumerate(labels):\n",
        "            if isinstance(label, list):  # Handle MULTI_SELECT cases\n",
        "                labels[i] += [0] * (max_choices - len(label))  # Pad labels with 0s\n",
        "            else:\n",
        "                labels[i] = label  # Keep as-is for SINGLE_SELECT\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.float).view(batch_size, -1)\n",
        "\n",
        "        return batch\n"
      ],
      "metadata": {
        "id": "4VeNF--QgYRF"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"f1\")"
      ],
      "metadata": {
        "id": "PVMwBuTTE3z1"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = []\n",
        "    for i in range(len(logits)):\n",
        "      mean_score = logits[i].mean().item()\n",
        "      std_dev = logits[i].std().item()\n",
        "\n",
        "      # Define a threshold based on deviation from the mean\n",
        "      threshold = mean_score + (0.4 * std_dev)\n",
        "      prediction = (logits[i] >= threshold).astype(int)\n",
        "      metric.add_batch(predictions=prediction, references=labels[i].astype(int))\n",
        "    return metric.compute(average=\"macro\") # maybe with parameter average = \"macro\""
      ],
      "metadata": {
        "id": "YuAtJJOHHPJR"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(dataset, tokenizer, model, epochs, output_dir):\n",
        "    # Preprocess the dataset\n",
        "    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        logging_dir=\"./logs\",\n",
        "        learning_rate=4e-5,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
        "\n",
        "    # Define Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset['train'],\n",
        "        eval_dataset=tokenized_dataset['test'],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "\n",
        "    drive.mount('/content/drive')\n",
        "\n",
        "    model_path = f\"/content/{output_dir}\"\n",
        "    save_path = f\"/content/drive/MyDrive/mc_models/{output_dir}\"\n",
        "    # Create the directory if it does not exist\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        print(f\"Directory created: {save_path}\")\n",
        "    else:\n",
        "        print(\"Directory already exists!\")\n",
        "    !cp -r {model_path} {save_path}  # Copy model to Google Drive\n"
      ],
      "metadata": {
        "id": "U_k1UsB9O-l4"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "bert_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lb4BVRLrnMr",
        "outputId": "981217af-ee9f-48b4-a5fe-133430f6753e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Try to apply fine-tuning methods"
      ],
      "metadata": {
        "id": "flJOdT49m_FE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_qa_dataset = qa_dataset.filter(lambda example: example['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'])\n",
        "mc_qa_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "24c3cd3b73044820ab7729ffb51e53f7",
            "5fcbe55a1b79459d89c1e590677b33fb",
            "5d9aee52a49e42c38b2a1bf2ea6a9661",
            "653ec0da35a7430b806fc9cc5349429c",
            "2f146d096fb8485c99048bd96ca843ee",
            "8b62718e0f314e82aa65cd339d10bad1",
            "1459ef83beda45c3a2ba350b5c7d40f1",
            "45069149fc1747118632af5e430bec57",
            "2c493580be134379b2422c319e7bbfae",
            "b3861bf8a39847e783ed666d963fedcb",
            "d82fa0540ceb45e0a69531bd94c1f79d",
            "ff8abba7b8d840ce9e1dc1a1b4986a93",
            "f4600fb96fd0420d98931be5d0dd1e35",
            "c3a3c3cb59bc46b0b43e8f530ecc18f2",
            "87501560ec434eb6a58c17bf42d4c31a",
            "38af7788c16c479a810ddd23b9a66fa3",
            "b495bdb8fac7465a9761209403d5ee11",
            "6211010e464e4f979dddb911a06cad5a",
            "e621060517174440be94c586bd7fa980",
            "c6a78016ce3f4280a7657b0d4e6d025c",
            "556254d0471549358804d5882e057be1",
            "22f52adba8b2482882c6eb0205951f1b"
          ]
        },
        "id": "3cZWKdZ4wTac",
        "outputId": "f902aa72-a662-4325-aaeb-d3cee3590ada"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "24c3cd3b73044820ab7729ffb51e53f7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ff8abba7b8d840ce9e1dc1a1b4986a93"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (937, 7), 'test': (235, 7)}"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_mc_qa_dataset = mc_qa_dataset.filter(lambda example, idx: idx > 105 and idx < 120, with_indices=True)\n",
        "sample_mc_qa_dataset.shape"
      ],
      "metadata": {
        "id": "ZaqiQhR6jh3X",
        "outputId": "04ea9d70-41c3-46a5-c38e-9fb06bcdd00e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "26e5afd36d0b4aa8b2ceb2854999fe01",
            "bcfaf0e172194f98af0c128c0c3f6dd8",
            "2fa8f90b2e0144d6bb96701f59b2aac7",
            "3fb069137e6d4af49e0ccfe5f7e03b3c",
            "1dbf0ebf6f9a40e0b3605b856a48ef28",
            "d6dbf701059b4d2e8d0502d67847aeba",
            "d3a3de3a21b74ddc9718a6e2d2725636",
            "c69e2470ca714cc0b4908d3b5b62c007",
            "913a527a8c7b4f4688d7903163bf45ab",
            "bdc65a740d0247eda713fa0c6df1d1b5",
            "6cbb8fe67da749528efe9e27e024877f",
            "697858837b734dc0b1da644602cd3787",
            "d244f1cf4f984fcd91a95df95a431e99",
            "f053db6e69454c87a337b2d280247c0a",
            "694bb480f12448c58ff328697c11bb18",
            "66b5901275474e7face6c742e48ff398",
            "af7ad24fb0844acd898846379bd7e89d",
            "edeb69d18d0c4bc69708ff2b8c4dbd01",
            "7ee8b352922346e18fc549954b415b27",
            "c71068aef7994394a2ae8a1adb75dbba",
            "8265364ac9ec43e2a123d3116163a929",
            "480c14d53ed5465b97303458601af4a2"
          ]
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "26e5afd36d0b4aa8b2ceb2854999fe01"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/235 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "697858837b734dc0b1da644602cd3787"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (14, 7), 'test': (14, 7)}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model(mc_qa_dataset, tokenizer, bert_model, 7, \"bert_fine_tuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "e5a9f92dacdd42aba2565cc688b26259",
            "6ce751d3668641908a1eaba1e9617983",
            "d383af551cc0451f81693b8a41c4baae",
            "52d15a82a0da4475a97547a834e92472",
            "8b2ae61c48ab432187bdb401d837bcba",
            "9d93fd218bf14786b13ff071efb3e431",
            "8fa0d2dd49454852a7064639922ce3a5",
            "726587e2fbca49cf940ff1168911a32d",
            "a4f0b4dda3e74241afbf00790567af79",
            "0b407616052e46db9ed9ebd8a6a620b4",
            "d7babf3b96cf4362ab1e013a170c90f0",
            "052cc03567bd462fbb1f8c73d53a95e7",
            "16bfe78648c148f19397b2d478655dd3",
            "2d46eaa1dc0542c49fa7e28f4739a9dd",
            "b6dc0e5745a346208213ba88839b52ec",
            "aad096bd72984f6faa700f6ccfe55bc8",
            "dfb27f854d8e4675917b5feeb77a9f49",
            "3a019f9deb674dc9a06923f58a7f3015",
            "d05c3189060f4e71b6fb2f41b7b8dd08",
            "38effe6673584c05b1f930914caf0258",
            "f621f287d15b4d3c88ad747fe4017678",
            "bdf306d1c34f4aa7b63d377593e46704"
          ]
        },
        "id": "fWCKXrftoKvu",
        "outputId": "b88af422-85c4-4179-f8c1-d96c2279f8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a9f92dacdd42aba2565cc688b26259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/235 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "052cc03567bd462fbb1f8c73d53a95e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-25329a740e37>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='28' max='826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 28/826 01:15 < 38:22, 0.35 it/s, Epoch 0.23/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"albert/albert-base-v2\"\n",
        "albert_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "rQ2bMn6RquYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a6084c-8104-43ab-f7ee-bed09a3f0f2e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tune_model(sample_mc_qa_dataset, tokenizer, albert_model, 7, \"albert/albert-base-v2\")"
      ],
      "metadata": {
        "id": "2Pvj_-XKGcFW",
        "outputId": "0f83114d-7d50-40b7-f2a9-ef39a925d189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "0615ce80df0f429db75363374f61cca5",
            "3d00b1995ae645548bdbea00e6f8431e",
            "3629e135de8c4176a4102d1d5f8e06d0",
            "541150d14e5644cfa78897894d5afb91",
            "c490762b2a5541949944eb4e8d97f05f",
            "ca7a568149824cfe80b8c0ade733079f",
            "a4c992dd19904f76b609e53988b5fd67",
            "54212caf83264951a60ca98b7b9f3819",
            "e6dbe4d6195042debe70e0ed08e5d5d1",
            "9c6de4b40e984107a374109491f2a21d",
            "034e1a5b37b341ec9b6b164aeabb8428",
            "fb7a71f0abeb49929cbf97579944383e",
            "d7492606e07b45d6a62b31f0dc777ee0",
            "c0d2ed25aef64202a55a782eccfacefc",
            "c660d50135ef479cac9265760eaeb1c6",
            "d2238b001cf14759ad6118fad4fbafe4",
            "e5e14b21c7414638b95fc6b0709c80ad",
            "4b48910f15844fe7bdae0f71df9c67ed",
            "0fdbd68e4f0e41b19eb5fa3a3af9ee22",
            "7dc8c9c96e62404ebfa11d59916ebef4",
            "a15c873cba65414aa3659fd8f6e1d0f0",
            "099c7a2a1fb34513ba80006b38af592a"
          ]
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0615ce80df0f429db75363374f61cca5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb7a71f0abeb49929cbf97579944383e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-319c72042967>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 00:33, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.969500</td>\n",
              "      <td>2.752164</td>\n",
              "      <td>0.285463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.696700</td>\n",
              "      <td>2.852798</td>\n",
              "      <td>0.237407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.698100</td>\n",
              "      <td>2.861069</td>\n",
              "      <td>0.214931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.683800</td>\n",
              "      <td>2.859945</td>\n",
              "      <td>0.225911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.657500</td>\n",
              "      <td>2.845096</td>\n",
              "      <td>0.241281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.598900</td>\n",
              "      <td>2.842575</td>\n",
              "      <td>0.245650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.600700</td>\n",
              "      <td>2.840811</td>\n",
              "      <td>0.245650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot create directory '/content/drive/MyDrive/albert/albert-base-v2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(answer_comparison):\n",
        "    '''\n",
        "    Computes the total accuracy and accuracy for each question type for the passed list of dicts. One dict in the list is one question with keys 'answer', 'predicted_answer', 'type'\n",
        "    parameters:\n",
        "    - list of dicts with entries 1) predicted answer 2) answer 3) type of question\n",
        "    '''\n",
        "    correct_multi_select = 0\n",
        "    correct_single_select = 0\n",
        "    correct_text = 0\n",
        "    correct_number = 0\n",
        "    correct_date = 0\n",
        "    correct_total = 0\n",
        "    total = 0\n",
        "\n",
        "    for entry in answer_comparison:\n",
        "        question_type = entry['type']\n",
        "        if entry['intended_answer'] == entry['predicted_answer']:\n",
        "            if question_type == 'MULTI_SELECT':\n",
        "                correct_multi_select += 1\n",
        "                total_multi_select += 1\n",
        "            elif question_type == 'SINGLE_SELECT':\n",
        "                correct_single_select += 1\n",
        "                total_single_select += 1\n",
        "            elif question_type == 'TEXT':\n",
        "                correct_text += 1\n",
        "                total_text += 1\n",
        "            elif question_type == 'NUMBER':\n",
        "                correct_number += 1\n",
        "                total_number += 1\n",
        "            elif question_type == 'DATE':\n",
        "                correct_date += 1\n",
        "                total_date += 1\n",
        "            else:\n",
        "              continue\n",
        "            correct_total += 1\n",
        "        total += 1\n",
        "    accuracy_total = correct_total / total\n",
        "    accuracy_multi_select = correct_multi_select / total_multi_select\n",
        "    accuracy_single_select = correct_single_select / total_single_select\n",
        "    accuracy_text = correct_text / total_text\n",
        "    accuracy_number = correct_number / total_number\n",
        "    accuracy_date = correct_date / total_date\n",
        "    return accuracy_total, accuracy_multi_select, accuracy_single_select, accuracy_text, accuracy_number, accuracy_date\n",
        "'''\n",
        "print_out_model_quality: takes the computations of function accuracy() and prints them out\n",
        "parameters:\n",
        "- accuracy_total\n",
        "- accuracy_multi_select\n",
        "- accuracy_single_select\n",
        "- accuracy_text\n",
        "- accuracy_number\n",
        "- accuracy_date\n",
        "'''\n",
        "def print_out_model_quality(accuracy_total, accuracy_multi_select, accuracy_single_select, accuracy_text, accuracy_number, accuracy_date):\n",
        "    # accuracy_total, accuracy_multi_select, accuracy_single_select, accuracy_text, accuracy_number, accuracy_date = accuracy(model, tokenizer, questions)\n",
        "    print(f\"\"\"Accuracy values of model: {model.name_or_path}\\n\n",
        "    Total: {accuracy_total}\\n\n",
        "    Multi-select: {accuracy_multi_select}\\n\n",
        "    Single-select: {accuracy_single_select}\\n\n",
        "    Text: {accuracy_text}\\n\n",
        "    Number: {accuracy_number}\\n\n",
        "    Date: {accuracy_date}\\n\"\"\")\n",
        "    return accuracy_total, accuracy_multi_select, accuracy_single_select, accuracy_text, accuracy_number, accuracy_date\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fZ1JBWSeGsP1"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing / Evaluation"
      ],
      "metadata": {
        "id": "0-5RFV-HgSeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Example dataset\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/alexk2206/tds_capstone/refs/heads/main/datasets/test_qa_dataset_with_answers.json\"\n",
        "data = pd.read_json(url)\n",
        "# Convert to DataFrame for easy handling\n",
        "test_df = pd.DataFrame(data)\n",
        "\n",
        "# Map the intended answer to the index of the option\n",
        "test_df['label'] = test_df.apply(lambda x: np.array([1 if option in x['intended_answer'] else 0 for option in x['options']]) if x['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'] else np.array([0]), axis=1)\n",
        "\n",
        "test_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "tMFWPl-TgRsM"
      },
      "execution_count": 197,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_dataset = pd.DataFrame(test_dataset)\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "id": "6_WigXBHg6IU",
        "outputId": "5e824b4b-cde7-4c0d-d6e1-625b523bb93f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 200,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2242, -0.1725, -0.1572]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, so for the follow up, I think either **2 weeks** or **3 weeks** would work; they seem to be the options I have to choose from.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.5023, -0.4445, -0.4900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.4463, 0.5764, 0.5914, 0.5636, 0.5752]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so for communication, I see we could use German. That's the only language option available.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3868, -0.1946, -0.3196,  0.0347, -0.1795, -0.2417, -0.2094, -0.4752,\n",
            "         -0.4786, -0.2388,  0.0562, -0.1707, -0.5296]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow up, I think I should copy Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, Sean Kennin, and also Tim Persson, just to keep everyone in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.3296,  0.3749, -0.0085, -0.1640, -0.1071, -0.0807, -0.0403]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I guess the customer group would be the \"End User\". That's what we have listed, at least.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0682, -0.4149,  0.1766,  0.2198, -0.4170]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1796, -0.0114,  0.0385]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3805, -0.4105, -0.3538, -0.4701, -0.3986, -0.3819]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4066, 0.4507, 0.1780, 0.1397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, well, we could send an email, maybe schedule a visit, or, you know, if nothing else is needed, we could take no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2610, -0.4002, -0.1776, -0.0752,  0.0602, -0.5405]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, based on what I see here, the contact person is interested in \"234 Assembly Systems\", that seems to be what they are focused on.\n",
            "The intended answer was: ['234 Assembly Systems']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2420, 0.3440, 0.2941]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I don't have any specific time options for a follow up yet. It seems that there were no provided options at all. I need the specific times!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1229, -0.5671, -0.1867,  0.0016, -0.2962, -0.5847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3161, 0.3314, 0.9195, 0.9347, 0.8772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.4749, -0.3391, -0.5230, -0.4011, -0.4400, -0.4260]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2406, -0.3727, -0.0968, -0.1012, -0.2956]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1513, -0.5203, -0.4918, -0.5017, -0.5245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4714, -0.5655, -0.4099, -0.1077, -0.4818, -0.4509]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh, I think they're interested in either '100 Additive Manufacturing', maybe '300 Advanced Manufacturing', perhaps '234 Assembly Systems', or potentially 'Others' I'm not sure which!\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0258, 0.2193, 0.1998]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0475, -0.0974, -0.2617, -0.0735,  0.3262, -0.2689, -0.2200, -0.3855,\n",
            "         -0.3089, -0.2958,  0.0849, -0.0774, -0.4205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, for follow up, I'd say copy Stephan Maier, Joachim Wagner, Erik Schneider, Angelina Haug, Sandro Kalter, and Jens Roschmann. They should all be in the loop.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2033, 0.2985]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5055, -0.2116]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3147, -0.1271, -0.5935, -0.5964]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, the customer type is an 'Applicant'. That seems straightforward. I guess there weren't any other options.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6425, 0.1219, 0.4493, 0.6006, 0.5004]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't think I have any additional notes at this time, but thank you for asking!\n",
            "The intended answer was: No, I don't think I have any additional notes at this time, but thank you for asking!\n",
            "The predicted answer was: no, I don't think I have any additional notes at this time . thank you for asking . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[0.6722, 0.7328, 0.2587, 0.7632, 0.8232, 0.5538, 0.6141, 0.2495]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I guess for a CRM system, maybe like SAP Sales Cloud? I think that’s an option available.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0621, -0.0878,  0.4606,  0.4220, -0.5107, -0.2868,  0.4151,  0.4214]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Well, for a CRM system, I'd recommend HubSpot, it’s a popular choice.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4357, 0.4819, 0.5371, 0.3262, 0.5656]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.5817, -0.6032, -0.6055, -0.5232, -0.5550, -0.5880, -0.5586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team is usually around 31-40 people, that's the average size I'd say.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2858, 0.1413, 0.6441, 0.6408, 0.6287]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0725, -0.0592, -0.4028, -0.4072]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so for customer type, I see only \"Applicant\" as an option, which I guess is the relevant category for this.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5210, 0.0926, 0.5722, 0.5677, 0.5794, 0.5458, 0.5779, 0.3082, 0.3320,\n",
            "         0.4011]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in the Physical Security industry. That's the only one listed.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4228, 0.4920, 0.2957, 0.4459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, let me see... for follow up, we could send an **email**, or, it's also possible that we take **no action**. I guess those are the options.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Actually, I don't think I have anything else to add right now. Thanks for asking, though.\n",
            "The intended answer was: Actually, I don't think I have anything else to add right now. Thanks for asking, though.\n",
            "The predicted answer was: i don't think I have anything else to add right now . thanks for asking, though, though . i'm not sure what to add .\n",
            "\n",
            "tensor([[-0.0370,  0.3140,  0.6275,  0.4256,  0.5646,  0.0793,  0.6133,  0.4504]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? Well, I guess one option could be Salesforce.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1683,  0.1452,  0.0081, -0.1784, -0.1820, -0.1380, -0.3889]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, a customer group? I guess that could be a Planner, since that's the only option provided. So, I'd say it's the Planner.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5208, -0.5785, -0.6333, -0.6298]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.5458,  0.4380,  0.1140,  0.1018, -0.4997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, we are larger than 2000. That's how big we are!\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1420, -0.4629, -0.3249,  0.3482, -0.4948]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like \"Noise figure measurements\", maybe \"Double-Pulse Testing\", and also possibly \"Display port debugging and compliance.\"\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0584, 0.5331, 0.1371, 0.1826, 0.1565, 0.1548, 0.2049, 0.5173, 0.2505,\n",
            "         0.3865]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I suppose I'm operating in the 'Physical Security' industry, if that's the only option there. Seems pretty self-explanatory.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0191, 0.3352, 0.7461, 0.1967, 0.4879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.3635,  0.2813,  0.3310,  0.3745,  0.6688,  0.4153,  0.2728, -0.0480,\n",
            "          0.1496,  0.3020,  0.3728,  0.4388,  0.0807]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Angelina Haug', 'Marisa Peng', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4993, -0.4042]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3841, -0.6321, -0.5296]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4029,  0.2302, -0.4471, -0.3029, -0.0663, -0.2682]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, let me see... I'm interested in \"MY-SYSTEM\", \"JS EcoLine\", and \"AX100\". Those are the products I'm currently looking at.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5198, -0.4011, -0.5407, -0.0501, -0.3589]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it's either an \"Existing customer\", someone we've helped before, or a \"New customer / Prospect\", meaning someone new who might be interested in our services.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3757, -0.3587, -0.6327, -0.6289]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0144, -0.0094,  0.0842,  0.0041,  0.0601]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2743, 0.0823, 0.1992]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3431, -0.2790,  0.6427,  0.5203,  0.4302,  0.0191,  0.5965,  0.6023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2417, 0.1197, 0.4856, 0.5535, 0.4461, 0.2713, 0.5120, 0.1527, 0.1432,\n",
            "         0.0128]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5855, -0.5868, -0.6087, -0.5709, -0.5969, -0.5971, -0.6002]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair teams are usually about 11-15 people. That's typically the size we need.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3699, 0.0252, 0.3488, 0.3264, 0.2947]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2118, -0.1037, -0.2876, -0.4335, -0.2782, -0.2871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they are interested in either the '200 Automation' option, or maybe it's the '256 Joining Systems for large components'. Both seem possible, honestly.\n",
            "The intended answer was: ['200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0170, -0.2213, -0.0692, -0.1370, -0.2441]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't think I have anything else to add right now, but I'll let you know if anything comes to mind later.\n",
            "The intended answer was: I don't think I have anything else to add right now, but I'll let you know if anything comes to mind later.\n",
            "The predicted answer was: I don't think I have anything else to add right now, but I'll let you know if anything comes to mind later .\n",
            "\n",
            "tensor([[-0.2968, -0.3040, -0.2749, -0.2665, -0.3021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, let's see... so, the language wanted is Italian. Seems that's the only option, then, so it'll have to be Italian!\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3515, -0.1012,  0.3282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step is having a meeting, because that's the only thing I see mentioned.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.3739, 0.4179, 0.0848, 0.0957]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4613, -0.5057, -0.2734, -0.2790, -0.5023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3406, -0.5224, -0.4243, -0.5100, -0.4782, -0.4541, -0.5448]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3229,  0.1975, -0.4062, -0.1105, -0.0738]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5066, -0.5387, -0.6041, -0.5110, -0.5953, -0.5953, -0.5980]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3476, -0.3805, -0.3400]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, I'd need to see the options to answer that properly, because I have no idea what times the person prefers!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1625, 0.2668]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1650, 0.4435, 0.2554, 0.0937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? Well, I could say they're **very unsatisfied**, I guess that's the only option given here.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0204, -0.2245, -0.1729,  0.2585,  0.2478, -0.0298, -0.0744, -0.3983,\n",
            "         -0.4011, -0.3780,  0.2008,  0.2582, -0.5240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0736,  0.2252, -0.1533,  0.2496, -0.2056, -0.3845, -0.2244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0787, -0.0419, -0.1027, -0.1399, -0.1238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, I don't think I have anything more to add at the moment. But if something comes to mind later, I'll definitely let you know.\n",
            "The intended answer was: Hmm, I don't think I have anything more to add at the moment. But if something comes to mind later, I'll definitely let you know.\n",
            "The predicted answer was: I don't think I have anything more to add at the moment . but if something comes to mind later, I'll definitely let you know .\n",
            "\n",
            "tensor([[ 0.5365,  0.1694,  0.6535, -0.0587,  0.6564]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Okay, I'm interested in... wait, there aren't any options listed! I guess I'm not interested in any products at this moment.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1221, -0.2060,  0.1490,  0.4771,  0.2404]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1366,  0.1661, -0.1251, -0.0545]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, for customer type, it looks like the only option we have right now is Partner.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.5970, -0.4938,  0.1666,  0.2825,  0.6538]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3204, -0.1551, -0.5331, -0.0393,  0.0899]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: We're about 11 to 50 people; that's the size of our company.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't have any other notes to add at this time, but thank you for asking.\n",
            "The intended answer was: I don't have any other notes to add at this time, but thank you for asking.\n",
            "The predicted answer was: i don't have any other notes to add at this time, but thank you for asking . if you have any questions, please contact me at the bottom of the page.\n",
            "\n",
            "tensor([[0.4007, 0.3115]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1797, -0.1583,  0.0049,  0.0014, -0.0957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess the contact could be either a Supplier, like someone we get stuff from, or maybe a Competitor, which is a company that we're up against.\n",
            "The intended answer was: ['Supplier', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4876, -0.2780,  0.0643,  0.3150, -0.2875]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it an existing customer, or maybe a new customer or prospect? I'd need to know which one of those it is.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1274,  0.2353, -0.1218,  0.2075, -0.1735]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3406,  0.3472,  0.3171, -0.0660,  0.3478]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4751, -0.3700, -0.3917, -0.2836, -0.2276, -0.3500, -0.4174, -0.4488,\n",
            "         -0.4081, -0.4121, -0.3295, -0.2694, -0.4658]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5898, 0.0725, 0.6300, 0.6529, 0.6135, 0.5875, 0.6236, 0.1720, 0.2667,\n",
            "         0.2511]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I think I'm operating in the **Physical Security** industry.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2863, -0.3302, -0.1596, -0.2046,  0.2341, -0.2276, -0.2682, -0.3783,\n",
            "         -0.3689, -0.3734,  0.0337,  0.0322, -0.4308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, I'll copy Joachim Wagner, Erik Schneider, Johannes Wagner, Sandro Kalter, and Jens Roschmann on the follow up. That covers everyone you listed, I believe.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2253,  0.3775,  0.2656,  0.4536,  0.4837,  0.2463,  0.1190, -0.1269,\n",
            "         -0.0098,  0.0131,  0.4918,  0.4092, -0.2421]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, for follow up? I guess I could copy Stephan Maier, maybe Erik Schneider too, or Angelina Haug... then there's Johannes Wagner, or even Jessica Hanke, or perhaps Tim Persson!\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1187, -0.0128,  0.5251,  0.5200,  0.5546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.1810, -0.1776, -0.3956,  0.4388, -0.0330,  0.0761,  0.2577]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the trade fair team size? I'd guess it's usually around 21 to 30 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1634, -0.3826, -0.0921, -0.4243, -0.4143, -0.4350, -0.1689]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is a Wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1308, -0.1274, -0.1937, -0.1900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3700, -0.3920,  0.0933, -0.2968, -0.2268, -0.3711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6676, -0.5899, -0.5739, -0.5706, -0.5765, -0.5776, -0.6885]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2654, -0.3036,  0.0802, -0.2071, -0.2843]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2341, -0.1752,  0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.5274, 0.5623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, for data processing consent, it looks like the only option here is 'Yes'. So, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3865, -0.2849, -0.3383, -0.4506, -0.4526, -0.2443]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's a production company. That means they probably make movies, TV shows, or something similar.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1348,  0.1007, -0.4916, -0.4207]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess the customer type would be an Applicant.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5602, -0.5612, -0.4934, -0.3884, -0.1189, -0.4663]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I think they might be interested in either 100 Additive Manufacturing, or maybe 200 Automation, or 300 Advanced Manufacturing, possibly 234 Assembly Systems, or even 256 Joining Systems for large components, or perhaps, something else, under Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Actually, no, I think I've covered everything I wanted to say. I don't have any additional notes at the moment.\n",
            "The intended answer was: Actually, no, I think I've covered everything I wanted to say. I don't have any additional notes at the moment.\n",
            "The predicted answer was: no, I think I've covered everything I wanted to say . i don't have any additional notes at the moment .\n",
            "\n",
            "tensor([[-0.2692, -0.2254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, so the only option is 'Yes', and yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4331, 0.5305, 0.2657, 0.5760, 0.4849]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3083, -0.3902,  0.1906, -0.4592, -0.3938, -0.3841]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2666,  0.2384, -0.3440, -0.0488,  0.0200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3317, -0.3624, -0.2396, -0.2655, -0.3120, -0.4330]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's an education sector company. It must be something in that area, right?\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4963, -0.2983,  0.3136, -0.2311,  0.2098]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, product interests? I'd say I'm looking into BusinessCards, you know, for networking, and also Data Cleansing, because accurate data is crucial.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.6404, -0.5415,  0.2682,  0.5683,  0.4987]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking to either clean up our CRM or improve its data quality, whichever seems to be the better solution.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Okay, I think I've covered everything. I don't have any additional notes or information to add right now.\n",
            "The intended answer was: Okay, I think I've covered everything. I don't have any additional notes or information to add right now.\n",
            "The predicted answer was: I don't have any additional notes or information to add right now . I'm not sure if there's any additional info to add .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1246, 0.3586, 0.2205, 0.2544, 0.2098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything for now. There isn't any additional information I can add at this time.\n",
            "The intended answer was: Nope, I think I've covered everything for now. There isn't any additional information I can add at this time.\n",
            "The predicted answer was: nope, there isn't any additional information I can add at this time . there is no additional information to add to the list .\n",
            "\n",
            "tensor([[-0.3312, -0.1717, -0.2446, -0.1548, -0.3348, -0.3130, -0.4324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the team is usually around 6 to 10 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6036, -0.6106, -0.6142, -0.6015, -0.6102, -0.6083, -0.6488]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0053, -0.1021,  0.0682,  0.0020,  0.4459, -0.2490, -0.1174, -0.3960,\n",
            "         -0.4133, -0.0251,  0.2777, -0.1717, -0.3915]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow up, I guess we could copy Stephan Maier, or maybe Joachim Wagner. Oliver Eibel could also work, and Marisa Peng is another possibility, as is Johannes Wagner and Jessica Hanke.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4135, -0.2885, -0.5867, -0.6120, -0.6062, -0.6034, -0.3580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group? I guess it's the R&D team then, since that's what's here.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5071, -0.0165]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1805, -0.2023,  0.1180]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, it seems like a meeting is what's planned, that makes sense.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1646, 0.3392, 0.2833]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1751, -0.3383,  0.2013,  0.3073,  0.2752]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0708,  0.4305,  0.1203, -0.0444]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0276, -0.0137,  0.0572, -0.0343,  0.0224]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking communication, I guess English is what I'm working with here.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3150, 0.4241, 0.1707, 0.2769, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Okay, let's see... I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and then High-speed interconnect testing too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3821, -0.1181,  0.5141,  0.5186,  0.4640,  0.3725,  0.4953, -0.2990,\n",
            "         -0.6517, -0.6201]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3063, 0.4056]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.5653, -0.5799, -0.5852, -0.5599, -0.5728, -0.5766, -0.5918]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average the trade fair team is usually more than 40 people, it seems. That's the only size I know about for now.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4235, -0.1422]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3686, -0.0980,  0.0511, -0.2186,  0.5731, -0.1763, -0.2586, -0.4375,\n",
            "         -0.1620, -0.3070,  0.0722,  0.0052, -0.4269]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 16. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4876, -0.2181,  0.4837,  0.5000,  0.4986,  0.4860,  0.5130,  0.0479,\n",
            "          0.2187,  0.2518]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I work in the **Government** industry, which is where I do my job. That is the only field that was mentioned as a choice.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think that covers everything for now, but thanks for checking!\n",
            "The intended answer was: I think that covers everything for now, but thanks for checking!\n",
            "The predicted answer was: i think that covers everything for now, but thanks for checking! thanks for stopping by e-mailing me on twitter . i'm not sure if you're a fan of this blog .\n",
            "\n",
            "tensor([[-0.4669, -0.3902]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0057,  0.0365, -0.5011,  0.1002, -0.0229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5363, 0.4863, 0.1285, 0.1271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, I can either call you, *phone*, or we can *schedule a visit*. If neither is needed, we'll take *no action*.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4779, -0.2341, -0.6227, -0.6294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1652, -0.2620, -0.3542,  0.0704,  0.1418, -0.2375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Okay, I think they might be interested in either \"100 Additive Manufacturing\", \"234 Assembly Systems\", or maybe even \"256 Joining Systems for large components\". They could also be interested in \"Others\".\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4387, -0.5197, -0.3797, -0.2904, -0.5168]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, the contact type is, let's see...it's 'Press / media', so I guess that's the type of contact we're talking about.\n",
            "The intended answer was: ['Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0212, -0.4531, -0.1371, -0.0411]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, regarding customer satisfaction, I guess I could be, like, \"very unsatisfied,\" depending on the situation. That's probably the only way I could answer.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1109,  0.0415, -0.2415, -0.1568,  0.0700, -0.1458]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, I'm interested in both Notion and the AX100. Notion seems like a productivity tool, while the AX100 might be a camera.\n",
            "The intended answer was: ['Notion', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1851,  0.1638, -0.1373,  0.0947, -0.4211]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1004, 0.1762, 0.3271, 0.1770, 0.1515]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in product features like **DataEnrichment**, which adds to data, and also **DataQuality**, to make sure it's reliable.\n",
            "The intended answer was: ['DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4145, 0.2228, 0.1771]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so the next step is to just call. That's the only thing it says.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.5655, -0.5273, -0.6350, -0.6317, -0.6278, -0.6354, -0.5491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0209,  0.3555,  0.1942,  0.3302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I believe the customer type is, let's see... ah, it looks like it's a new customer. That's what they've listed.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1131, 0.1353, 0.1927, 0.1667, 0.1534]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, if we're talking language, it seems like **German** is the one they're looking for. Is that the only option right now?\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think I've covered everything for now, so I don't have any additional notes to share at the moment.\n",
            "The intended answer was: I think I've covered everything for now, so I don't have any additional notes to share at the moment.\n",
            "The predicted answer was: I think I've covered everything for now, so I don't have any additional notes to share at the moment . i'm not sure if I'll share anything with you .\n",
            "\n",
            "tensor([[0.4594, 0.2715, 0.3583, 0.0197, 0.2737]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 34. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3364, -0.3251, -0.2963, -0.2809, -0.3017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, if you're asking about which language I should use, then it's **Spanish**. I only know to speak that one right now.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think that's all I've got for now. Unless you need anything else, I don't have any more notes to share.\n",
            "The intended answer was: I think that's all I've got for now. Unless you need anything else, I don't have any more notes to share.\n",
            "The predicted answer was: unless you need anything else, I don't have any more notes to share . I think that's all I've got for now .\n",
            "\n",
            "tensor([[-0.1771, -0.3577, -0.3935, -0.4797]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I guess I'd say I'm an existing customer, since that's the only option here.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2098,  0.5541, -0.2937, -0.2461, -0.2483, -0.1326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4798, 0.5562, 0.0524, 0.3127, 0.1486]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4786, -0.4829, -0.1669, -0.3515, -0.1382, -0.4486]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Okay, let's see. I think they are interested in either '200 Automation', maybe '300 Advanced Manufacturing', or possibly even '256 Joining Systems for large components'.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5534, -0.5521, -0.6527, -0.4083, -0.3163]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think we're a very small company; likely we are in the 1-10 employee range.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I don't have any additional notes at the moment, but I'm happy to clarify anything if needed.\n",
            "The intended answer was: I don't have any additional notes at the moment, but I'm happy to clarify anything if needed.\n",
            "The predicted answer was: i don't have any additional notes at the moment, but I'm happy to clarify anything if needed . if you have any further notes, please contact me .\n",
            "\n",
            "tensor([[-0.5112, -0.5525, -0.5707, -0.5376, -0.5490, -0.5756, -0.5610]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 1-5\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3026, -0.4029]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4785, -0.4606, -0.5075, -0.4988, -0.4797, -0.4732, -0.5248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is usually around 16-20 people, give or take. That seems to be the typical amount.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1105,  0.0765, -0.0113,  0.1061,  0.0710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3891, -0.3956, -0.3781, -0.3552, -0.3831]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4341, -0.1900, -0.2152,  0.3745]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say the customer is likely Unsatisfied, since that's the only option I'm given to choose from.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2657,  0.2083]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5331, -0.6049, -0.4903, -0.5688, -0.5497, -0.6233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Well, I think it's an education sector company; it must be something to do with schools or learning, I reckon.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.5339, -0.4244,  0.1220,  0.4577,  0.5958,  0.5050,  0.5543,  0.1828]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I've heard of Pipedrive, which is supposed to be good. Is there anything else, though?\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2119, -0.2525, -0.0231]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3945, -0.3458, -0.6327, -0.6369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, the customer type is an **Applicant**. That's the only option available, so it must be who we're dealing with.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3652, 0.1593, 0.3038]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3273,  0.3415, -0.1154, -0.0413]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4899, -0.6834, -0.6494, -0.4449]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I would say I'm definitely **Very satisfied**, which I think is good!\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0070, -0.2051,  0.1465,  0.3022, -0.1915]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1952, 0.4061, 0.4753, 0.1178, 0.0331]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in, let's see, either `BusinessCards`, for networking, or `DataEnrichment`, which sounds like it could improve existing info.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5129, 0.2544, 0.4320, 0.2833, 0.2104]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn about **noise figure measurements** and also **display port debugging and compliance**.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.5144,  0.0927,  0.1619,  0.1680,  0.1695,  0.1498, -0.0267]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0214, 0.3877, 0.0337, 0.1280, 0.4574, 0.2608]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4986, -0.3480, -0.5950, -0.4683, -0.5397, -0.5352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in Notion, and also curious about the JS EcoLine, and that AKW100 product as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3923, 0.1574, 0.1539, 0.3151]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Okay, customer satisfaction? Well, if you mean whether they were, you know, **satisfied**, I guess that's it.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1064, 0.1543, 0.5263, 0.5584, 0.5421]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.0351,  0.3809,  0.0587,  0.3367,  0.3389, -0.0252,  0.3724, -0.3041,\n",
            "         -0.0958, -0.0382,  0.4062,  0.1716, -0.3636]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, in the follow up, I should copy Stephan Maier, and also Erik Schneider. I will also add Sandro Kalter and Sean Kennin and finally, Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Sandro Kalter', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1947, 0.4671, 0.2124, 0.0639, 0.1552, 0.0692, 0.1331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5720, -0.5973, -0.6290, -0.5417, -0.5743, -0.5831]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm not seeing any specific product options listed right now, so I don't have anything particular to say I'm interested in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1206, 0.0176, 0.2975]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4225, -0.3803, -0.5401, -0.0194, -0.4776]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, my company's size is probably around 1-10 people; that's what's currently in the options list.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3689, 0.4122, 0.1725, 0.3736]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4532, 0.4755, 0.0944, 0.3512]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I guess I could either send an **Email**, or take **No action** at all. I'm not sure which is the best route to take here.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.6583, -0.5828,  0.0207,  0.1236,  0.5855]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2700, -0.3897, -0.1575,  0.0287]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0018,  0.1795, -0.0828, -0.1261, -0.1107,  0.0264, -0.0717,  0.0559,\n",
            "         -0.3113, -0.4712]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'm operating in the **Physical Security** industry, focusing on things like access control and surveillance, you know, keeping things safe and secure in the real world.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4637, 0.1764, 0.4327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be a meeting. Seems like that's the only thing to do right now.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2816, -0.4085, -0.2551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, I guess I could **offer** something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.5534, -0.3660]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1458, -0.2020,  0.1503, -0.2239, -0.4159]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Okay, so I'm searching for a solution, and I guess that includes how to 'capture trade fair contacts', that makes sense.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4171, -0.3724, -0.3391, -0.3577, -0.3408]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, you want to know which language? Well, I guess the only option is German then. It's the only one specified here for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4138, -0.5110, -0.3914, -0.3989, -0.4065]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if you're asking about a language for communication, it seems like Italian is the only option available right now.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0107,  0.1340,  0.5256,  0.4413, -0.3577, -0.1055,  0.4049,  0.5363]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, for a CRM system, I guess the best option would be something like HubSpot, if that's the kind of thing we're considering.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5033, 0.3624, 0.4443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1530, -0.2540, -0.2619]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2976, -0.0995, -0.4043, -0.3330, -0.4395, -0.4847, -0.0044]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group might be a Consultant, since that's the only option available here.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2002, 0.1417]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3456, -0.3710]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3247, -0.4695, -0.1463, -0.2123, -0.1059]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I'm trying to find something that will either let me scan business cards or improve CRM data quality. Either of those would be really helpful.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think I've covered everything for now, but I'll certainly speak up if anything else comes to mind.\n",
            "The intended answer was: I think I've covered everything for now, but I'll certainly speak up if anything else comes to mind.\n",
            "The predicted answer was: i think I've covered everything for now, but I'll certainly speak up if anything else comes to mind . i'm not sure what to do if I'm going to talk up .\n",
            "\n",
            "tensor([[-0.2803, -0.2699,  0.2798, -0.2409, -0.0587, -0.4597, -0.3076,  0.3556]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Okay, so a CRM-System? Hmm, I guess that could be something like Salesforce, if that's what you mean. I'm not too sure about other possibilities, to be honest.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1299,  0.3793,  0.2704,  0.1805,  0.3992, -0.0129,  0.3830, -0.0472,\n",
            "         -0.0888,  0.0614,  0.4616, -0.0730, -0.3411]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow up, I guess we should copy Erik Schneider, or maybe Oliver Eibel? Or it could be Angelina Haug, or even Marisa Peng, hmm maybe Sean Kennin, or perhaps Tim Persson would be best.\n",
            "The intended answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3050, 0.3461]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0222, -0.2217,  0.1274, -0.0845, -0.0477, -0.1459]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2523,  0.1244,  0.0452, -0.0880, -0.0371, -0.0762, -0.0872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, the customer group would be a *wholesaler*. I guess that's the only option?\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3256, 0.4097]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6203, -0.6215, -0.6349]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, I'm not sure when the contact person wishes to receive a follow-up, because there are no options provided.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[ 0.4041,  0.1666,  0.1366, -0.0949]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I'm an existing customer. I think that's the only possibility, right?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0149,  0.3489, -0.0668, -0.0405,  0.2006, -0.1579]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so products I'm interested in... Hmm, let's see. I'd say Notion, JTS, and also AX100, those are what come to mind.\n",
            "The intended answer was: ['Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6166, 0.0687, 0.3367, 0.7038, 0.7868, 0.5038, 0.7418, 0.3764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, for a CRM system, I guess maybe something like Pipedrive? I've heard good things about that.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4032, -0.5678, -0.6544, -0.6886, -0.6494, -0.5696, -0.5628]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0878,  0.1575, -0.2204,  0.1841]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so the follow-up will be either an email or a phone call. We're planning to use one of those methods.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2319, -0.0782, -0.3952,  0.2023, -0.1182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6389, 0.5008, 0.5958, 0.6016, 0.2449]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution. Maybe I could *Scan business cards*, or *Clean up CRM*. *Improve CRM data quality* could help, and possibly even *Capture trade fair contacts*.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1739, -0.0879]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4399, -0.5345, -0.3520]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, next steps. Well, we could schedule a **meeting**, that would probably be the most useful thing right now, I think.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2930,  0.3460, -0.2573,  0.0335]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3831, -0.2577, -0.4959, -0.3361, -0.3917, -0.3815]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in a few products. There's 'MY-SYSTEM', 'JTS', and 'JS EcoLine', plus I'm also looking into 'AKW100'.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.4060, -0.4775,  0.0377,  0.2033,  0.1250]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0672, -0.6655, -0.4632,  0.0498]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess if you asked about customer satisfaction, I'd have to say that one option would be 'Unsatisfied', and that's not ideal, right?\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Actually, I don't have any other notes to add right now, but I appreciate you asking!\n",
            "The intended answer was: Actually, I don't have any other notes to add right now, but I appreciate you asking!\n",
            "The predicted answer was: i don't have any other notes to add right now, but I appreciate you asking . i'm not sure if it's a good idea to add a note .\n",
            "\n",
            "tensor([[ 0.6556, -0.2259,  0.6781,  0.7019,  0.6973,  0.6003,  0.6917, -0.0705,\n",
            "          0.1204,  0.1402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0871,  0.2828,  0.4016,  0.1772,  0.5141,  0.0521,  0.1252, -0.1661,\n",
            "         -0.0671, -0.1129,  0.1918, -0.1853, -0.2545]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, in the follow up, I should probably copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jens Roschmann, Domiki Stein, and also Sean Kennin, right? Got it.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4534, -0.2854, -0.5609, -0.4756, -0.4177, -0.0675]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2171, -0.3117, -0.1183, -0.1696, -0.1340, -0.3590]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's an **education sector** company, like one involved in teaching or training.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6160, 0.4866]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, about data processing consent? Hmm, it looks like the only option is \"No\". So, I'm saying no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1812, -0.5268, -0.1038,  0.1649]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0694,  0.3375,  0.0015,  0.0919,  0.4705,  0.3654]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1135,  0.1362,  0.1891,  0.1425, -0.0189]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4101, 0.1373, 0.4577, 0.2351, 0.0562]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3796, 0.4302]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2736,  0.3342,  0.5008,  0.4713,  0.4471,  0.4846,  0.4696,  0.3861,\n",
            "          0.4073, -0.2042]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in Aerospace? It's the only option provided.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3511, -0.1277, -0.4534, -0.2823, -0.3928, -0.4448]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3136, 0.2666, 0.0254, 0.2716, 0.3936]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, we're a pretty small operation. We fall into the size of **1-10** employees. So yeah, a small business for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.4311,  0.4399, -0.0391,  0.3835]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so the planned follow up, it looks like, is by Phone.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4724, -0.3798, -0.5239, -0.3513, -0.5159, -0.5056]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in both the JTS and AX100 products. It's hard to choose, as I'd like to explore each one of them in more detail.\n",
            "The intended answer was: ['JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3507, 0.4461, 0.0285, 0.2500, 0.3135]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4181, -0.4335, -0.3902, -0.4337, -0.4177]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess if we're talking language, it seems like Spanish is the only option available, so that's what I'd be going with.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3763, -0.4690, -0.3827, -0.5021, -0.0650, -0.4167, -0.4706, -0.5147,\n",
            "         -0.4422, -0.4521, -0.3644, -0.5095, -0.5061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up, I could copy Stephan Maier, maybe Joachim Wagner, or perhaps Jessica Hanke? Sean Kennin and Tim Persson could be good options too, I'm not sure which.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3837, -0.3583, -0.5960, -0.6903]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2678, -0.0595,  0.1906,  0.0017, -0.0874]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4452, -0.2696, -0.6065, -0.6227, -0.6205, -0.6071, -0.5283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group could be a Planner, you know, someone who likes to organize and plan ahead.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0298,  0.1227, -0.0121,  0.1202,  0.4051, -0.1162,  0.1608, -0.2120,\n",
            "         -0.1786, -0.3179,  0.1013,  0.1654, -0.4343]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for the follow up, I guess I should copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Domiki Stein, and also Tim Persson then.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.5391, -0.5390, -0.4652, -0.5416]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2370, 0.2742, 0.7153, 0.2245, 0.5581]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests... Hmm, let's see. I'm definitely interested in things like \"Data Cleansing\" and also \"DataQuality,\" I need my data to be good!\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3644, 0.3200]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0124,  0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I consent, so that means 'Yes'.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4100, -0.3999, -0.3900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I think that covers everything for now. I don't have any additional notes or information to share at this time.\n",
            "The intended answer was: Okay, I think that covers everything for now. I don't have any additional notes or information to share at this time.\n",
            "The predicted answer was: I think that covers everything for now . I don't have any additional notes or information to share at this time . if you have any questions, please contact me at the bottom of the page.\n",
            "\n",
            "tensor([[-0.0948, -0.0239]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2116,  0.1495,  0.2656,  0.0349,  0.1910, -0.0975, -0.0657]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0182,  0.1359,  0.1703,  0.1123,  0.1692]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I can communicate in German, if that's what's wanted. That's the only option provided, so it has to be German.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2916, -0.3794, -0.1645, -0.4251, -0.3632]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1432, 0.3625]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I understand. So, it looks like there's just one option: \"Yes\". If I'm reading that right, my answer would be yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3718,  0.1446, -0.3803, -0.3662, -0.3791, -0.3603, -0.3830,  0.0928,\n",
            "          0.1837,  0.2087]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5976, -0.5661, -0.5133, -0.1585, -0.5432]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a **Supplier**, someone who provides us with goods or services, or maybe a **Competitor**, another company we are vying with.\n",
            "The intended answer was: ['Supplier', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0659,  0.1062,  0.3627,  0.4342, -0.4733, -0.0012,  0.3417,  0.5150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I'd probably go with HubSpot, since that seems to be the only option listed right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2419, 0.2353, 0.4043, 0.1777]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1563, -0.4603, -0.0735,  0.3148]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2726,  0.1953, -0.1343, -0.1431, -0.1875, -0.2206, -0.1367,  0.2376,\n",
            "          0.2574,  0.0310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I suppose I'm operating in the **Medical** industry then, since that's the only option available here.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1958,  0.3871, -0.1360,  0.5167, -0.2785]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2221, -0.3124, -0.1291,  0.0022, -0.1070]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, our company size is about 51 to 200 people, it's in that range.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1032, -0.0524, -0.1562, -0.1360]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, we could follow up by a phone call, maybe we should schedule a visit, or perhaps take no action at all.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5426, -0.5421, -0.5334, -0.5557, -0.5432]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I suppose Italian would be the language needed, as that's the only option available.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4618,  0.5273, -0.0471,  0.2693,  0.7267,  0.3332]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, also Notion. Plus, I'm into JTS and JS EcoLine. Oh, and AKW100 as well as AX100, I think.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2560, -0.0738,  0.0739, -0.1543, -0.0254, -0.0498, -0.1913]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I'm not sure about all the options, but I guess the customer group is R and D, so I'll just say R and D.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4477, -0.3567]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4595, 0.4662, 0.4905, 0.4362, 0.4650]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1912, 0.2524]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.3901,  0.3423, -0.0498,  0.3565, -0.1223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6032, -0.5960, -0.5814]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, next steps. Hmm, I'd say it would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.6168, -0.0952, -0.1016,  0.5336]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, well, if you are asking me about customer satisfaction, I'd say they are probably unsatisfied. I mean, I do not know the options you had, so I'll go with that.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5731, -0.5169, -0.4300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.2629,  0.0116, -0.2070,  0.1506,  0.4166, -0.3814]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0855,  0.1260, -0.4165, -0.4657, -0.4488, -0.4550, -0.3833]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.7596, 0.4509, 0.8099, 0.8141, 0.7996, 0.7557, 0.8089, 0.5608, 0.5830,\n",
            "         0.6809]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I guess I'm working in physical security then. I mean, that sounds right.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0783, 0.1205, 0.0905]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.3011, 0.0952, 0.5016, 0.4453, 0.5125, 0.3121, 0.4323, 0.2298]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh gosh, I'm not sure. Maybe it's Pipedrive? I'm not very knowledgeable about those types of systems.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.7533, 0.6650, 0.7138, 0.5375, 0.6001]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, well, I think I'm interested in both Noise figure measurements and Double-Pulse Testing. Those sound like things I could explore more.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4527, 0.7417, 0.4894, 0.4132, 0.3979, 0.3844]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5373, -0.4854, -0.5599, -0.4344, -0.5322, -0.5644, -0.3971]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1854, -0.1401,  0.1344,  0.2886,  0.3055,  0.1963,  0.1741, -0.0887]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4105, 0.4385, 0.4067, 0.4130, 0.4430]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, hmm. I think I'd probably go with Japanese for this conversation.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0492, 0.0335, 0.0282, 0.0373, 0.2029]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2534, -0.1626,  0.1158, -0.3457, -0.3112, -0.1182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company, that's the type it is.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2573, -0.1552, -0.1228, -0.1657, -0.1582]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh gosh, I am not sure which language you are offering, but I would say German.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything on my end right now, thanks for asking though!\n",
            "The intended answer was: No, I think that covers everything on my end right now, thanks for asking though!\n",
            "The predicted answer was: no, I think that covers everything on my end right now . thanks for asking though . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[0.2437, 0.3166]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5668, -0.4951, -0.4971, -0.5411, -0.5531, -0.5530, -0.4972, -0.5193,\n",
            "         -0.5010, -0.5298, -0.5038, -0.5716, -0.5686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.6410,  0.0861,  0.4222,  0.4554, -0.0311]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2313, -0.2721, -0.5849, -0.5801]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I'm guessing the customer type is probably Applicant. I'm not really sure about other types though.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't think I have anything else to add right now, but thanks for asking.\n",
            "The intended answer was: I don't think I have anything else to add right now, but thanks for asking.\n",
            "The predicted answer was: i don't think I have anything else to add right now, but thanks for asking . i'm not sure if I'd like to add anything to the list .\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't have any additional notes at the moment, thanks for asking though.\n",
            "The intended answer was: No, I don't have any additional notes at the moment, thanks for asking though.\n",
            "The predicted answer was: no, I don't have any additional notes at the moment, thanks for asking though . i'm not sure if there's a link to this post .\n",
            "\n",
            "tensor([[ 0.1645,  0.2508, -0.0532,  0.2670]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4425, 0.3174, 0.1251, 0.3382, 0.3459]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 4.1021e-04,  4.5956e-01,  6.5462e-01,  6.0232e-01, -2.9734e-01,\n",
            "          2.9404e-01,  1.7421e-01,  4.7544e-01]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0982, 0.0599]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess I'd say no, since that's the only option there.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.7238, -0.2897,  0.3808,  0.3246,  0.4627]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something, like, to clean up CRM or extract data from emails. I might also improve CRM data quality or maybe even capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, I don't think I have anything else to add at this time, thanks for checking though.\n",
            "The intended answer was: Hmm, I don't think I have anything else to add at this time, thanks for checking though.\n",
            "The predicted answer was: i don't think I have anything else to add at this time, thanks for checking though . i'm not sure if I'll add anything to this time .\n",
            "\n",
            "tensor([[ 0.3493,  0.2856, -0.0774,  0.2158,  0.1333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh I'm not really sure about the company size, but I'd guess it's around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3556, -0.4120, -0.2113, -0.3337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think a phone call would probably be best.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5428,  0.5063, -0.2983, -0.2103,  0.2661,  0.1499]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.5280, -0.4765,  0.0671,  0.0661, -0.4793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3392, 0.0205, 0.2941]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.4538, -0.0102,  0.0320, -0.1782,  0.4498, -0.1573,  0.0161, -0.3189,\n",
            "         -0.2384,  0.2566,  0.0978, -0.2626, -0.2538]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess copy Jessica Hanke, Jens Roschmann and Tim Persson in the follow up.\n",
            "The intended answer was: ['Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0837, -0.1882,  0.3027,  0.1517,  0.0693, -0.0015]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I guess it must be craft enterprises then, since that's the only one I know.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3121, 0.4393, 0.3539, 0.5447, 0.2068]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay so I guess I like BusinessCards and also DataQuality that seems right.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5935, 0.3633, 0.5950, 0.6939, 0.4164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh wow, that's a good question, I think I'm most interested in automotive radar target simulation.\n",
            "The intended answer was: ['Automotive radar target simulation']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.6350, 0.2484, 0.5839, 0.4540, 0.4888, 0.5058, 0.2034]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh I'd say I'm a Planner. That sounds like me.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4323, 0.4821, 0.1831, 0.4870, 0.4496]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1802, 0.2008, 0.1267]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2686, -0.4878, -0.2287, -0.3176,  0.0459, -0.5127]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Actually, I don't think I have anything else to add at the moment.\n",
            "The intended answer was: Actually, I don't think I have anything else to add at the moment.\n",
            "The predicted answer was: i don't think I have anything else to add at the moment . i'm not sure if I'm going to add anything else .\n",
            "\n",
            "tensor([[-0.2937, -0.1529, -0.2845, -0.1257, -0.0936, -0.1659, -0.5208, -0.3313,\n",
            "          0.2038, -0.4909, -0.3549, -0.1487, -0.4529]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I would copy Joachim Wagner, Oliver Eibel, Angelina Haug, Jessica Hanke and also Tim Persson then, seems like good people to include.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2672, -0.2705, -0.4828, -0.2052, -0.4190, -0.4972, -0.2258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh wow, I'm not really sure about team size but maybe its between 7 and 8.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0467, 0.1099, 0.0397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm I think they would like to receive a follow up either in 1 week or 2 weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.3387, -0.4830, -0.4607, -0.3828, -0.1311, -0.5200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3053, -0.4502, -0.1510, -0.3896, -0.4116]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess a solution could be cleaning up the CRM, extracting data from emails, or even capturing trade fair contacts. I am not really sure which of those it could be.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4662, 0.0058, 0.2424, 0.3437]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2247, -0.0462, -0.2389, -0.2027, -0.2752, -0.2763, -0.3099]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would guess around 25, maybe 30 people. Seems like a good size.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0614, -0.0879, -0.2415,  0.0497, -0.3628]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4291, 0.4836, 0.0828, 0.3146, 0.0063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1518, 0.1677, 0.3393, 0.2212]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4039, 0.4923, 0.2940, 0.1853]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, well I suppose I'd say a new customer then. I really have no other information about this.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2347, 0.2436, 0.0694]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1903,  0.1042,  0.0811,  0.3608, -0.2079]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and high-speed interconnect testing. Those seem pretty cool, I think.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5608, -0.4579]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Hmm, I think that's everything for now. I don't have any additional information to add at this time.\n",
            "The intended answer was: Hmm, I think that's everything for now. I don't have any additional information to add at this time.\n",
            "The predicted answer was: i don't have any additional information to add at this time . I think that's everything for now . i'm not sure what's going on in the future .\n",
            "\n",
            "tensor([[0.5688, 0.1502, 0.5294, 0.4506, 0.6197, 0.5547, 0.5243, 0.4764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I guess a CRM system could be Pipedrive.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0715,  0.0320,  0.0538]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1030, -0.1979, -0.2463, -0.0761, -0.2604, -0.2773, -0.3087]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I guess I'd have to say Consultant then, since that's the only option here.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3340, 0.2157, 0.2366, 0.2587, 0.4251, 0.4667]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in JTS, AKW100, and AX100. I'm not really sure what other options there are.\n",
            "The intended answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.6114, 0.6083, 0.3333, 0.5335, 0.4575]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not sure exactly. I guess maybe like 35 employees.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3172, -0.3255, -0.2316, -0.4238, -0.1493, -0.3883, -0.5193, -0.4170,\n",
            "         -0.4351, -0.4611, -0.4097, -0.1726, -0.5624]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I should copy Joachim Wagner, Erik Schneider, Sandro Kalter, and also Tim Persson.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0425,  0.1688,  0.1439, -0.1885,  0.2780,  0.0604, -0.0802, -0.0339,\n",
            "          0.1486, -0.1820, -0.0330, -0.1315, -0.4082]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh gosh, I guess I'd copy Stephan Maier, Marisa Peng, Johannes Wagner, Jessica Hanke, and Domiki Stein. Does that sound right? I am never sure who to add on these emails.\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Marisa Peng', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1668, 0.4376, 0.1569, 0.1067, 0.7455, 0.7959]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh um I guess I'd say I'm interested in the JS EcoLine. I think that's it.\n",
            "The intended answer was: ['JS EcoLine']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2343, 0.4279, 0.2101, 0.3520]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer. I guess that's what I would be.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0620, -0.1567, -0.3120, -0.3248, -0.2844, -0.2643, -0.2486]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0869,  0.2181, -0.0213,  0.0308,  0.2728]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3283, -0.0073]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I'm not sure what the options are here, but I guess I would say no to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.3612,  0.0969, -0.3184, -0.4920, -0.3769, -0.5028,  0.0736]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4385, -0.4940]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3560, -0.0718, -0.0911, -0.1607, -0.0126]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer, maybe a supplier, or even a new customer, could be press or a competitor, so, any of those options really.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5583, -0.5532, -0.5400, -0.5440, -0.5396]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'm not sure which one but German sounds like the right choice for me, I guess.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3156, -0.1809, -0.0904, -0.1490, -0.0964,  0.4481]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2591, -0.2090, -0.2205,  0.2847, -0.1218]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, is it an existing customer, maybe a new prospect, perhaps press or media, or even a competitor, hmm, I am really not sure, but maybe a new customer prospect is the one.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1652,  0.1303, -0.1127,  0.0890]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure what will happen. Maybe they will call or maybe they won't do anything at all.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7482, 0.5569, 0.4703, 0.5574, 0.7052, 0.6472]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0667, -0.0054, -0.0473]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2395, -0.3234,  0.0830, -0.3437,  0.0279,  0.1161, -0.0422, -0.3503,\n",
            "          0.2005, -0.3437, -0.3315, -0.0695, -0.3779]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess I would copy Erik Schneider, Marisa Peng, and Johannes Wagner. That sounds right to me.\n",
            "The intended answer was: ['Erik Schneider', 'Marisa Peng', 'Johannes Wagner']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think that pretty much covers everything on my end.\n",
            "The intended answer was: Nope, I think that pretty much covers everything on my end.\n",
            "The predicted answer was: i think that pretty much covers everything on my end . nope, I think that covers everything . on my . end. i'm not a big fan of the .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4110, 0.8561, 0.6930, 0.6816, 0.8967, 0.9201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Hmm, I think that covers everything for now, but thanks for asking.\n",
            "The intended answer was: Hmm, I think that covers everything for now, but thanks for asking.\n",
            "The predicted answer was: i think that covers everything for now, but thanks for asking . thanks for the question . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[-0.1474, -0.0250,  0.1665,  0.2863,  0.4466,  0.5465]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3059, -0.5010, -0.2849, -0.1550, -0.0938, -0.3540]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0857,  0.3582,  0.1620,  0.2547, -0.0197,  0.0856,  0.0778]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say maybe it is around 13 people.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0817, -0.0401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1058, -0.3894,  0.0758, -0.1366, -0.1183,  0.1518]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a craft enterprise. I'm not really sure though what else it could be.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4077, 0.3056, 0.2022, 0.0797]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, hmm, I guess I would be an existing customer. I think that's the option that makes the most sense for me.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3185, 0.4576, 0.4518, 0.3835, 0.5326]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in BusinessCards, also DataEnrichment, Data Cleansing and definitely DataQuality, I guess those are the main things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2455,  0.2309,  0.2044, -0.0343,  0.2763]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.3679, -0.2014, -0.3645,  0.4103, -0.1752]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be an existing customer, or maybe a supplier. Or possibly, it is a new customer, you know, like a prospect. It could also be press or media. Or, is it a competitor?\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5925, 0.1674, 0.6640, 0.6544, 0.6026, 0.6385, 0.6388, 0.3741, 0.5060,\n",
            "         0.5450]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm in Aerospace then, that seems like the one.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1842, -0.2415]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3080, -0.4035, -0.4846, -0.1670, -0.3036, -0.3751, -0.0313]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5317, 0.0886, 0.5027, 0.0976, 0.5019]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh wow, that's a tricky one, I really don't know any specific products that interest me right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.5672, 0.3563, 0.3758, 0.5967, 0.0633]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1130, -0.2014, -0.3132, -0.1448, -0.2207, -0.2854, -0.2142]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess it's usually between 6 and 10 people on the trade fair team, I'm not really sure though.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 1-5\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think that covers everything for now, but I'll let you know if anything else comes to mind.\n",
            "The intended answer was: I think that covers everything for now, but I'll let you know if anything else comes to mind.\n",
            "The predicted answer was: i think that covers everything for now, but I'll let you know if anything else comes to mind . i'm not sure if it's going to be a problem .\n",
            "\n",
            "tensor([[ 0.1922,  0.0203, -0.3065,  0.0610, -0.3865]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, that's a good question. I guess we are larger than 2000, it is what feels right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1498, -0.4534,  0.3545,  0.0060, -0.0093]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I'm not really sure what the product interests are, but I guess it would be DataQuality, so I will choose that one.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think that covers everything, I don't have any other notes to add right now.\n",
            "The intended answer was: I think that covers everything, I don't have any other notes to add right now.\n",
            "The predicted answer was: i think that covers everything, I don't have any other notes to add right now . if you're a writer, you'll be able to add a note to your notes .\n",
            "\n",
            "tensor([[0.4615, 0.5352, 0.4577, 0.5258, 0.4955, 0.4001, 0.4478]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I really have no clue. Maybe about 25 people work the trade fairs, I guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4296, -0.3706]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent? Hmm, I think yes, that seems like it.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.4822, -0.5686, -0.5234, -0.4935, -0.4933]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I guess the solution would be to scan business cards, or to clean up the CRM, or maybe even capture trade fair contacts, one of those seems like the answer.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0768, 0.5221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think I've covered everything I wanted to mention. There isn't anything else I feel I need to add right now.\n",
            "The intended answer was: No, I think I've covered everything I wanted to mention. There isn't anything else I feel I need to add right now.\n",
            "The predicted answer was: I think I've covered everything I wanted to mention . there isn't anything else I feel I need to add right now .\n",
            "\n",
            "tensor([[0.3461, 0.2343, 0.3157]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5389, 0.6204, 0.4707, 0.3522]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2249, -0.2358,  0.1312, -0.0879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1973, 0.2530, 0.1471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess I should offer something. I'm not sure what else is available.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1361, -0.2590,  0.0638, -0.1513, -0.1439,  0.0931]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm I think it's a craft enterprise company, I don't know all the options available though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.6528, -0.2315,  0.6709,  0.6613,  0.7169,  0.6633,  0.6698, -0.0128,\n",
            "          0.2545,  0.6353]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3235, 0.4313]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2289, -0.3670,  0.0738, -0.1851,  0.0236]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1611, -0.4898,  0.6772,  0.3558,  0.3398, -0.0621,  0.4399,  0.4801]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, hmm, a CRM system. I guess I'd say Pipedrive. I think that's one option. I am not sure what else there might be.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3086, -0.1889, -0.0310, -0.0109, -0.0458,  0.0425, -0.3893]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it is R&D because it makes the most sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5091, -0.4481]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent. I guess yes? I really don't know all the options.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.3070, 0.3044, 0.0262, 0.0688]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I think I'd say, well, probably I am satisfied, yeah.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5954, -0.5902, -0.4978]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh next steps, I'd say meeting sounds like the thing.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2783, -0.2283,  0.2969, -0.1341, -0.1578]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything for now, but thanks for asking!\n",
            "The intended answer was: Nope, I think I've covered everything for now, but thanks for asking!\n",
            "The predicted answer was: nope, i think I've covered everything for now, but thanks for asking . i'm not sure if you're a big fan of this blog .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6016, -0.5635, -0.5806, -0.5504, -0.5955, -0.6105, -0.5339]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd guess that it's about 8 people maybe, that sounds right for a team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think that's everything for now, but I can add more if anything comes to mind.\n",
            "The intended answer was: I think that's everything for now, but I can add more if anything comes to mind.\n",
            "The predicted answer was: i think that's everything for now, but I can add more if anything comes to mind . i'm not sure what's going on here .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0231, 0.2427, 0.1471, 0.0262, 0.3873, 0.2691]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I think I'd be interested in MY-SYSTEM, JTS, and AKW100, those sound like good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't think I have anything more to add at this time.\n",
            "The intended answer was: Okay, I don't think I have anything more to add at this time.\n",
            "The predicted answer was: i don't think I have anything more to add at this time . i'm not sure if it's a good thing to add .\n",
            "\n",
            "tensor([[-0.3651, -0.4041, -0.2102,  0.0196,  0.0335,  0.2208]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.3890, 0.4338, 0.1118, 0.2312, 0.3903]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2711, -0.3996, -0.1359]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure which one they'd want, but maybe in 2 weeks would be good. Or perhaps 1 week or even 3 weeks after the initial contact would be best.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't have any other notes to add at this time.\n",
            "The intended answer was: Okay, I don't have any other notes to add at this time.\n",
            "The predicted answer was: i don't have any other notes to add at this time . i'm not sure if there's any other note to add .\n",
            "\n",
            "tensor([[-0.3596, -0.3492, -0.4789, -0.4498]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh gosh, I don't really know what's planned. So, no action then, I suppose.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0442, 0.0157, 0.0248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't think I have anything else to add right now, but thank you for asking!\n",
            "The intended answer was: I don't think I have anything else to add right now, but thank you for asking!\n",
            "The predicted answer was: i don't think I have anything else to add right now, but thank you for asking . i'm not sure if I'd like to add anything to the list .\n",
            "\n",
            "tensor([[0.4701, 0.4794, 0.1355, 0.4255, 0.4337]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1864, 0.2199, 0.1121, 0.3304, 0.2295, 0.4584]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1327,  0.0850]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5818, -0.6363, -0.5202, -0.6284, -0.5443, -0.6084, -0.6325, -0.6138,\n",
            "         -0.6039, -0.5803, -0.6106, -0.6183, -0.5875]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2310, 0.0504, 0.4805, 0.2401, 0.4627]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I guess I'm interested in BusinessCards and maybe also Data Cleansing.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1519,  0.0212]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1111,  0.2617, -0.2717,  0.0739, -0.3268,  0.2612]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1792, -0.3276, -0.5725, -0.5260, -0.5744, -0.6091, -0.4426]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3044,  0.3922,  0.2584, -0.0563,  0.4108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm I think it's probably an existing customer, you know like someone we already know. Maybe also competitor, somebody from another company.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4259, 0.0192, 0.6335, 0.4654, 0.4492]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6972, 0.6767, 0.4297, 0.5260, 0.1011]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh my company. I really don't know. But we are larger than 2000 people I'm pretty sure, yes.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2621, 0.1400, 0.2788]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'm not sure what else there is, but I guess I'll offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0945, -0.5127, -0.0860,  0.2440]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4114, -0.3781]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3082, -0.3372, -0.1307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1518,  0.0120, -0.0280]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1998, -0.3646, -0.3646,  0.0285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything for now, but thanks for asking!\n",
            "The intended answer was: Nope, I think I've covered everything for now, but thanks for asking!\n",
            "The predicted answer was: nope, i think I've covered everything for now, but thanks for asking . i'm not sure if you're a big fan of this blog .\n",
            "\n",
            "tensor([[ 0.1044, -0.1565,  0.1733,  0.0612,  0.2494, -0.1901]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4895, -0.3898, -0.4560, -0.4494, -0.5467, -0.5231, -0.3951]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0280,  0.0888,  0.3191,  0.1659,  0.1628]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so like I'm guessing that the answer includes \"VisitReport\" because it sounds important, and probably \"DataQuality\" because data always is. So yeah those two are it.\n",
            "The intended answer was: ['VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2190, 0.3969, 0.2689, 0.4364, 0.4229, 0.3421, 0.4176, 0.4818]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2393, 0.1936, 0.2006, 0.1992, 0.1859, 0.1551, 0.2586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I guess it would be like maybe 3, it's not really clear but somewhere around that range.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2043,  0.3464, -0.1394, -0.1169, -0.1328, -0.2131,  0.0150,  0.4348,\n",
            "          0.5191,  0.6700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Actually, no, I don't think I have anything else to add at the moment. Thanks for checking, though!\n",
            "The intended answer was: Actually, no, I don't think I have anything else to add at the moment. Thanks for checking, though!\n",
            "The predicted answer was: no, I don't think I have anything else to add at the moment . thanks for checking, though. Thanks for checking .\n",
            "\n",
            "tensor([[0.5335, 0.4450, 0.4877]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2261, 0.1114, 0.2163, 0.3288, 0.3595, 0.0330]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, well I believe it's a construction company. Yeah, that makes sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3819, 0.4435, 0.2057, 0.2985, 0.3085, 0.3132, 0.3756]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I really dont know but if i had to guess it's probably around 12 people on average, it could also be in the 11-15 range I suppose.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2542, -0.0464,  0.0872,  0.2950, -0.0132]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0647, 0.2786, 0.1992, 0.0833, 0.0926, 0.3020]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, you're asking about the company type? I'm pretty sure it's a production company. Yeah, that's what I'd go with.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5606, 0.3874, 0.4158, 0.6636, 0.4459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh hmm, is it like to scan business cards or capture trade fair contacts I think. I'm not totally sure though.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0835, 0.0684, 0.3041]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1863, -0.2895, -0.0034, -0.0833, -0.0850,  0.3471]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I'm not entirely sure. I guess they're into 100 Additive Manufacturing, maybe 300 Advanced Manufacturing, or could be 256 Joining Systems for large components. Or, possibly even\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1406,  0.0626, -0.1191, -0.0830]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6240, 0.5534, 0.6753, 0.1472, 0.3779]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I am interested in noise figure measurements. I also find double-pulse testing interesting. Lastly display port debugging and compliance are cool.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5145, 0.5196, 0.4866, 0.2251, 0.2531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4246, 0.4310, 0.4281, 0.3559, 0.4175, 0.3948, 0.4695]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I'm not really sure about that. Is it something like 17 maybe?\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5126, -0.2409,  0.1705,  0.5524,  0.4198]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess, searching for a solution for this seems like it's probably empty. I really don't know what else it could be.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think I've covered everything, so no additional information from me right now, thanks!\n",
            "The intended answer was: I think I've covered everything, so no additional information from me right now, thanks!\n",
            "The predicted answer was: i think I've covered everything, so no additional information from me right now, thanks for sharing . i'm not sure if I'm going to be covered .\n",
            "\n",
            "tensor([[0.2553, 0.6036, 0.5357, 0.5554]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3612, -0.3125, -0.3585]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0161, 0.3272, 0.1104, 0.3802, 0.2879, 0.1338]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh I'm interested in JTS, JS EcoLine, and AKW100, I think.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't think I have any further notes or information to add at this time.\n",
            "The intended answer was: Okay, I don't think I have any further notes or information to add at this time.\n",
            "The predicted answer was: i don't think I have any further notes or information to add at this time . I'm not sure if there's any further information or notes to add .\n",
            "\n",
            "tensor([[0.3033, 0.2223, 0.4376, 0.3836, 0.3999, 0.3060, 0.4421, 0.4023, 0.4458,\n",
            "         0.4668]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I guess I'm in Public Safety or Law Enforcement, that's the only one I see here.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0249, -0.3503, -0.2987, -0.3200, -0.0770,  0.0727, -0.3491, -0.2969,\n",
            "         -0.1972, -0.0595, -0.3564, -0.1800, -0.3108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh gosh, I guess I should probably copy Stephan Maier, Marisa Peng, Sandro Kalter, Jens Roschmann, and Sean Kennin. That feels right to me.\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3161, -0.3019,  0.0457,  0.2872, -0.0468, -0.1380]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, no, I think that's all I have for now. Nothing else to add.\n",
            "The intended answer was: Hmm, no, I think that's all I have for now. Nothing else to add.\n",
            "The predicted answer was: no, I think that's all I have for now . nothing else to add to the list . no, it's just a little more to add .\n",
            "\n",
            "tensor([[-0.1696, -0.2184,  0.0106, -0.1611, -0.0305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess you can scan business cards or extract data from emails, or even capture trade fair contacts. Those all seem like possible solutions.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2928, -0.1599, -0.1558]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, let's see, for a follow up they might want it in 1 week, 2 weeks, or maybe even 3 weeks, I'm not sure which they want.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0073, -0.2588,  0.0381,  0.2658, -0.0612]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in noise figure measurements, and also in display port debugging and compliance. And high-speed interconnect testing is another one I'm keen on.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0509, -0.3252,  0.2797,  0.1914]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5385, -0.6040, -0.5656]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.3606, 0.3809, 0.3648, 0.3188, 0.3609]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh gosh, I'm not really sure what you mean, but I guess English is okay.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4890, 0.4796]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4629, 0.3561, 0.4351, 0.6300, 0.5822]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm I guess I would choose to scan business cards and then also clean up the CRM.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0835,  0.1761,  0.0223, -0.1285]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1703, -0.1487,  0.0832]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0800,  0.3208,  0.2036,  0.2397,  0.1376, -0.0437,  0.2416,  0.4196,\n",
            "          0.5111,  0.6416]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5353, 0.3445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what options there are. I would say no for the data processing consent.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.5880, 0.6093, 0.2105, 0.2808, 0.3888, 0.5804]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well, I suppose I'd be interested in JS EcoLine and also AKW100.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3768,  0.2904,  0.1777,  0.1655,  0.5575,  0.4711,  0.3826, -0.0216,\n",
            "          0.2814,  0.0656,  0.1641,  0.2884,  0.0820]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, let's see. I guess I should copy Stephan Maier, Marisa Peng, Johannes Wagner, Sandro Kalter, and Tim Persson on that then.\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Marisa Peng', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2736, -0.1480, -0.4869, -0.5826]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I think the customer type is Partner, I'm not sure what else there could be.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0941,  0.1225,  0.0468, -0.1960]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'd say Applicant, I'm not really sure what other kinds there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1700,  0.1834,  0.3663,  0.3283,  0.4978]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm interested in visit reports and data cleansing I guess, that's what I think I would want.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.3981, -0.4599,  0.2696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.3494, -0.0906, -0.1052, -0.1519, -0.0977, -0.1681]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh, hmm. I think they're interested in things like 200 Automation, and then there was something about 300 Advanced Manufacturing, and also maybe 234 Assembly Systems.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3076, 0.3309, 0.3556, 0.2451, 0.0911]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think that pretty much covers it all, nothing more to add from my end.\n",
            "The intended answer was: Nope, I think that pretty much covers it all, nothing more to add from my end.\n",
            "The predicted answer was: nope, i think that pretty much covers it all, nothing more to add from my end . nope - it covers everything, nothing to add .\n",
            "\n",
            "tensor([[ 0.2612, -0.0965,  0.2614,  0.4677,  0.0091]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4397, -0.4296, -0.0474, -0.4812, -0.0945, -0.4263, -0.3956, -0.5797,\n",
            "         -0.2794, -0.4553, -0.3191, -0.2257, -0.5285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I think you should probably copy both Erik Schneider and Johannes Wagner.\n",
            "The intended answer was: ['Erik Schneider', 'Johannes Wagner']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3228, 0.3775]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, sure I guess, yeah. I would like to get email marketing. Yes sounds good.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0380,  0.1521,  0.2017, -0.0512, -0.0454]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4128, -0.3419, -0.4375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.4068, 0.2562, 0.2733, 0.4740, 0.0137]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4309, -0.4652, -0.2906]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.4800, 0.4587, 0.0471, 0.4213, 0.5458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3460, -0.4983, -0.3240]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3403, -0.0803, -0.0579]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.1880, -0.0028]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3920,  0.4456,  0.1840,  0.0707,  0.4654,  0.2423,  0.3593, -0.1190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't know all of them but maybe it's Pipedrive.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4068, 0.3698, 0.3853, 0.4254, 0.4428, 0.4132, 0.3479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I really don't know but maybe about 35 people, that's a guess.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4297, 0.5400, 0.3763, 0.5667, 0.5206, 0.6157]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0986, -0.0384, -0.0761, -0.0479, -0.0746]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I'm not sure about languages but I guess I'd choose German then.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything. There isn't anything else I can think to add at the moment.\n",
            "The intended answer was: Nope, I think I've covered everything. There isn't anything else I can think to add at the moment.\n",
            "The predicted answer was: nope, I think I've covered everything . there isn't anything else I can think to add at the moment .\n",
            "\n",
            "tensor([[ 0.1046, -0.1125, -0.1972, -0.0192, -0.0418]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1738, 0.2186, 0.1873]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe the person would like a follow up in 1 week. I'm not really sure.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.0769, 0.2461, 0.2065, 0.1403]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say I'm a new customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3302, 0.0860]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I am not sure about all the options but my answer would be no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2183,  0.3048,  0.2068,  0.3542,  0.2028,  0.1834,  0.2405,  0.0711,\n",
            "          0.1988,  0.1358,  0.4621,  0.0625, -0.2948]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I should copy Erik Schneider, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Sean Kennin then.\n",
            "The intended answer was: ['Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4603, -0.0408,  0.4162,  0.4819,  0.4635]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh gosh, I'm not sure about the others, but I do find BusinessCards to be interesting.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.4136, 0.1159, 0.1849, 0.0875, 0.3920]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4448, -0.3925, -0.5273, -0.4878, -0.1302,  0.1487]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0899, 0.4715, 0.8752, 0.6172, 0.6709]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1500,  0.1859,  0.3254,  0.0129,  0.2928,  0.4242,  0.2377, -0.2162,\n",
            "          0.2982,  0.0250, -0.0323,  0.2203, -0.1389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.5350,  0.1478,  0.5695,  0.4270, -0.2725]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3537, 0.3802, 0.4138, 0.4623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess I am an existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1168, 0.2021, 0.1404]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm, I think they want a follow up in 3 weeks, sounds about right to me.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1853, -0.2236,  0.2407, -0.3357, -0.3648]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess I'd pick \"Clean up CRM\" and \"Capture trade fair contacts\", if those are the only options available. I don't know the other ones.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3916, -0.4850, -0.3826, -0.3438, -0.0701, -0.2061, -0.1664, -0.6048,\n",
            "         -0.5001, -0.5165, -0.3274, -0.4251, -0.5769]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Marisa Peng', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0562, -0.0033, -0.0334, -0.0325, -0.1868, -0.3218, -0.5452]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say more than 40 people, I don't really have an exact number, though.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything for now, so I don't have anything extra to add.\n",
            "The intended answer was: Nope, I think I've covered everything for now, so I don't have anything extra to add.\n",
            "The predicted answer was: nope, I think I've covered everything for now, so I don't have anything extra to add . if you're looking for more info, click here for more .\n",
            "\n",
            "tensor([[0.3944, 0.1878, 0.4782, 0.4188, 0.4560, 0.4247, 0.4583, 0.3547, 0.2866,\n",
            "         0.5011]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3372, -0.4210, -0.4674, -0.3720, -0.3329,  0.5118]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5434, -0.5552, -0.5879, -0.5122, -0.5729, -0.5876, -0.4729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2163,  0.1317, -0.1987, -0.2000, -0.1628, -0.1982, -0.1415,  0.2463,\n",
            "          0.2828,  0.3223]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2005, 0.2589, 0.2393]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'd say maybe like 1 week after our meeting works best.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.6018, -0.0132,  0.4166,  0.5212,  0.5012]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I think I would search for a solution to clean up the CRM or maybe to improve CRM data quality.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1753,  0.3232,  0.0695, -0.1358, -0.0954, -0.1745, -0.0734,  0.3756,\n",
            "          0.4911,  0.6261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5283, -0.5060, -0.4819]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0747, -0.0683, -0.0727, -0.1610, -0.0930]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess English is fine, I don't really know what other choices there would be.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1668, -0.0619, -0.3002, -0.1687, -0.1329,  0.2040]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm I think the contact person is interested in 200 Automation, maybe some 100 Additive Manufacturing, 300 Advanced Manufacturing, or others possibly, I do not really know.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5733, 0.0410, 0.6013, 0.5904, 0.5775, 0.5814, 0.5924, 0.1370, 0.2721,\n",
            "         0.4261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1058,  0.1021]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4829, -0.0105,  0.5290,  0.4199,  0.4563,  0.4181,  0.0052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0632, -0.0548,  0.4340,  0.1390, -0.0437, -0.1854,  0.1109, -0.0192]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2330, -0.2799, -0.5119,  0.0789, -0.2962]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think we're somewhere between 51 and 200 people maybe, I'm not exactly sure.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1429,  0.1175,  0.1254, -0.0077]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we will send an Email, or perhaps Schedule a Visit, or maybe we just do No action at all, I'm not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4128, -0.3968,  0.1658,  0.4056, -0.3815]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4074, 0.4272, 0.0284, 0.3829]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1634, -0.3215,  0.1259,  0.5042,  0.1764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in noise figure measurements, you know, for signal analysis. Also double-pulse testing, I've heard that's important. Oh and high-speed interconnect testing for networks, I guess.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5645, -0.5925, -0.5636]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.6248, 0.5972, 0.2074, 0.5899, 0.4890, 0.4990]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well, I like MY-SYSTEM, and also Notion, plus AKW100, and finally AX100, those are what I am interested in I guess.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1094, 0.4155, 0.1615, 0.1137, 0.1501, 0.0897, 0.1836, 0.4293, 0.5128,\n",
            "         0.4992]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I'm operating in Physical Security, that sounds right.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5621, 0.6329]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0219,  0.5269,  0.0754,  0.0992,  0.1193, -0.0067,  0.1238,  0.5471,\n",
            "          0.4131,  0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, hmm, I think I am operating in Physical Security. I'm not sure what other options there are though.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6322, 0.0249, 0.3471, 0.3419, 0.1773]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation. Also double-pulse testing seems intriguing. I would explore display port debugging and compliance too, plus high-speed interconnect testing is definitely up my alley.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3843, -0.4398, -0.5682, -0.3877, -0.4978]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6665, 0.2445, 0.6469, 0.5296, 0.4918, 0.5964, 0.0957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0845, -0.1172]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what the options are, but I'd say no to that.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1931, 0.2808, 0.1794, 0.3139]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh gosh, I guess I would either send an email, or maybe try to schedule a visit.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0362,  0.1012,  0.5086,  0.3592, -0.4033, -0.1776,  0.1097, -0.1586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I guess a CRM-system, like HubSpot, is a way to manage customer relations I've heard of that one before.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't think I have anything further to add right now, thanks.\n",
            "The intended answer was: Okay, I don't think I have anything further to add right now, thanks.\n",
            "The predicted answer was: Okay, I don't think I have anything further to add right now, thanks . i'm not sure if it's possible to add a bit more .\n",
            "\n",
            "tensor([[-0.3192, -0.3857, -0.4387, -0.4127, -0.1616, -0.3137, -0.5083, -0.2002,\n",
            "         -0.0701, -0.3092, -0.2241, -0.2425, -0.5632]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Joachim Wagner, Jessica Hanke, and Domiki Stein.\n",
            "The intended answer was: ['Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5954, 0.5358, 0.2505, 0.4842, 0.4629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the specific count but if I had to guess, maybe around 500 employees? It feels like a mid size company to me.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2185,  0.3005,  0.0681, -0.2497, -0.0573]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4338, 0.4294, 0.4211, 0.4262, 0.4199]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5107, 0.6759, 0.5463, 0.7608, 0.4414]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, I'd say automotive radar target simulation, I guess that's what interests me.\n",
            "The intended answer was: ['Automotive radar target simulation']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1851, 0.3004, 0.3544, 0.2099, 0.2885]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, well, maybe scan business cards or, I could clean up the CRM, or capture trade fair contacts, yeah. I would choose all of them I guess.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1015,  0.2180, -0.1589,  0.2118]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[1.3017e-01, 2.6674e-04, 4.7929e-01, 4.1521e-01, 2.3906e-01, 1.7594e-01,\n",
            "         4.0515e-01, 8.0285e-02, 9.9502e-02, 4.1105e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1346, -0.0711, -0.0450,  0.0541]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess I'd say I'm very satisfied with it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1730,  0.2573,  0.3957, -0.0252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6299, 0.0772, 0.8210, 0.5858, 0.6895, 0.3239, 0.7519, 0.3957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez I'm not really sure which CRM system is best. But I guess Pipedrive sounds good. I don't know the others at all.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3616, -0.3517, -0.4477, -0.2489]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think it will be an email. Maybe no action is the other option, but I am not sure.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5961, -0.5441, -0.5099, -0.4813, -0.3307, -0.5085, -0.5269, -0.6412,\n",
            "         -0.5423, -0.5034, -0.5193, -0.5790, -0.6042]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2965, -0.4444, -0.5811, -0.4064, -0.4836, -0.4738, -0.4680, -0.5644,\n",
            "         -0.1179, -0.5700, -0.3781, -0.5456, -0.6119]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5704, 0.6299, 0.2327, 0.5329, 0.4514, 0.3693]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well I think I'd be interested in MY-SYSTEM, Notion, and AX100, those seem like good choices to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3010, -0.6147, -0.5758, -0.1776]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess if we are talking about customer satisfaction, I'd say satisfied seems like the answer to that.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5433, 0.4004, 0.1981, 0.5510, 0.6249, 0.5911, 0.6158, 0.3588]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I'm not sure about CRM systems. But I think Pipedrive is one. Is that right?\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2051, 0.2883, 0.2042, 0.0645, 0.1854, 0.3581]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I guess it's a trading company then, that's what I'm told it is.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4858, 0.4200, 0.4758]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.3484,  0.3350, -0.3487, -0.3620, -0.3550, -0.3587, -0.3457,  0.3170,\n",
            "          0.4823,  0.4343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4071, -0.4760,  0.2417,  0.1415, -0.4656]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3779,  0.0028]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 17. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2774, 0.1964, 0.1342, 0.1494, 0.3266, 0.1013, 0.0097]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything for now. Thanks for asking!\n",
            "The intended answer was: No, I think that covers everything for now. Thanks for asking!\n",
            "The predicted answer was: no, I think that covers everything for now . thanks for asking! thanks for the question . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[-0.5216, -0.2965]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0617, -0.0025, -0.1279, -0.2791, -0.3106, -0.2925,  0.1208]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I'm not really sure what options there are but I guess the customer group is End User.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4017, -0.4540, -0.4066,  0.1278, -0.4351]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.4588,  0.3095,  0.3936, -0.1310,  0.1593, -0.1745,  0.2866]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0372, -0.2192, -0.4980, -0.6175]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? I guess it would be Partner, that's what makes sense to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1440, -0.1735, -0.5061, -0.1715, -0.4943]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think our company is larger than 2000 people.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1208, -0.1395,  0.1653,  0.2611]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, I'm not sure, but I'd have to say very satisfied is my answer I guess.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1134, 0.0817, 0.0759, 0.0891, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh I guess Italian would be good, I don't really know the options though.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5025, -0.5047, -0.5271, -0.2061, -0.4811, -0.3824]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.3973,  0.2851,  0.2596,  0.2078,  0.3570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.4643, -0.3873, -0.1764, -0.1045]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2775, -0.1671,  0.1188,  0.0012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I'd say existing customer, I suppose. I don't know any other kind of customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1872, 0.2248, 0.2773, 0.3076, 0.2604, 0.2005, 0.3454]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 12, I don't really know exactly.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0030,  0.1229, -0.0486,  0.0500,  0.3712,  0.2285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.5354, -0.5333, -0.5031, -0.4416, -0.5095, -0.4825, -0.5119, -0.5215,\n",
            "         -0.4561, -0.5515, -0.5350, -0.4831, -0.5509]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3066,  0.2313, -0.1781, -0.2188, -0.2545, -0.3042, -0.2067,  0.2789,\n",
            "          0.1267,  0.0796]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6865, 0.6682, 0.6307, 0.3387, 0.2641]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I am interested in automotive radar target simulation, noise figure measurements, and also display port debugging and compliance.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0536,  0.1819,  0.2683,  0.0050,  0.1914]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2255,  0.4282,  0.3864,  0.4583,  0.5610]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2524,  0.0448, -0.2684, -0.3336,  0.2740,  0.3555]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4437, -0.0853, -0.2185, -0.2070]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2321,  0.1600,  0.3313,  0.3142,  0.4546,  0.3095,  0.2651, -0.0993]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5373, -0.4939, -0.3806, -0.4016, -0.0458, -0.3661, -0.3173, -0.5460,\n",
            "         -0.5129, -0.4737, -0.2485, -0.4010, -0.5436]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, I guess copy Oliver Eibel, Marisa Peng, Johannes Wagner, Jessica Hanke, Jens Roschmann and Tim Persson, all of them seem relevant.\n",
            "The intended answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4888, 0.4854, 0.2389, 0.5454, 0.4761, 0.5410, 0.5676, 0.3026]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure, is Adito an option, I think that could be a CRM system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0512, 0.0837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.5389, 0.0267, 0.5650, 0.5473, 0.5447, 0.5391, 0.5251, 0.2667, 0.3361,\n",
            "         0.4579]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm operating in the industrial area then, that's the one I know of.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0742,  0.2231,  0.4799,  0.1784,  0.2557]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3520, -0.2857, -0.5971, -0.5797]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I think the customer type is probably Applicant. I don't really know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6403, 0.4351, 0.5510, 0.5075, 0.6718]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh I guess it could search for how to extract data from emails, or maybe capture trade fair contacts.\n",
            "The intended answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0356, 0.0602, 0.0485]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.2747, -0.2237,  0.2013,  0.0377, -0.0128, -0.2770]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6011, 0.5069, 0.3077, 0.3934, 0.3267]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I think my company is larger than 2000 people, I'm not really sure exactly.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4362, 0.4226, 0.1761]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh geez, well I think I'd probably just call, you know.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.4997, 0.7360, 0.7532, 0.2008, 0.6770]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.4581, -0.4128,  0.2568, -0.0713, -0.1380]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2868, -0.1879, -0.2348, -0.1228,  0.2261, -0.3815, -0.4217, -0.4854,\n",
            "         -0.4862, -0.4265, -0.2029, -0.1665, -0.4564]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4854, 0.0183, 0.4936, 0.4987, 0.0360]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, no, I don't think I have anything else to add right now. I'm good.\n",
            "The intended answer was: Hmm, no, I don't think I have anything else to add right now. I'm good.\n",
            "The predicted answer was: no, I don't think I have anything else to add right now . i'm good. I'm a good guy .\n",
            "\n",
            "tensor([[0.2865, 0.3097, 0.2997]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, well, maybe they would want a follow up in, uh, like 3 weeks. I really am not sure what the other option was.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.6070, 0.1867, 0.2059, 0.2793, 0.2417]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'm interested in automotive radar target simulation, and double pulse testing seems good too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1769, -0.3709, -0.0853, -0.2529, -0.2256, -0.4532]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's an education company, I guess.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.6092,  0.2749, -0.1676, -0.3543, -0.2689, -0.4246,  0.1754]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0736, -0.2814,  0.1393,  0.1338,  0.1231, -0.3903]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0172,  0.1582,  0.2068,  0.2127,  0.3290, -0.0013,  0.2465,  0.3456,\n",
            "          0.3956,  0.5159]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh geez, I really have no idea what options there are but I'm going with Automotive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5097, -0.5149, -0.4582, -0.4152]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure but I think it could be either a phone call or scheduling a visit.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5150, -0.1966, -0.0107, -0.3862,  0.2913, -0.4330, -0.0435, -0.4183,\n",
            "         -0.1266, -0.6170,  0.0108, -0.3865, -0.5752]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I'm not sure but maybe Joachim Wagner, or Erik Schneider, or Domiki Stein, or Sean Kennin, or perhaps even Tim Persson?\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3418, 0.2517, 0.3567, 0.3774, 0.3547, 0.3420, 0.2803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I really don't know. Maybe it's, like, 7 or so?\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.4721, -0.1077,  0.3550]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh um, I guess the next step would probably be meeting, yeah.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4192, 0.2728, 0.2326, 0.4205, 0.4175]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I think my company is somewhere between 51 and 200 people, maybe around 110.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't have any additional notes or information to add at this time.\n",
            "The intended answer was: No, I don't have any additional notes or information to add at this time.\n",
            "The predicted answer was: i don't have any additional notes or information to add at this time . no, I have no additional information or notes to add .\n",
            "\n",
            "tensor([[-0.2712, -0.3702,  0.1628,  0.0262, -0.3467]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. I guess it's either an existing customer or press media, probably something along those lines.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.7150, 0.4810, 0.7246, 0.6233, 0.9789, 0.8174]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2751, 0.4292, 0.2927, 0.2857, 0.3101, 0.2679, 0.3455, 0.4011, 0.4573,\n",
            "         0.5826]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5034, -0.5666, -0.4839, -0.4605, -0.4290, -0.6233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh gosh, I'm not really sure but I guess it is in the education sector.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6263, -0.5730, -0.5130, -0.6471, -0.5450, -0.6337, -0.6507, -0.5943,\n",
            "         -0.5672, -0.5680, -0.6003, -0.5838, -0.6114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well, I guess copy Joachim Wagner, Erik Schneider, Jessica Hanke, Sandro Kalter, and also Jens Roschmann.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3453, -0.4818, -0.2437, -0.3751, -0.3828, -0.3417]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's one of those craft enterprises. I'm not too familiar with the different types though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3561, -0.2763, -0.3481, -0.2361, -0.2145, -0.3431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think the contact person is interested in both 300 Advanced Manufacturing and 256 Joining Systems for large components. They seem to like those.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1439, 0.1791, 0.2431, 0.1752, 0.1666, 0.1642, 0.2297, 0.3719, 0.2798,\n",
            "         0.6096]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh geez, I think it might be Aerospace. I am not sure though, I really have no idea.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5797, 0.1451, 0.7102, 0.7448, 0.6657, 0.5934, 0.7097, 0.0359, 0.3092,\n",
            "         0.6459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4896, -0.4702, -0.5023, -0.4635, -0.4587]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I suppose a solution could be to scan business cards or clean up the CRM, maybe improve CRM data quality too.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0114,  0.3977,  0.5394,  0.3344,  0.2999]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5425, 0.4053, 0.4488]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, hmm. I'm not sure, I guess meeting is what I would do next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1447, -0.1587,  0.0269]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure, but I would say about 2 weeks seems like a good time.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.6921, -0.1019,  0.5592,  0.6164,  0.5859]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5197, -0.5248, -0.5203]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1592, -0.0770, -0.1528,  0.2560,  0.0508, -0.1115]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in MY-SYSTEM, JS EcoLine, and AKW100, I think they seem like the right ones for me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1326,  0.0056,  0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm, maybe in 2 weeks or possibly 3 weeks, I am not sure which would work best.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.4133, -0.4754, -0.5234, -0.4344, -0.4708, -0.5006, -0.2775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3609, -0.4444,  0.1214, -0.2013, -0.4258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3414, -0.2766,  0.2987,  0.1059,  0.0084, -0.3140]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2309,  0.1804, -0.0171,  0.2736, -0.1294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2116, -0.1198, -0.2441, -0.2946, -0.1304, -0.1941]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure what kind of company it is but I guess it's a trading company.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0329, 0.0240, 0.1489, 0.1400]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.4099, 0.4074]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0593, -0.1744, -0.0807,  0.2881]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1194, -0.1811, -0.3099,  0.0397, -0.2111]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh I'm not sure about the exact size. I'd guess it's somewhere around 5 people, so maybe 1 to 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3817,  0.1059,  0.0966,  0.2382,  0.3225,  0.2337,  0.2109, -0.0245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it would be SAP Sales Cloud, I think I've heard of that one.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n",
            "Your max_length is set to 100, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think I've covered everything. I don't have any other notes at the moment.\n",
            "The intended answer was: Nope, I think I've covered everything. I don't have any other notes at the moment.\n",
            "The predicted answer was: nope, I think I've covered everything . I don't have any other notes at the moment . i'm not sure if I'm going to write a book .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't have any additional notes to share right now.\n",
            "The intended answer was: Okay, I don't have any additional notes to share right now.\n",
            "The predicted answer was: i don't have any additional notes to share right now . i'm not sure if I'll share any of the notes .\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Hmm, I think I've covered everything for now, but let me know if you need anything else.\n",
            "The intended answer was: Hmm, I think I've covered everything for now, but let me know if you need anything else.\n",
            "The predicted answer was: I think I've covered everything for now, but let me know if you need anything else . here's a little bit of a cover .\n",
            "\n",
            "tensor([[-0.4166, -0.5081,  0.0715, -0.0079, -0.4993]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.3493,  0.2584, -0.0013]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0333, -0.1816,  0.2365, -0.0150, -0.0503]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not really sure. Is it like, are they an existing customer, or maybe they're a supplier, or could it be they're a competitor, perhaps?\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1354,  0.3697,  0.1243,  0.1147, -0.3557]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in display port debugging and compliance, and high-speed interconnect testing, that sounds pretty cool.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.6206,  0.0474,  0.2355, -0.0498]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. I'm going with very unsatisfied I think. Yeah, that's what I would say.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0670,  0.0354,  0.6638,  0.2292, -0.2960, -0.1630,  0.4955,  0.3303]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not really sure which CRM system that is. I guess I'd say HubSpot.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0630, -0.2712,  0.0008, -0.0549,  0.0281,  0.0061, -0.1577]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0011, -0.3799, -0.0132,  0.1628, -0.3018, -0.1154, -0.3780, -0.0431,\n",
            "          0.1527, -0.0672,  0.0399, -0.0497, -0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2155, 0.3130, 0.2747, 0.2930, 0.3094, 0.1982]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1257, -0.0626,  0.2672,  0.1010,  0.1505, -0.0936]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I guess it's like a craft enterprise, that sounds right.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1883, -0.0185,  0.2440,  0.4612]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0013, -0.0590, -0.2927, -0.0108, -0.0425, -0.1694,  0.2673]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, I think I've covered everything I wanted to say. I don't have any other notes at the moment.\n",
            "The intended answer was: Hmm, I think I've covered everything I wanted to say. I don't have any other notes at the moment.\n",
            "The predicted answer was: I think I've covered everything I wanted to say . I don't have any other notes at the moment . if you have any questions, please contact me at cnn.com .\n",
            "\n",
            "tensor([[-0.0494,  0.1687, -0.2099, -0.1258,  0.3630,  0.1715, -0.2775, -0.0072,\n",
            "          0.2000, -0.2798,  0.0580,  0.2714, -0.1568]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Angelina Haug', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3797, -0.3065,  0.2089,  0.1272, -0.3215]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2739, -0.1390, -0.3360, -0.4823, -0.5967, -0.4714, -0.2081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I guess the customer group is Planner, I'm not sure what other groups there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 32. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2270, -0.2213,  0.0341, -0.0672, -0.1847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe it's like scan business cards, clean up CRM, improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Nope, I think I've covered everything I needed to. There isn't anything else to add from my side right now.\n",
            "The intended answer was: Nope, I think I've covered everything I needed to. There isn't anything else to add from my side right now.\n",
            "The predicted answer was: nope, I think I've covered everything I needed to . there isn't anything else to add from my side right now .\n",
            "\n",
            "tensor([[0.1762, 0.0806]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Nope, I think I've covered everything I needed to. There isn't anything else to add at this time.\n",
            "The intended answer was: Nope, I think I've covered everything I needed to. There isn't anything else to add at this time.\n",
            "The predicted answer was: nope, I think I've covered everything I needed to . there isn't anything else to add at this time .\n",
            "\n",
            "tensor([[-0.1016, -0.0999, -0.1243]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 15. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0208, -0.0495]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not really sure about the options, but I think I would say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think that covers everything on my end.\n",
            "The intended answer was: Nope, I think that covers everything on my end.\n",
            "The predicted answer was: nope, i think that covers everything on my end . nope - I think it covers everything . on the end of my end.\n",
            "\n",
            "tensor([[-0.0975, -0.0402,  0.0231,  0.1017,  0.4962,  0.4910]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and JS EcoLine, those are the ones I like.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0642, -0.3985, -0.0276,  0.2636]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3447, 0.1583, 0.4384, 0.3178, 0.3635, 0.1310]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I guess it's a construction company then. That's what I think.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5274, 0.5014, 0.2801, 0.4933, 0.5999, 0.4731, 0.5225, 0.1908]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3340,  0.2324,  0.3755,  0.5128, -0.0030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements and also in double-pulse testing. Both of those seem like pretty interesting options.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3764, 0.1324, 0.4504]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0703, 0.1048, 0.6064, 0.4487, 0.5097]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I'm not really sure. Maybe it's something like BusinessCards, or could it be DataQuality, perhaps it's both.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I don't think I have anything else to add at the moment, but I'll let you know if something comes to mind later.\n",
            "The intended answer was: I don't think I have anything else to add at the moment, but I'll let you know if something comes to mind later.\n",
            "The predicted answer was: I don't think I have anything else to add at the moment . but I'll let you know if something comes to mind later .\n",
            "\n",
            "tensor([[-0.1732, -0.0110, -0.5785, -0.5892]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1819, -0.4605,  0.0124, -0.2593, -0.2172, -0.0062]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a craft enterprise. I'm not really sure about other types though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3336, -0.2017,  0.2788,  0.3989, -0.1781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2441, 0.2765, 0.2675, 0.2396, 0.2823]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5703, 0.4207, 0.5178, 0.2535, 0.3823, 0.3158, 0.2296]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.6471, -0.3625,  0.6629,  0.6537,  0.6544,  0.6647,  0.6507, -0.0324,\n",
            "          0.3448,  0.5300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I am operating in the automotive industry, yeah that sounds right.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4974, -0.4835, -0.4851, -0.3202, -0.1421, -0.2501]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in 100 additive manufacturing, joining systems for large components that's 256 and also, others, I guess.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0050, -0.4670,  0.2401, -0.3600,  0.1009, -0.1144, -0.0444, -0.4965,\n",
            "          0.1540, -0.4382, -0.3433,  0.0286, -0.5348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3323,  0.4600,  0.4338,  0.5596,  0.6372]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5366, 0.4219, 0.2908, 0.1929]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't have any additional notes at the moment, but thanks for asking.\n",
            "The intended answer was: I don't have any additional notes at the moment, but thanks for asking.\n",
            "The predicted answer was: i don't have any additional notes at the moment, but thanks for asking . i'm not sure if there's any other notes in the comments .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2699, 0.2681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know, but I guess No. I'm not sure what the options are.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't think I have anything else to add at this time, thanks for asking though.\n",
            "The intended answer was: No, I don't think I have anything else to add at this time, thanks for asking though.\n",
            "The predicted answer was: no, I don't think I have anything else to add at this time . thanks for asking though, thanks for the question .\n",
            "\n",
            "tensor([[0.2291, 0.5135, 0.3900, 0.4736, 0.5126]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, well, I'm interested in automotive radar target simulation, also noise figure measurements, and then high speed interconnect testing too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3770, 0.3645, 0.1326]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess the next thing I would do is call, seems right to me.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.4865, 0.4732, 0.5135, 0.5470]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I am an existing customer then.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2589,  0.1098, -0.3529, -0.4875, -0.0676, -0.0111]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0027, -0.5340,  0.4640, -0.0236,  0.0997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0674, -0.1223,  0.4635,  0.5711, -0.0094, -0.0072,  0.5351,  0.4058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I'm not sure which CRM system you mean, is it maybe Adito?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Nope, I don't have anything else to add at the moment.\n",
            "The intended answer was: Nope, I don't have anything else to add at the moment.\n",
            "The predicted answer was: nope, I don't have anything else to add at the moment . i'm not sure what's going on in the future .\n",
            "\n",
            "tensor([[-0.3876, -0.0709, -0.3691, -0.0228, -0.0374]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it is probably an existing customer, or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.3141,  0.2214, -0.0467, -0.0197, -0.1817, -0.2242, -0.0457]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4641, 0.4258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I guess I'd rather not receive any emails for marketing purposes, so no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0526,  0.2941,  0.6592,  0.5799,  0.6040]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I'm interested in DataEnrichment, and also I think I like Data Cleansing. Those are the ones that I would pick.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.5715, 0.4718, 0.5570, 0.5388, 0.3956, 0.4633, 0.4857, 0.2919]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, hmm. I'm not sure what the options are, but I guess CAS is the answer then.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2846,  0.2442,  0.4593,  0.4048,  0.5202,  0.3162,  0.2685, -0.1267,\n",
            "          0.3508,  0.2648,  0.4896,  0.3971,  0.1023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I guess I should copy Oliver Eibel, Angelina Haug, Domiki Stein, and also Tim Persson. I think those are all of them.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.5676, -0.4369, -0.4858, -0.5531, -0.4575, -0.5038, -0.5599, -0.6075,\n",
            "         -0.5729, -0.5757, -0.5310, -0.4441, -0.5913]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Marisa Peng', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.4316,  0.2150, -0.1973, -0.3584, -0.5623, -0.3833,  0.1967]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably Planner, I don't really know any other options.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4252, 0.2257, 0.4433]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.3906, 0.3589, 0.3578]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4569,  0.4839,  0.1167,  0.4572,  0.5449,  0.5085,  0.3354, -0.0666]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think maybe it's SAP Sales Cloud, that sounds right for a CRM system to me.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1797, 0.0503, 0.2620]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, hmm, I guess my next step would probably be 'offer'.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I think I've covered everything for now, but let me know if you need anything further.\n",
            "The intended answer was: Okay, I think I've covered everything for now, but let me know if you need anything further.\n",
            "The predicted answer was: let me know if you need anything further . I think I've covered everything for now . here's a little bit of a look at what you need .\n",
            "\n",
            "tensor([[ 0.0335, -0.1489, -0.0213]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2352, -0.2419]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4833, -0.4808,  0.0365, -0.0163, -0.4848]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a supplier. Or maybe a new customer, or even a prospect. Oh, or someone from the press or media. I'm not really sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0135,  0.0829]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, sure, I guess I'd like to get emails about marketing stuff. Yeah, that's fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0458,  0.3318,  0.4987,  0.3750,  0.4055]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think I'm interested in BusinessCards, and also DataEnrichment, and maybe even DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.3766, -0.4037, -0.3857, -0.4086, -0.3830]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1250, -0.0118,  0.5446,  0.4022,  0.3905]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.3293, 0.2214, 0.6539, 0.3535, 0.4181, 0.1162, 0.5713, 0.4537]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system, is that like, maybe, CAS. I am not too sure about any other options though.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4953, 0.1795, 0.5020, 0.2775, 0.3810, 0.3636, 0.1862]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4654, 0.5095]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4766,  0.5124,  0.4589,  0.5561, -0.1935,  0.2900,  0.6808,  0.4434]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. Hmm, I guess I'd say HubSpot. That's the only one I can really think of right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Hmm, I don't think I have anything more to add right now, but thanks for asking!\n",
            "The intended answer was: Hmm, I don't think I have anything more to add right now, but thanks for asking!\n",
            "The predicted answer was: i don't think I have anything more to add right now, but thanks for asking . i'm not sure if I'm going to add more to the list .\n",
            "\n",
            "tensor([[0.3958, 0.4241, 0.4065, 0.3947, 0.4109]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh I think Spanish would work well. I'm not sure what else is possible though.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5289, -0.5319, -0.5163, -0.5375, -0.5168]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4580, 0.0047, 0.4209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1212,  0.2030]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0312, -0.5614, -0.3103,  0.0996]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4736, 0.5622]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4204, 0.5165, 0.4780, 0.5130, 0.6985, 0.5756]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1840, 0.1487, 0.2411, 0.2766]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh gosh, I'm not really sure about the options but I guess I would pick new customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0381, 0.4263, 0.5782, 0.0087, 0.2335]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4239, 0.9331, 0.6796, 0.7024, 0.8768, 0.7308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3975, -0.4255, -0.4383, -0.4535, -0.0239, -0.3411, -0.4301, -0.4066,\n",
            "         -0.4953, -0.4429, -0.4916, -0.4643, -0.4781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess you could copy Joachim Wagner, or maybe Jessica Hanke. Then again, Sandro Kalter seems good, and also Sean Kennin would work.\n",
            "The intended answer was: ['Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Sean Kennin']\n",
            "The predicted answer was: ['Angelina Haug', 'Marisa Peng']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0787, 0.1429, 0.1059]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think either 1 week or 3 weeks would work. It doesn't matter too much to me.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I think I've covered everything, so there's nothing more to add on my end.\n",
            "The intended answer was: Okay, I think I've covered everything, so there's nothing more to add on my end.\n",
            "The predicted answer was: I think I've covered everything, so there's nothing more to add on my end . here's a little bit of a look at my end.\n",
            "\n",
            "tensor([[ 0.3846,  0.3053,  0.5001, -0.3524,  0.5450,  0.0698,  0.6222,  0.4301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, a CRM system? Hmm, I'd probably say Microsoft Dynamics. I've heard of it.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4732, 0.5151]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, well, if you need to process data, I guess, yes, that's fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think I'm all set for now, nothing else to add at the moment.\n",
            "The intended answer was: I think I'm all set for now, nothing else to add at the moment.\n",
            "The predicted answer was: i think I'm all set for now, nothing else to add at the moment . i'm set for the moment, no more to add .\n",
            "\n",
            "tensor([[-0.5501, -0.4913, -0.4971, -0.3332, -0.2621, -0.1794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they are interested in 100 Additive Manufacturing, also 234 Assembly Systems, and maybe 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4440, -0.4510, -0.4159, -0.4467, -0.4428]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I suppose English is the language that would work best.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think that's everything for now, I don't have any other notes or information to add at this time.\n",
            "The intended answer was: I think that's everything for now, I don't have any other notes or information to add at this time.\n",
            "The predicted answer was: i think that's everything for now, I don't have any other notes or information to add at this time . i'm not sure if there's any other information or notes .\n",
            "\n",
            "tensor([[0.2236, 0.3403, 0.1118, 0.0036, 0.0397, 0.0222, 0.0072]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0049, -0.2640,  0.0307, -0.1920, -0.0994]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1443, -0.2942,  0.1777,  0.0126]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction. I'd say, like, I am very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3228, -0.2909, -0.3365]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.0877,  0.1621]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5060, 0.5004, 0.2615, 0.0901, 0.6082, 0.5295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well I'm mostly into Notion, and also the JS EcoLine is kinda interesting to me.\n",
            "The intended answer was: ['Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3256, 0.3123, 0.3445, 0.3116, 0.3167, 0.2825, 0.3319, 0.1767, 0.2712,\n",
            "         0.3327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0296, -0.0743,  0.2829,  0.0488]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1751, -0.0416, -0.1041, -0.3012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess it's either email or we do nothing at all, like no action. I'm not really sure which is it.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1858, 0.2517, 0.5561, 0.4842, 0.5397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.5842, 0.4381, 0.3211, 0.1678]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0831, -0.4173, -0.0187, -0.0024, -0.0555, -0.3376]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0818, 0.0740, 0.3139, 0.3376, 0.3182, 0.0369, 0.4396, 0.2417, 0.5389,\n",
            "         0.6388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I'd say I operate in the Industrial sector. Yeah, that seems right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4164, 0.3366, 0.3736]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would say I'll call then.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2245, 0.1084]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1857, -0.2191, -0.1460, -0.2489, -0.1695, -0.2328]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1560, -0.1821,  0.1752, -0.1367, -0.1011]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6107, -0.5473, -0.5800, -0.4991, -0.5815, -0.5974, -0.3472]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4408, 0.2021, 0.4570, 0.2421, 0.3317, 0.1655, 0.0363]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, I think it's Architect, yeah that sounds like it.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1794,  0.1760, -0.4825, -0.4849]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3369, 0.2780, 0.3612, 0.4530, 0.2471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements and also high-speed interconnect testing. Both seem really important to me right now.\n",
            "The intended answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6992, 0.7284, 0.3456, 0.5443, 0.2797, 0.3031]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1226,  0.2411, -0.4388,  0.0120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I really don't know what follow up is planned, sorry.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4378, -0.4138, -0.4137, -0.3228, -0.4189, -0.3522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.3047,  0.3035, -0.2380,  0.0556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess either I could schedule a visit or there would be no action at all, either of those two.\n",
            "The intended answer was: ['Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0501, -0.2252,  0.0522,  0.3071]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2894, 0.1025, 0.2463, 0.3963]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure but maybe unsatisfied is the answer, I guess.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Nope, I don't have any other notes to add at the moment. Thanks for asking!\n",
            "The intended answer was: Nope, I don't have any other notes to add at the moment. Thanks for asking!\n",
            "The predicted answer was: nope, I don't have any other notes to add at the moment . thanks for asking! I'd love to hear from you .\n",
            "\n",
            "tensor([[0.0588, 0.2421, 0.2105]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.6927, 0.7239, 0.4820, 0.4314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7468, 0.6581, 0.6850, 0.5873, 0.6510]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I think I am interested in automotive radar target simulation. Also I like noise figure measurements. Display port debugging and compliance sounds interesting too and so does high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3641, 0.2301, 0.4274, 0.2772, 0.3141, 0.4051]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it must be a craft enterprise. That sounds like the type of thing it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5569, 0.5640, 0.2691, 0.3630]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, well, I guess it's either a phone call or maybe no action at all, not sure which one it will be though.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7206, 0.6350, 0.2590, 0.6284, 0.7196, 0.7223, 0.7020, 0.3413]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4553, 0.5760, 0.6650, 0.5249, 0.5860]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0074, -0.0533,  0.0452, -0.2642, -0.1391,  0.0284,  0.0566, -0.2828]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3596,  0.2633,  0.1417, -0.2310, -0.1825]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2772, -0.2902,  0.5590,  0.4626,  0.5259,  0.5663, -0.2036]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what groups there are but I think it's probably a wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3580, -0.4301, -0.0240, -0.1778, -0.1319, -0.4497]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3783, -0.2914]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, sure. Yeah, I would like to get emails about that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0811,  0.2064,  0.1856, -0.0549,  0.1111,  0.2001]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, that sounds right.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4483, -0.0194, -0.4471, -0.4246, -0.4193, -0.4580, -0.4276, -0.1274,\n",
            "          0.0564, -0.1162]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5510, -0.5835, -0.5435]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1893, 0.2279, 0.0932, 0.2907, 0.1289]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question. I'm honestly not sure of the exact number. I think we have somewhere around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1978, -0.1752, -0.2049, -0.1970, -0.1465]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3076,  0.0058,  0.1388, -0.2339, -0.4644]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe it's none.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Hmm, I don't think I have anything else to add at the moment. But thanks for asking!\n",
            "The intended answer was: Hmm, I don't think I have anything else to add at the moment. But thanks for asking!\n",
            "The predicted answer was: i don't think I have anything else to add at the moment . thanks for asking! thanks for the question . if you have any other questions, please contact me .\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think I've covered everything I wanted to share. I don't have any further notes at the moment.\n",
            "The intended answer was: No, I think I've covered everything I wanted to share. I don't have any further notes at the moment.\n",
            "The predicted answer was: no, I think I've covered everything I wanted to share . I don't have any further notes at the moment . if you're interested in sharing your thoughts, please contact me .\n",
            "\n",
            "tensor([[-0.5725, -0.5693, -0.5774, -0.4229, -0.5949, -0.3407]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.5348, 0.5972, 0.4617, 0.5928, 0.5468, 0.4784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay so I'm interested in MY-SYSTEM, Notion, JS EcoLine and also AKW100. I think those are my options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.4247, -0.1200,  0.5612, -0.1227,  0.3119]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, my product interests are DataEnrichment, VisitReport, Data Cleansing and DataQuality, I think. Those sound like my sort of thing.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7029, 0.7284, 0.6613, 0.7397, 0.6720, 0.5852, 0.3746]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0434, -0.1846,  0.0928, -0.0600,  0.0495, -0.1297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a production company, yeah. I believe that's what it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0760, 0.3396]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1730, -0.2971,  0.1549,  0.0396,  0.0306,  0.1522,  0.1232,  0.1821,\n",
            "          0.2520,  0.2748]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4562,  0.0989, -0.2035, -0.0804,  0.0977,  0.0644]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think I've covered everything. There isn't anything else to add at this time.\n",
            "The intended answer was: No, I think I've covered everything. There isn't anything else to add at this time.\n",
            "The predicted answer was: no, I think I've covered everything . there isn't anything else to add at this time . no, there's nothing to add .\n",
            "\n",
            "tensor([[ 0.0369,  0.0668, -0.3778,  0.2486,  0.2388,  0.2850,  0.2137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5712, -0.5621]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1569, 0.3403, 0.2006, 0.4637, 0.4742]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1005,  0.1259,  0.3024, -0.0812]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I'm not really sure what's next, maybe an Email, or we could try a Phone call, or even Schedule a Visit if needed. Oh, or maybe No action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4982, 0.2714, 0.1651, 0.3148]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, I guess I would say I'm satisfied with the service.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think that covers everything for now; I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything for now; I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything for now . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[0.3997, 0.4542, 0.4357, 0.3863, 0.4373]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2991,  0.3619, -0.0688,  0.2713,  0.0264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5043, 0.4439, 0.3421, 0.4142, 0.5245, 0.6557]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0507, -0.0979, -0.1345]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't think I have anything else to add right now, but I appreciate the opportunity to share.\n",
            "The intended answer was: I don't think I have anything else to add right now, but I appreciate the opportunity to share.\n",
            "The predicted answer was: i don't think I have anything else to add right now, but I appreciate the opportunity to share . if you have any questions, please contact me at e-mail .\n",
            "\n",
            "tensor([[-0.5076, -0.4947, -0.3981, -0.1002, -0.4872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be an existing customer, maybe a supplier, or it could be someone from the press or media. Perhaps they're even a competitor, I don't really know.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0277,  0.4176,  0.7864,  0.4912,  0.6238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.3162, -0.3613, -0.3264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.4724, 0.5329, 0.4947, 0.5180]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, well I guess I'd say I am a new customer, I think.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0349, -0.2940, -0.1841,  0.3491, -0.0300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1913, 0.1325, 0.3924, 0.4365, 0.4486]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1907, 0.5661, 0.5102, 0.5207, 0.5038]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1511,  0.2881,  0.0365,  0.0507,  0.3222]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either an existing customer or a competitor, maybe an existing customer.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3652, -0.3821,  0.3358]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.3762, -0.2760, -0.3992, -0.3182, -0.3945, -0.4372, -0.0049]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh geez, well I would say it's about 3 people, maybe a bit more. That seems right for a team.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3202, -0.4314, -0.3143,  0.0852, -0.2594, -0.3211]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0789, 0.0927, 0.1011, 0.0848, 0.0803]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4897, 0.3244, 0.0250, 0.4698, 0.5214, 0.4158, 0.4297, 0.2934]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. I guess I'd go with Close.io, I think that's what it's called.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4648, 0.4426, 0.3071]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'm not sure what options there are but I think I'll call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.7269, 0.6798]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we follow up around January 22nd of 2025? That should work nicely.\n",
            "The intended answer was: 2025-01-22\n",
            "The predicted answer was: 22nd of 2025\n",
            "\n",
            "tensor([[0.4727, 0.4187, 0.2122, 0.3787, 0.5109, 0.3779, 0.4020, 0.1772]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't know all the options but I guess it's Close.io. I've heard good things about it.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.4412, -0.3752,  0.2343,  0.3873]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction? I'd say, I guess, I'm satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4120, -0.2362]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I think yes, I'd like to receive emails.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0089,  0.1931,  0.0257,  0.2458,  0.3893,  0.2120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, AKW100, and AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1929, 0.3717, 0.2534, 0.2720, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, product interests, hmm. Well I'd say BusinessCards, and maybe DataEnrichment. Then possibly Data Cleansing. Oh, and definitely DataQuality, those are what I'm thinking.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5495, 0.2975, 0.3881, 0.0356, 0.1913, 0.0240, 0.2391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess it would be Wholesaler. That seems like the best fit.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4454,  0.2104]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3639, 0.2812]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 19. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3208, -0.4425]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think that covers everything on my end, so no additional notes from me.\n",
            "The intended answer was: I think that covers everything on my end, so no additional notes from me.\n",
            "The predicted answer was: i think that covers everything on my end, so no additional notes from me . if you have any questions, please contact me at cnn.com.\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think that covers everything for now. I don't have any additional notes to share.\n",
            "The intended answer was: Nope, I think that covers everything for now. I don't have any additional notes to share.\n",
            "The predicted answer was: nope, I think that covers everything for now . I don't have any additional notes to share . i'm not sure if I'm going to share any more notes .\n",
            "\n",
            "tensor([[0.3840, 0.3367, 0.3256, 0.3214]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh I guess it would be existing customer, if that's the only option. I mean, is that what you're asking?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3381, -0.5856, -0.5730, -0.4397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1904, -0.0242,  0.0231,  0.0179, -0.1209, -0.0813, -0.0226,  0.0652,\n",
            "          0.0886, -0.1074]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0616, -0.1619, -0.4039,  0.2131, -0.1849]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not sure. Is it something like 25 maybe? I'd guess somewhere in that range, but I don't really know.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5648, 0.1514, 0.5773, 0.5556, 0.5673, 0.5271, 0.5613, 0.2862, 0.2933,\n",
            "         0.4141]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2667,  0.2775, -0.2980, -0.5054]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type. I guess that would be Partner then. Yeah, it makes sense.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3683, -0.0989,  0.3904, -0.2993, -0.3339]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I would look at \"scan business cards\", and maybe also \"clean up CRM\". I'm also thinking of \"extract data from emails\". I don't really know what else.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1338,  0.1856,  0.3192,  0.1309,  0.0435]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in DataEnrichment, also VisitReport, and Data Cleansing, those seem like good options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3869, -0.1191,  0.5398,  0.5077,  0.4706,  0.4988,  0.5697, -0.1705,\n",
            "          0.2376,  0.5437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3648, -0.0766,  0.2695,  0.4858,  0.4475,  0.4626, -0.1400]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh I think it would be distributor, that sounds right for this.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3960, -0.3395]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I don't think I have anything else to add at the moment. Thanks!\n",
            "The intended answer was: I don't think I have anything else to add at the moment. Thanks!\n",
            "The predicted answer was: i don't think I have anything else to add at the moment . thanks for the comments . I'm looking forward to seeing you soon .\n",
            "\n",
            "tensor([[ 0.3264, -0.1241,  0.2097,  0.4600,  0.3460]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'd be interested in noise figure measurements, double-pulse testing and high-speed interconnect testing, those seem like good things to explore.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1927, 0.5559, 0.7471, 0.2848, 0.4302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think it might be DataEnrichment and also maybe DataQuality. Those seem like possible areas that could be interesting.\n",
            "The intended answer was: ['DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 22. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0042,  0.0807,  0.1393,  0.0356, -0.0296,  0.0822]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, I don't think I have anything more to add at this time, thanks.\n",
            "The intended answer was: Okay, I don't think I have anything more to add at this time, thanks.\n",
            "The predicted answer was: i don't think I have anything more to add at this time, thanks . i'm not sure if I'm going to add anything more .\n",
            "\n",
            "tensor([[0.4162, 0.3183, 0.5078, 0.6611, 0.7924, 0.7433, 0.3584, 0.2741]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I think it's probably SAP Sales Cloud then. I'm not really sure about other ones.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0367,  0.2220]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yeah I would like to get emails about marketing information.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.2051, -0.1658, -0.3157,  0.0090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5889, 0.6296, 0.3439, 0.6411, 0.7372, 0.6627, 0.3580, 0.2255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'd say it's probably SAP Sales Cloud. That's the only one I know, to be honest.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6835, 0.0216, 0.4657, 0.6550, 0.6086]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I guess I search for a solution to extract data from emails, or maybe to improve CRM data quality, or capture trade fair contacts, one of those.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0957, -0.3837, -0.4108,  0.2566]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3659,  0.0408, -0.3868,  0.4221,  0.2207,  0.5061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not really sure, maybe it's 200 Automation. That sounds kind of interesting.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.5928, -0.5328,  0.0226, -0.1549, -0.5179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure about all the types, but I think it must be Competitor.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5940, -0.6300, -0.6430, -0.5963, -0.5364, -0.3783]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure but I'd say they're looking into 300 Advanced Manufacturing, and then maybe also 234 Assembly Systems and, uh, 256 Joining Systems for large components.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, I don't think I have anything else to add right now, but thanks for checking.\n",
            "The intended answer was: Hmm, I don't think I have anything else to add right now, but thanks for checking.\n",
            "The predicted answer was: i don't think I have anything else to add right now, but thanks for checking . i'm not sure if I'm adding anything else .\n",
            "\n",
            "tensor([[0.3373, 0.4165, 0.3249, 0.3323, 0.3671]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2054,  0.4767,  0.6601,  0.5873,  0.6721]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay so, I think my interests are DataEnrichment, you know adding stuff, VisitReport like what happened, Data Cleansing to clean up and also DataQuality so good data.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.0722, -0.1805,  0.1046,  0.1036,  0.0943,  0.1975, -0.2032]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4854, -0.3877, -0.3289, -0.3212, -0.2817, -0.3883, -0.3275, -0.3690,\n",
            "         -0.3903, -0.3670, -0.2731, -0.4134, -0.4650]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd say copy Erik Schneider, Oliver Eibel, Johannes Wagner, Jessica Hanke, Sandro Kalter and Domiki Stein in the follow up. They are all involved I guess.\n",
            "The intended answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5143, 0.4701, 0.7516, 0.5384, 0.6536]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh gosh, I'd say I'm interested in BusinessCards, DataEnrichment, and also Data Cleansing plus DataQuality. I think that's about right.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0444, -0.0443,  0.1393, -0.0038,  0.2925, -0.1596]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0250,  0.3179, -0.0183,  0.1024, -0.1172, -0.2997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in Notion, I've heard it's pretty good.\n",
            "The intended answer was: ['Notion']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7818, 0.7794, 0.5377, 0.5186, 0.7240, 0.5961]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3514, 0.5219, 0.3633, 0.5690, 0.5523, 0.4978]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5932, 0.5009, 0.3296, 0.7221, 0.3512]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2343, -0.2771, -0.1458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh I guess the next step is a meeting. I'm not sure what else it would be.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.4123, 0.1049, 0.6041, 0.5998, 0.5450, 0.5200, 0.5810, 0.2567, 0.3136,\n",
            "         0.3610]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm in Aerospace. That sounds right for what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3319, 0.1350]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1280, 0.3141, 0.5008, 0.5846, 0.5001]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.3490, -0.3913, -0.1426, -0.2274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3612, 0.5072, 0.2482, 0.1240, 0.5387]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2052, 0.2803, 0.2539, 0.3199]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5036, 0.6404, 0.3533, 0.6755, 0.7499, 0.5649, 0.5265, 0.5424]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess Salesforce is what I would go with.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2674, -0.4073]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3726,  0.1437, -0.3408,  0.4298,  0.4575,  0.3728,  0.3903,  0.1849]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think maybe it's Close.io? I'm really not sure though.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: Okay, let me see... hmm, nope, I think I've covered everything for now, but thanks for checking.\n",
            "The intended answer was: Okay, let me see... hmm, nope, I think I've covered everything for now, but thanks for checking.\n",
            "The predicted answer was: hmm, nope, I think I've covered everything for now, but thanks for checking . thanks for your comment .\n",
            "\n",
            "tensor([[0.4494, 0.2120, 0.0916, 0.2341, 0.2377]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I really don't know the exact size. Hmm, is it like larger than 2000? I'm guessing that might be right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3321, -0.1647, -0.1017, -0.1628,  0.3456, -0.1081,  0.0884, -0.4454,\n",
            "         -0.3122, -0.1234, -0.1805,  0.0607, -0.2519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess we should copy Marisa Peng, and also Johannes Wagner. And then Jessica Hanke too. We also should include Sean Kennin, plus maybe Tim Persson.\n",
            "The intended answer was: ['Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Johannes Wagner', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4069, -0.4575,  0.0013, -0.3374, -0.2766, -0.4446]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4145,  0.2821,  0.1319,  0.2514,  0.2359]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.5995, 0.6098, 0.5784, 0.4231, 0.4589]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh gosh, I really don't know. I'm just gonna say display port debugging and compliance.\n",
            "The intended answer was: ['Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6661, 0.6818, 0.2213, 0.6447]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.5191, -0.5610, -0.5285, -0.5260, -0.5395]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2118, 0.4905, 0.4963, 0.4159, 0.2029, 0.3575, 0.2771, 0.2538]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I think it's probably CAS. I really don't know much about those.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4615, -0.3724, -0.4124, -0.3764, -0.4935, -0.5212, -0.4752]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the team is around 35 people, give or take a few, but I am not really sure.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3293,  0.5504,  0.0712, -0.3729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5602, 0.5081, 0.3567]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1201,  0.0246,  0.3286,  0.3209,  0.4319]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1489,  0.0108,  0.0565]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, well maybe they'd want a follow up in, uh, like, 2 weeks? I'm not sure if it could be 1 week or maybe even 3 weeks instead.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think I've covered everything for now, thanks! I don't have any additional notes or information to share at the moment.\n",
            "The intended answer was: No, I think I've covered everything for now, thanks! I don't have any additional notes or information to share at the moment.\n",
            "The predicted answer was: no, I think I've covered everything for now, thanks! I don't have any additional notes or information to share at the moment .\n",
            "\n",
            "tensor([[ 0.0826, -0.0206, -0.0854, -0.1820,  0.0911,  0.1565,  0.2073,  0.0759,\n",
            "          0.3465,  0.0626, -0.2269,  0.0936, -0.1055]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Marisa Peng', 'Johannes Wagner', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4822, -0.4486, -0.5223]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1625, -0.4547,  0.1567, -0.2743, -0.4611]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, I'm not sure about the contact type, maybe it's a new customer or possibly press media, I can't say.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3866, -0.5010, -0.4925, -0.4039, -0.4505]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say that solution might be to clean up the CRM. Or maybe, improve CRM data quality? Then again, it could be capturing trade fair contacts too. I'm not really sure which of those it is.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1636, 0.1293, 0.0758]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3384, -0.5086,  0.0603,  0.3079]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3174, 0.3153, 0.1636, 0.1861, 0.3679]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5227, 0.6063, 0.9135, 0.5031, 0.7084]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3003, -0.2912,  0.4257,  0.0449,  0.1900, -0.4735,  0.1324,  0.1608]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6667, 0.6613, 0.7068, 0.1986, 0.4575]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Hmm, I think I've covered everything for now. I don't have any additional notes to add.\n",
            "The intended answer was: Hmm, I think I've covered everything for now. I don't have any additional notes to add.\n",
            "The predicted answer was: I think I've covered everything for now . I don't have any additional notes to add . i'm not sure if I'll add any more notes .\n",
            "\n",
            "tensor([[0.5470, 0.2526, 0.3737, 0.1555, 0.2379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in things like automotive radar target simulation. Also maybe noise figure measurements and double pulse testing. And also I'd say display port debugging and compliance as well as high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0885, -0.0720, -0.1236, -0.0617,  0.0864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3683, -0.4237]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2833, -0.0398, -0.4298, -0.3335]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2773,  0.1436,  0.2854,  0.4235,  0.1665,  0.1573, -0.0331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0672, -0.0473,  0.3164,  0.3887]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2294,  0.1838, -0.0491,  0.2862,  0.1396,  0.0849,  0.3104]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would guess maybe 8 people would be on the trade fair team, somewhere around there.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6482, 0.7591, 0.6835, 0.5860, 0.6775, 0.3849, 0.5035, 0.4707]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Pipedrive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I don't have anything else to add right now, but thanks for asking.\n",
            "The intended answer was: I don't have anything else to add right now, but thanks for asking.\n",
            "The predicted answer was: i don't have anything else to add right now, but thanks for asking . i'm not sure what to add, but thank you for asking.\n",
            "\n",
            "tensor([[0.8159, 0.4221, 0.6474, 0.3709, 0.2643]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I am interested in automotive radar target simulation and also display port debugging and compliance. Those seem like interesting things to learn about.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1925, -0.3515, -0.0886, -0.3130, -0.1947, -0.1473]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3466, 0.3410, 0.4161, 0.3980, 0.3634, 0.4246, 0.3262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0351, -0.0150,  0.0801, -0.1424,  0.0852,  0.0661]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think I've covered everything for now, but thanks for asking!\n",
            "The intended answer was: I think I've covered everything for now, but thanks for asking!\n",
            "The predicted answer was: i think I've covered everything for now, but thanks for asking . i'm not sure if you're a fan of this blog .\n",
            "\n",
            "tensor([[0.4470, 0.4927, 0.2536]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.6138,  0.1306,  0.5850,  0.5516,  0.5719,  0.5993,  0.5786,  0.3046,\n",
            "          0.2354, -0.1118]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1215, 0.2283, 0.2540, 0.1150, 0.2541]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4443, 0.4814, 0.5115]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2962, -0.0380, -0.0667,  0.1262, -0.0125]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5265, 0.5354, 0.3995, 0.5112, 0.6321, 0.5762]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4859, -0.4779, -0.4354, -0.5012, -0.4892, -0.4580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6078, 0.5149, 0.7030, 0.6806, 0.6409, 0.6234, 0.6758, 0.4050, 0.6224,\n",
            "         0.5205]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I work in Computers and Networks. It sounds like that is where I belong.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1209, -0.0601, -0.1133,  0.1911, -0.5459]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3651, 0.3911, 0.3603, 0.3830, 0.4182]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2839, -0.2812,  0.3252, -0.1245, -0.0707, -0.3750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I guess it's a construction company. That sounds right to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1424, -0.1395, -0.5337, -0.5361]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0584, -0.4952,  0.1368, -0.0848, -0.0586, -0.3921]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3341,  0.2846,  0.1038,  0.3698, -0.4634]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I think I am interested in high-speed interconnect testing, if that's an option.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6086, 0.1549, 0.3279, 0.2993, 0.5758]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I don't see any options, so I guess it's an empty set then.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1923, 0.3676, 0.5165, 0.5671, 0.5229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm interested in BusinessCards, and also DataEnrichment, plus I like DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2164, 0.4157, 0.1452, 0.3861, 0.3142, 0.1007]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4426, -0.4206, -0.4616, -0.4792, -0.4303, -0.3351, -0.4696, -0.4337,\n",
            "         -0.4503, -0.4492, -0.4825, -0.4112, -0.4705]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess copy Stephan Maier, Joachim Wagner, Marisa Peng, Jessica Hanke, and also Sandro Kalter. That sounds like it would get to the right people.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Marisa Peng', 'Jessica Hanke', 'Sandro Kalter']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.4354, -0.0338,  0.4249,  0.7021, -0.3721]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, also noise figure measurements. And I find high-speed interconnect testing very interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3104, 0.4590, 0.4035, 0.5525, 0.6164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5809, 0.4498, 0.4855, 0.6591, 0.4553]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I guess I'm interested in noise figure measurements and also high-speed interconnect testing, those sound important.\n",
            "The intended answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think I've covered everything, so no additional notes from me at the moment.\n",
            "The intended answer was: I think I've covered everything, so no additional notes from me at the moment.\n",
            "The predicted answer was: I think I've covered everything, so no additional notes from me at the moment . i think I have covered everything - so no further notes .\n",
            "\n",
            "tensor([[0.0558, 0.2534]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4566, 0.5364, 0.2653, 0.3277, 0.4730]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5359, -0.4517, -0.5504, -0.1394, -0.5404, -0.4976]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3458, -0.3435, -0.4048, -0.3234]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh gosh, I'm not sure. It looks like a phone call or no action is the plan. I'm thinking no action is it.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4049, -0.4118, -0.2292, -0.2188, -0.2465, -0.4301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2727, -0.3585, -0.3783, -0.1798, -0.3257, -0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4196, 0.2104, 0.3951, 0.1787, 0.2979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'm interested in automotive radar target simulation, noise figure measurements, double-pulse testing, display port debugging and compliance, and high-speed interconnect testing. Those all sound quite fascinating to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4893, -0.4641, -0.5890]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 3 weeks sounds good, that's when I'd like a follow up.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1997, -0.0808]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1842, -0.0258]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4345, -0.4754,  0.0864]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4438, -0.0712,  0.0865,  0.2924]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0334, -0.0097,  0.1940,  0.4453,  0.4289]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh geez I don't know. I think it might be VisitReport.\n",
            "The intended answer was: ['VisitReport']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1493, -0.1565,  0.1232,  0.2592, -0.1016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2867, 0.3200, 0.7122, 0.4873, 0.4840]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for Scan business cards, also to Clean up CRM, and maybe to Extract data from emails. I would also improve CRM data quality and try to Capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0623, -0.0304, -0.4280,  0.1638]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3253, -0.3674, -0.2165, -0.3106, -0.0646, -0.3803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4602, 0.3695, 0.0835, 0.4239, 0.2744]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2715,  0.4968,  0.5350,  0.4875,  0.4802]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4779,  0.1961,  0.2360,  0.6259, -0.0951]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and double-pulse testing. Those seem like the things I'd like to know more about.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4529, 0.3993, 0.4833, 0.4923, 0.5097, 0.3909, 0.5077, 0.4165, 0.4405,\n",
            "         0.0532]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, um, I think I'm in physical security, I guess.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1732, -0.1643,  0.1783]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh I guess the next step would be meeting, seems right.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0329, -0.0043, -0.2132, -0.1877]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I don't know of any planned action right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1604, -0.2047,  0.3070,  0.0580,  0.1619, -0.2777]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it must be a construction company. That makes the most sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0580, 0.3309, 0.2246, 0.2244, 0.1660, 0.0426, 0.2592, 0.4188, 0.3425,\n",
            "         0.3819]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6985, 0.3254, 0.2476, 0.7588, 0.7398, 0.6006, 0.7838, 0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I think a CRM system? Hmm, I guess maybe Pipedrive would be it.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0260,  0.1490]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.4241, -0.4517, -0.4531, -0.4692, -0.2843, -0.3992]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I believe they're interested in 300 Advanced Manufacturing, 234 Assembly Systems, or maybe 256 Joining Systems for large components. Could also be others, you know.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think I've covered everything for now, so no additional notes from me.\n",
            "The intended answer was: I think I've covered everything for now, so no additional notes from me.\n",
            "The predicted answer was: i think I've covered everything for now, so no additional notes from me . i'm not sure if I'm going to write a review .\n",
            "\n",
            "tensor([[-0.0996,  0.2013,  0.2109]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'm not sure, maybe it is best after 1 week? I guess that makes sense to me.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.5784, 0.5632, 0.5739, 0.5576, 0.5784]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess Italian is the language we should use then.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0368, -0.1480,  0.5147,  0.1306,  0.0586, -0.0254,  0.2469,  0.5037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not sure which CRM system that is. Maybe CAS, I don't know, I'd choose that.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5602, -0.5128, -0.5785, -0.5188, -0.5891, -0.5937, -0.4244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1319, -0.3320, -0.2439, -0.3601,  0.1394, -0.0061, -0.3197, -0.5275,\n",
            "          0.0496, -0.4150, -0.2877,  0.0499, -0.4805]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2356, -0.3589,  0.1381,  0.1284, -0.3174]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh I'm not sure, is it like a new customer or a competitor maybe, I really have no clue.\n",
            "The intended answer was: ['New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3392, -0.2194]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, hmm, yes I guess I would, sure.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4933, 0.4878, 0.4926, 0.4924, 0.5101]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess Italian is the language I'd like then.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0339,  0.1419, -0.0747,  0.4590,  0.1017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2529, -0.1133]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Yeah, I would like to receive that marketing information through e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I don't have any other notes at this time, but thanks for asking.\n",
            "The intended answer was: I don't have any other notes at this time, but thanks for asking.\n",
            "The predicted answer was: i don't have any other notes at this time, but thanks for asking . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[ 0.1035,  0.0806,  0.1672, -0.0573,  0.0743, -0.0155]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I guess it's an education sector company then, that makes sense.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3125, 0.0187, 0.1656, 0.3747]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm I think I would have to say New customer then since thats the only one available as an option I see.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0670, -0.0828, -0.1745,  0.2926,  0.2946]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.4124, 0.4030, 0.4250, 0.4482, 0.4318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh I'd say Italian sounds good to me.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0335, -0.1479, -0.1945,  0.2553, -0.1253]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, well it could be an existing customer, a supplier, or a new customer or prospect. I think maybe it's a new customer then.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4584, 0.2840, 0.3654]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.0193,  0.3490,  0.3369,  0.4594,  0.1687,  0.2670,  0.2970]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I guess it would be somewhere around 3 people. I'm not sure really.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2943, -0.2884,  0.2271, -0.1576]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5200, 0.5342, 0.2008, 0.4781]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2695, -0.3422,  0.1216,  0.0244, -0.2932]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: Nope, I think that covers everything for now. There isn't anything else I'd like to add at the moment.\n",
            "The intended answer was: Nope, I think that covers everything for now. There isn't anything else I'd like to add at the moment.\n",
            "The predicted answer was: nope, I think that covers everything for now . there isn't anything else I'd like to add at the moment .\n",
            "\n",
            "tensor([[-0.4146, -0.4144, -0.4345, -0.4716, -0.2890, -0.3698, -0.2840, -0.1584,\n",
            "         -0.3884, -0.3275, -0.4503, -0.4238, -0.4426]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I'm not sure, maybe Johannes Wagner, or perhaps Jessica Hanke. It could be Sandro Kalter too, or maybe Jens Roschmann. I think Sean Kennin is an option.\n",
            "The intended answer was: ['Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5268, 0.5292, 0.3936, 0.4229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2597, 0.3046, 0.2659]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: I think that covers everything for now, I don't have any additional notes at this time.\n",
            "The intended answer was: I think that covers everything for now, I don't have any additional notes at this time.\n",
            "The predicted answer was: i think that covers everything for now, I don't have any additional notes at this time . it's a good thing to keep in mind that if you're reading this, you'll find out more about it .\n",
            "\n",
            "tensor([[ 0.2001,  0.3733,  0.2319,  0.1225, -0.1115, -0.3467, -0.3838]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1154, -0.0156, -0.2780, -0.2937, -0.2574]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1502,  0.1570, -0.2488, -0.2119]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3343, -0.3439, -0.0171, -0.0606,  0.0387]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything on my end. I don't have any additional notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything on my end. I don't have any additional notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything on my end . I don't have any additional notes to add at this time . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[-0.4481, -0.5006, -0.5937, -0.5014, -0.5478, -0.5666, -0.3922]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, gosh, I really don't know much about those things but maybe the average size of a trade fair team is about 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2633, 0.1751, 0.3869, 0.5195, 0.2468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4390, 0.1764, 0.5018, 0.4336, 0.4368, 0.3501]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I think it must be a craft enterprise then.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5275, 0.4864]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6084, -0.6058, -0.5679, -0.5781]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I think the follow up will be either an email or a phone call, seems about right.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3283, -0.3851, -0.4793, -0.3460, -0.3993, -0.4353, -0.3996]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2646, -0.1055, -0.2893, -0.1941, -0.4259, -0.5538, -0.3144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd guess the team is probably between 31 and 40 people, I don't know for sure though.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5832, -0.5499, -0.3005,  0.1705]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1628,  0.0777]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3407, -0.2310, -0.3592, -0.3017, -0.3966]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3907, -0.4832, -0.3226, -0.4331, -0.3750, -0.4423]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3392, 0.2558]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 29. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5120, 0.5678, 0.5027, 0.5151, 0.5170]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: I think that's all I have for now, but I'll let you know if anything else comes to mind.\n",
            "The intended answer was: I think that's all I have for now, but I'll let you know if anything else comes to mind.\n",
            "The predicted answer was: i think that's all I have for now, but I'll let you know if anything else comes to mind . i'm not sure what's going on in the future .\n",
            "\n",
            "tensor([[-0.1714,  0.1119, -0.0102,  0.2080, -0.1414, -0.1781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1261,  0.0006, -0.0174,  0.0170, -0.1010, -0.1139, -0.1017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3801, 0.3635, 0.5209]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4606, 0.4273, 0.4188, 0.2980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.5564,  0.4603,  0.4829, -0.0417,  0.3870]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.4648,  0.4615,  0.2496,  0.0112,  0.0987, -0.0290,  0.2471]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.6277, -0.3371]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1035, -0.0065,  0.2771,  0.2763,  0.0721]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4021, 0.3798, 0.3953, 0.5956, 0.6832]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2210, -0.1880, -0.4577, -0.1556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1490, -0.0118]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3090,  0.4585, -0.1733, -0.1456, -0.2025, -0.2806, -0.1402,  0.4038,\n",
            "          0.5573,  0.5628]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, hmm. I guess I'm in Network Operators and Infrastructure. I didn't really pick.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4843, -0.5900, -0.4448, -0.7025, -0.6163, -0.5994, -0.5518,  0.3512]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4042, -0.0014,  0.1560,  0.3237]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0683,  0.1214,  0.0374, -0.0043,  0.1864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I think my product interests are BusinessCards, because those seem useful, and also VisitReport which is interesting, plus Data Cleansing, and finally DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5576, 0.6142, 0.4482, 0.4058, 0.3835]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0575, -0.3760,  0.1447,  0.1913, -0.3479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3402, 0.4705, 0.2206, 0.2214, 0.5041]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0697,  0.3461,  0.3166,  0.3969,  0.5451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4014, 0.5039, 0.3160, 0.1703, 0.1334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, um, well I guess I'd be interested in Double-Pulse Testing and Display port debugging and compliance, those sound like things I could use.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0793,  0.1844,  0.1241,  0.1560,  0.1201, -0.0281,  0.1520,  0.1709,\n",
            "          0.0739, -0.3022]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5134, -0.3659]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1461,  0.1592,  0.1796, -0.2993, -0.3410]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I would probably try to scan business cards, or maybe extract data from emails. Possibly also, capture trade fair contacts? I'm not sure.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1618,  0.3344, -0.2260,  0.0042,  0.3116]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I guess it would be an existing customer then, that sounds right to me.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 34. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2048,  0.0190, -0.1745, -0.0665, -0.2476, -0.2646]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in AKW100. I'm not really sure what else is available.\n",
            "The intended answer was: ['AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't believe so; I think I've covered everything.  Unless there's something specific you'd like to know?\n",
            "The intended answer was: No, I don't believe so; I think I've covered everything.  Unless there's something specific you'd like to know?\n",
            "The predicted answer was: no, I don't believe so; I think I've covered everything . unless there's something specific you'd like to know?\n",
            "\n",
            "tensor([[-0.1231, -0.1642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.3392, -0.3906, -0.3884, -0.5322, -0.4877, -0.1789]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in assembly systems, maybe something around joining large components,  or potentially additive or advanced manufacturing processes.  It could be any of those things, really.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2703,  0.1052, -0.3257, -0.4367, -0.3441, -0.4555,  0.1223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5821, 0.0857, 0.4108, 0.3714, 0.3261, 0.5455, 0.5016, 0.2984, 0.4342,\n",
            "         0.2463]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5979, -0.3585, -0.6037, -0.3482, -0.3608, -0.4639]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and JS EcoLine because they seem like good products.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.0244, 0.4273, 0.5378, 0.3589, 0.4321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2504, -0.2790, -0.2406, -0.2602, -0.2765]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, I suppose.  I don't know what other options there are, but Italian is what comes to mind.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.5299,  0.2371, -0.0398,  0.1633,  0.5964,  0.1970,  0.2124,  0.0267]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've heard of Adito.  It's a CRM system, I think.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5047, -0.4932, -0.5147, -0.5019, -0.5186, -0.5305, -0.4658]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 25 people.  I don't know what the other options are, but that's my best estimate for the average size of a trade fair team.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4567, 0.0658, 0.5949, 0.5765, 0.5673, 0.5078, 0.5535, 0.3670, 0.4444,\n",
            "         0.3850]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the industrial sector.  That's my understanding, anyway.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0187, -0.1217, -0.0965]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[-0.3130, -0.1248, -0.3366, -0.3543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0783, -0.0450, -0.0347, -0.0216,  0.0885,  0.0417]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4763, -0.4726, -0.4577, -0.4288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4164, -0.2961]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3593, -0.3334, -0.0840, -0.3001]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2295,  0.2063, -0.3841, -0.0677, -0.4986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4817, -0.4777, -0.4928, -0.5849, -0.2880, -0.0052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4622, -0.0946, -0.5083, -0.4657,  0.0442, -0.4061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS,  whatever that is, JS EcoLine, sounds like a product line, and AX100, which I'm not familiar with.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4988, -0.4565, -0.5915, -0.1879, -0.3723]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1321, -0.0710, -0.0991]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two weeks, I think.  That seems like a good middle ground.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.0026,  0.3279,  0.3841,  0.4825,  0.4454]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2696, -0.1560, -0.3020, -0.2542, -0.3251, -0.3999, -0.1678]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 45 people,  I don't know what the other options are but that sounds about right for a trade fair team.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 18. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=9)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5908,  0.1781, -0.4990, -0.4562, -0.2821, -0.4871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't believe so; I think that covers everything.\n",
            "The intended answer was: No, I don't believe so; I think that covers everything.\n",
            "The predicted answer was: no, I don't believe so; I think that covers everything . no, i think so, but that's not the case .\n",
            "\n",
            "tensor([[0.4373, 0.2395, 0.0599, 0.2977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 43. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=21)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we connect again on January 17th?  That works for me.\n",
            "The intended answer was: 2025-01-17\n",
            "The predicted answer was: january 17th\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't think so; that covers everything.  Or, if you want, I could add [Add additional information here], but I'm not sure it's necessary.\n",
            "The intended answer was: No, I don't think so; that covers everything.  Or, if you want, I could add [Add additional information here], but I'm not sure it's necessary.\n",
            "The predicted answer was: no, I don't think so; that covers everything . if you want, I could add additional information here . but I'm not sure it's necessary.\n",
            "\n",
            "tensor([[-0.1351, -0.1521, -0.1488]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they'd prefer a follow up in two weeks,  that seems like a good compromise between a week and three weeks.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2656, -0.3180, -0.1246, -0.3911, -0.3398, -0.2563]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[0.4160, 0.3851, 0.0489, 0.2659]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4168, -0.3411, -0.5604, -0.0914, -0.0959]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4958, -0.4686, -0.5536, -0.5061, -0.5395, -0.5706, -0.3395]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0762, -0.1926,  0.3160,  0.3153,  0.1910,  0.0896,  0.2487, -0.3080,\n",
            "         -0.2090, -0.2032]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1475, 0.0987, 0.0468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3429,  0.1601,  0.4378,  0.4029,  0.4368,  0.4086,  0.4143,  0.2596,\n",
            "          0.2967, -0.1264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4142, -0.1660, -0.2034, -0.1169,  0.2383, -0.1589]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0489, -0.0201,  0.0949,  0.3544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a partner, because that's the only type I know.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4047, -0.1762]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4373, 0.2395, 0.0599, 0.2977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3807, 0.1454, 0.1959, 0.0512]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm very unsatisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3445, 0.2628, 0.3284, 0.5870, 0.5486]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4474, -0.5998, -0.5360, -0.3214, -0.4405, -0.4096, -0.4692, -0.5533,\n",
            "         -0.2633, -0.4713, -0.3117, -0.3234, -0.5525]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Sandro Kalter', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1144, -0.0112, -0.4279,  0.0449,  0.0248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of the company sizes, but that seems about right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.6266, -0.0403,  0.6218,  0.5898,  0.6238,  0.6513,  0.6282,  0.2659,\n",
            "          0.3453,  0.3683]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the medical industry.  That's what I understand, anyway.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3535, -0.1609, -0.3144,  0.1037, -0.1912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier, or even someone from the press or media, I'm really not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3130, -0.1248, -0.3366, -0.3543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2101, -0.2766,  0.5315,  0.2997,  0.2025,  0.2382,  0.3519,  0.1238,\n",
            "          0.2856,  0.3599]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4517, -0.3986, -0.5900, -0.1449, -0.2196]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2888, -0.5197]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.7439, -0.3824,  0.5801,  0.3958,  0.6137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd say I need to clean up the CRM and improve the data quality in it.  That seems like the best approach.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0267, -0.0169, -0.2727, -0.3159, -0.4134]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1619, 0.1394, 0.3508, 0.2500, 0.5926]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2752, -0.2531, -0.5495, -0.0826]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm very unsatisfied, actually.  I didn't get what I wanted, and the whole experience was frustrating.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0513,  0.0486, -0.3292, -0.3381]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[0.5021, 0.4660, 0.4279]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 28. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=14)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2090, -0.3181, -0.2959,  0.1327, -0.1175,  0.1983]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation, maybe something around 210 automation systems, or possibly assembly systems, perhaps around 220.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't believe there's anything else to add at this time.  Everything relevant should be covered already.\n",
            "The intended answer was: No, I don't believe there's anything else to add at this time.  Everything relevant should be covered already.\n",
            "The predicted answer was: no, I don't believe there's anything else to add at this time . everything relevant should be covered already . if you're looking for a new one, click here for more information .\n",
            "\n",
            "tensor([[-0.1957, -0.2114, -0.4487, -0.3591, -0.4826]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0444,  0.0034,  0.1129,  0.3116,  0.3545,  0.3756, -0.1957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[-0.0195, -0.1328, -0.4804, -0.3474, -0.5170]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3130, -0.1248, -0.3366, -0.3543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4800, -0.5563]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 23. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=11)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't think there's anything else I need to add at this time.\n",
            "The intended answer was: No, I don't think there's anything else I need to add at this time.\n",
            "The predicted answer was: no, I don't think there's anything else I need to add at this time . no, i'm not sure if it's a problem .\n",
            "\n",
            "tensor([[ 0.0426,  0.3600,  0.1840, -0.0043,  0.4182]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0323,  0.0201, -0.1851, -0.3204, -0.2911, -0.3066,  0.0341]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor group, because that's what comes to mind.  I don't know what other options there are.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2064, -0.4302, -0.1984]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd offer a solution, I suppose.  That seems like the next logical step.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1167, -0.2052, -0.1212, -0.0480,  0.2064, -0.2600]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2920, -0.3288,  0.0188,  0.4604, -0.2968]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2640, -0.5636, -0.5046, -0.2498, -0.3268, -0.4103, -0.4364, -0.4397,\n",
            "         -0.2026, -0.4743, -0.5000, -0.3053, -0.4967]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2773, -0.2806,  0.0813, -0.0191, -0.3362]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a supplier, maybe even press or media.  I'm not sure,  it could be either one.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3272,  0.2932,  0.4677,  0.4291,  0.4429]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Data Enrichment, because it sounds useful, and also Visit Reports, to see where things are going.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.2703,  0.1052, -0.3257, -0.4367, -0.3441, -0.4555,  0.1223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects, I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3471, -0.3837, -0.2104, -0.1716, -0.3084, -0.3615]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in additive manufacturing,  perhaps advanced manufacturing, or something else entirely.  I really don't know.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't believe I have anything else to add at this time.  Everything relevant, I think, is already included.\n",
            "The intended answer was: No, I don't believe I have anything else to add at this time.  Everything relevant, I think, is already included.\n",
            "The predicted answer was: I don't believe I have anything else to add at this time . everything relevant, I think, is already included . if you have any questions, please contact me at e-mail .\n",
            "\n",
            "tensor([[ 0.2795, -0.2543,  0.0360,  0.1759, -0.1671]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards, cleaning up my CRM, and capturing trade fair contacts to find a solution.  It seems like a good approach.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2804, 0.4140, 0.5531, 0.6227, 0.5259, 0.2955, 0.5862, 0.1009]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4662, -0.0820, -0.5058,  0.1376, -0.0433]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer,  but it could also be a new customer or prospect, or maybe even press or media; I really don't know.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1337, -0.2525, -0.2668]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4663, -0.2746]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1873,  0.1492,  0.4213, -0.3881,  0.4220,  0.1735,  0.2759,  0.4518]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what CRM systems are available, but I'd guess Microsoft Dynamics, since I've heard of that one.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1345,  0.0722, -0.1272,  0.1080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email', 'No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[0.7169, 0.0366, 0.7377, 0.7363, 0.6845, 0.7227, 0.7137, 0.1823, 0.4395,\n",
            "         0.2533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4547, -0.4135, -0.4167]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe,  not too soon and not too late.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.1184, -0.1435, -0.1175, -0.1347, -0.1806]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4373, 0.2395, 0.0599, 0.2977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4740, -0.3139]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3376, -0.1025]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.2172, -0.1900, -0.2190, -0.1141, -0.2156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3912, -0.3238, -0.4417, -0.1666, -0.3269]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5284, -0.0335, -0.5329, -0.5426, -0.5410, -0.5520, -0.1143]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4392, 0.1820]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what the options are, but I'd say no.  I'm not comfortable with my data being processed.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.4988, -0.5420, -0.5039, -0.5047, -0.4867, -0.5035, -0.5495, -0.5582,\n",
            "         -0.5434, -0.5270, -0.5167, -0.5266, -0.5121]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4322, -0.3765, -0.5670, -0.5045, -0.1210,  0.2735]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.5968, -0.5957, -0.6143, -0.5986, -0.5984, -0.6101, -0.5937]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.6288,  0.0069,  0.4231,  0.1748, -0.3676]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try cleaning up the CRM, maybe extracting data from emails to improve the CRM data quality, and definitely capture those trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0561, -0.1870,  0.0251, -0.2642, -0.1311, -0.1657]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company,  because that's what comes to mind.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.4169, -0.2527,  0.2848, -0.0499,  0.1265]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0524, -0.0246,  0.2465,  0.2230,  0.2087,  0.0840, -0.2933]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think they're architects, because that's the only group that comes to mind.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3246,  0.3972, -0.0939,  0.0113,  0.4128,  0.4949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, I think.  That's the only one that comes to mind.\n",
            "The intended answer was: ['JTS']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1108,  0.4015,  0.7387,  0.5938,  0.5914]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.3731, -0.3039, -0.3480]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in about two weeks, I think.  That seems like a good timeframe.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.2929,  0.0376,  0.0684,  0.1214, -0.2568]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because that sounds really interesting, and also high-speed interconnect testing, which I think is important for modern electronics.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.5214, -0.1441, -0.5494, -0.4388, -0.0934, -0.2483]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4492, -0.3895, -0.5235, -0.4768, -0.5142,  0.0919]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation, maybe something around joining systems for large components, or possibly additive manufacturing;  I'm not sure, it could even be advanced manufacturing or something else entirely.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2448,  0.3479,  0.6934,  0.5629,  0.6333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because they're useful for networking.  Data enrichment and cleansing also sound important to me, for keeping information accurate and complete.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.4615,  0.4282, -0.0917,  0.2270, -0.3864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2888, -0.5197]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3665, 0.4748, 0.3013, 0.4572, 0.4897, 0.4261, 0.4959, 0.0208]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with CAS,  I don't know what other CRM systems are out there.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4950, -0.0321, -0.4768, -0.0321,  0.0358]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, but it could also be a supplier, someone from the press or media, or even a competitor, I'm really not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1971, -0.1920,  0.3450,  0.5310,  0.4183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2372, 0.8821, 0.1608, 0.4071, 0.6628, 0.6052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and a few others I think, like JS EcoLine,  AKW100, and maybe AX100.  I'm not sure what all the options are\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1929, 0.2097, 0.0632, 0.0398]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4549,  0.3197, -0.1594, -0.0839,  0.5161,  0.4478]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM,  because that's the only one I know about.\n",
            "The intended answer was: ['MY-SYSTEM']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0639,  0.0040]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I assume that's an option, right?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1560, -0.1190, -0.1635, -0.1112, -0.1753]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1590, -0.2880,  0.1270, -0.3915, -0.2637, -0.2914]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4409, -0.4053, -0.5751, -0.0430, -0.1286]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 5 employees.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5172, -0.5179, -0.4225, -0.3408]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't think I have anything else to add at this time.  Everything relevant should be included already.\n",
            "The intended answer was: No, I don't think I have anything else to add at this time.  Everything relevant should be included already.\n",
            "The predicted answer was: no, I don't think I have anything else to add at this time . everything relevant should be included already . if you have any questions, please contact me at the bottom of the page.\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we touch base again on January 15th?  That works for me.\n",
            "The intended answer was: 2025-01-15\n",
            "The predicted answer was: january 15th\n",
            "\n",
            "tensor([[-0.1525, -0.2998, -0.0385, -0.3926, -0.2388, -0.2609]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education company,  because that's what comes to mind.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0252, -0.0049, -0.0374, -0.0034, -0.0301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2683, -0.2154, -0.0091, -0.1434, -0.1565]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards, I guess.  That seems like the most likely way to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[-0.5660, -0.3200, -0.5955, -0.4743, -0.5592, -0.5209]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4537, 0.0165, 0.4490]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2482, -0.1596, -0.3062, -0.3461]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3809, -0.5079, -0.5320, -0.5045, -0.4743, -0.3961, -0.5156, -0.5196,\n",
            "         -0.5203, -0.4244, -0.3836, -0.2894, -0.5429]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Domiki Stein, and Tim Persson;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Marisa Peng', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.3986, -0.3303,  0.4426,  0.3958,  0.3620,  0.4733,  0.3450,  0.1564,\n",
            "          0.2855, -0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5264, -0.5612, -0.3675, -0.3046, -0.4759, -0.3408]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0974, -0.2980,  0.2114, -0.0120, -0.1411]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3926, 0.3520, 0.2560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5684, -0.6236, -0.5901, -0.4571, -0.5203,  0.1438]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4165, 0.5179, 0.3837, 0.4685, 0.6904, 0.5282, 0.1049, 0.1254]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with SAP Sales Cloud, I think.  I don't know much about other CRM systems.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1642, -0.0102, -0.2946, -0.3625]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1829, 0.4263, 0.3270, 0.3017, 0.0443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3941, -0.3881, -0.3983, -0.4061, -0.4195]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2186, -0.0469, -0.3129, -0.1975]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a partner, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0549, 0.0271, 0.1259]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should offer to help,  because that seems like the next logical step.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4697, -0.4343, -0.5967, -0.1552, -0.2405]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't think so; I believe I've covered everything.\n",
            "The intended answer was: No, I don't think so; I believe I've covered everything.\n",
            "The predicted answer was: no, I don't think so; I believe I've covered everything . no, but I think it's all covered .\n",
            "\n",
            "tensor([[0.3796, 0.3721, 0.4155, 0.0904, 0.4011]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get the information, or maybe extract data from emails if there's relevant information there.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2888, -0.5197]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.6038, -0.0425,  0.6037,  0.5797,  0.6342,  0.6148,  0.6110,  0.2806,\n",
            "          0.3828,  0.4352]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.4052,  0.0332, -0.0940,  0.1453]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2990,  0.2084,  0.0788,  0.5110, -0.2646]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, since it sounds fascinating.  Double-pulse testing also piques my interest, and I'd like to learn more about high-speed interconnect testing too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.4453, -0.0947,  0.4530, -0.0499,  0.3659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try cleaning up the CRM,  then maybe extract data from emails to see if that helps, and finally, I'd  capture contacts from trade fairs, hoping one of those things solves it.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 20. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.5400,  0.0449,  0.5807,  0.5760,  0.4106,  0.5534,  0.5435,  0.1083,\n",
            "          0.1187, -0.4161]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't believe so; I think I've covered everything.\n",
            "The intended answer was: No, I don't believe so; I think I've covered everything.\n",
            "The predicted answer was: no, I don't believe so; I think I've covered everything . no, i think I have covered everything, but I think it's a good thing .\n",
            "\n",
            "tensor([[-0.4203, -0.3255]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4781,  0.5533, -0.3018,  0.0517, -0.1263, -0.3032]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM and AKW100,  I think those are good products.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2049,  0.3802, -0.1139,  0.3012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm very satisfied, I think.  I don't know what other options there are to compare it to, but that's how I feel.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3375, 0.6291, 0.3394, 0.3617, 0.4425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0572,  0.2758, -0.3478,  0.0219, -0.6679]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in high-speed interconnect testing, because that sounds like a really important field.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5498, 0.4800, 0.3711]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think we should have a meeting next.  That seems like the best way to move forward.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2365, -0.2359, -0.1927, -0.2552, -0.2667]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2888, -0.5197]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2836, -0.0569, -0.1344, -0.2491, -0.1791, -0.1971, -0.1672]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's the end user group,  because that's who I usually deal with.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2101, -0.1983]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what options there are, but I'd say no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0702, -0.0959,  0.3255,  0.3514,  0.1609,  0.1106,  0.2421, -0.4114,\n",
            "         -0.0571, -0.0542]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3037, 0.5680, 0.3054, 0.4892, 0.5102]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like maybe double-pulse testing or high-speed interconnect testing.  I think those sound interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.5655, -0.5814, -0.6075, -0.5719, -0.5863, -0.6115, -0.5221]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4469, -0.5205, -0.4716, -0.4164, -0.4720, -0.5058, -0.5133, -0.4751,\n",
            "         -0.5028, -0.5021, -0.4636, -0.5446, -0.4897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5456, -0.5313, -0.6345, -0.3088, -0.3740]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd say we have around 30 employees.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2982, -0.3631, -0.4109, -0.5211, -0.5078, -0.5370, -0.4695]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects, because that's what comes to mind.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1231, -0.1642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4373, 0.2395, 0.0599, 0.2977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.7009, -0.1246,  0.1574,  0.2882,  0.0790]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try to clean up the CRM first,  then I'd  capture contacts from the trade fair. That seems like the best approach to me.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3332,  0.2624,  0.5950,  0.6246,  0.4990,  0.4090,  0.5573,  0.1773,\n",
            "         -0.2805, -0.4519]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.4064, -0.5674,  0.2579,  0.1262,  0.2343]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd search for a way to improve my CRM data quality, maybe by scanning business cards from trade fairs to capture new contacts, then cleaning up the CRM and extracting data from emails to make it all accurate.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0378,  0.4009, -0.5917,  0.1082, -0.2905]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in Double-Pulse Testing,  because it sounds interesting, and Display port debugging and compliance, as I'd like to learn more about that.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3464, -0.3096, -0.5593, -0.2143, -0.1299]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4770, -0.4977, -0.1522, -0.3953, -0.3057, -0.4510]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[0.0716, 0.4529, 0.3536, 0.3446, 0.2619, 0.1104, 0.3165, 0.4470, 0.4775,\n",
            "         0.2919]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1231, -0.1642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.5242, -0.6037, -0.6053, -0.5295, -0.5642, -0.4881, -0.6162, -0.5432,\n",
            "         -0.4561, -0.4718, -0.5781, -0.5286, -0.5544]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3267, -0.0098, -0.2083,  0.0113,  0.0260]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 25. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4211, -0.4193, -0.4385, -0.3406, -0.2801, -0.3940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in additive manufacturing, automation, assembly systems, or joining systems for large components.  Or something else entirely.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The intended answer was: No, I think that covers everything.  I don't have any other notes to add at this time.\n",
            "The predicted answer was: no, I think that covers everything . I don't have any other notes to add at this time . i'm not sure if it's a good thing to do .\n",
            "\n",
            "tensor([[-0.1469,  0.4031,  0.1309,  0.1927,  0.0693, -0.1263,  0.1381,  0.4436,\n",
            "          0.1163,  0.2880]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in public safety, I think.  That's what comes to mind, anyway.  I'm not sure what other options there are.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4233, 0.4014, 0.3126]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3831, -0.4432, -0.3665, -0.3665, -0.3710, -0.4509]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I'm not sure, but I think it's an education company.  That's my guess.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3418, -0.0131,  0.0880,  0.3629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm very satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2877, -0.2696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.0812, 0.0465, 0.0108]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1491, -0.1100, -0.0623, -0.0800, -0.0927]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think German is best for communication,  since I don't know what other languages are being considered.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3158,  0.3037,  0.0771,  0.4722, -0.0997,  0.5314,  0.4072,  0.2116]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3363, -0.0513, -0.2828, -0.3611]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5177, -0.5020, -0.5580, -0.4825, -0.5178, -0.4451, -0.6202, -0.5898,\n",
            "         -0.4120, -0.5846, -0.4744, -0.5581, -0.5593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Domiki Stein, and Sean Kennin,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Domiki Stein', 'Sean Kennin']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4463, 0.4370, 0.1293, 0.6246, 0.1721, 0.6694, 0.4816, 0.1263]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've used HubSpot before.  It seemed pretty good to me.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2160, 0.2671, 0.1416, 0.2140, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3814, -0.1036,  0.4518,  0.4565,  0.4542,  0.4086,  0.4950,  0.2078,\n",
            "          0.2618,  0.4906]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in public safety, I guess.  I help with law enforcement. I don't really know what other industries there are to be honest.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4856, -0.3786, -0.4896, -0.4939, -0.4862]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5190, -0.5955, -0.5932, -0.4726, -0.5742, -0.5110, -0.5956, -0.5195,\n",
            "         -0.5590, -0.5314, -0.5756, -0.5425, -0.5352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6665, 0.1065, 0.4063, 0.7004, 0.4232]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1060, 0.2780, 0.0675, 0.0884, 0.3207]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2364, -0.1409, -0.1892]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.5205, -0.4932, -0.5595, -0.5330, -0.5404, -0.5479, -0.4863]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around eight people.  I don't know what the other options are, but eight seems like a reasonable size for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3971, -0.5446, -0.5206, -0.4026, -0.2193, -0.3705, -0.5013, -0.5195,\n",
            "         -0.3243, -0.4458, -0.3583, -0.1788, -0.5415]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Erik Schneider, Angelina Haug, Johannes Wagner, Jens Roschmann, Domiki Stein, and Tim Persson;  I think they all need to be kept in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Sandro Kalter', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4870, -0.4914, -0.5163, -0.4847, -0.5007, -0.5056, -0.5147]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say the trade fair team is usually around 45 people.  I'm not sure what other sizes are possible.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0473,  0.4624,  0.3453,  0.3635,  0.6738,  0.5561]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM,  because it sounds interesting, and also JS EcoLine, I think that sounds good too.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4949, -0.5515, -0.5117, -0.0492, -0.1545, -0.3241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4673, -0.2473, -0.5659, -0.5547,  0.2494,  0.0757]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4907, -0.4871, -0.5537, -0.5690, -0.4864, -0.3114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5022, -0.4486, -0.0682, -0.4820, -0.0139]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we have around 100 employees.  I don't know the exact range, like 51-200 or anything like that.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2865, -0.1323]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1346, 0.0915, 0.3861]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5687, -0.5637, -0.5750, -0.5564, -0.5741, -0.5895, -0.5614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 25 people, give or take a few.  I don't know what the other options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 16-20\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4508, 0.4651, 0.2448, 0.0856]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3759, 0.2979, 0.2191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call, that seems like the next thing to do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.0793, 0.0979, 0.0888, 0.0629, 0.1820]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4903, 0.1794, 0.1291, 0.3750]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm unsatisfied, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5789, -0.5937, -0.5591, -0.5524, -0.4492, -0.5474, -0.4759, -0.5983,\n",
            "         -0.5704, -0.5213, -0.4787, -0.5582, -0.5601]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2965, -0.2241, -0.4783,  0.0714, -0.1973]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 26. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0111, -0.1080, -0.1695]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Notes\n",
            "Context: No, I don't believe I have anything else to add at this time.  Everything relevant is already included.\n",
            "The intended answer was: No, I don't believe I have anything else to add at this time.  Everything relevant is already included.\n",
            "The predicted answer was: no, I don't believe I have anything else to add at this time . everything relevant is already included . if you have any questions, please contact me .\n",
            "\n",
            "tensor([[ 0.3995,  0.0526,  0.5249,  0.5096,  0.4494,  0.4474,  0.4722,  0.0683,\n",
            "          0.1341, -0.1039]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5650, 0.1005, 0.4017, 0.3491, 0.3011, 0.4831, 0.4139, 0.2921, 0.3935,\n",
            "         0.3122]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Aerospace\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5262, -0.2639, -0.5222, -0.2743, -0.4727, -0.5312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AX100,  I think those sound like good products.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4611, -0.4529, -0.4327, -0.4375, -0.3340, -0.4030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2865, -0.1323]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1590, -0.2880,  0.1270, -0.3915, -0.2637, -0.2914]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0232, -0.0301,  0.2392,  0.0667,  0.2444]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1514, -0.1679, -0.0429, -0.3211, -0.0922, -0.1453]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0664,  0.3905,  0.5392,  0.5352,  0.4952]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 100, but your input_length is only 16. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=8)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: Any additional notes?\n",
            "Context: No, I don't think so; that covers everything.\n",
            "The intended answer was: No, I don't think so; that covers everything.\n",
            "The predicted answer was: no, I don't think so; that covers everything . no, that's what I'm talking about . it's a bit of a mystery .\n",
            "\n",
            "tensor([[ 0.6079, -0.1601,  0.2418,  0.2396,  0.5395]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get them into my system, then clean up my CRM to make sure everything's organized, and finally improve the CRM data quality so it's accurate.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3179, -0.1102, -0.1583, -0.0837, -0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Supplier', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3334, 0.1604, 0.1074, 0.3324]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4378, 0.2261, 0.0411, 0.2463]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied, that's how I feel about my experience.  I don't know what other options there might be.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0807, 0.0440, 0.1412]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in two weeks, I think.  That's somewhere between a week and three weeks.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0969, 0.2327, 0.1489, 0.2212, 0.0598]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4166, -0.4561, -0.6220, -0.3492, -0.1102]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd say we're a small company, maybe around 5 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1740, -0.2916, -0.0815, -0.3081, -0.1952, -0.3353]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2897, -0.4845, -0.4076, -0.1600, -0.3794, -0.3632, -0.5035, -0.5610,\n",
            "         -0.2983, -0.4555, -0.4388, -0.4428, -0.5016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4758, -0.5243]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0252, -0.0049, -0.0374, -0.0034, -0.0301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('bert_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)"
      ],
      "metadata": {
        "id": "kMob_9mrhbZk"
      },
      "execution_count": 202,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "bkodumdkigBv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}