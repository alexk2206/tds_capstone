{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMN3YzrOpRjRpWGplKsinWB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "83d1325d0ba44d02b6bb11470d7d2d36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7c74ec8814dc49c2bbfc20d72038259f",
              "IPY_MODEL_c812037c5d1b4fbaa71abb0705286244",
              "IPY_MODEL_14792d75bd214dc8949ab2d95cad387b"
            ],
            "layout": "IPY_MODEL_3417727dbcb44ae0a0cdcd524d51af46"
          }
        },
        "7c74ec8814dc49c2bbfc20d72038259f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8ac411076aee47a4a10e365b40884c9c",
            "placeholder": "​",
            "style": "IPY_MODEL_dbda537cc05f49949bbf20251ffc6bbd",
            "value": "Filter: 100%"
          }
        },
        "c812037c5d1b4fbaa71abb0705286244": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1be6fca06f364f0fabf87f684c9cd1fb",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_472dc07b8c004906bdf60243cc2d9a77",
            "value": 1104
          }
        },
        "14792d75bd214dc8949ab2d95cad387b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ec6ae0556fd4007a216c5d4029386a1",
            "placeholder": "​",
            "style": "IPY_MODEL_418bdeb69f134121a98e564f5eb44400",
            "value": " 1104/1104 [00:00&lt;00:00, 6802.06 examples/s]"
          }
        },
        "3417727dbcb44ae0a0cdcd524d51af46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ac411076aee47a4a10e365b40884c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dbda537cc05f49949bbf20251ffc6bbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1be6fca06f364f0fabf87f684c9cd1fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "472dc07b8c004906bdf60243cc2d9a77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ec6ae0556fd4007a216c5d4029386a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "418bdeb69f134121a98e564f5eb44400": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "07f09fc8642c4be2af28b299a388673e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0cc50ecaf5e249a9aa679808858b31b7",
              "IPY_MODEL_096731b680d5441fb64791b01e370ec3",
              "IPY_MODEL_f61ce49970974612a188ab2ddfbb5fec"
            ],
            "layout": "IPY_MODEL_031c7f9d87df44c2a36f9e1622feb6df"
          }
        },
        "0cc50ecaf5e249a9aa679808858b31b7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_217059b930b44e26b1baf852849c1120",
            "placeholder": "​",
            "style": "IPY_MODEL_29aead24867c48d18f183c6253d889c9",
            "value": "config.json: 100%"
          }
        },
        "096731b680d5441fb64791b01e370ec3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8676e0d61b654e95ac353ba2f2df63d6",
            "max": 451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_48acd096373f437184364ba614ff89aa",
            "value": 451
          }
        },
        "f61ce49970974612a188ab2ddfbb5fec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1ed1cc426e974fbfb1b3ed61a2636b2d",
            "placeholder": "​",
            "style": "IPY_MODEL_71048ee89be147a58239f5b9068a7a1a",
            "value": " 451/451 [00:00&lt;00:00, 4.61kB/s]"
          }
        },
        "031c7f9d87df44c2a36f9e1622feb6df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "217059b930b44e26b1baf852849c1120": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29aead24867c48d18f183c6253d889c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8676e0d61b654e95ac353ba2f2df63d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "48acd096373f437184364ba614ff89aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ed1cc426e974fbfb1b3ed61a2636b2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71048ee89be147a58239f5b9068a7a1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f74b412389b4e009c1acec331ca5c14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8024e954a0f1495fac8a73a1be7b9916",
              "IPY_MODEL_5a5f799d8ec74a49ad3818c2b02a58c8",
              "IPY_MODEL_0a3c4f12ddea4b118c6209302267f8fd"
            ],
            "layout": "IPY_MODEL_49b64e431c6e4b6bb1a50114dc261b4d"
          }
        },
        "8024e954a0f1495fac8a73a1be7b9916": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_27ee434c2561405985d70c6436a683e7",
            "placeholder": "​",
            "style": "IPY_MODEL_8cdc83a9768341a7b10b9978bb0dacb6",
            "value": "model.safetensors: 100%"
          }
        },
        "5a5f799d8ec74a49ad3818c2b02a58c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6f74b007eeae4e918c2a8234c4b93411",
            "max": 265470036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a41a9a217ead46b18745a35a7ca8f290",
            "value": 265470036
          }
        },
        "0a3c4f12ddea4b118c6209302267f8fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1441c1a48ee444a099826efb4bcfa86f",
            "placeholder": "​",
            "style": "IPY_MODEL_fcf6eb4c3e6d4246ab61e964745e9592",
            "value": " 265M/265M [00:04&lt;00:00, 57.1MB/s]"
          }
        },
        "49b64e431c6e4b6bb1a50114dc261b4d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27ee434c2561405985d70c6436a683e7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8cdc83a9768341a7b10b9978bb0dacb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6f74b007eeae4e918c2a8234c4b93411": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a41a9a217ead46b18745a35a7ca8f290": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1441c1a48ee444a099826efb4bcfa86f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fcf6eb4c3e6d4246ab61e964745e9592": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e998d52f92b47fd86d4ddac45564e9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c61eb22617fd4563b133a97dc8c40da0",
              "IPY_MODEL_bbe388e672de488db74cb2b60da92005",
              "IPY_MODEL_2d6e621b294b4319bb35bdbab0c4b748"
            ],
            "layout": "IPY_MODEL_3a8c24351e14471c8a4174fe6d985c5e"
          }
        },
        "c61eb22617fd4563b133a97dc8c40da0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5bc76879f8d46cfb84ac9c55de3521c",
            "placeholder": "​",
            "style": "IPY_MODEL_dde8287bb20149088b19555aaf316d58",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "bbe388e672de488db74cb2b60da92005": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f9a43c53f3b467d8e62b77ef6d10cee",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bbdf023ab8fb4683a7236fb253c4c646",
            "value": 48
          }
        },
        "2d6e621b294b4319bb35bdbab0c4b748": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2127853b6b224996a23f6730c72094fd",
            "placeholder": "​",
            "style": "IPY_MODEL_2096ca82f4f943ee8c6b711d413d2d3f",
            "value": " 48.0/48.0 [00:00&lt;00:00, 494B/s]"
          }
        },
        "3a8c24351e14471c8a4174fe6d985c5e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5bc76879f8d46cfb84ac9c55de3521c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dde8287bb20149088b19555aaf316d58": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f9a43c53f3b467d8e62b77ef6d10cee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bbdf023ab8fb4683a7236fb253c4c646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2127853b6b224996a23f6730c72094fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2096ca82f4f943ee8c6b711d413d2d3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5f0e5efb088244a0aceaec12405473de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ef94527288c4e478fa188e5b70a4ceb",
              "IPY_MODEL_0c249fe8f66148ce9d4427396496e808",
              "IPY_MODEL_9230a945d172478296f5adb218556c7f"
            ],
            "layout": "IPY_MODEL_02d5eb8bb1744765a77fbf0edb35e80f"
          }
        },
        "6ef94527288c4e478fa188e5b70a4ceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7da7428e4ef545a3a32e9676ac4033cc",
            "placeholder": "​",
            "style": "IPY_MODEL_c97ed8cf46cf4b9994d4e7b1bb231ea5",
            "value": "vocab.txt: 100%"
          }
        },
        "0c249fe8f66148ce9d4427396496e808": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ddc22c91d5e846899f510912588c0305",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_8d025c708a01434c89d0eb633399dd15",
            "value": 231508
          }
        },
        "9230a945d172478296f5adb218556c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e6ad5ad614345838823bd3920e88b8f",
            "placeholder": "​",
            "style": "IPY_MODEL_4276aa6a50774d8b8c22fa15f76528c2",
            "value": " 232k/232k [00:00&lt;00:00, 2.55MB/s]"
          }
        },
        "02d5eb8bb1744765a77fbf0edb35e80f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7da7428e4ef545a3a32e9676ac4033cc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c97ed8cf46cf4b9994d4e7b1bb231ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ddc22c91d5e846899f510912588c0305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d025c708a01434c89d0eb633399dd15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7e6ad5ad614345838823bd3920e88b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4276aa6a50774d8b8c22fa15f76528c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "236e432245f54ff1a5f49d8963e279a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a421b8ac6bb43108bee0c7fe3ce19ac",
              "IPY_MODEL_e5c726605bdf4066a547fa49a1303fc1",
              "IPY_MODEL_d74db1b8fb1847349dac026993e2e12c"
            ],
            "layout": "IPY_MODEL_38d91bc4481446a6b9806701509a6ad2"
          }
        },
        "4a421b8ac6bb43108bee0c7fe3ce19ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52433b3181fa45b4930fcb428efd8f32",
            "placeholder": "​",
            "style": "IPY_MODEL_3ccbd606f7b94a7780ea4b564a59d328",
            "value": "tokenizer.json: 100%"
          }
        },
        "e5c726605bdf4066a547fa49a1303fc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c87d85dc75af4aa3a85ba8bc2d441b9c",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b17f77069e5b4a90aadaa1f0cd6c54af",
            "value": 466062
          }
        },
        "d74db1b8fb1847349dac026993e2e12c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1077cd2ee534547892acd989fe0628a",
            "placeholder": "​",
            "style": "IPY_MODEL_b576524f3a744714a3126abe5e8b820d",
            "value": " 466k/466k [00:00&lt;00:00, 5.41MB/s]"
          }
        },
        "38d91bc4481446a6b9806701509a6ad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52433b3181fa45b4930fcb428efd8f32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3ccbd606f7b94a7780ea4b564a59d328": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c87d85dc75af4aa3a85ba8bc2d441b9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b17f77069e5b4a90aadaa1f0cd6c54af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1077cd2ee534547892acd989fe0628a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b576524f3a744714a3126abe5e8b820d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9de015e7816443cca2e81f9a1505ca77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d2fbc91c04ca449baef1d90fcc9eb63b",
              "IPY_MODEL_59fa1a64c85241559c97ad0b55c166b3",
              "IPY_MODEL_16c23ce2a6164efeba5a37a329f1d55b"
            ],
            "layout": "IPY_MODEL_087094e9afe64c148921877879f95ed4"
          }
        },
        "d2fbc91c04ca449baef1d90fcc9eb63b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6c3c6ec3df0e4e498e4dd06fc45281b8",
            "placeholder": "​",
            "style": "IPY_MODEL_ac481cd784864fa882653cdfe2cd414d",
            "value": "Filter: 100%"
          }
        },
        "59fa1a64c85241559c97ad0b55c166b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d2461b472c24f5c81c1a5fb0b3dcc73",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_041e7be7b6724a09aa5769fc7cfa67a8",
            "value": 1104
          }
        },
        "16c23ce2a6164efeba5a37a329f1d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c60218148fac459888cbd8a9f4aa133c",
            "placeholder": "​",
            "style": "IPY_MODEL_2a5bdf3691f743f5800415ff700da562",
            "value": " 1104/1104 [00:00&lt;00:00, 10789.26 examples/s]"
          }
        },
        "087094e9afe64c148921877879f95ed4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c3c6ec3df0e4e498e4dd06fc45281b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac481cd784864fa882653cdfe2cd414d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d2461b472c24f5c81c1a5fb0b3dcc73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "041e7be7b6724a09aa5769fc7cfa67a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c60218148fac459888cbd8a9f4aa133c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a5bdf3691f743f5800415ff700da562": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a16df523eaf94f76b2ac1e07b44c1bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_63ac4b190935457e9a2208435dcac6ed",
              "IPY_MODEL_33b40819120b4ec6abf387d54b241e2e",
              "IPY_MODEL_30a7895eff374ccba813f0a6e7ee6412"
            ],
            "layout": "IPY_MODEL_f610fc7112f9417fbca1a5b40ab052fc"
          }
        },
        "63ac4b190935457e9a2208435dcac6ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f118ae65c9d34c5b89688c56e7bc9d11",
            "placeholder": "​",
            "style": "IPY_MODEL_581fbefcc6234c3d9d85d0ccc7f44ecb",
            "value": "config.json: 100%"
          }
        },
        "33b40819120b4ec6abf387d54b241e2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38616febf684434c99cd6e36c93086b6",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ec9d849c33784b118e906435de5c20b0",
            "value": 684
          }
        },
        "30a7895eff374ccba813f0a6e7ee6412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9908716e59a349a282594e49e7a923cd",
            "placeholder": "​",
            "style": "IPY_MODEL_efcc6ff9f0b3407dbd9f7bc8b1439bcf",
            "value": " 684/684 [00:00&lt;00:00, 10.0kB/s]"
          }
        },
        "f610fc7112f9417fbca1a5b40ab052fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f118ae65c9d34c5b89688c56e7bc9d11": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "581fbefcc6234c3d9d85d0ccc7f44ecb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "38616febf684434c99cd6e36c93086b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec9d849c33784b118e906435de5c20b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9908716e59a349a282594e49e7a923cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "efcc6ff9f0b3407dbd9f7bc8b1439bcf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7f58c1164d1142478968257d7936123e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_866ebc4490c64d1d8e132bfa23b5449c",
              "IPY_MODEL_7d19a7184cb74e6fa3c1b302d11e3977",
              "IPY_MODEL_954c563eca1f49e89cc31ab1053a90ee"
            ],
            "layout": "IPY_MODEL_733972cc6fc645c4bde46213ce994139"
          }
        },
        "866ebc4490c64d1d8e132bfa23b5449c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c1dbeff9dff4225b10581622da91ce7",
            "placeholder": "​",
            "style": "IPY_MODEL_50d3fd723e4f49c8ada234dcc7e41608",
            "value": "model.safetensors: 100%"
          }
        },
        "7d19a7184cb74e6fa3c1b302d11e3977": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c49842ee1bde4670a7c5a30d44ebc785",
            "max": 47372894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5cca4728d31f4bbe88250f62de0de2bf",
            "value": 47372894
          }
        },
        "954c563eca1f49e89cc31ab1053a90ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0409901b030c4b499dc27937d52b9216",
            "placeholder": "​",
            "style": "IPY_MODEL_e8b3eb8f868749418a3643ee354a168c",
            "value": " 47.4M/47.4M [00:00&lt;00:00, 78.7MB/s]"
          }
        },
        "733972cc6fc645c4bde46213ce994139": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c1dbeff9dff4225b10581622da91ce7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d3fd723e4f49c8ada234dcc7e41608": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49842ee1bde4670a7c5a30d44ebc785": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5cca4728d31f4bbe88250f62de0de2bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0409901b030c4b499dc27937d52b9216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e8b3eb8f868749418a3643ee354a168c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9858c3d7d4584d3dbaf6e3fce07d6022": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_01ed020d255b4493b68909b4f68c3919",
              "IPY_MODEL_ea0abb6b4eec4052a6b29e7c2a820740",
              "IPY_MODEL_ef9e7f3990cf47ac813268ec18666845"
            ],
            "layout": "IPY_MODEL_1af9a5744f1d482db336a7ba7434b8e8"
          }
        },
        "01ed020d255b4493b68909b4f68c3919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e40214daa9474f25a3485d8372ef6890",
            "placeholder": "​",
            "style": "IPY_MODEL_6d7b70771e0f40b7bc2c80387e3e40b5",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "ea0abb6b4eec4052a6b29e7c2a820740": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9491bcd4bd634d2da4eae5be751f883c",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6e80adcc785d4f91be7f7c5631922238",
            "value": 25
          }
        },
        "ef9e7f3990cf47ac813268ec18666845": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_202f2b58dba340848f6127e8e4135447",
            "placeholder": "​",
            "style": "IPY_MODEL_b642f48df26648699450f61b56af37ae",
            "value": " 25.0/25.0 [00:00&lt;00:00, 668B/s]"
          }
        },
        "1af9a5744f1d482db336a7ba7434b8e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e40214daa9474f25a3485d8372ef6890": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d7b70771e0f40b7bc2c80387e3e40b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9491bcd4bd634d2da4eae5be751f883c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e80adcc785d4f91be7f7c5631922238": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "202f2b58dba340848f6127e8e4135447": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b642f48df26648699450f61b56af37ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "869473187683442ebe0ae6111bb8dc96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_70dce515a1c44780a3b3fce7177db3ec",
              "IPY_MODEL_3165b3ad4ab7405baedbd1a2a3d31be6",
              "IPY_MODEL_de49c1b6de0a4328992d59c951c4b754"
            ],
            "layout": "IPY_MODEL_3c75e550e7b74d37934bc2fff08b2cb8"
          }
        },
        "70dce515a1c44780a3b3fce7177db3ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_53b23cecfd354ccf8548f8de6c3bc1ab",
            "placeholder": "​",
            "style": "IPY_MODEL_925163e9ae1745fe9ad7167c09cf29cc",
            "value": "spiece.model: 100%"
          }
        },
        "3165b3ad4ab7405baedbd1a2a3d31be6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9bf97a9e3a84c94be32797a8ddd389b",
            "max": 760289,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f534404ee49e46f8b1aee58911443255",
            "value": 760289
          }
        },
        "de49c1b6de0a4328992d59c951c4b754": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1277da6f76344ec8e3e13f89f938c10",
            "placeholder": "​",
            "style": "IPY_MODEL_9ce1a17fbf2d4bbf86c087c591e53848",
            "value": " 760k/760k [00:00&lt;00:00, 5.67MB/s]"
          }
        },
        "3c75e550e7b74d37934bc2fff08b2cb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "53b23cecfd354ccf8548f8de6c3bc1ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "925163e9ae1745fe9ad7167c09cf29cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9bf97a9e3a84c94be32797a8ddd389b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f534404ee49e46f8b1aee58911443255": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b1277da6f76344ec8e3e13f89f938c10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ce1a17fbf2d4bbf86c087c591e53848": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5333de9228684fcfa067d67443339d41": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_565fd76ff65249e284c69efa5ce62cc8",
              "IPY_MODEL_09cb3af7e3fe4f6db9c0e3eb4c23ddaf",
              "IPY_MODEL_f33286a085fa4c12a17ce40588e7e462"
            ],
            "layout": "IPY_MODEL_2b71f4d6c758424099e4ba0cbf6a9b54"
          }
        },
        "565fd76ff65249e284c69efa5ce62cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_83d6bc16da0f4e89aa9072b705a55684",
            "placeholder": "​",
            "style": "IPY_MODEL_9b56361ccd8246bb87b049414f646354",
            "value": "tokenizer.json: 100%"
          }
        },
        "09cb3af7e3fe4f6db9c0e3eb4c23ddaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2072c72b679443b0aefe2fd109236464",
            "max": 1312669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3bd7434bc0c4d778beaa78bb2711401",
            "value": 1312669
          }
        },
        "f33286a085fa4c12a17ce40588e7e462": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b42b112574a347c7b6cfecc31b5821ca",
            "placeholder": "​",
            "style": "IPY_MODEL_ec59251d22ed4b12a2ec362b6f0fa27b",
            "value": " 1.31M/1.31M [00:00&lt;00:00, 6.55MB/s]"
          }
        },
        "2b71f4d6c758424099e4ba0cbf6a9b54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83d6bc16da0f4e89aa9072b705a55684": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b56361ccd8246bb87b049414f646354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2072c72b679443b0aefe2fd109236464": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3bd7434bc0c4d778beaa78bb2711401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b42b112574a347c7b6cfecc31b5821ca": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec59251d22ed4b12a2ec362b6f0fa27b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85a7c501c07c48d4971ee52ed3660800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a67389b8dbb42459b53dbcd9528f904",
              "IPY_MODEL_88056cc4f6da45d6a45f0a93018fcfd3",
              "IPY_MODEL_79f9ab26bf5c4d5cb80abdbf1d23bf98"
            ],
            "layout": "IPY_MODEL_a0b17e38d0c44a9dafd60bdf82ea5dde"
          }
        },
        "5a67389b8dbb42459b53dbcd9528f904": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfa25f2f1d694b1d8f2c5610d3b979fc",
            "placeholder": "​",
            "style": "IPY_MODEL_a3d463d7d17a4826be8a4cf4b09b2ef2",
            "value": "Downloading builder script: 100%"
          }
        },
        "88056cc4f6da45d6a45f0a93018fcfd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_715d7f678ae243a59f0ffde618b3d636",
            "max": 6785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9cc1b46c2e8343228d6dfb5bfd6ed4ce",
            "value": 6785
          }
        },
        "79f9ab26bf5c4d5cb80abdbf1d23bf98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7846e17e1207488e94831bcc2795af75",
            "placeholder": "​",
            "style": "IPY_MODEL_823fe7a97b644cea94581536c41dcc87",
            "value": " 6.79k/6.79k [00:00&lt;00:00, 111kB/s]"
          }
        },
        "a0b17e38d0c44a9dafd60bdf82ea5dde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfa25f2f1d694b1d8f2c5610d3b979fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3d463d7d17a4826be8a4cf4b09b2ef2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "715d7f678ae243a59f0ffde618b3d636": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cc1b46c2e8343228d6dfb5bfd6ed4ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7846e17e1207488e94831bcc2795af75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "823fe7a97b644cea94581536c41dcc87": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1f5ace57a2f4818b0b42bb45111c847": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d314fbdfdbca4e22af269a31b8a152d6",
              "IPY_MODEL_7101e252a20442d6bdde5a2ecc073c7b",
              "IPY_MODEL_b37ad38c731945f9b2868e395f2abf11"
            ],
            "layout": "IPY_MODEL_9655d661cc0941598426daee96169be5"
          }
        },
        "d314fbdfdbca4e22af269a31b8a152d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ab911148a1974d56a83204f7cb530197",
            "placeholder": "​",
            "style": "IPY_MODEL_27436f46e8e048e095e15bae93bee202",
            "value": "Filter: 100%"
          }
        },
        "7101e252a20442d6bdde5a2ecc073c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5c24f597099643f182d5fbcd629b47b8",
            "max": 1104,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_626d330965be40c4a1c05677513f833b",
            "value": 1104
          }
        },
        "b37ad38c731945f9b2868e395f2abf11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_420300cb47bc450887fcb5027e65deda",
            "placeholder": "​",
            "style": "IPY_MODEL_e379c79f0eea42c7b1d2895fc20f0b88",
            "value": " 1104/1104 [00:00&lt;00:00, 4741.27 examples/s]"
          }
        },
        "9655d661cc0941598426daee96169be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab911148a1974d56a83204f7cb530197": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "27436f46e8e048e095e15bae93bee202": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5c24f597099643f182d5fbcd629b47b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "626d330965be40c4a1c05677513f833b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "420300cb47bc450887fcb5027e65deda": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e379c79f0eea42c7b1d2895fc20f0b88": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f61bd280a0e74cee800ff74f352b062c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bf4e3a3831f9419d9b8cf6a8c885f3e2",
              "IPY_MODEL_3f207356bfb7424ba64c1f8cceea8c7b",
              "IPY_MODEL_964d010124c74ec88635d08df91dbeef"
            ],
            "layout": "IPY_MODEL_14ace249903b43fa9efd27c3d33bd3d9"
          }
        },
        "bf4e3a3831f9419d9b8cf6a8c885f3e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7e8bd61f61dc42bfaf7bba15d993715b",
            "placeholder": "​",
            "style": "IPY_MODEL_482ccabd1ec148ff9f70a62409ae5413",
            "value": "Filter: 100%"
          }
        },
        "3f207356bfb7424ba64c1f8cceea8c7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_aeeaf608b7264e10829a042ef165531a",
            "max": 277,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d3340a7e80d34a57bd731eb8af4c30c5",
            "value": 277
          }
        },
        "964d010124c74ec88635d08df91dbeef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ac615ee175d4c24abf4ac804327b66c",
            "placeholder": "​",
            "style": "IPY_MODEL_ebe4756769db4687b13681fa0d3871c8",
            "value": " 277/277 [00:00&lt;00:00, 3260.31 examples/s]"
          }
        },
        "14ace249903b43fa9efd27c3d33bd3d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e8bd61f61dc42bfaf7bba15d993715b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "482ccabd1ec148ff9f70a62409ae5413": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "aeeaf608b7264e10829a042ef165531a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3340a7e80d34a57bd731eb8af4c30c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ac615ee175d4c24abf4ac804327b66c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ebe4756769db4687b13681fa0d3871c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e5a9f92dacdd42aba2565cc688b26259": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6ce751d3668641908a1eaba1e9617983",
              "IPY_MODEL_d383af551cc0451f81693b8a41c4baae",
              "IPY_MODEL_52d15a82a0da4475a97547a834e92472"
            ],
            "layout": "IPY_MODEL_8b2ae61c48ab432187bdb401d837bcba"
          }
        },
        "6ce751d3668641908a1eaba1e9617983": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d93fd218bf14786b13ff071efb3e431",
            "placeholder": "​",
            "style": "IPY_MODEL_8fa0d2dd49454852a7064639922ce3a5",
            "value": "Map: 100%"
          }
        },
        "d383af551cc0451f81693b8a41c4baae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_726587e2fbca49cf940ff1168911a32d",
            "max": 937,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a4f0b4dda3e74241afbf00790567af79",
            "value": 937
          }
        },
        "52d15a82a0da4475a97547a834e92472": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0b407616052e46db9ed9ebd8a6a620b4",
            "placeholder": "​",
            "style": "IPY_MODEL_d7babf3b96cf4362ab1e013a170c90f0",
            "value": " 937/937 [00:01&lt;00:00, 491.83 examples/s]"
          }
        },
        "8b2ae61c48ab432187bdb401d837bcba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d93fd218bf14786b13ff071efb3e431": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8fa0d2dd49454852a7064639922ce3a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "726587e2fbca49cf940ff1168911a32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4f0b4dda3e74241afbf00790567af79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0b407616052e46db9ed9ebd8a6a620b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7babf3b96cf4362ab1e013a170c90f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "052cc03567bd462fbb1f8c73d53a95e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_16bfe78648c148f19397b2d478655dd3",
              "IPY_MODEL_2d46eaa1dc0542c49fa7e28f4739a9dd",
              "IPY_MODEL_b6dc0e5745a346208213ba88839b52ec"
            ],
            "layout": "IPY_MODEL_aad096bd72984f6faa700f6ccfe55bc8"
          }
        },
        "16bfe78648c148f19397b2d478655dd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dfb27f854d8e4675917b5feeb77a9f49",
            "placeholder": "​",
            "style": "IPY_MODEL_3a019f9deb674dc9a06923f58a7f3015",
            "value": "Map: 100%"
          }
        },
        "2d46eaa1dc0542c49fa7e28f4739a9dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d05c3189060f4e71b6fb2f41b7b8dd08",
            "max": 235,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38effe6673584c05b1f930914caf0258",
            "value": 235
          }
        },
        "b6dc0e5745a346208213ba88839b52ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f621f287d15b4d3c88ad747fe4017678",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf306d1c34f4aa7b63d377593e46704",
            "value": " 235/235 [00:00&lt;00:00, 569.84 examples/s]"
          }
        },
        "aad096bd72984f6faa700f6ccfe55bc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfb27f854d8e4675917b5feeb77a9f49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a019f9deb674dc9a06923f58a7f3015": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d05c3189060f4e71b6fb2f41b7b8dd08": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38effe6673584c05b1f930914caf0258": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "f621f287d15b4d3c88ad747fe4017678": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf306d1c34f4aa7b63d377593e46704": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0615ce80df0f429db75363374f61cca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3d00b1995ae645548bdbea00e6f8431e",
              "IPY_MODEL_3629e135de8c4176a4102d1d5f8e06d0",
              "IPY_MODEL_541150d14e5644cfa78897894d5afb91"
            ],
            "layout": "IPY_MODEL_c490762b2a5541949944eb4e8d97f05f"
          }
        },
        "3d00b1995ae645548bdbea00e6f8431e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ca7a568149824cfe80b8c0ade733079f",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c992dd19904f76b609e53988b5fd67",
            "value": "Map: 100%"
          }
        },
        "3629e135de8c4176a4102d1d5f8e06d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_54212caf83264951a60ca98b7b9f3819",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e6dbe4d6195042debe70e0ed08e5d5d1",
            "value": 14
          }
        },
        "541150d14e5644cfa78897894d5afb91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c6de4b40e984107a374109491f2a21d",
            "placeholder": "​",
            "style": "IPY_MODEL_034e1a5b37b341ec9b6b164aeabb8428",
            "value": " 14/14 [00:00&lt;00:00, 159.02 examples/s]"
          }
        },
        "c490762b2a5541949944eb4e8d97f05f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca7a568149824cfe80b8c0ade733079f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a4c992dd19904f76b609e53988b5fd67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "54212caf83264951a60ca98b7b9f3819": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e6dbe4d6195042debe70e0ed08e5d5d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9c6de4b40e984107a374109491f2a21d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "034e1a5b37b341ec9b6b164aeabb8428": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "fb7a71f0abeb49929cbf97579944383e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d7492606e07b45d6a62b31f0dc777ee0",
              "IPY_MODEL_c0d2ed25aef64202a55a782eccfacefc",
              "IPY_MODEL_c660d50135ef479cac9265760eaeb1c6"
            ],
            "layout": "IPY_MODEL_d2238b001cf14759ad6118fad4fbafe4"
          }
        },
        "d7492606e07b45d6a62b31f0dc777ee0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e5e14b21c7414638b95fc6b0709c80ad",
            "placeholder": "​",
            "style": "IPY_MODEL_4b48910f15844fe7bdae0f71df9c67ed",
            "value": "Map: 100%"
          }
        },
        "c0d2ed25aef64202a55a782eccfacefc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fdbd68e4f0e41b19eb5fa3a3af9ee22",
            "max": 14,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7dc8c9c96e62404ebfa11d59916ebef4",
            "value": 14
          }
        },
        "c660d50135ef479cac9265760eaeb1c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a15c873cba65414aa3659fd8f6e1d0f0",
            "placeholder": "​",
            "style": "IPY_MODEL_099c7a2a1fb34513ba80006b38af592a",
            "value": " 14/14 [00:00&lt;00:00, 199.05 examples/s]"
          }
        },
        "d2238b001cf14759ad6118fad4fbafe4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5e14b21c7414638b95fc6b0709c80ad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b48910f15844fe7bdae0f71df9c67ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0fdbd68e4f0e41b19eb5fa3a3af9ee22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dc8c9c96e62404ebfa11d59916ebef4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a15c873cba65414aa3659fd8f6e1d0f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "099c7a2a1fb34513ba80006b38af592a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f7780089a43488baf155999188f82bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7297bdbb23704f4f93e7d4aa79947f11",
              "IPY_MODEL_e6e41f94ea644a2da529acd3e4c670af",
              "IPY_MODEL_6157724ba257439595dee6838cf21700"
            ],
            "layout": "IPY_MODEL_cd29c37d0ca64bb098d816547519318b"
          }
        },
        "7297bdbb23704f4f93e7d4aa79947f11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_040b52671a824db893aec3e5d4791a67",
            "placeholder": "​",
            "style": "IPY_MODEL_f00a5e4c8e8d41d3a0aa92d690361dfc",
            "value": "Casting to class labels: 100%"
          }
        },
        "e6e41f94ea644a2da529acd3e4c670af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5baa8e95d26849ebbf5c3839c6499474",
            "max": 1381,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_b6955d98c19741c38e3f1b8c73b22f0d",
            "value": 1381
          }
        },
        "6157724ba257439595dee6838cf21700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a442c6e30ac345b2a1e420abec3ec8d9",
            "placeholder": "​",
            "style": "IPY_MODEL_991430bd705a4f21a1ce32d9ce124df5",
            "value": " 1381/1381 [00:00&lt;00:00, 26687.86 examples/s]"
          }
        },
        "cd29c37d0ca64bb098d816547519318b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "040b52671a824db893aec3e5d4791a67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f00a5e4c8e8d41d3a0aa92d690361dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5baa8e95d26849ebbf5c3839c6499474": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b6955d98c19741c38e3f1b8c73b22f0d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a442c6e30ac345b2a1e420abec3ec8d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "991430bd705a4f21a1ce32d9ce124df5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eb34c6b5a14b4b4b94e6490812d3f647": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c4c6bbfc38ed4728b8e482bfcb9188f3",
              "IPY_MODEL_964a01d45c4e4f8fb82f409b5a9ca90b",
              "IPY_MODEL_a165a7b2064740c9bc7b009a3559851e"
            ],
            "layout": "IPY_MODEL_3539b8fdeaa1405e989d6534a5b2d750"
          }
        },
        "c4c6bbfc38ed4728b8e482bfcb9188f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b435faa2531f4e039f6cda2b61ba9f10",
            "placeholder": "​",
            "style": "IPY_MODEL_e5cc7f55cc9a43c8bdb6a1ffcf6ff9b9",
            "value": "config.json: 100%"
          }
        },
        "964a01d45c4e4f8fb82f409b5a9ca90b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a57bd06da8b348fbb41b6f799a3748cb",
            "max": 1206,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4df27aa7c4f04bb0a52dad455ca015d5",
            "value": 1206
          }
        },
        "a165a7b2064740c9bc7b009a3559851e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1a4a4500e704415483cc06e01cfa292a",
            "placeholder": "​",
            "style": "IPY_MODEL_a37375b3666c490b85e4497f40566dc1",
            "value": " 1.21k/1.21k [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "3539b8fdeaa1405e989d6534a5b2d750": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b435faa2531f4e039f6cda2b61ba9f10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5cc7f55cc9a43c8bdb6a1ffcf6ff9b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a57bd06da8b348fbb41b6f799a3748cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4df27aa7c4f04bb0a52dad455ca015d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1a4a4500e704415483cc06e01cfa292a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a37375b3666c490b85e4497f40566dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5fabaaadde044c6f99af9b0dff077bc9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18bd37f03f8642f0ad0f5c079df7c330",
              "IPY_MODEL_3ab062a3537645298e7ad4d8e3eb2c2e",
              "IPY_MODEL_e358ee6b523a4ce0b34eab90fa5a232e"
            ],
            "layout": "IPY_MODEL_d2877b460f344343a09c80742d0b8c15"
          }
        },
        "18bd37f03f8642f0ad0f5c079df7c330": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bc42311f93fe495592040a6c7d933311",
            "placeholder": "​",
            "style": "IPY_MODEL_b273e2714f824a3cb23caad525e0741c",
            "value": "model.safetensors: 100%"
          }
        },
        "3ab062a3537645298e7ad4d8e3eb2c2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed845f529a9c4746ba095c478b984922",
            "max": 242043056,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6865d5e92dc04f5796833b027ac3f3f8",
            "value": 242043056
          }
        },
        "e358ee6b523a4ce0b34eab90fa5a232e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8103a43a49a1465f8dffe5617556b347",
            "placeholder": "​",
            "style": "IPY_MODEL_bce9bd33163f48998cf0515dc1489834",
            "value": " 242M/242M [00:02&lt;00:00, 137MB/s]"
          }
        },
        "d2877b460f344343a09c80742d0b8c15": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc42311f93fe495592040a6c7d933311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b273e2714f824a3cb23caad525e0741c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ed845f529a9c4746ba095c478b984922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6865d5e92dc04f5796833b027ac3f3f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8103a43a49a1465f8dffe5617556b347": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bce9bd33163f48998cf0515dc1489834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b74e8183fd7848f4a46378d94809efec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9eaed3783953471ca4a5ba14a2517228",
              "IPY_MODEL_cda2254ddc72401e9215d6b6a7d41014",
              "IPY_MODEL_7f0fd560f64f49b8882771c0d947d529"
            ],
            "layout": "IPY_MODEL_2b401ee597b34fb49dae9b9ad8dc3001"
          }
        },
        "9eaed3783953471ca4a5ba14a2517228": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_08ccd37a2d694c748c3ae6a1c607d4c8",
            "placeholder": "​",
            "style": "IPY_MODEL_ed513f32795748a980b8eaebc5d8005a",
            "value": "generation_config.json: 100%"
          }
        },
        "cda2254ddc72401e9215d6b6a7d41014": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f12e660caa6142c29ba1c680d4590f41",
            "max": 147,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f5d1bc7810674f149c6a3759ad3cd66d",
            "value": 147
          }
        },
        "7f0fd560f64f49b8882771c0d947d529": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7f249de6554e4079aecbc9d528bd0689",
            "placeholder": "​",
            "style": "IPY_MODEL_c82f4a3586de4bec862ea59e2f60f23e",
            "value": " 147/147 [00:00&lt;00:00, 3.07kB/s]"
          }
        },
        "2b401ee597b34fb49dae9b9ad8dc3001": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ccd37a2d694c748c3ae6a1c607d4c8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed513f32795748a980b8eaebc5d8005a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f12e660caa6142c29ba1c680d4590f41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5d1bc7810674f149c6a3759ad3cd66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7f249de6554e4079aecbc9d528bd0689": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c82f4a3586de4bec862ea59e2f60f23e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c7f1c332c85e40aa963a5654c7833f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_acd36614ea764cdea68d6ab9efbf32f2",
              "IPY_MODEL_e553b5b737b4498aa5ce230661c0a1cb",
              "IPY_MODEL_65c4af3133e34d39bc268427fd63bbce"
            ],
            "layout": "IPY_MODEL_011e9ee215b94f8ea9dbae76544deaae"
          }
        },
        "acd36614ea764cdea68d6ab9efbf32f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a0ffe47c35e64a74894e4ecdab100be5",
            "placeholder": "​",
            "style": "IPY_MODEL_b4005a6d2eb64121b646cac8e2f49ffa",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "e553b5b737b4498aa5ce230661c0a1cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c2506df2c91d49bf80b557dac1c8e8e9",
            "max": 2324,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_c5b6f041ea4141248e31f7dedb5838dd",
            "value": 2324
          }
        },
        "65c4af3133e34d39bc268427fd63bbce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_32167908c72f478598cce9dc4154b16d",
            "placeholder": "​",
            "style": "IPY_MODEL_0d0e99df0cf24295828de46198b96613",
            "value": " 2.32k/2.32k [00:00&lt;00:00, 41.4kB/s]"
          }
        },
        "011e9ee215b94f8ea9dbae76544deaae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a0ffe47c35e64a74894e4ecdab100be5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4005a6d2eb64121b646cac8e2f49ffa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c2506df2c91d49bf80b557dac1c8e8e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5b6f041ea4141248e31f7dedb5838dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "32167908c72f478598cce9dc4154b16d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d0e99df0cf24295828de46198b96613": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a5fb5d7b2b5e441092f9088a8194024b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1b25c73e079a40cda2a4a109d9962698",
              "IPY_MODEL_fd08e9368e644622961dcc6022cfd22f",
              "IPY_MODEL_184ca16523d5406f992b6667322f966f"
            ],
            "layout": "IPY_MODEL_3e717b04406e4129806a033219a70f71"
          }
        },
        "1b25c73e079a40cda2a4a109d9962698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8e1b81f950b34ff5888e66d831e6ec0d",
            "placeholder": "​",
            "style": "IPY_MODEL_f4083d8b4f07419f8ce955853b1acf76",
            "value": "spiece.model: 100%"
          }
        },
        "fd08e9368e644622961dcc6022cfd22f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99a33b7853f943d396af5e6c91cdd20c",
            "max": 791656,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_9ad79b7928ae4eea8841ee5877ea7e64",
            "value": 791656
          }
        },
        "184ca16523d5406f992b6667322f966f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7397e33a1654a73815abb3e1de2a1bc",
            "placeholder": "​",
            "style": "IPY_MODEL_d6a25b89997b45c5ab68d5b22ca4b62f",
            "value": " 792k/792k [00:00&lt;00:00, 12.6MB/s]"
          }
        },
        "3e717b04406e4129806a033219a70f71": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e1b81f950b34ff5888e66d831e6ec0d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4083d8b4f07419f8ce955853b1acf76": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "99a33b7853f943d396af5e6c91cdd20c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9ad79b7928ae4eea8841ee5877ea7e64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7397e33a1654a73815abb3e1de2a1bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6a25b89997b45c5ab68d5b22ca4b62f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "587b93171baa423c8c65a125eba23ec7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8cbb94beae1f4b8aa6ba1277344bbb43",
              "IPY_MODEL_b891ae20bc6c4066b5dbc9a690e3d55b",
              "IPY_MODEL_485709f2ea664e59ac830f36bc16c22a"
            ],
            "layout": "IPY_MODEL_b2a12746ab08406490b09e0885f20d0a"
          }
        },
        "8cbb94beae1f4b8aa6ba1277344bbb43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b4f7cdae5deb47108e0b4fb64582c2ec",
            "placeholder": "​",
            "style": "IPY_MODEL_1e02c97616004d9196a873ed7c106923",
            "value": "tokenizer.json: 100%"
          }
        },
        "b891ae20bc6c4066b5dbc9a690e3d55b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55282e032dc24572b59926e0af5d4e0e",
            "max": 1389353,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_91f8a1008ed04e3796d1cea48b7c9408",
            "value": 1389353
          }
        },
        "485709f2ea664e59ac830f36bc16c22a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7d11e9f975a4f6994a28ea471af2bf4",
            "placeholder": "​",
            "style": "IPY_MODEL_86b2e164208f448c9fa15b595a2b128e",
            "value": " 1.39M/1.39M [00:00&lt;00:00, 21.4MB/s]"
          }
        },
        "b2a12746ab08406490b09e0885f20d0a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b4f7cdae5deb47108e0b4fb64582c2ec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1e02c97616004d9196a873ed7c106923": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55282e032dc24572b59926e0af5d4e0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "91f8a1008ed04e3796d1cea48b7c9408": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b7d11e9f975a4f6994a28ea471af2bf4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "86b2e164208f448c9fa15b595a2b128e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8b30e98d2b344c288bd7f9b1b042411": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_b34416d3e9564af1ac60e3b644f1c3f6",
              "IPY_MODEL_9cc52a2766b74c22995dc0f38dac414e",
              "IPY_MODEL_6621fc6825e645bc99c7e8a9e3f1c1fd"
            ],
            "layout": "IPY_MODEL_5c28eb61ef9e4dfca3df0de4c755886a"
          }
        },
        "b34416d3e9564af1ac60e3b644f1c3f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_895654bd36654f6cb104fb980d33c4b5",
            "placeholder": "​",
            "style": "IPY_MODEL_0d4142c93b114ccf8385f18bcea72d79",
            "value": "config.json: 100%"
          }
        },
        "9cc52a2766b74c22995dc0f38dac414e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f795a9c30e134620a7bdaf203947864c",
            "max": 451,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_32b2abcc142e4d9ebe5129da3dd4f9ee",
            "value": 451
          }
        },
        "6621fc6825e645bc99c7e8a9e3f1c1fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c8e275c342d848b09ef9a2b0099512f9",
            "placeholder": "​",
            "style": "IPY_MODEL_01dc3796b8a34494905604aa3a67063f",
            "value": " 451/451 [00:00&lt;00:00, 7.07kB/s]"
          }
        },
        "5c28eb61ef9e4dfca3df0de4c755886a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "895654bd36654f6cb104fb980d33c4b5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0d4142c93b114ccf8385f18bcea72d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f795a9c30e134620a7bdaf203947864c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "32b2abcc142e4d9ebe5129da3dd4f9ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c8e275c342d848b09ef9a2b0099512f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "01dc3796b8a34494905604aa3a67063f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c49b2c99d64041eb806e43c07f9a1f67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_229b28c1a2324202b2a41e40839846e3",
              "IPY_MODEL_6638e2738a544982b37cb387e2cbe0ae",
              "IPY_MODEL_d1324178dc6f4b6e9f162c6b802ed037"
            ],
            "layout": "IPY_MODEL_2dca1601f4be402597b940a7a93b2793"
          }
        },
        "229b28c1a2324202b2a41e40839846e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2469465147ce49479d49f8fd16b3f379",
            "placeholder": "​",
            "style": "IPY_MODEL_e5dcf07bfb8443488d8c17723c0a54e0",
            "value": "model.safetensors: 100%"
          }
        },
        "6638e2738a544982b37cb387e2cbe0ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de849a9303424458a05da695e5360857",
            "max": 265470036,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_3e82b0dd7af1420e9490b35c3144e8cc",
            "value": 265470036
          }
        },
        "d1324178dc6f4b6e9f162c6b802ed037": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b5c3165146784cc5b5f3b88cdf512dc2",
            "placeholder": "​",
            "style": "IPY_MODEL_8a43371a99d54ab6bf62b184c8ff962d",
            "value": " 265M/265M [00:03&lt;00:00, 88.5MB/s]"
          }
        },
        "2dca1601f4be402597b940a7a93b2793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2469465147ce49479d49f8fd16b3f379": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5dcf07bfb8443488d8c17723c0a54e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de849a9303424458a05da695e5360857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e82b0dd7af1420e9490b35c3144e8cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b5c3165146784cc5b5f3b88cdf512dc2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a43371a99d54ab6bf62b184c8ff962d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "73ea0d7f1a2a4b118ee604ee96ad75c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e12a6bbca7a144b0bb451cfeb700cf36",
              "IPY_MODEL_302248e8c4a646bc91cdcc53ea1368cf",
              "IPY_MODEL_7479987a7f144839b484588e1c16efd6"
            ],
            "layout": "IPY_MODEL_fc5cdad26781498ba478a9c64f75d30b"
          }
        },
        "e12a6bbca7a144b0bb451cfeb700cf36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_de9afaeb85fa4f518c65f8b7f80d6f5f",
            "placeholder": "​",
            "style": "IPY_MODEL_1a5e05e1d0ba472bab439eb3e17198dc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "302248e8c4a646bc91cdcc53ea1368cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e1573e3ad1884ff5939e1f5e510a0135",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7696b55f4ab94560ad1c15ee6fad298d",
            "value": 48
          }
        },
        "7479987a7f144839b484588e1c16efd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c95f3435bd8c48c9b73f6f455cef9b8f",
            "placeholder": "​",
            "style": "IPY_MODEL_133cc4b712ac402895a4cf2b258b6ef5",
            "value": " 48.0/48.0 [00:00&lt;00:00, 862B/s]"
          }
        },
        "fc5cdad26781498ba478a9c64f75d30b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de9afaeb85fa4f518c65f8b7f80d6f5f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1a5e05e1d0ba472bab439eb3e17198dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e1573e3ad1884ff5939e1f5e510a0135": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7696b55f4ab94560ad1c15ee6fad298d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c95f3435bd8c48c9b73f6f455cef9b8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "133cc4b712ac402895a4cf2b258b6ef5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d21916ceaa564f7ea6f95701a21e97a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_dfdd2b9d40ab496b9e2599b92759b5db",
              "IPY_MODEL_be559ffc42784598a93fcfa9c139c29e",
              "IPY_MODEL_15099752963c40cdb56c199a2591db43"
            ],
            "layout": "IPY_MODEL_0b07f6d346e44245b61191abbb58bd38"
          }
        },
        "dfdd2b9d40ab496b9e2599b92759b5db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8252be69a164d4289e70caf50d58902",
            "placeholder": "​",
            "style": "IPY_MODEL_2e56d5610304485babb0bbc708aa0fbd",
            "value": "vocab.txt: 100%"
          }
        },
        "be559ffc42784598a93fcfa9c139c29e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_eeb8a2357d68410f83252faaf536701b",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a9c7d45ef2ec40cea6477d70865f9171",
            "value": 231508
          }
        },
        "15099752963c40cdb56c199a2591db43": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b241630860584ad999a274beae71d5d6",
            "placeholder": "​",
            "style": "IPY_MODEL_67d0ceb4ce5e4a7ebf768ceff78b57c3",
            "value": " 232k/232k [00:00&lt;00:00, 3.73MB/s]"
          }
        },
        "0b07f6d346e44245b61191abbb58bd38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8252be69a164d4289e70caf50d58902": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2e56d5610304485babb0bbc708aa0fbd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "eeb8a2357d68410f83252faaf536701b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9c7d45ef2ec40cea6477d70865f9171": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b241630860584ad999a274beae71d5d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67d0ceb4ce5e4a7ebf768ceff78b57c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9c951dc0e1144e998bc4c6b73385952b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_146012a71fec408bbe0ab7eaf69e6986",
              "IPY_MODEL_8320c9d6adac4512a008f33f9a066038",
              "IPY_MODEL_554bc975a5c848c994f7767c0e65ad4a"
            ],
            "layout": "IPY_MODEL_157198d387024822ad325e97a2f3bc24"
          }
        },
        "146012a71fec408bbe0ab7eaf69e6986": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc3b0c2d989946bca998c124bef90822",
            "placeholder": "​",
            "style": "IPY_MODEL_d3731f6405d74568a424b3c8f457efa7",
            "value": "tokenizer.json: 100%"
          }
        },
        "8320c9d6adac4512a008f33f9a066038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dbda707a7704cb2bff31d2fb351a70f",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_365eb48747a240818ab473b1726b42eb",
            "value": 466062
          }
        },
        "554bc975a5c848c994f7767c0e65ad4a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e93112e88bd4472ba82e4c177f075d20",
            "placeholder": "​",
            "style": "IPY_MODEL_df4b0c92209144d3be2aca5739f0d9fb",
            "value": " 466k/466k [00:00&lt;00:00, 4.68MB/s]"
          }
        },
        "157198d387024822ad325e97a2f3bc24": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cc3b0c2d989946bca998c124bef90822": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d3731f6405d74568a424b3c8f457efa7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7dbda707a7704cb2bff31d2fb351a70f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "365eb48747a240818ab473b1726b42eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e93112e88bd4472ba82e4c177f075d20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df4b0c92209144d3be2aca5739f0d9fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f39c44efbc4b4c35a34920895d037d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e08697926ee0451ba181f1466dd71eda",
              "IPY_MODEL_7fb8bb6d2c6c4f98bbe100d4914ce504",
              "IPY_MODEL_90407ae9328941d7bb91528f94e0bd40"
            ],
            "layout": "IPY_MODEL_6890d881c3ae4d94b6215c407e01502a"
          }
        },
        "e08697926ee0451ba181f1466dd71eda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_349bed5c42c14b89a39a401a34bf1b60",
            "placeholder": "​",
            "style": "IPY_MODEL_ad10b446b02a4a8fb6ca326551b19da7",
            "value": "Downloading builder script: 100%"
          }
        },
        "7fb8bb6d2c6c4f98bbe100d4914ce504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59ab57c2d94e4b82b2e3b8080c7f763c",
            "max": 4203,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_f7ca2261bc734092ba3ea7512e034656",
            "value": 4203
          }
        },
        "90407ae9328941d7bb91528f94e0bd40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d05088db2bb40e8993ecf040213845c",
            "placeholder": "​",
            "style": "IPY_MODEL_438979ebecd1401eb8fd3a0ab7449d31",
            "value": " 4.20k/4.20k [00:00&lt;00:00, 102kB/s]"
          }
        },
        "6890d881c3ae4d94b6215c407e01502a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "349bed5c42c14b89a39a401a34bf1b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ad10b446b02a4a8fb6ca326551b19da7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59ab57c2d94e4b82b2e3b8080c7f763c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f7ca2261bc734092ba3ea7512e034656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "9d05088db2bb40e8993ecf040213845c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "438979ebecd1401eb8fd3a0ab7449d31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "377026b5aeec408394b8685699e771fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_21a0e768c04c4939a2aca35e97b33a31",
              "IPY_MODEL_cdf20f57dbd24acf891baffa4c6c61d7",
              "IPY_MODEL_3450a8d462c74db8aa975d83ff123cec"
            ],
            "layout": "IPY_MODEL_01272869449b489c9be96d1f6a272478"
          }
        },
        "21a0e768c04c4939a2aca35e97b33a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_52e9c0d60a60482ab5e7c8df2ab4ffb8",
            "placeholder": "​",
            "style": "IPY_MODEL_4e3079b223804fa0990f0041916b4af1",
            "value": "Downloading builder script: 100%"
          }
        },
        "cdf20f57dbd24acf891baffa4c6c61d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7b74da1b96834fddb2deed892a44ac0c",
            "max": 6785,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4bdf935b4955491b94e25fe2a57a833d",
            "value": 6785
          }
        },
        "3450a8d462c74db8aa975d83ff123cec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9b748fbacac4ce0b98d755fb80203e8",
            "placeholder": "​",
            "style": "IPY_MODEL_9825f96414f94eb4bdaa3adb47e7a579",
            "value": " 6.79k/6.79k [00:00&lt;00:00, 95.1kB/s]"
          }
        },
        "01272869449b489c9be96d1f6a272478": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52e9c0d60a60482ab5e7c8df2ab4ffb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e3079b223804fa0990f0041916b4af1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b74da1b96834fddb2deed892a44ac0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4bdf935b4955491b94e25fe2a57a833d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e9b748fbacac4ce0b98d755fb80203e8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9825f96414f94eb4bdaa3adb47e7a579": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ea31951510864140a3ab9faf61b63ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_28468b86e4d244e2b6cbe74ec14f53b0",
              "IPY_MODEL_fabd428c9d9c407aa772928ce7a7ed79",
              "IPY_MODEL_d893295253f842709493eb84b47c3db1"
            ],
            "layout": "IPY_MODEL_d93236e3a49e4bea973e7ebbec01259a"
          }
        },
        "28468b86e4d244e2b6cbe74ec14f53b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5eb06fd7bda44c598a0d2c2dc32379df",
            "placeholder": "​",
            "style": "IPY_MODEL_ccfcd3626bed452ca44f267db7ed87e1",
            "value": "Downloading builder script: 100%"
          }
        },
        "fabd428c9d9c407aa772928ce7a7ed79": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b1585ea2645b4ee1b255dfd629b8e9a5",
            "max": 7560,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ed0d015b9f304a4bad825c9f12983917",
            "value": 7560
          }
        },
        "d893295253f842709493eb84b47c3db1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6dd409cd568a45b6b5e387af8658c25b",
            "placeholder": "​",
            "style": "IPY_MODEL_200c46c388284cebaa8ca57b0cf2ee1e",
            "value": " 7.56k/7.56k [00:00&lt;00:00, 149kB/s]"
          }
        },
        "d93236e3a49e4bea973e7ebbec01259a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5eb06fd7bda44c598a0d2c2dc32379df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccfcd3626bed452ca44f267db7ed87e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1585ea2645b4ee1b255dfd629b8e9a5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed0d015b9f304a4bad825c9f12983917": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6dd409cd568a45b6b5e387af8658c25b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "200c46c388284cebaa8ca57b0cf2ee1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1998430c8a5747d48db003dca1aac8c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79fc64f597134afdaf4dfd2fbd70a682",
              "IPY_MODEL_e0d76a1fe1934a6ea4cd26aceabb9460",
              "IPY_MODEL_3c59cb541ba24ee9aeac4dbaf1fc0c02"
            ],
            "layout": "IPY_MODEL_f5d32fa2c344405ea7e35887577e1853"
          }
        },
        "79fc64f597134afdaf4dfd2fbd70a682": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_33f8b91e008d4156b7c5d96d16ad15de",
            "placeholder": "​",
            "style": "IPY_MODEL_7fc5ece4e8c24900a00c83f77189d300",
            "value": "Downloading builder script: 100%"
          }
        },
        "e0d76a1fe1934a6ea4cd26aceabb9460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_958d5d569efc49e78975e0d6545fd216",
            "max": 7377,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6356ff5b16f14371aae5a8f7f48301a9",
            "value": 7377
          }
        },
        "3c59cb541ba24ee9aeac4dbaf1fc0c02": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c261c196eae34e80b84e9349e5173300",
            "placeholder": "​",
            "style": "IPY_MODEL_dfbb8afe7de64c1fa65a7301fdc58b38",
            "value": " 7.38k/7.38k [00:00&lt;00:00, 166kB/s]"
          }
        },
        "f5d32fa2c344405ea7e35887577e1853": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f8b91e008d4156b7c5d96d16ad15de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7fc5ece4e8c24900a00c83f77189d300": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "958d5d569efc49e78975e0d6545fd216": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6356ff5b16f14371aae5a8f7f48301a9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c261c196eae34e80b84e9349e5173300": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dfbb8afe7de64c1fa65a7301fdc58b38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "baad341cfbea4448a2bb24e562d814f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_901c536c210a41a48c2c56e925653229",
              "IPY_MODEL_f42920e381024f6c892da8fd80e87027",
              "IPY_MODEL_433c09ee9b0b42b5b8df30a48e22a154"
            ],
            "layout": "IPY_MODEL_b505b46fbd9046e4b0773d5a87e37aa4"
          }
        },
        "901c536c210a41a48c2c56e925653229": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7ae117c01e324939b61244a58a712559",
            "placeholder": "​",
            "style": "IPY_MODEL_02f877f7b1f344b2b479addf5cac5ff0",
            "value": "Downloading builder script: 100%"
          }
        },
        "f42920e381024f6c892da8fd80e87027": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_91501c46ac774d1d9da21c1dd061a3a7",
            "max": 5669,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08fc50dc93eb4b6c88e3ea8b16bfd2f6",
            "value": 5669
          }
        },
        "433c09ee9b0b42b5b8df30a48e22a154": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2d028ff075404d1b8ea84964946ed64a",
            "placeholder": "​",
            "style": "IPY_MODEL_1d5d71d8e1244d3e8ec905b6957ae895",
            "value": " 5.67k/5.67k [00:00&lt;00:00, 100kB/s]"
          }
        },
        "b505b46fbd9046e4b0773d5a87e37aa4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7ae117c01e324939b61244a58a712559": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "02f877f7b1f344b2b479addf5cac5ff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "91501c46ac774d1d9da21c1dd061a3a7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08fc50dc93eb4b6c88e3ea8b16bfd2f6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d028ff075404d1b8ea84964946ed64a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d5d71d8e1244d3e8ec905b6957ae895": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b3417cfcc0f048029c99603cd54d6233": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fc6628435c6947529b876afdff0122cf",
              "IPY_MODEL_147df80d777843c5b758670edb3e100e",
              "IPY_MODEL_d5fbc7b899e0471492928fce3eb123b2"
            ],
            "layout": "IPY_MODEL_9cd6f2ac7e4249eb88fa78bb5ca9dc2f"
          }
        },
        "fc6628435c6947529b876afdff0122cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d7e2616cfbec46e88cfd58c1109af9b8",
            "placeholder": "​",
            "style": "IPY_MODEL_cd0ec660e8074398a653a0071420b364",
            "value": "config.json: 100%"
          }
        },
        "147df80d777843c5b758670edb3e100e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a640fc8b8d949c29bcf612c811daedb",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e43a9515068e42a4b94be5277d9b5ae2",
            "value": 684
          }
        },
        "d5fbc7b899e0471492928fce3eb123b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4586db1b2904473d8d12d6bb5deedb1b",
            "placeholder": "​",
            "style": "IPY_MODEL_ff8587a345fb4fe0b0e60a0237143ea4",
            "value": " 684/684 [00:00&lt;00:00, 13.8kB/s]"
          }
        },
        "9cd6f2ac7e4249eb88fa78bb5ca9dc2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7e2616cfbec46e88cfd58c1109af9b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd0ec660e8074398a653a0071420b364": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8a640fc8b8d949c29bcf612c811daedb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e43a9515068e42a4b94be5277d9b5ae2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4586db1b2904473d8d12d6bb5deedb1b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff8587a345fb4fe0b0e60a0237143ea4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98415c2c92694dee9f20672ed891271e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_94e399e8870a4506ae1795fc1a1ff2a4",
              "IPY_MODEL_008296480d95424191982cde18059f69",
              "IPY_MODEL_99e18304a2204561bdce18a102c2624a"
            ],
            "layout": "IPY_MODEL_e0f76008b215496c9ac242e9b7bab4b1"
          }
        },
        "94e399e8870a4506ae1795fc1a1ff2a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_102a63d1e8654abfb8b1a44b5248b070",
            "placeholder": "​",
            "style": "IPY_MODEL_b3a066628cfd4842841628d01e55674f",
            "value": "config.json: 100%"
          }
        },
        "008296480d95424191982cde18059f69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f6787c4f0ea1443d98438a5fac19b7c5",
            "max": 684,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e909889b87644000b5c63cdb1d609a3b",
            "value": 684
          }
        },
        "99e18304a2204561bdce18a102c2624a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2903c770c49a48b5b389404aed9d1759",
            "placeholder": "​",
            "style": "IPY_MODEL_f22c3359658f4111b60a8b20dfa02bee",
            "value": " 684/684 [00:00&lt;00:00, 12.6kB/s]"
          }
        },
        "e0f76008b215496c9ac242e9b7bab4b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "102a63d1e8654abfb8b1a44b5248b070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b3a066628cfd4842841628d01e55674f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f6787c4f0ea1443d98438a5fac19b7c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e909889b87644000b5c63cdb1d609a3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2903c770c49a48b5b389404aed9d1759": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f22c3359658f4111b60a8b20dfa02bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0da050df2e52482fb51b0fa66a98150d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f65e8de343ef488ebda4b5d699e97ca5",
              "IPY_MODEL_0d273a9302ce461c81518e09e39a04e7",
              "IPY_MODEL_9557be24330c4eb69673779cfaecb598"
            ],
            "layout": "IPY_MODEL_ed273da053c0445c9ca6eed0fb709934"
          }
        },
        "f65e8de343ef488ebda4b5d699e97ca5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_345e50e554494350a74a24df99f7f4ff",
            "placeholder": "​",
            "style": "IPY_MODEL_71254db339d643c99af7751213f55c44",
            "value": "model.safetensors: 100%"
          }
        },
        "0d273a9302ce461c81518e09e39a04e7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_74564c057b6a4a5796d5ffe50644208d",
            "max": 47372894,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4d388692ebe14fd7bfc6cbd107287a91",
            "value": 47372894
          }
        },
        "9557be24330c4eb69673779cfaecb598": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0550cdc1c76d45e4bef64ac87cbf7a43",
            "placeholder": "​",
            "style": "IPY_MODEL_fce5df8e411f4df8a11f9a94d9ee7ddc",
            "value": " 47.4M/47.4M [00:00&lt;00:00, 165MB/s]"
          }
        },
        "ed273da053c0445c9ca6eed0fb709934": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "345e50e554494350a74a24df99f7f4ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71254db339d643c99af7751213f55c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "74564c057b6a4a5796d5ffe50644208d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d388692ebe14fd7bfc6cbd107287a91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0550cdc1c76d45e4bef64ac87cbf7a43": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fce5df8e411f4df8a11f9a94d9ee7ddc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f60150445cbe4e8b874c4115dac88b59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_11638fd3e84349808d7409ca648eff98",
              "IPY_MODEL_b715ddccaf374696bf7d2958902578a3",
              "IPY_MODEL_16918f1492554e82b69f90d8e315755d"
            ],
            "layout": "IPY_MODEL_6917b15fb1d845ccb4de7e0993375837"
          }
        },
        "11638fd3e84349808d7409ca648eff98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_979233db488c4474855fe692353b6e9f",
            "placeholder": "​",
            "style": "IPY_MODEL_e403fa5c929e4142b037073bca1bbe64",
            "value": "config.json: 100%"
          }
        },
        "b715ddccaf374696bf7d2958902578a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_481bd2848a6244b7ab83bef89ba4cea8",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ab04d649afde4b8ba477fdb8a342b4df",
            "value": 570
          }
        },
        "16918f1492554e82b69f90d8e315755d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5519073c9e684bcc8db6bb35d78f6426",
            "placeholder": "​",
            "style": "IPY_MODEL_cd1d3233055b48f18a889a6dcfa81700",
            "value": " 570/570 [00:00&lt;00:00, 42.1kB/s]"
          }
        },
        "6917b15fb1d845ccb4de7e0993375837": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "979233db488c4474855fe692353b6e9f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e403fa5c929e4142b037073bca1bbe64": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "481bd2848a6244b7ab83bef89ba4cea8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab04d649afde4b8ba477fdb8a342b4df": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5519073c9e684bcc8db6bb35d78f6426": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd1d3233055b48f18a889a6dcfa81700": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5b222a6d76ac4e9198b5d7466ddc7896": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6feb442af21845ccbfc0584c3b1cbb2c",
              "IPY_MODEL_99902225999140f99224fb61e9b7c7c2",
              "IPY_MODEL_dd39e389b3c34899b5f0db0c22bc29c5"
            ],
            "layout": "IPY_MODEL_6c3b5c26925b48999c7dfa4eb808ad3d"
          }
        },
        "6feb442af21845ccbfc0584c3b1cbb2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1d8d413305864d2f98209f17284d4e41",
            "placeholder": "​",
            "style": "IPY_MODEL_1b158fba7d9f4c5899daa2bc7c90c2e8",
            "value": "model.safetensors: 100%"
          }
        },
        "99902225999140f99224fb61e9b7c7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_24e515ae70c347e08719282f0e1323f1",
            "max": 435755784,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_31860be7690e4ff0ab726db11b791e48",
            "value": 435755784
          }
        },
        "dd39e389b3c34899b5f0db0c22bc29c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b3021fb5281e421bbdd3ee6b16f8b792",
            "placeholder": "​",
            "style": "IPY_MODEL_736ba52c477247b381100ea584596251",
            "value": " 436M/436M [00:08&lt;00:00, 75.2MB/s]"
          }
        },
        "6c3b5c26925b48999c7dfa4eb808ad3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1d8d413305864d2f98209f17284d4e41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1b158fba7d9f4c5899daa2bc7c90c2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "24e515ae70c347e08719282f0e1323f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "31860be7690e4ff0ab726db11b791e48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "b3021fb5281e421bbdd3ee6b16f8b792": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "736ba52c477247b381100ea584596251": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a1e4d05f1b6844e39bdf73704a60a03c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8486aaefe5cc43d38997b26c24d2eb9d",
              "IPY_MODEL_1a17790140fd4849841ba4f60e3ebbf4",
              "IPY_MODEL_cd3189d50e60438cac660f281c80e060"
            ],
            "layout": "IPY_MODEL_d5802f967cde45dcb62a790f96e04b16"
          }
        },
        "8486aaefe5cc43d38997b26c24d2eb9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2cb6fabb24d44d2e843d63fcabdc305c",
            "placeholder": "​",
            "style": "IPY_MODEL_366186f214da468e80014297df4535f3",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "1a17790140fd4849841ba4f60e3ebbf4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6a91c0741071406cb51794a6be89fbf6",
            "max": 49,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_409464a192e94d019e50fdeb99aac606",
            "value": 49
          }
        },
        "cd3189d50e60438cac660f281c80e060": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ef6ce791c8f477f951c6166f4b0aa84",
            "placeholder": "​",
            "style": "IPY_MODEL_7dd622e926c04e6eb1c5b9d479f69ea5",
            "value": " 49.0/49.0 [00:00&lt;00:00, 2.01kB/s]"
          }
        },
        "d5802f967cde45dcb62a790f96e04b16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2cb6fabb24d44d2e843d63fcabdc305c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "366186f214da468e80014297df4535f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6a91c0741071406cb51794a6be89fbf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "409464a192e94d019e50fdeb99aac606": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ef6ce791c8f477f951c6166f4b0aa84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7dd622e926c04e6eb1c5b9d479f69ea5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae83b688f1bf40638a91e437b56de1bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffddf66fcf4645eba6cd5c586914ac5d",
              "IPY_MODEL_91543d134e0b426f8d457cf171675d26",
              "IPY_MODEL_f0b51069006943769fab4d42858bb13d"
            ],
            "layout": "IPY_MODEL_87802be71be74d4a913b9ffb94b38de8"
          }
        },
        "ffddf66fcf4645eba6cd5c586914ac5d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0687b2511c2c46909c56de6302892bd0",
            "placeholder": "​",
            "style": "IPY_MODEL_15dfdd3218f64ada9ccebe5977333ee7",
            "value": "vocab.txt: 100%"
          }
        },
        "91543d134e0b426f8d457cf171675d26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df4713493f7d463fb4f60d38172d7179",
            "max": 213450,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_386ca7cf669646a89f18b4a7a97647bc",
            "value": 213450
          }
        },
        "f0b51069006943769fab4d42858bb13d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4c6e18b230f6471ab7d4ce731d75c6ae",
            "placeholder": "​",
            "style": "IPY_MODEL_471a429397f94801af54c8b7c73acc36",
            "value": " 213k/213k [00:00&lt;00:00, 2.97MB/s]"
          }
        },
        "87802be71be74d4a913b9ffb94b38de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0687b2511c2c46909c56de6302892bd0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "15dfdd3218f64ada9ccebe5977333ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "df4713493f7d463fb4f60d38172d7179": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "386ca7cf669646a89f18b4a7a97647bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4c6e18b230f6471ab7d4ce731d75c6ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "471a429397f94801af54c8b7c73acc36": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ec008061dee949949aac7fe5f125bdd6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9ac9431891a3452fad91e89a6cf3edfb",
              "IPY_MODEL_78887b2ba3194bd3ad5b292b8b294f8a",
              "IPY_MODEL_e2868fc4c6744212b99a3594dd737627"
            ],
            "layout": "IPY_MODEL_82d2707071944813805b11ee070a5919"
          }
        },
        "9ac9431891a3452fad91e89a6cf3edfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_87a8d0d256c04142a09a72157749689d",
            "placeholder": "​",
            "style": "IPY_MODEL_8a7c650090fa4aeca911bf030911ca82",
            "value": "tokenizer.json: 100%"
          }
        },
        "78887b2ba3194bd3ad5b292b8b294f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_058ebb992b6141d39f2eeac443c56f92",
            "max": 435797,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e3642b071cb24350ab93e37ca247a7cd",
            "value": 435797
          }
        },
        "e2868fc4c6744212b99a3594dd737627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d14dd5c0c5d444739364f0414f301fb8",
            "placeholder": "​",
            "style": "IPY_MODEL_028a00e4541e4fcfb9a68f7ef1d06ff6",
            "value": " 436k/436k [00:00&lt;00:00, 5.65MB/s]"
          }
        },
        "82d2707071944813805b11ee070a5919": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "87a8d0d256c04142a09a72157749689d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a7c650090fa4aeca911bf030911ca82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "058ebb992b6141d39f2eeac443c56f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3642b071cb24350ab93e37ca247a7cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d14dd5c0c5d444739364f0414f301fb8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "028a00e4541e4fcfb9a68f7ef1d06ff6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c0f6519513c740cc95bef09a5cf1bdb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_edae1145cfbd4029844a2d08fc321299",
              "IPY_MODEL_e8b0ebb7cb0a4e98b907af2f7dfe3c7e",
              "IPY_MODEL_16e2f766ef2b419f9172883dadb3b844"
            ],
            "layout": "IPY_MODEL_dc477df027f5496098215fe1dd35d1af"
          }
        },
        "edae1145cfbd4029844a2d08fc321299": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2741fee796394ea18807271a28490f23",
            "placeholder": "​",
            "style": "IPY_MODEL_e4c29ac49085492d842984ffbabe0d1f",
            "value": "config.json: 100%"
          }
        },
        "e8b0ebb7cb0a4e98b907af2f7dfe3c7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ceb1a508e135485795d6e242475cb9f3",
            "max": 481,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4909afe8f64e40f7b9c7470e8597274c",
            "value": 481
          }
        },
        "16e2f766ef2b419f9172883dadb3b844": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef0046d8936042a8b567e3894b0a2445",
            "placeholder": "​",
            "style": "IPY_MODEL_e5705d2ff9aa463f959ae706e6619634",
            "value": " 481/481 [00:00&lt;00:00, 23.1kB/s]"
          }
        },
        "dc477df027f5496098215fe1dd35d1af": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2741fee796394ea18807271a28490f23": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e4c29ac49085492d842984ffbabe0d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ceb1a508e135485795d6e242475cb9f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4909afe8f64e40f7b9c7470e8597274c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef0046d8936042a8b567e3894b0a2445": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5705d2ff9aa463f959ae706e6619634": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "56c84e45d215489bbe703a473444daaa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9c1327851ce34d4c8e25f7138e6381d7",
              "IPY_MODEL_513dbeb54bec478699868fd731c888a0",
              "IPY_MODEL_cc79a948337c45769bc3142ab7c867cd"
            ],
            "layout": "IPY_MODEL_f3049f7783674f869f53bed14af51d86"
          }
        },
        "9c1327851ce34d4c8e25f7138e6381d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b82d0d9635a74d2891367467cdd9227d",
            "placeholder": "​",
            "style": "IPY_MODEL_d74cf150ec4d4091848582e5df6a7182",
            "value": "model.safetensors: 100%"
          }
        },
        "513dbeb54bec478699868fd731c888a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9d4e670d9e8e4ad4916a16a7f5f66550",
            "max": 498818054,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_66eb4cdcfb9d4f2d8fb65f7e89fd2d90",
            "value": 498818054
          }
        },
        "cc79a948337c45769bc3142ab7c867cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_605862d5ffd34e6ba29470c1992de93a",
            "placeholder": "​",
            "style": "IPY_MODEL_2bb4f61963784f08bd173c3eefcfda38",
            "value": " 499M/499M [00:06&lt;00:00, 107MB/s]"
          }
        },
        "f3049f7783674f869f53bed14af51d86": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b82d0d9635a74d2891367467cdd9227d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d74cf150ec4d4091848582e5df6a7182": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9d4e670d9e8e4ad4916a16a7f5f66550": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "66eb4cdcfb9d4f2d8fb65f7e89fd2d90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "605862d5ffd34e6ba29470c1992de93a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2bb4f61963784f08bd173c3eefcfda38": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "30b18058d7ae4d99a8312254a644d68a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_18268add51d24302b070da22d4f49f55",
              "IPY_MODEL_7abe26d0564b4137af53cc3f44c32667",
              "IPY_MODEL_6fe0d41d423e4f98bdd92f49f1fabe1a"
            ],
            "layout": "IPY_MODEL_e62ffed94df14960a1856fce074d8b8d"
          }
        },
        "18268add51d24302b070da22d4f49f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_260fd4e7c9804cf0b2bc1f0e431b2cff",
            "placeholder": "​",
            "style": "IPY_MODEL_0aa3fa72338946469e41f77d49eb3be9",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "7abe26d0564b4137af53cc3f44c32667": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6ee5eb83069a4c93aed9464f0c58a134",
            "max": 25,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_569b500cb6db4d40b92dd0cacd339c5a",
            "value": 25
          }
        },
        "6fe0d41d423e4f98bdd92f49f1fabe1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e6079f20ce24644bf0952a6bf9cfad3",
            "placeholder": "​",
            "style": "IPY_MODEL_799e163274304a3cab546d95056339d6",
            "value": " 25.0/25.0 [00:00&lt;00:00, 1.84kB/s]"
          }
        },
        "e62ffed94df14960a1856fce074d8b8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "260fd4e7c9804cf0b2bc1f0e431b2cff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0aa3fa72338946469e41f77d49eb3be9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6ee5eb83069a4c93aed9464f0c58a134": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "569b500cb6db4d40b92dd0cacd339c5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5e6079f20ce24644bf0952a6bf9cfad3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "799e163274304a3cab546d95056339d6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e16174787fa7461fac9046eaf9584ed2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_8b49eb4063d24d05b6b829b89bcb2bd4",
              "IPY_MODEL_8f8a211434084670bb3ad76fad5aa60a",
              "IPY_MODEL_688706ee32634604a9a906fb4175d25c"
            ],
            "layout": "IPY_MODEL_02b713a1bb6e4be4977164f3eede2efb"
          }
        },
        "8b49eb4063d24d05b6b829b89bcb2bd4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_71471468d62b4eeea7c1485501cc91b2",
            "placeholder": "​",
            "style": "IPY_MODEL_9f2f9bc472184f0db9200775879d65c0",
            "value": "vocab.json: 100%"
          }
        },
        "8f8a211434084670bb3ad76fad5aa60a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bbf3d433907448cbaa53cdb6bd8472e",
            "max": 898823,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_58bb86bb5a564b5280ad47c3569daad5",
            "value": 898823
          }
        },
        "688706ee32634604a9a906fb4175d25c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3a073fec2e13430f9c86eaf5cc87594a",
            "placeholder": "​",
            "style": "IPY_MODEL_cb21c27e39464108a75408e76efaa94a",
            "value": " 899k/899k [00:00&lt;00:00, 8.60MB/s]"
          }
        },
        "02b713a1bb6e4be4977164f3eede2efb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71471468d62b4eeea7c1485501cc91b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f2f9bc472184f0db9200775879d65c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8bbf3d433907448cbaa53cdb6bd8472e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58bb86bb5a564b5280ad47c3569daad5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "3a073fec2e13430f9c86eaf5cc87594a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb21c27e39464108a75408e76efaa94a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4444d29c3cbc4fb683cffc30e62098bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d1b75a7fb79540bc934e8287e646e709",
              "IPY_MODEL_53d6ded5766245ccae496abc1f3861ba",
              "IPY_MODEL_4dc74fb4af3644a4aa7ceb7a4011d086"
            ],
            "layout": "IPY_MODEL_f60712f269b04e2ebab8b25e0cd46935"
          }
        },
        "d1b75a7fb79540bc934e8287e646e709": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d162db941e24943acb027b04d5b928d",
            "placeholder": "​",
            "style": "IPY_MODEL_670fbddbd9bf4c539f9fe358a5f52476",
            "value": "merges.txt: 100%"
          }
        },
        "53d6ded5766245ccae496abc1f3861ba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_59c2a1bda2fa493a8f88acae07d54401",
            "max": 456318,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_04be63f69ce84956a716d9d232d489c1",
            "value": 456318
          }
        },
        "4dc74fb4af3644a4aa7ceb7a4011d086": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20e15dcff64b4509982987b035d264e9",
            "placeholder": "​",
            "style": "IPY_MODEL_095799e540884d00b9c04159323e540f",
            "value": " 456k/456k [00:00&lt;00:00, 10.5MB/s]"
          }
        },
        "f60712f269b04e2ebab8b25e0cd46935": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6d162db941e24943acb027b04d5b928d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "670fbddbd9bf4c539f9fe358a5f52476": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "59c2a1bda2fa493a8f88acae07d54401": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04be63f69ce84956a716d9d232d489c1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "20e15dcff64b4509982987b035d264e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "095799e540884d00b9c04159323e540f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7b7664eb52a84223bda4067f12b2d1fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e1aaca525bf424397ad1ff9ed91ce77",
              "IPY_MODEL_142bb841eea04953ab865749b3aa72de",
              "IPY_MODEL_6d396e30088746f1b086bdf2a0339ce8"
            ],
            "layout": "IPY_MODEL_6af235cf10ac44ecab9033a81d3f7202"
          }
        },
        "0e1aaca525bf424397ad1ff9ed91ce77": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb93670b225646caac7d2d66f9b71598",
            "placeholder": "​",
            "style": "IPY_MODEL_6211e3adec6546b998178cf916fe4f54",
            "value": "tokenizer.json: 100%"
          }
        },
        "142bb841eea04953ab865749b3aa72de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad75c2914aa8494e90647f83e5908c54",
            "max": 1355863,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_194dbce6cca9461db87db0f732ced127",
            "value": 1355863
          }
        },
        "6d396e30088746f1b086bdf2a0339ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4fa7f523f0ee4fe1875e53f8f42c1b14",
            "placeholder": "​",
            "style": "IPY_MODEL_98ff251bc63843b69b2e2f33c58c4dfc",
            "value": " 1.36M/1.36M [00:00&lt;00:00, 15.8MB/s]"
          }
        },
        "6af235cf10ac44ecab9033a81d3f7202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cb93670b225646caac7d2d66f9b71598": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6211e3adec6546b998178cf916fe4f54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad75c2914aa8494e90647f83e5908c54": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "194dbce6cca9461db87db0f732ced127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4fa7f523f0ee4fe1875e53f8f42c1b14": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "98ff251bc63843b69b2e2f33c58c4dfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7d2d11a36c5842138f225636d4e862db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_96c37c340c504d349d2c9c48a1ea33b1",
              "IPY_MODEL_bdb2f10afa3f4b6e9e57a3c6060e6fa6",
              "IPY_MODEL_3ad2da873e074ec48fba6a86956e1b85"
            ],
            "layout": "IPY_MODEL_c1c5ecca123b47d09548f7533d17c1df"
          }
        },
        "96c37c340c504d349d2c9c48a1ea33b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a85cd74d06074da49c2e796fc383ac66",
            "placeholder": "​",
            "style": "IPY_MODEL_40677f5e275441ddaa5b05c6c90c42b5",
            "value": "config.json: 100%"
          }
        },
        "bdb2f10afa3f4b6e9e57a3c6060e6fa6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6d23ca2010df4892992cfc53ad8c8cc0",
            "max": 760,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_bc0f7f4d3aae4b36b18323723fd04b08",
            "value": 760
          }
        },
        "3ad2da873e074ec48fba6a86956e1b85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee52686d4d74c659e5b5b9240a02ef0",
            "placeholder": "​",
            "style": "IPY_MODEL_c081389c5c8047c4be73d375b023d0c3",
            "value": " 760/760 [00:00&lt;00:00, 30.1kB/s]"
          }
        },
        "c1c5ecca123b47d09548f7533d17c1df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a85cd74d06074da49c2e796fc383ac66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "40677f5e275441ddaa5b05c6c90c42b5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6d23ca2010df4892992cfc53ad8c8cc0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc0f7f4d3aae4b36b18323723fd04b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "dee52686d4d74c659e5b5b9240a02ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c081389c5c8047c4be73d375b023d0c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "72a93c9a7be548738580262d5c43c6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5a8f31d6602e45adabb7608534828a1e",
              "IPY_MODEL_7f2e15f45c4e4f7091436bfd48bb97b3",
              "IPY_MODEL_2c315ea3329d414a8a48553ef56318c3"
            ],
            "layout": "IPY_MODEL_6b2c41e23a624ceb930ab44bfdbdca99"
          }
        },
        "5a8f31d6602e45adabb7608534828a1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_904281611b0f447283afd7acc252f53b",
            "placeholder": "​",
            "style": "IPY_MODEL_0133df7afe0a4c48aac81d230475c7b6",
            "value": "pytorch_model.bin: 100%"
          }
        },
        "7f2e15f45c4e4f7091436bfd48bb97b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9a2f194bb9bc4544a6933da02cf564fe",
            "max": 467042463,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_804e66c787934292a69e3e9a58ba71da",
            "value": 467042463
          }
        },
        "2c315ea3329d414a8a48553ef56318c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4349ca5baad14e3dbfbf308db84b15fa",
            "placeholder": "​",
            "style": "IPY_MODEL_3e055f59457648d7bfcb57bd0c8175ef",
            "value": " 467M/467M [00:05&lt;00:00, 33.7MB/s]"
          }
        },
        "6b2c41e23a624ceb930ab44bfdbdca99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "904281611b0f447283afd7acc252f53b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0133df7afe0a4c48aac81d230475c7b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "9a2f194bb9bc4544a6933da02cf564fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "804e66c787934292a69e3e9a58ba71da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4349ca5baad14e3dbfbf308db84b15fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3e055f59457648d7bfcb57bd0c8175ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a54398c1f46f4623ac8d89f9331a56fe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e2d86acb7fcf4a44a39c28e5d7db10e5",
              "IPY_MODEL_c439dd452046459e8e91a16d0c409345",
              "IPY_MODEL_adfe5c0e5af8480aa4497f4d3e7aca96"
            ],
            "layout": "IPY_MODEL_dd1374a4f0154fecb734df6fc29c0028"
          }
        },
        "e2d86acb7fcf4a44a39c28e5d7db10e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_608deb81a9f5420f95ab58ea334c314d",
            "placeholder": "​",
            "style": "IPY_MODEL_52b9753ccb284284af02b546f247aaf0",
            "value": "spiece.model: 100%"
          }
        },
        "c439dd452046459e8e91a16d0c409345": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_20d699401eb447ccbf09f77506a9e669",
            "max": 798011,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4b1f36da112046a3afa7ce449b180d47",
            "value": 798011
          }
        },
        "adfe5c0e5af8480aa4497f4d3e7aca96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8a8a0c3d72dc40dda9a56779fcd61311",
            "placeholder": "​",
            "style": "IPY_MODEL_8c35f611410e4730959a14f4ad1550fa",
            "value": " 798k/798k [00:00&lt;00:00, 18.2MB/s]"
          }
        },
        "dd1374a4f0154fecb734df6fc29c0028": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "608deb81a9f5420f95ab58ea334c314d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "52b9753ccb284284af02b546f247aaf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "20d699401eb447ccbf09f77506a9e669": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b1f36da112046a3afa7ce449b180d47": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "8a8a0c3d72dc40dda9a56779fcd61311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8c35f611410e4730959a14f4ad1550fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "6babf2e685f04b1e8c4ab356a10e735a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e9d4d1c9384a43e88afe26f49d6705f3",
              "IPY_MODEL_38ece8f4ef044eaba3a9d03d93fa9d8b",
              "IPY_MODEL_6f892e9d7a8b43b6bc559e80f938fa8b"
            ],
            "layout": "IPY_MODEL_92e11c6a5948467698cac6d5cab2f0fd"
          }
        },
        "e9d4d1c9384a43e88afe26f49d6705f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b2c6af1847014b5aaaf8be1762417519",
            "placeholder": "​",
            "style": "IPY_MODEL_e151c509a98a4c77bdd9238e66029f8c",
            "value": "tokenizer.json: 100%"
          }
        },
        "38ece8f4ef044eaba3a9d03d93fa9d8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5a2f7497b3af43e0b201703d89617d3b",
            "max": 1382015,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_339d4e578a0b4dd1a8b4a51625718149",
            "value": 1382015
          }
        },
        "6f892e9d7a8b43b6bc559e80f938fa8b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d3506c3353e04e36a4667e72f6597d19",
            "placeholder": "​",
            "style": "IPY_MODEL_6407ade4cdf049b894728cc9211a7f00",
            "value": " 1.38M/1.38M [00:00&lt;00:00, 30.2MB/s]"
          }
        },
        "92e11c6a5948467698cac6d5cab2f0fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b2c6af1847014b5aaaf8be1762417519": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e151c509a98a4c77bdd9238e66029f8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5a2f7497b3af43e0b201703d89617d3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "339d4e578a0b4dd1a8b4a51625718149": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d3506c3353e04e36a4667e72f6597d19": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6407ade4cdf049b894728cc9211a7f00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alexk2206/tds_capstone/blob/Domi-DEV/Productive.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Model Choice, Fine-tuning and Evaluation**\n",
        "Created by: 95% Dominik Schuster, 5% Alexander Keßler\n",
        "\n",
        "After having set up the QA-dataset, we are now capable of evaluating different models on the task that the dataset implicitly represents.\n",
        "For that, we have to create all corresponding functions which translate our dataset entries into model input and vice versa the model output to humanly understandable text.\n",
        "Therafter - or at the same time, as we will do it - the evaluation of that created output has to happen.\n",
        "\n",
        "On the basis of this data, we will decide which model we will fine-tune afterwards, to improve the model's performance even more.\n",
        "\n",
        "At last, we will test the newly fine-tuned model against the other models evaluated before."
      ],
      "metadata": {
        "id": "0mkPc0ZfHFc7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "But first things first, let's start with installing and importing all the necessary packages."
      ],
      "metadata": {
        "id": "bS3CxBr6mS7Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install --upgrade sympy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SLjPgWr_1-kF",
        "outputId": "ffb291a2-709c-45b1-c827-3b9b8c673fd1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Collecting datasets>=2.0.0 (from evaluate)\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.9-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n",
            "Collecting xxhash (from evaluate)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.17-py311-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.10.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.27.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Collecting dill (from evaluate)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting multiprocess (from evaluate)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec>=2021.05.0 (from fsspec[http]>=2021.05.0->evaluate)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.11)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2024.12.14)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, fsspec, dill, multiprocess, datasets, evaluate\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 evaluate-0.4.3 fsspec-2024.9.0 multiprocess-0.70.16 xxhash-3.5.0\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (1.13.1)\n",
            "Collecting sympy\n",
            "  Downloading sympy-1.13.3-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy) (1.3.0)\n",
            "Downloading sympy-1.13.3-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sympy\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torch 2.5.1+cu124 requires nvidia-cublas-cu12==12.4.5.8; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cublas-cu12 12.5.3.2 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-cupti-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-cupti-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-nvrtc-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-nvrtc-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cuda-runtime-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cuda-runtime-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cudnn-cu12==9.1.0.70; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cudnn-cu12 9.3.0.75 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cufft-cu12==11.2.1.3; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cufft-cu12 11.2.3.61 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-curand-cu12==10.3.5.147; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-curand-cu12 10.3.6.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusolver-cu12==11.6.1.9; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusolver-cu12 11.6.3.83 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-cusparse-cu12==12.3.1.170; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-cusparse-cu12 12.5.1.3 which is incompatible.\n",
            "torch 2.5.1+cu124 requires nvidia-nvjitlink-cu12==12.4.127; platform_system == \"Linux\" and platform_machine == \"x86_64\", but you have nvidia-nvjitlink-cu12 12.5.82 which is incompatible.\n",
            "torch 2.5.1+cu124 requires sympy==1.13.1; python_version >= \"3.9\", but you have sympy 1.13.3 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed sympy-1.13.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "import urllib\n",
        "from itertools import chain, combinations\n",
        "from transformers import AutoTokenizer, AutoModelForMultipleChoice, AutoModelForQuestionAnswering, TrainingArguments, pipeline, Trainer, DataCollatorWithPadding, XLNetForMultipleChoice\n",
        "import torch\n",
        "import requests\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from dataclasses import dataclass\n",
        "from transformers.tokenization_utils_base import PreTrainedTokenizerBase, PaddingStrategy\n",
        "from datasets import Dataset\n",
        "from typing import Optional, Union\n",
        "from dateutil import parser\n",
        "from datetime import datetime\n",
        "import os\n",
        "import re\n",
        "from google.colab import drive\n"
      ],
      "metadata": {
        "id": "9KoU8tBBI45u"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Choice for fine-tuning\n",
        "\n",
        "Which models work best on the task? We want to get a glimpse of that in order to decide which model we want to fine-tune. But before that, we definitly have to prepare the dataset itself and some functions for generating output of a model.\n",
        "\n",
        "### Prepare dataset\n",
        "\n",
        "Here we split the previously created QA-dataset into train and validation dataset. For that, we download it from the public github account, where it was uploaded before.\n",
        "Additionally, we prepare the dataset for the response-generation and for fine-tuning of a model."
      ],
      "metadata": {
        "id": "7zDNcgGRHOQo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load datset\n",
        "url = \"https://raw.githubusercontent.com/alexk2206/tds_capstone/refs/heads/main/datasets/combined_qa_dataset.json\"\n",
        "data = pd.read_json(url)\n",
        "# Convert to DataFrame for easy handling\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Map the intended answer to the index of the option\n",
        "df['label'] = df.apply(lambda x: np.array([1 if option in x['intended_answer'] else 0 for option in x['options']]) if x['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'] else np.array([0]), axis=1)\n",
        "df['stratify_key'] = df['difficulty'] + '_' + df['type']\n",
        "\n",
        "# Convert to Huggingface Dataset dataset\n",
        "qa_dataset = Dataset.from_pandas(df)"
      ],
      "metadata": {
        "id": "ykW3Lop-3ok5"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# split dataset into train and validation (here called test) dataset with stratifying with question type and difficulty of context\n",
        "qa_dataset = qa_dataset.class_encode_column(\n",
        "    \"stratify_key\"\n",
        ").train_test_split(test_size=0.2, stratify_by_column=\"stratify_key\", seed=42).remove_columns(\"stratify_key\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2f7780089a43488baf155999188f82bf",
            "7297bdbb23704f4f93e7d4aa79947f11",
            "e6e41f94ea644a2da529acd3e4c670af",
            "6157724ba257439595dee6838cf21700",
            "cd29c37d0ca64bb098d816547519318b",
            "040b52671a824db893aec3e5d4791a67",
            "f00a5e4c8e8d41d3a0aa92d690361dfc",
            "5baa8e95d26849ebbf5c3839c6499474",
            "b6955d98c19741c38e3f1b8c73b22f0d",
            "a442c6e30ac345b2a1e420abec3ec8d9",
            "991430bd705a4f21a1ce32d9ce124df5"
          ]
        },
        "id": "W9tqK5cL4oyC",
        "outputId": "a268ed10-b0a0-4883-a1ee-e5ebb09bb3a9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Casting to class labels:   0%|          | 0/1381 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f7780089a43488baf155999188f82bf"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qa_dataset"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K8YC0gsu4my2",
        "outputId": "055ace14-70e8-408f-ef91-792ec3084f13"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['question', 'type', 'options', 'intended_answer', 'context', 'difficulty', 'label'],\n",
              "        num_rows: 1104\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['question', 'type', 'options', 'intended_answer', 'context', 'difficulty', 'label'],\n",
              "        num_rows: 277\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Label column: the intended_answer as list of binary variables for every option if question type is mc questions, list of entry 0 else\n",
        "qa_dataset[\"train\"][\"label\"][:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gJAy5V8-2o-",
        "outputId": "3835d264-9f08-48fd-baae-33d60e002d5b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[0, 1, 0, 0, 0, 0, 0, 0], [0, 1], [0, 1, 0, 1, 0], [0], [1, 0]]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Generate model output\n",
        "\n",
        "After creating and praparing the QA-dataset, it's time for generating model output for different Huggingface models.\n",
        "Since it's not possible to feed the models with humanly understandable text, we have to preprocess inputs, i.e. the questions of the QA-dataset.\n",
        "\n",
        "**But which approach do we take?** A very good question, because there are several ways to extract an answer and map it to given options. Zero-Shot Classification, QA where the best answers are tested on similarity to the options, and not but least, our approach, to directly find out the best option(s) with a QA (Multiple Choice respectively) model.\n",
        "\n",
        "**!!!!!! Attention:** The models are called Multiple Choice models, where multiple options for the input question exist. In the model inference, every option is given a certain weight.\n",
        "By contrast, we define multiple choice questions where one can select one or more options. Single choice question are also questions where many options exist, but it's only possible to choose ONE.\n",
        "Thus, in the dataset\n",
        "* MULTI_SELECT = multiple choice question\n",
        "* SINGLE_SELECT = single choice question\n",
        "* questions for the multiple choice models = mc questions\n",
        "\n",
        "\n",
        "As we found out, QA-models, or their tokenizer respectively, expect to get a question and an associated context with which the question can be answered as input.\n",
        "This is very easy for open-ended (oe) questions like 'NUMBER' or 'DATE', as we can directly pose it to the model without making any changes.\n",
        "But it's getting cumbersome for the mc questions, where one has to choose from different options.\n",
        "There, we have to pass the context as often as there are options, saved as a list.\n",
        "We also pass a list as a question, whereby each entry of the question (of the QA-dataset) is linked to an option.\n",
        "In doing so, the model is able to chose one of the options as the most likely one, in contrary to the model of the oe questions, which returns the most likely start and end position of the answer in the context.\n",
        "In fact, the required output format forces us to not use QA-models for this task, but the more specialiced Multiple-Choice models.\n",
        "\n",
        "Besides, we'll use a text-summarization pipeline to summarize the context of 'TEXT' questions, as it doesn't seem reasonable to extract an answer out of these questions.\n",
        "\n",
        "For handling all of that mentioned above, following functions come in to play:\n",
        "\n",
        "\n",
        "*   tokenize_function():\n",
        "Converts string input into tokens \"readable\" for the model.\n",
        "For that it differentiates between the different question types as mentioned above.\n",
        "*   model_output(): the \"main\" operator for generating model output\n",
        "Needs a model, which should create the output, its tokenizer and the questions, for which output should be created.\n",
        "Additionally, one can pass on the metrics for evaluating the model output for the mc and the oe questions on the fly.\n",
        "To handle 'TEXT' questions, one also has to pass a text-summarizing pipeline. Hands on the task to the following functions. These create the model's output, a list of logits\n",
        "  * single_select_model_output(): one logit for each option.\n",
        "  It chooses the option where the logit is highest\n",
        "  * multi_select_model_output(): one logit for each option.\n",
        "  It derives a standard normal distribution from the logits distribution and chooses every option that is 40% above the mean\n",
        "  * text_model_output(): just summarizes the context\n",
        "  * number_model_output(): calculates the most likely start and end token and outputs everything in between\n",
        "  * date_model_output(): as in number_model_output(), but auxiliary function \"convert_date_format()\" converts the output to the format \"yyyy-MM-dd\", if possible\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "8iquDfG7gYdM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenize function"
      ],
      "metadata": {
        "id": "JqmpIL11m2kG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_function(example, tokenizer):\n",
        "    '''\n",
        "    Converts the question with its context and the given options for multi-/single-select questions, into IDs the model later can make sense of. Distinguishes between multi-/single-select and the other question types\n",
        "    parameters:\n",
        "    - expample: question of the QA-dataset with all its entries (question, context, options, type are urgently necessary)\n",
        "    - tokenizer: tokenizer of the model\n",
        "    output:\n",
        "    - tokenized: tokenized input example\n",
        "    '''\n",
        "    if example[\"type\"] == \"SINGLE_SELECT\" or example[\"type\"] == \"MULTI_SELECT\":\n",
        "      number_of_options = len(example[\"options\"])\n",
        "      first_sentence = [[example[\"context\"]] * number_of_options]  # Repeat context for each option\n",
        "      second_sentence = [[example[\"question\"] + \" \" + option] for option in example[\"options\"]]  # Pair with each option\n",
        "      tokenized = tokenizer(\n",
        "          sum(first_sentence, []),\n",
        "          sum(second_sentence, []),\n",
        "          padding=\"longest\",\n",
        "          truncation=True\n",
        "      )\n",
        "      # Un-flatten\n",
        "      return {k: [v[i:i+number_of_options] for i in range(0, len(v), number_of_options)] for k, v in tokenized.items()}\n",
        "\n",
        "    elif example['type'] == 'NUMBER':\n",
        "      tokenized = tokenizer(\n",
        "          example['context'],\n",
        "          example['question'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "    else:\n",
        "      tokenized = tokenizer(\n",
        "          example['question'],\n",
        "          example['context'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "hUzIIwagzO6P"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model output"
      ],
      "metadata": {
        "id": "OwhUmKznnjR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, questions, sum_pipeline=None, mc_metric=None, oe_metric=None):\n",
        "    '''\n",
        "    model_output -> creates output for every question in the dataset and safes it in a list of dicts\n",
        "    parameters:\n",
        "    - mc_model: one hugging face model for mc questions\n",
        "    - mc_tokenizer: hugging face tokenizer for mc questions\n",
        "    - oe_model: one hugging face model for oe questions\n",
        "    - oe_tokenizer: hugging face tokenizer for oe questions\n",
        "    - questions: QA-dataset as pd.DataFrame\n",
        "    - sum_pipeline: huggingface text-summarization pipeline to handle 'TEXT' questions\n",
        "    - mc_metric: metric for evaluating mc questions\n",
        "    - oe_metric: metric for evaluating oe questions\n",
        "    output:\n",
        "    - mc_answer_comparison: list of dicts with keys 'model', 'intended_answer_binary', 'predicted_answer_binary', 'intended_answer', 'predicted_answer', 'type', 'difficulty'\n",
        "    - answer_comparison: list of dicts with keys 'model', 'intended_answer', 'predicted_answer', 'type', 'difficulty'\n",
        "    '''\n",
        "    answer_comparison = []\n",
        "    mc_answer_comparison = []\n",
        "    mc_model_name = mc_model.config._name_or_path\n",
        "    oe_model_name = oe_model.config._name_or_path\n",
        "\n",
        "    for index, question in questions.iterrows():\n",
        "        context = question['context']\n",
        "        question_text = question['question']\n",
        "        options = question['options']\n",
        "        question_type = question['type']\n",
        "        difficulty = question['difficulty']\n",
        "\n",
        "        mc_question_type = question_type in [\"MULTI_SELECT\", \"SINGLE_SELECT\"]\n",
        "\n",
        "        if question_type == \"MULTI_SELECT\":\n",
        "          intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = multi_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "        elif question_type == \"SINGLE_SELECT\":\n",
        "          intended_answer, intended_answer_binary, predicted_answer_binary, predicted_answer = single_select_model_output(mc_model, mc_tokenizer, question, mc_metric)\n",
        "        elif question_type == \"TEXT\":\n",
        "          intended_answer, predicted_answer = text_model_output(question, sum_pipeline)\n",
        "          continue\n",
        "        elif question_type == \"NUMBER\":\n",
        "          intended_answer, predicted_answer = number_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "        elif question_type == \"DATE\":\n",
        "          intended_answer, predicted_answer = date_model_output(oe_model, oe_tokenizer, question, oe_metric)\n",
        "        else:\n",
        "          continue\n",
        "        if predicted_answer != intended_answer:\n",
        "          print('======= Wrong answer =======')\n",
        "          print(f\"Question: {question_text}\")\n",
        "          print(f\"Context: {context}\")\n",
        "          print(f\"The intended answer was: {intended_answer}\")\n",
        "          print(f\"The predicted answer was: {predicted_answer}\")\n",
        "          if mc_question_type:\n",
        "            print(f\"The intended answer in BINARY was: {intended_answer_binary}\")\n",
        "            print(f\"The predicted answer in BINARY was: {predicted_answer_binary}\\n\")\n",
        "          else:\n",
        "            print(\"\")\n",
        "        if mc_question_type:\n",
        "          mc_answer_comparison.append({'model': mc_model_name, 'intended_answer_binary': intended_answer_binary, 'predicted_answer_binary': predicted_answer_binary, 'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "        else:\n",
        "          answer_comparison.append({'model': oe_model_name, 'intended_answer': intended_answer, 'predicted_answer': predicted_answer, 'type': question_type, 'difficulty': difficulty})\n",
        "\n",
        "    # Compute metrics, if they were passed as arguments\n",
        "    if mc_metric is not None:\n",
        "      try:\n",
        "        mc_metric_result = mc_metric.compute()\n",
        "      except:\n",
        "        mc_metric_result = None\n",
        "    else:\n",
        "      mc_metric_result = None\n",
        "    if oe_metric is not None:\n",
        "      try:\n",
        "        oe_metric_result = oe_metric.compute()\n",
        "      except:\n",
        "        oe_metric_result = None\n",
        "    else:\n",
        "      oe_metric_result = None\n",
        "    return mc_answer_comparison, answer_comparison, mc_metric_result, oe_metric_result\n"
      ],
      "metadata": {
        "id": "tWqdWvQrgtle"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Additionally to the output, if the answer was predicted wrong, it prints out some values for debugging, including the output logits tensor, the question text, its context, the intended answer and the predicted answer This looks like this:\n",
        "\n",
        "```\n",
        "tensor([[ 0.2761,  0.2655,  0.2123,  0.2723,  0.1614,  0.2863,  0.2624,  0.0581,\n",
        "          0.1172,  0.2708,  0.0551, -0.2568,  0.2749]],\n",
        "       grad_fn=<ViewBackward0>)\n",
        "======= Wrong answer =======\n",
        "Question: Who to copy in follow up\n",
        "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
        "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
        "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
        "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
        "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "cmKrk8U1m51y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Single-select output"
      ],
      "metadata": {
        "id": "MwvDlSsVG3XH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def single_select_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question, its context and its options for a single-select question and generates output\n",
        "    parameters:\n",
        "    - model: one MC hugging face model\n",
        "    - tokenizer: MC hugging face tokenizer\n",
        "    - question: one question of the QA-dataset as row of pd.DataFrame\n",
        "    - metric: metric for evaluating the model output (optional)\n",
        "    output:\n",
        "    - intended_answer: the correct/intended answer as a string\n",
        "    - intended_answer_binary: the correct/intended answer as a list of binary variables, where each entry is one, if option is chosen, 0 else\n",
        "    - predicted_answer_binary: the predicted answer as a list of binary variables, where each entry is one, if option is chosen, 0 else\n",
        "    - options[predicted_option]: the predicted answer as a list of strings\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "    options = question['options']\n",
        "\n",
        "    # creating input ids by tokenizing the question\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    input_ids = {key: torch.tensor(array) for key, array in input_ids.items()}\n",
        "\n",
        "    # generating the output\n",
        "    outputs = model(**input_ids)\n",
        "    logits = outputs.logits  # Shape: [batch_size, num_choices]\n",
        "    print(logits)\n",
        "\n",
        "    # Predict the option with the highest score\n",
        "    predicted_option = torch.argmax(logits, dim=1).item()\n",
        "    predicted_answer_binary = [0] * len(options)\n",
        "    predicted_answer_binary[predicted_option] = 1\n",
        "\n",
        "    intended_answer_binary = [1 if option == intended_answer else 0 for option in options]\n",
        "\n",
        "    # Add the results to the metric\n",
        "    if metric is not None:\n",
        "      metric.add_batch(predictions=predicted_answer_binary, references=intended_answer_binary)\n",
        "\n",
        "    return intended_answer, intended_answer_binary, predicted_answer_binary, options[predicted_option]\n"
      ],
      "metadata": {
        "id": "KgWVBNWlGkrC"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Multi-select output\n",
        "\n",
        "For multi-select questions, we choose all options where their logits are higher than the mean logit + 40% of the standard deviation. This is a reasonable approach because:\n",
        "\n",
        "+++++++++++++ **Capturing Confident Predictions 🎯**\n",
        "\n",
        "The mean logit represents the average confidence of the model across all options.\n",
        "Adding 40% of the standard deviation creates a threshold that selects options significantly above the average, meaning the model is more confident about these choices.\n",
        "\n",
        "+++++++++++++ **Accounting for Variability 📊**\n",
        "\n",
        "The standard deviation measures how much the logits vary.\n",
        "By setting the threshold based on 40% of the standard deviation, we balance between selecting only the highest confidence options while not being overly restrictive.\n",
        "\n",
        "+++++++++++++ **Preventing Over-Selection & Under-Selection ⚖**\n",
        "\n",
        "If the threshold were too high, the model might miss correct answers.\n",
        "If it were too low, the model might select too many, including incorrect ones.\n",
        "40% of the standard deviation is a reasonable balance based on the natural spread of logits."
      ],
      "metadata": {
        "id": "4XwAHnUIGy-V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def multi_select_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question, its context and its options for a multi-select question\n",
        "    parameters:\n",
        "    - model: one MC hugging face model\n",
        "    - tokenizer: MC hugging face tokenizer\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    - metric: metric for evaluating the model output (optional)\n",
        "    output:\n",
        "    - intended_answer: the correct/intended answers as a list of strings\n",
        "    - intended_answer_binary: the correct/intended answers as a list of binary variables, where each entry is one, if option is chosen, 0 else\n",
        "    - predicted_answer_binary: the predicted answers as a list of binary variables, where each entry is one, if option is chosen, 0 else\n",
        "    - high_score_answers: the predicted answers as a list of strings\n",
        "    '''\n",
        "    intended_answer = question['intended_answer']\n",
        "    options = question['options']\n",
        "\n",
        "    # creating input ids by tokenizing the question\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    input_ids = {key: torch.tensor(array) for key, array in input_ids.items()}\n",
        "\n",
        "    # generating the output\n",
        "    outputs = model(**input_ids)\n",
        "    logits = outputs.logits  # Shape: [batch_size, num_choices]\n",
        "    print(logits)\n",
        "\n",
        "    ### Use a threshold from deviation and take all options that are higher than the mean + 40% of standard deviation\n",
        "    mean_score = logits.mean().item()\n",
        "    std_dev = logits.std().item()\n",
        "    threshold = mean_score + (0.4 * std_dev)\n",
        "    high_score_options = (logits >= threshold).nonzero(as_tuple=True)[1]  # Get the indices of valid options\n",
        "\n",
        "    # List the corresponding options\n",
        "    high_score_answers = [options[idx] for idx in high_score_options.tolist()]\n",
        "    intended_answer_binary = [1 if option in intended_answer else 0 for option in options]\n",
        "\n",
        "    predicted_answer_binary = [1 if option in high_score_answers else 0 for option in options]\n",
        "\n",
        "    # Add the results to the metric\n",
        "    if metric is not None:\n",
        "        metric.add_batch(predictions=predicted_answer_binary, references=intended_answer_binary)\n",
        "\n",
        "    return intended_answer, intended_answer_binary, predicted_answer_binary, high_score_answers\n",
        "\n"
      ],
      "metadata": {
        "id": "V52Kz-lNGqca"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Text output"
      ],
      "metadata": {
        "id": "UXc_BEivG7nV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def text_model_output(question, pipeline):\n",
        "    '''\n",
        "    Handles an open text question and summarizes it\n",
        "    parameter:\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    - pipeline: huggingface text-summarization pipeline\n",
        "    output:\n",
        "    - intended_answer: the full context of the question as a string\n",
        "    - summary[0][summary_text]: the generated summary as a string\n",
        "    '''\n",
        "    intended_answer = question['context']\n",
        "    summary = pipeline(intended_answer, max_length=len(intended_answer), do_sample=False)\n",
        "    return intended_answer, summary[0]['summary_text']\n",
        "\n"
      ],
      "metadata": {
        "id": "D7dedyjuGwXb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Phone Number output"
      ],
      "metadata": {
        "id": "XhVsQSw7G-G2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def number_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question where the context should contain a phone number and generates an answer to that question\n",
        "    parameters:\n",
        "    - model: one QA hugging face model\n",
        "    - tokenizer: QA hugging face tokenizer\n",
        "    - question: one question of the QA-dataset as a dictionary\n",
        "    - metric: metric for evaluating the model output (optional)\n",
        "    output:\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    output = model(**input_ids)\n",
        "    start_logits, end_logits = output.start_logits, output.end_logits\n",
        "\n",
        "    # Get most probable start and end index\n",
        "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "    end_idx = torch.argmax(end_logits, dim=1).item() + 1  # Include last token\n",
        "\n",
        "    # Convert token IDs to text\n",
        "    predicted_tokens = input_ids[\"input_ids\"][0][start_idx:end_idx]\n",
        "    predicted_number = tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "\n",
        "    # Add results to the metric\n",
        "    if metric is not None:\n",
        "        metric.add(predictions=predicted_number, references=intended_answer)\n",
        "\n",
        "    return intended_answer, predicted_number"
      ],
      "metadata": {
        "id": "7h0RxjaPGvXO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Date output\n",
        "\n",
        "Here we have an auxiliary function, that converts the model outut, which mostly is a date in any format, into a date in the format YYYY-mm-dd"
      ],
      "metadata": {
        "id": "9UZp9MuGHCoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_date_format(date_str):\n",
        "  '''\n",
        "  extracts date f\n",
        "  '''\n",
        "  try:\n",
        "    parsed_date = parser.parse(date_str)\n",
        "    return parsed_date.strftime('%Y-%m-%d')\n",
        "  except Exception as e:\n",
        "    return date_str\n",
        "\n",
        "def find_date_and_convert(input_string):\n",
        "  date_regex = r'\\b(?:\\d{1,2}(?:st|nd|rd|th)?\\s+[A-Za-z]+\\s+\\d{4}|\\d{1,2}[./-]\\d{1,2}[./-]\\d{2,4}|\\b[A-Za-z]+\\s+\\d{1,2}(?:st|nd|rd|th)?,?\\s+\\d{4})\\b'\n",
        "  match = re.search(date_regex, input_string)\n",
        "  if match:\n",
        "    extracted_date = match.group(0)\n",
        "    formatted_date = convert_date_format(extracted_date)\n",
        "    return formatted_date\n",
        "  else:\n",
        "    return input_string\n"
      ],
      "metadata": {
        "id": "Du-hjdJCSKPk"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def date_model_output(model, tokenizer, question, metric=None):\n",
        "    '''\n",
        "    Handles a question where the context should contain a date and generates an answer to that question\n",
        "    '''\n",
        "    intended_answer = question['intended_answer'][0]\n",
        "\n",
        "    input_ids = tokenize_function(question, tokenizer)\n",
        "    output = model(**input_ids)\n",
        "    start_logits, end_logits = output.start_logits, output.end_logits\n",
        "    # Get most probable start and end index\n",
        "    start_idx = torch.argmax(start_logits, dim=1).item()\n",
        "    end_idx = torch.argmax(end_logits, dim=1).item() + 1  # Include last token\n",
        "\n",
        "    # Convert token IDs to text\n",
        "    predicted_tokens = input_ids[\"input_ids\"][0][start_idx:end_idx]\n",
        "    predicted_answer = tokenizer.decode(predicted_tokens, skip_special_tokens=True)\n",
        "    formatted_predicted_answer = find_date_and_convert(predicted_answer)\n",
        "\n",
        "    if metric is not None:\n",
        "        metric.add(predictions=formatted_predicted_answer, references=intended_answer)\n",
        "\n",
        "    return intended_answer, formatted_predicted_answer\n",
        "\n"
      ],
      "metadata": {
        "id": "0trBt0BSGuQ4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Selection\n",
        "\n",
        "**Which model works best to predict the intended answer?**\n",
        "This is what we'll find out here.\n",
        "\n",
        "We firstly load the metrics we want the models to be evaluated on.\n",
        "As we want to take into account as much as we can and also to get a better feeling for the model output, we choose all of the metrics \"accuracy\", \"f1\", \"precision\" and \"recall\" for the mc model questions. For the oe model questions, only \"exact match\", as receiving a false phone number and/or date would be very problematic. The last task ('TEXT' questions) won't be evaluated, since there is no real basis on which we can extract the right or wrong answer. We'll only summarize the notes.\n",
        "\n",
        "And which dataset take to evaluate on?\n",
        "Since the model in this stage won't remember the intended answers of the questions, we just use the training part of the QA-dataset.\n",
        "This won't overfit/underfit a model and its big enough to really get a glimpse of how good the models perform.\n",
        "\n",
        "\n",
        "\n",
        "**Remark,** that we only consider relatively small models as we heard the other groups have memory and other problems that relate to technical ressources.\n"
      ],
      "metadata": {
        "id": "qBzA_tYRHFDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load metrics\n",
        "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
        "exact_match = evaluate.load(\"exact_match\")"
      ],
      "metadata": {
        "id": "2IlwKlBCkbq1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load text-summarization pipeline\n",
        "summarization_pipeline = pipeline(\"summarization\", model=\"t5-small\")"
      ],
      "metadata": {
        "id": "OqjZCcSen3B3",
        "outputId": "1747a495-7e81-4e53-e1b2-ae865c4a1b98",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter train dataset on mc questions for oe model evaluation\n",
        "mc_train_qa_dataset = pd.DataFrame(qa_dataset['train'].filter(lambda example: example['type'] in ['MULTI_SELECT', 'SINGLE_SELECT']))\n",
        "mc_train_qa_dataset.shape\n",
        "\n",
        "model_results = []"
      ],
      "metadata": {
        "id": "jlMX2rCjtMi3",
        "outputId": "6d26b3fd-bb9c-42f3-edd8-782ca42bca91",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "83d1325d0ba44d02b6bb11470d7d2d36",
            "7c74ec8814dc49c2bbfc20d72038259f",
            "c812037c5d1b4fbaa71abb0705286244",
            "14792d75bd214dc8949ab2d95cad387b",
            "3417727dbcb44ae0a0cdcd524d51af46",
            "8ac411076aee47a4a10e365b40884c9c",
            "dbda537cc05f49949bbf20251ffc6bbd",
            "1be6fca06f364f0fabf87f684c9cd1fb",
            "472dc07b8c004906bdf60243cc2d9a77",
            "2ec6ae0556fd4007a216c5d4029386a1",
            "418bdeb69f134121a98e564f5eb44400"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "83d1325d0ba44d02b6bb11470d7d2d36"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Model for open-ended questions\n",
        "\n",
        "In order to be able to evaluate, we have to define both a oe and mc model.\n",
        "That's why we already instanciate the \"bert-base-cased\" model used for mc.\n",
        "Afterwards we initialize the \"distilbert-base-uncased-distilled-squad\" for oe questions, a QA model fine-tuned on the squad dataset.\n",
        "In the last step, we filter over the train QA-dataset, so that only questions of type 'DATE' or 'NUMBER' are left."
      ],
      "metadata": {
        "id": "qtKtW6l8rVqU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"bert-base-cased\"\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name, torch_dtype=\"auto\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "q95bFIxx1X8E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bf0de43-591e-4591-e828-ee0cd0093800"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oe_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")\n",
        "oe_tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")"
      ],
      "metadata": {
        "id": "AwK34z3JFMic",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304,
          "referenced_widgets": [
            "07f09fc8642c4be2af28b299a388673e",
            "0cc50ecaf5e249a9aa679808858b31b7",
            "096731b680d5441fb64791b01e370ec3",
            "f61ce49970974612a188ab2ddfbb5fec",
            "031c7f9d87df44c2a36f9e1622feb6df",
            "217059b930b44e26b1baf852849c1120",
            "29aead24867c48d18f183c6253d889c9",
            "8676e0d61b654e95ac353ba2f2df63d6",
            "48acd096373f437184364ba614ff89aa",
            "1ed1cc426e974fbfb1b3ed61a2636b2d",
            "71048ee89be147a58239f5b9068a7a1a",
            "2f74b412389b4e009c1acec331ca5c14",
            "8024e954a0f1495fac8a73a1be7b9916",
            "5a5f799d8ec74a49ad3818c2b02a58c8",
            "0a3c4f12ddea4b118c6209302267f8fd",
            "49b64e431c6e4b6bb1a50114dc261b4d",
            "27ee434c2561405985d70c6436a683e7",
            "8cdc83a9768341a7b10b9978bb0dacb6",
            "6f74b007eeae4e918c2a8234c4b93411",
            "a41a9a217ead46b18745a35a7ca8f290",
            "1441c1a48ee444a099826efb4bcfa86f",
            "fcf6eb4c3e6d4246ab61e964745e9592",
            "5e998d52f92b47fd86d4ddac45564e9b",
            "c61eb22617fd4563b133a97dc8c40da0",
            "bbe388e672de488db74cb2b60da92005",
            "2d6e621b294b4319bb35bdbab0c4b748",
            "3a8c24351e14471c8a4174fe6d985c5e",
            "d5bc76879f8d46cfb84ac9c55de3521c",
            "dde8287bb20149088b19555aaf316d58",
            "2f9a43c53f3b467d8e62b77ef6d10cee",
            "bbdf023ab8fb4683a7236fb253c4c646",
            "2127853b6b224996a23f6730c72094fd",
            "2096ca82f4f943ee8c6b711d413d2d3f",
            "5f0e5efb088244a0aceaec12405473de",
            "6ef94527288c4e478fa188e5b70a4ceb",
            "0c249fe8f66148ce9d4427396496e808",
            "9230a945d172478296f5adb218556c7f",
            "02d5eb8bb1744765a77fbf0edb35e80f",
            "7da7428e4ef545a3a32e9676ac4033cc",
            "c97ed8cf46cf4b9994d4e7b1bb231ea5",
            "ddc22c91d5e846899f510912588c0305",
            "8d025c708a01434c89d0eb633399dd15",
            "7e6ad5ad614345838823bd3920e88b8f",
            "4276aa6a50774d8b8c22fa15f76528c2",
            "236e432245f54ff1a5f49d8963e279a4",
            "4a421b8ac6bb43108bee0c7fe3ce19ac",
            "e5c726605bdf4066a547fa49a1303fc1",
            "d74db1b8fb1847349dac026993e2e12c",
            "38d91bc4481446a6b9806701509a6ad2",
            "52433b3181fa45b4930fcb428efd8f32",
            "3ccbd606f7b94a7780ea4b564a59d328",
            "c87d85dc75af4aa3a85ba8bc2d441b9c",
            "b17f77069e5b4a90aadaa1f0cd6c54af",
            "b1077cd2ee534547892acd989fe0628a",
            "b576524f3a744714a3126abe5e8b820d"
          ]
        },
        "outputId": "735bb049-997c-4bb0-f14b-963a6a0ed6a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "07f09fc8642c4be2af28b299a388673e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f74b412389b4e009c1acec331ca5c14"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5e998d52f92b47fd86d4ddac45564e9b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5f0e5efb088244a0aceaec12405473de"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "236e432245f54ff1a5f49d8963e279a4"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oe_qa_train_dataset = pd.DataFrame(qa_dataset['train'].filter(lambda example: example['type'] in ['DATE', 'NUMBER']))\n",
        "oe_qa_train_dataset.shape"
      ],
      "metadata": {
        "id": "meA0KR7mlS3b",
        "outputId": "d3079e15-0a91-4b4d-b304-5812bd0c2352",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "9de015e7816443cca2e81f9a1505ca77",
            "d2fbc91c04ca449baef1d90fcc9eb63b",
            "59fa1a64c85241559c97ad0b55c166b3",
            "16c23ce2a6164efeba5a37a329f1d55b",
            "087094e9afe64c148921877879f95ed4",
            "6c3c6ec3df0e4e498e4dd06fc45281b8",
            "ac481cd784864fa882653cdfe2cd414d",
            "2d2461b472c24f5c81c1a5fb0b3dcc73",
            "041e7be7b6724a09aa5769fc7cfa67a8",
            "c60218148fac459888cbd8a9f4aa133c",
            "2a5bdf3691f743f5800415ff700da562"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9de015e7816443cca2e81f9a1505ca77"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So let's try to get an output for the oe model."
      ],
      "metadata": {
        "id": "uw1EcrEMldG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, oe_qa_train_dataset, mc_metric=clf_metrics, oe_metric=exact_match)\n",
        "print(f\"The exact_match metric for all open-ended questions in the train dataset: {oe_metric_result['exact_match']}\")"
      ],
      "metadata": {
        "id": "JfiuSgE5m75C",
        "outputId": "e8dc979f-5a1b-4f60-f06f-1740fbfc04bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we touch base again on January 15th?  That works for me.\n",
            "The intended answer was: 2025-01-15\n",
            "The predicted answer was: january 15th\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we connect again on January 17th?  That works for me.\n",
            "The intended answer was: 2025-01-17\n",
            "The predicted answer was: january 17th\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you wish to receive a follow-up?\n",
            "Context: How about we follow up around January 22nd of 2025? That should work nicely.\n",
            "The intended answer was: 2025-01-22\n",
            "The predicted answer was: 22nd of 2025\n",
            "\n",
            "The exact_match metric for all open-ended questions in the train dataset: 0.9651162790697675\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Actually, this looks quite good, there is no need of searching for another model here.\n",
        "So we can concentrate on the mc models"
      ],
      "metadata": {
        "id": "k99_LAIpqupY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Models for multiple and single choice questions\n",
        "\n",
        "We decided to test a BERT, ALBERT, XLNet and RoBERTa model each.\n",
        "All of them can handle the same type of input and are able to weight the options.\n",
        "A weight what we afterwards use to predict the right option(s).\n",
        "\n",
        "So let's start!!! 🥳"
      ],
      "metadata": {
        "id": "AEdVFzXitkeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### BERT base model (cased)"
      ],
      "metadata": {
        "id": "EwsbEfOhX892"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "id": "xvWK_VxTq6By",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a9fdc-a64e-4f88-ad61-937135a06367"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1124, -0.1531,  0.2460, -0.4431, -0.3133]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, well it could be an existing customer, a supplier, or a new customer or prospect. I think maybe it's a new customer then.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3315, -0.2121, -0.1967, -0.0708,  0.2705, -0.4947]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I guess they might be into 256 joining systems for large components, or something else, like maybe something different.\n",
            "The intended answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2758, 0.2698, 0.2468, 0.2405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2563, -0.3034, -0.2855, -0.2780, -0.1959]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not sure. Is it something like 25 maybe? I'd guess somewhere in that range, but I don't really know.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2900, 0.2377, 0.2921, 0.1172, 0.2930]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and double-pulse testing. Those seem like the things I'd like to know more about.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0759,  0.0529, -0.1229,  0.0523,  0.1846]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1751,  0.2530, -0.2849,  0.2291,  0.2606]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe it's like scan business cards, clean up CRM, improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2853, 0.2799, 0.2734, 0.2778, 0.2785, 0.2763, 0.2926]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, gosh, I really don't know much about those things but maybe the average size of a trade fair team is about 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0770, 0.2850, 0.1872, 0.0493, 0.0298, 0.1218, 0.0968, 0.2851, 0.1693,\n",
            "         0.2634]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0640, -0.2320, -0.0083,  0.2129, -0.2369]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be an existing customer, maybe a supplier, or it could be someone from the press or media. Perhaps they're even a competitor, I don't really know.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1882, -0.4252, -0.4919, -0.5280]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2650, 0.2524, 0.2574, 0.2656, 0.2854, 0.2568, 0.2647, 0.2178, 0.2557,\n",
            "         0.2618]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2883, 0.2814, 0.2887, 0.2231, 0.2904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.2878, -0.0557, -0.0415, -0.2280, -0.0463,  0.0051,  0.0238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2205,  0.2653,  0.2709,  0.1936,  0.1879, -0.0015,  0.2644,  0.2655,\n",
            "          0.1231,  0.2694,  0.1455,  0.2607,  0.1636]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I should copy Erik Schneider, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Sean Kennin then.\n",
            "The intended answer was: ['Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2884,  0.2879, -0.2053, -0.3181,  0.2854,  0.2851]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2651, 0.2918, 0.2727, 0.2469, 0.2749]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2296, 0.2801, 0.2846, 0.2171, 0.2909]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I guess I'm interested in noise figure measurements and also high-speed interconnect testing, those sound important.\n",
            "The intended answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.4157, -0.4177,  0.2719,  0.2775]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2589, -0.0937,  0.2159, -0.3405, -0.2132]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I guess it would be an existing customer then, that sounds right to me.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2715, 0.2704, 0.2578, 0.2526, 0.2509, 0.2330, 0.2649, 0.2709, 0.2492,\n",
            "         0.2632, 0.2444, 0.2642, 0.2731]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up, I could copy Stephan Maier, maybe Joachim Wagner, or perhaps Jessica Hanke? Sean Kennin and Tim Persson could be good options too, I'm not sure which.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1473,  0.1266,  0.0940]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1994, 0.1789, 0.1859, 0.2150, 0.2403, 0.2527, 0.2849]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0021, -0.2893, -0.1582, -0.4639]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2626, 0.2730, 0.2495, 0.2562, 0.2601, 0.2652]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2712,  0.2740,  0.2722,  0.2789,  0.2714, -0.4923]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2672, 0.2684, 0.2687]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm I think they would like to receive a follow up either in 1 week or 2 weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2785, 0.2526, 0.2538, 0.2291, 0.2691, 0.2707, 0.2495, 0.2431, 0.2463,\n",
            "         0.2631]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1453, 0.2195, 0.2230]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe,  not too soon and not too late.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2102, 0.1807, 0.2116, 0.2027, 0.2566, 0.2752, 0.1726, 0.2487, 0.1871,\n",
            "         0.2545, 0.1981, 0.2433, 0.1802]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2182, 0.1808, 0.1828, 0.1626, 0.2674, 0.1749]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2433, 0.2581, 0.2678, 0.0718]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1203, 0.1742, 0.1117, 0.2087, 0.2595]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2820, 0.2838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, so the only option is 'Yes', and yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2282, 0.2147]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.5239, -0.4985, -0.5012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'm not sure what options there are but I think I'll call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.0938, 0.2678, 0.1361, 0.0411, 0.0917, 0.0957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0735,  0.1020, -0.2020]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2738, 0.2827, 0.2734, 0.2664, 0.2804]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Okay, I'm interested in... wait, there aren't any options listed! I guess I'm not interested in any products at this moment.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2468, 0.2501, 0.2507, 0.2475, 0.2474, 0.2322, 0.2728]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1799, 0.2209, 0.1838, 0.2367, 0.2658]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2939, 0.2944, 0.2919, 0.2959, 0.2969, 0.2956, 0.2998]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2377, 0.2493, 0.2332, 0.2487, 0.2423, 0.2241, 0.2555, 0.2142, 0.2370,\n",
            "         0.2454]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2207, 0.0995, 0.1064, 0.1642, 0.1779, 0.1159, 0.2757, 0.0582]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2755, -0.1066,  0.2691, -0.2008, -0.2331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1950,  0.0603, -0.0022, -0.1039,  0.2763, -0.0100,  0.1529]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2731,  0.2701,  0.2203,  0.2734,  0.1977, -0.0303,  0.2662,  0.1124,\n",
            "          0.1743,  0.2498,  0.2698, -0.1782, -0.0143]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2532, 0.2645, 0.2607]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1291, -0.4581, -0.3953, -0.4421, -0.4009, -0.3860, -0.3737]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2765,  0.2681,  0.2711,  0.2355,  0.2738, -0.1631]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in 100 additive manufacturing, joining systems for large components that's 256 and also, others, I guess.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2542, 0.2644, 0.2523, 0.2546, 0.2519, 0.2582, 0.2782]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would guess maybe 8 people would be on the trade fair team, somewhere around there.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0790, -0.4117,  0.0976,  0.2722, -0.3029, -0.2876]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh um I guess I'd say I'm interested in the JS EcoLine. I think that's it.\n",
            "The intended answer was: ['JS EcoLine']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2490, 0.2494, 0.2393, 0.2637, 0.2406, 0.2418]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1962, 0.1813, 0.1856, 0.0908]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2879, 0.2804, 0.2734, 0.2822, 0.2675]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I am interested in automotive radar target simulation, noise figure measurements, and also display port debugging and compliance.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1878, 0.2892, 0.1814, 0.1901, 0.1266, 0.0999, 0.2138, 0.2896, 0.0886,\n",
            "         0.2741]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1446,  0.1070,  0.1521, -0.2889]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0150,  0.0716,  0.0151, -0.2719, -0.1872,  0.0303, -0.0352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2613, 0.2894, 0.2775, 0.2605, 0.2708]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0969, -0.0912, -0.1286, -0.1681,  0.2748, -0.0903,  0.0872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1088, 0.2623, 0.2686, 0.2533, 0.2727]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.4904, -0.4557, -0.4377, -0.3978]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think a phone call would probably be best.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2780,  0.2697,  0.2731,  0.2661,  0.2728, -0.4258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I'm not entirely sure. I guess they're into 100 Additive Manufacturing, maybe 300 Advanced Manufacturing, or could be 256 Joining Systems for large components. Or, possibly even\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2641, 0.2545, 0.2498, 0.2782, 0.2557, 0.2633]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0541, -0.3565,  0.2648,  0.1249,  0.2774,  0.2398]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4410, -0.3873]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3330,  0.2535,  0.2561,  0.1340,  0.2548]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0558, -0.0805, -0.0284, -0.1097,  0.1231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2102, 0.2535, 0.2816, 0.1325]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0875, -0.2041, -0.3289, -0.3531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I'm an existing customer. I think that's the only possibility, right?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2407, -0.1387, -0.3327]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2690, 0.1481, 0.1027]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2767, -0.1697, -0.4103, -0.3478, -0.3544]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess, searching for a solution for this seems like it's probably empty. I really don't know what else it could be.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0756, -0.4173, -0.4116, -0.2222, -0.2693, -0.4106,  0.2803, -0.4505]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2122, 0.1688, 0.2770, 0.2906, 0.2914]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2875, 0.2622, 0.2874, 0.2839, 0.2879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.4319, -0.3053, -0.1105]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2723, 0.2736]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent? I guess the only option here is 'Yes', so, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.1396,  0.1014,  0.1304,  0.2389,  0.1769,  0.1808,  0.1174, -0.1393,\n",
            "          0.0579,  0.2154]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2397, 0.2521, 0.2216, 0.2658, 0.2677]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3198, -0.3053,  0.2220,  0.2313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1985, 0.2737, 0.2802, 0.1362, 0.2849]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0318, -0.0792, -0.0761, -0.2867, -0.1284, -0.1158,  0.2687]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5480, -0.4816, -0.4537]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'd offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2469, -0.1681, -0.3988,  0.2319, -0.0815]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2834,  0.1830,  0.1312,  0.0233,  0.1187,  0.2385,  0.0304, -0.0045,\n",
            "         -0.1780,  0.1696]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1730, 0.0661, 0.0664, 0.0616, 0.0179]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0622, -0.1607, -0.2396, -0.1814,  0.2693, -0.1247, -0.0381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0714, 0.1129, 0.0079, 0.0113, 0.0928, 0.1620, 0.0337, 0.2704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2529,  0.2490,  0.2679,  0.2724,  0.2034, -0.2791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in advanced manufacturing, perhaps something around 300 units, or assembly systems, something like 234, or possibly something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0375,  0.0077, -0.1528, -0.3458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I'd say existing customer, I suppose. I don't know any other kind of customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0806,  0.0952,  0.2426,  0.1287, -0.0371]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4499,  0.1056,  0.0019,  0.2237, -0.4376]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2130, 0.1949, 0.1905, 0.1811, 0.1856, 0.2805]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0940, 0.2752, 0.1672, 0.2781, 0.1974]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2886, -0.0467, -0.0827, -0.1210,  0.0204, -0.0191, -0.0117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4226,  0.0289, -0.4337,  0.1857, -0.0928]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1137, -0.0226,  0.0043,  0.0146,  0.1501]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0007, -0.0676,  0.1462,  0.0527]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2647, 0.2708, 0.2619, 0.0716]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1517, 0.2091, 0.1369, 0.2839]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2535, 0.2762, 0.2752, 0.2341, 0.2872]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements and also high-speed interconnect testing. Both seem really important to me right now.\n",
            "The intended answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0756, -0.1104,  0.0924, -0.2536, -0.1415, -0.1710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2839, 0.2693, 0.2625, 0.2506, 0.2685]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1795, -0.1123,  0.1532, -0.3700, -0.2043]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either an existing customer or a competitor, maybe an existing customer.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2291,  0.2105,  0.2356, -0.2279,  0.0850]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2245, 0.2178, 0.2077, 0.2063, 0.1998, 0.2791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2330, 0.1760, 0.2279, 0.0973, 0.1826, 0.1335]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2127, 0.2536, 0.2487]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2869, -0.2850, -0.1121, -0.0332,  0.2427,  0.2829]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2483,  0.2008,  0.1577, -0.1314]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2633, 0.2732, 0.2507, 0.2632, 0.2406, 0.2698, 0.2439, 0.2726, 0.2860,\n",
            "         0.2837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I'm operating in Physical Security, that sounds right.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1419, -0.1381,  0.2488,  0.2359, -0.1319]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, is it an existing customer, maybe a new prospect, perhaps press or media, or even a competitor, hmm, I am really not sure, but maybe a new customer prospect is the one.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2823, 0.2818]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Well, I see that my only option here is 'No', so, I would say no, I don't want marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2663, 0.1712, 0.1968, 0.1925, 0.2414, 0.2498, 0.2011, 0.1182, 0.0396,\n",
            "         0.2270]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0803, 0.2472, 0.2233, 0.2694, 0.2701]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I guess I search for a solution to extract data from emails, or maybe to improve CRM data quality, or capture trade fair contacts, one of those.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2619, 0.2306, 0.2883, 0.2863, 0.2878]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2122, 0.2550, 0.2611]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, well, maybe they would want a follow up in, uh, like 3 weeks. I really am not sure what the other option was.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2547, 0.2646, 0.2698]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1694, 0.1116, 0.0945, 0.1429, 0.2649, 0.1236, 0.1624, 0.0921]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3477, -0.3550, -0.3547, -0.2845, -0.2638]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2879, -0.2905,  0.1272,  0.2758,  0.2730]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4969, -0.3968, -0.4880, -0.4819, -0.4814,  0.2462, -0.2819, -0.5126]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4042, -0.3996, -0.3993, -0.4893, -0.2717]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2750, 0.2363, 0.2745, 0.2738, 0.2577, 0.2105, 0.2478, 0.2727, 0.2565,\n",
            "         0.2699, 0.2730, 0.2158, 0.2780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for the follow up, I guess I should copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Domiki Stein, and also Tim Persson then.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.4978, -0.4283, -0.4453, -0.0870, -0.4744]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I don't see any options, so I guess it's an empty set then.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2368, 0.2435]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do you need consent for data processing? Well, I'd have to say yes, then. That's the only option.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3948, -0.2322, -0.2739, -0.4358, -0.4888, -0.3438, -0.3113]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1499, 0.1172, 0.1203, 0.0595, 0.2443, 0.0255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3084,  0.2683, -0.3017,  0.2364,  0.2588]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1864,  0.0413,  0.0980, -0.2697]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1358, -0.1597, -0.1094, -0.0514, -0.1233, -0.1608,  0.0814]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2294,  0.0475,  0.0543, -0.1062,  0.1034, -0.0082]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1359, -0.1810]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess I'd say no, since that's the only option there.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.4776, -0.4144,  0.2730, -0.2365, -0.4892, -0.4315, -0.1156, -0.3890]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0721, -0.1337, -0.0209,  0.1042,  0.1470,  0.1693, -0.1583]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2637, -0.3040, -0.4270, -0.3488]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2827, -0.1618,  0.2712,  0.2843,  0.2434,  0.2767]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2584, 0.2771, 0.2478, 0.2134, 0.2521, 0.2298]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2768, -0.0338, -0.2436, -0.4181, -0.3834, -0.3154, -0.2252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2689, 0.2654, 0.2464, 0.2651, 0.2392, 0.1983, 0.2627, 0.2689, 0.2399,\n",
            "         0.2567, 0.2196, 0.2019, 0.2729]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1982, 0.2450, 0.2463]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2734, 0.2093, 0.2023, 0.1381, 0.2266, 0.1987]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3477,  0.2172, -0.2463, -0.3317, -0.3334, -0.5333,  0.2360,  0.2370,\n",
            "          0.2622,  0.2469, -0.4709,  0.2465, -0.3649]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I'm not sure, maybe Johannes Wagner, or perhaps Jessica Hanke. It could be Sandro Kalter too, or maybe Jens Roschmann. I think Sean Kennin is an option.\n",
            "The intended answer was: ['Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2648, 0.2739, 0.2692, 0.2345, 0.2757]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4277, -0.4707, -0.4797,  0.2181, -0.4620, -0.4955, -0.4453, -0.3521,\n",
            "         -0.4926, -0.3973]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2599,  0.2716,  0.2616,  0.2346,  0.2730, -0.3131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they are interested in either the '200 Automation' option, or maybe it's the '256 Joining Systems for large components'. Both seem possible, honestly.\n",
            "The intended answer was: ['200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1609, 0.2322, 0.1773, 0.2655, 0.1556, 0.1382]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0900,  0.2826,  0.1666,  0.0506,  0.0902,  0.0350,  0.1240,  0.2670,\n",
            "         -0.0292,  0.2292]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0041, -0.3616,  0.2501,  0.2396, -0.3053]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4022, -0.4406, -0.4224, -0.3075, -0.3400, -0.3805, -0.2957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0408,  0.2740,  0.1288, -0.0341,  0.0693,  0.0481]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1198, 0.2121, 0.1446]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2560, 0.2485, 0.2519, 0.2271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2686, 0.2736, 0.2649, 0.2700, 0.2611, 0.2650, 0.2643, 0.2723, 0.2773,\n",
            "         0.2830]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4617, -0.3885, -0.0572, -0.1625, -0.1526, -0.4038,  0.2564]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4275, -0.3441, -0.4142, -0.2009, -0.0436]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0244, 0.1633, 0.0404, 0.0890, 0.2277]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2649, 0.2646, 0.2648]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0982, -0.1828, -0.2007, -0.2506, -0.0748, -0.1407, -0.0737]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects, I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2398, -0.2082, -0.2411, -0.3187, -0.1167]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2826, 0.2773, 0.2711, 0.2814, 0.2882, 0.2690, 0.2756, 0.2712, 0.2785,\n",
            "         0.2797]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1526, 0.2008, 0.1875]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2130, 0.1886, 0.1731, 0.2740, 0.2227, 0.2253, 0.1990, 0.2144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0315, -0.0378,  0.2283,  0.0976, -0.1008]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0649, -0.0787, -0.0497,  0.2270,  0.2743]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5211, -0.5055, -0.5135]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would say I'll call then.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2056, 0.2730, 0.1477, 0.1935, 0.2042, 0.2119, 0.1896, 0.2238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2378, 0.0986, 0.2197, 0.2777, 0.1031]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0963, -0.1456, -0.1779, -0.2860, -0.0882]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2795,  0.2773,  0.2766,  0.2797,  0.2733, -0.3857]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure but I'd say they're looking into 300 Advanced Manufacturing, and then maybe also 234 Assembly Systems and, uh, 256 Joining Systems for large components.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1728,  0.0390,  0.0661, -0.3611]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1933,  0.0859,  0.1545,  0.1922,  0.2295, -0.3546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in additive manufacturing, automation, assembly systems, or joining systems for large components.  Or something else entirely.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2440, 0.2774, 0.2196, 0.2076, 0.2794]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2645,  0.2719,  0.2666,  0.2467,  0.2100, -0.4422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2534, 0.2827, 0.2856, 0.2815, 0.2734]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2339, 0.2633, 0.2601, 0.0796, 0.0679]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0479, 0.1468, 0.1992, 0.1402, 0.1730, 0.1248, 0.2280]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1002, 0.2794, 0.0897, 0.0144, 0.1991]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2581, 0.2587]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2499, -0.2592]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what the options are, but I'd say no.  I'm not comfortable with my data being processed.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2660, 0.1961, 0.2823, 0.2805]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. I'm going with very unsatisfied I think. Yeah, that's what I would say.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2636, 0.2122, 0.2122, 0.2465, 0.2208]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1702, 0.1612, 0.1157]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2372,  0.2703, -0.2803,  0.2662, -0.1875]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1176, 0.1741, 0.1374, 0.0935, 0.0294, 0.2769]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1289, 0.2737, 0.1529, 0.1023, 0.2045, 0.1804, 0.1111, 0.2200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2556, 0.2710, 0.2506, 0.2674, 0.2467, 0.2219, 0.2651, 0.2661, 0.2664,\n",
            "         0.2524, 0.2674, 0.2198, 0.2227]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2785,  0.2752,  0.2759,  0.2779,  0.2645, -0.2423]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0956,  0.2505,  0.1176, -0.0107, -0.0532,  0.1103,  0.1410,  0.2774,\n",
            "         -0.0389,  0.2395]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1916,  0.0836, -0.2043, -0.1669]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, I guess I would say I'm satisfied with the service.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4397, -0.4080, -0.3778,  0.1365, -0.3430]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm interested in visit reports and data cleansing I guess, that's what I think I would want.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2484, -0.0340, -0.2446, -0.2944]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4258,  0.2742, -0.4398, -0.4689, -0.3061, -0.3633, -0.4188, -0.4102]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2742, 0.2768, 0.2718, 0.2689, 0.2743, 0.2805, 0.2656, 0.2757, 0.2849,\n",
            "         0.2867]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2741, 0.2710, 0.2505, 0.2617, 0.2757]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2155, -0.2377,  0.1010,  0.2786,  0.2683]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1679, -0.2385, -0.2782, -0.3511, -0.0849, -0.0714, -0.1885]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2390, 0.1538, 0.0609, 0.0168, 0.1481, 0.1246]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1338,  0.1932,  0.1972,  0.2619,  0.2422, -0.3592]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3666, -0.3577]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2312, 0.2114, 0.2759, 0.2783, 0.2716]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2170,  0.2711, -0.3364, -0.0584,  0.2655]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2232, 0.2463]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2621, 0.2790, 0.2678, 0.2856, 0.2720]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4266,  0.2655, -0.4179, -0.0871,  0.2620]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2839, 0.2820, 0.2241, 0.2837, 0.2759, 0.2552]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay so I'm interested in MY-SYSTEM, Notion, JS EcoLine and also AKW100. I think those are my options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3208, -0.2292, -0.2516]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1559, 0.2686, 0.1614, 0.0953, 0.1654, 0.1107]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0755,  0.2417,  0.1134,  0.2543,  0.0713, -0.2884,  0.2537, -0.0634,\n",
            "         -0.0164,  0.1719,  0.2614, -0.1799,  0.2643]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2500, 0.1893, 0.2135, 0.1921, 0.2367, 0.2488, 0.1896, 0.1093, 0.1206,\n",
            "         0.2293]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2680,  0.2703, -0.0711, -0.1022, -0.0723, -0.3916,  0.2505,  0.2624,\n",
            "          0.2701,  0.1154,  0.2645, -0.4583, -0.2860]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2818,  0.2811,  0.0081,  0.0567, -0.0813,  0.0337]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4663, -0.4144, -0.3080, -0.4374,  0.1986, -0.4293, -0.4261]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1996, 0.2713, 0.1946, 0.1443, 0.1796, 0.1944]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2877, 0.2188, 0.2523, 0.2578, 0.2824, 0.2745]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM and AKW100,  I think those are good products.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0393, -0.0064,  0.0450, -0.1449,  0.0996]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0740, 0.2039, 0.0590, 0.1120, 0.0712, 0.1982, 0.0788, 0.1847, 0.2639,\n",
            "         0.2878]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0181,  0.2154,  0.2268,  0.2761,  0.2412, -0.4072]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2854,  0.2699,  0.2772,  0.2705,  0.2769, -0.2252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2686,  0.2695,  0.2696,  0.2752,  0.2504, -0.1565]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation, maybe something around 210 automation systems, or possibly assembly systems, perhaps around 220.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2896, -0.5249, -0.5352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh geez, well I think I'd probably just call, you know.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2550, 0.0876, 0.1148, 0.0243, 0.1647]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1723, -0.3234]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well I suppose no is my answer here, I'm not sure what the other choices could be though.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2893, 0.2789, 0.2805, 0.2749, 0.2909, 0.2745]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2835, 0.2835, 0.2756, 0.2867, 0.2800, 0.2798]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, also Notion. Plus, I'm into JTS and JS EcoLine. Oh, and AKW100 as well as AX100, I think.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0945, -0.0201]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2826, -0.0241,  0.2496, -0.0264,  0.2836]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2282, 0.2147]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2512,  0.2787,  0.2787,  0.2404,  0.2300, -0.0194,  0.2752,  0.2798,\n",
            "          0.2767,  0.2764,  0.2070, -0.0685,  0.1969]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well, I guess copy Joachim Wagner, Erik Schneider, Jessica Hanke, Sandro Kalter, and also Jens Roschmann.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2601, 0.2534]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0667,  0.2740,  0.2041,  0.2781, -0.2055, -0.1149]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4598, -0.3740, -0.0180, -0.4452, -0.4622, -0.4316, -0.4596, -0.3631,\n",
            "         -0.3014, -0.3904]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2609, 0.2398, 0.2231, 0.2350]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2722, 0.2629, 0.2702, 0.2425, 0.2707, 0.0857, 0.2632, 0.2274, 0.2237,\n",
            "         0.2564, 0.2079, 0.0268, 0.1951]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2642, -0.3452]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2759, 0.2675, 0.2736, 0.2162, 0.1814, 0.0817]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1057,  0.0549, -0.0462, -0.1495,  0.0158,  0.1024, -0.0896,  0.2574]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2209, 0.2177]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1284, 0.1614, 0.0514, 0.0849, 0.1324, 0.2601, 0.0547, 0.1836]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2767,  0.2700,  0.2743,  0.1650,  0.1377, -0.4519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0844,  0.1101,  0.0272, -0.2980]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4437, -0.2839,  0.1610, -0.3572]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2761,  0.2750,  0.2743,  0.2767,  0.2695, -0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh, hmm. I think they're interested in things like 200 Automation, and then there was something about 300 Advanced Manufacturing, and also maybe 234 Assembly Systems.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2381, 0.2190, 0.2242, 0.2182, 0.2117, 0.2868]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2882, 0.2932, 0.2933, 0.2990, 0.2981, 0.2948, 0.2990]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3597, -0.3657, -0.3821, -0.3250, -0.2587]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2158, 0.2806, 0.1830, 0.1139]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0775, -0.0522, -0.2595, -0.3276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I am an existing customer then.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2368, 0.2628, 0.0893, 0.2942]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3660, -0.2425, -0.3248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1534, 0.1920, 0.1896]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2642, 0.2010, 0.2300, 0.2386]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I guess I could either send an **Email**, or take **No action** at all. I'm not sure which is the best route to take here.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2821, -0.1600, -0.3291,  0.0711]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1084, 0.1872, 0.1424, 0.2439, 0.1041, 0.0815]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0229, -0.0558, -0.0293,  0.1099,  0.1127,  0.1344, -0.0551]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I really don't know. Maybe it's, like, 7 or so?\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4927, -0.5161, -0.4968]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2773, 0.2690, 0.2747, 0.2690, 0.2692, 0.2868, 0.2637, 0.2597, 0.2796,\n",
            "         0.2835]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1907, 0.2714, 0.2025, 0.1680, 0.1077, 0.1989, 0.1791, 0.2703, 0.0835,\n",
            "         0.2432]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5522, -0.3320, -0.3963]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.0135, -0.0935,  0.2453,  0.1097, -0.1474]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3111, -0.3497]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I'm not really sure what options there are but I'll say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2503, 0.2756, 0.2444, 0.2637, 0.2378, 0.2614, 0.2576, 0.2785, 0.2804,\n",
            "         0.2818]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0576, -0.0431,  0.1194,  0.0633,  0.2797,  0.2847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0360,  0.2761,  0.0572, -0.1876, -0.0164, -0.1618]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0944, 0.1541, 0.0633, 0.2877]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2828, 0.2834, 0.1947, 0.2841, 0.2787, 0.2815]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and a few others I think, like JS EcoLine,  AKW100, and maybe AX100.  I'm not sure what all the options are\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0385,  0.2648,  0.1364,  0.2624,  0.2706]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2631,  0.2325,  0.1712,  0.2490,  0.2577, -0.1474,  0.2447,  0.2549,\n",
            "          0.1066,  0.2586,  0.0389, -0.1722,  0.0795]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2677, 0.2443, 0.2521, 0.2717]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2748, 0.2836, 0.2750, 0.2755, 0.2705, 0.2659, 0.2754, 0.2834, 0.2579,\n",
            "         0.2828]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4252, -0.1191, -0.4246, -0.0909, -0.2655]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because they're useful for networking.  Data enrichment and cleansing also sound important to me, for keeping information accurate and complete.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1985, 0.1842, 0.1478, 0.1663, 0.1990, 0.2712, 0.1775, 0.2327]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0285, 0.0061, 0.1337, 0.1994, 0.2588]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2797, 0.2777]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I don't know about marketing information by e-mail, so no, I wouldn't like to.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2146, 0.1627, 0.2858, 0.2820]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5254, -0.3025, -0.4483]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2884, 0.2866, 0.2791, 0.2865, 0.2605, 0.2736, 0.2847, 0.2852, 0.2739,\n",
            "         0.2889]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2778,  0.0416, -0.1191,  0.2229]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3326,  0.1653, -0.3864, -0.1566,  0.2024]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2762, 0.2754, 0.2422, 0.0026, 0.1990, 0.2742]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2698, 0.2737, 0.2668, 0.2707, 0.2709, 0.2638, 0.2799]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around eight people.  I don't know what the other options are, but eight seems like a reasonable size for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2593, 0.2750, 0.2585, 0.2532, 0.2459, 0.2839, 0.2710, 0.2270, 0.2732,\n",
            "         0.2703, 0.2512, 0.2113, 0.2431]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2838, 0.2883]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, sure I guess, yeah. I would like to get email marketing. Yes sounds good.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2294,  0.0475,  0.0543, -0.1062,  0.1034, -0.0082]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1051,  0.2882,  0.0894, -0.1190,  0.0088,  0.1943,  0.1650]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2034, 0.2316, 0.1821, 0.1826, 0.1908, 0.2720, 0.2139, 0.2557]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2596, -0.4040]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3215, -0.3245, -0.3193, -0.3350, -0.1464]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2811,  0.2744,  0.2744,  0.2780,  0.2592, -0.3591]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2064, 0.2600, 0.1599, 0.1826, 0.2123]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4391,  0.2653,  0.2610, -0.0794, -0.0595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3478,  0.2364, -0.2703,  0.2268,  0.2486]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1438, -0.1524, -0.1162,  0.2774, -0.0180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3831, -0.2358, -0.3757]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3612, -0.4033, -0.2505, -0.5208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3416,  0.2583,  0.2572, -0.0502,  0.2501]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0104,  0.1747, -0.3955, -0.1284,  0.2300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, well, maybe scan business cards or, I could clean up the CRM, or capture trade fair contacts, yeah. I would choose all of them I guess.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2301,  0.1993, -0.0555,  0.0083,  0.2354]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try cleaning up the CRM,  then maybe extract data from emails to see if that helps, and finally, I'd  capture contacts from trade fairs, hoping one of those things solves it.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2640, 0.2662, 0.2671]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1487, 0.1867, 0.1839]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1517, -0.0256, -0.0254,  0.1984, -0.1718, -0.0698,  0.1791,  0.0811]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1763,  0.0132,  0.1497,  0.2092,  0.1660, -0.3514]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4229, -0.3899, -0.4296,  0.2429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess it's either email or we do nothing at all, like no action. I'm not really sure which is it.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2863,  0.2849, -0.0319,  0.0791,  0.2841,  0.2580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2071,  0.1515, -0.2548, -0.1720, -0.0996]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4613, -0.4289, -0.4709, -0.5063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure what will happen. Maybe they will call or maybe they won't do anything at all.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2278, 0.2407, 0.2381]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure which one they'd want, but maybe in 2 weeks would be good. Or perhaps 1 week or even 3 weeks after the initial contact would be best.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2468,  0.1905,  0.2309, -0.0416]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0150, -0.1545, -0.1074, -0.1076,  0.0262,  0.2558,  0.0427]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2774, 0.2771]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I do not want to receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1214,  0.1384, -0.4082,  0.1899, -0.4479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2429, 0.2508, 0.2819, 0.2762]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5159, -0.4687, -0.2841, -0.3837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess either I could schedule a visit or there would be no action at all, either of those two.\n",
            "The intended answer was: ['Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0896, 0.0514, 0.0370]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2699, 0.2699, 0.2637, 0.1717]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2838, 0.2831, 0.2806, 0.2874, 0.2868]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so for communication, I see we could use German. That's the only language option available.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2821, 0.2828]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent? Hmm, I think yes, that seems like it.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2502, 0.2289, 0.2688, 0.2674, 0.2696, 0.2798, 0.2293, 0.2353, 0.2395,\n",
            "         0.2619, 0.2333, 0.2610, 0.2720]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow up, I guess we should copy Erik Schneider, or maybe Oliver Eibel? Or it could be Angelina Haug, or even Marisa Peng, hmm maybe Sean Kennin, or perhaps Tim Persson would be best.\n",
            "The intended answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2659, 0.2621, 0.2678, 0.2530, 0.2674, 0.2144, 0.2640, 0.2695, 0.2457,\n",
            "         0.2629, 0.2416, 0.2109, 0.2718]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, for follow up? I guess I could copy Stephan Maier, maybe Erik Schneider too, or Angelina Haug... then there's Johannes Wagner, or even Jessica Hanke, or perhaps Tim Persson!\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2410, 0.2565, 0.2501, 0.2326, 0.2587, 0.2397, 0.2614, 0.2490, 0.2536,\n",
            "         0.2595]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2401, -0.1569]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, I guess I would say yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0747, -0.1162,  0.0053, -0.4750, -0.3059]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1121,  0.0349,  0.0609, -0.0487,  0.0094,  0.2479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2817, 0.2803]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Hmm, I guess no, I'm not really interested in marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2498, 0.2502, 0.2626, 0.2417, 0.2879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0570, -0.2555,  0.0609, -0.4939, -0.2788]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not really sure. Is it like, are they an existing customer, or maybe they're a supplier, or could it be they're a competitor, perhaps?\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2769, 0.2740]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't want marketing emails; I prefer not to receive them.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2784, 0.2738, 0.2645, 0.2691, 0.2724, 0.2711, 0.2834]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2737, 0.2801, 0.2717, 0.2823, 0.2867]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn about **noise figure measurements** and also **display port debugging and compliance**.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0866, -0.3831, -0.3590, -0.3831]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2282, 0.2147]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0881,  0.0951,  0.0997,  0.1429,  0.1416,  0.1569, -0.1067]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I guess it would be somewhere around 3 people. I'm not sure really.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2603, 0.2675, 0.2738]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1969,  0.1693,  0.1413, -0.1840]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh hmm, I think I'd say existing customer is the type.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2086,  0.2695, -0.1860,  0.2682, -0.1864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0330,  0.2866, -0.0606, -0.2233, -0.0938,  0.0688,  0.0544]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0413, -0.1447,  0.1308,  0.1544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm unsatisfied, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0879,  0.1358,  0.1666, -0.0272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0704, 0.2819, 0.1816, 0.2790, 0.1811, 0.2759]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2747, 0.2771, 0.2771, 0.2824, 0.2745, 0.2707]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1745, 0.2756, 0.0915, 0.1195, 0.1774, 0.1848, 0.1155, 0.1866]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2039,  0.1784,  0.2423, -0.2199]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0737,  0.0096,  0.2349,  0.1742, -0.0184]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0320,  0.0623,  0.1082, -0.0843,  0.2002]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2231,  0.0583,  0.2117, -0.1888, -0.0861]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm I think it's probably an existing customer, you know like someone we already know. Maybe also competitor, somebody from another company.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1525, 0.2246, 0.2640, 0.0517]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4094, -0.5270, -0.5381]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2855, 0.2086, 0.2860, 0.2829, 0.2857]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.3954, -0.2986,  0.2556,  0.2782]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1637,  0.0388,  0.1786,  0.2400,  0.2168,  0.1946,  0.1354, -0.1952,\n",
            "          0.2241,  0.2459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2401, -0.2279, -0.2461, -0.2851, -0.2878, -0.3052, -0.0784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1999, 0.2909, 0.2266, 0.1416, 0.2558]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2783, -0.2109, -0.1193,  0.0338, -0.1135, -0.0758]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2609, 0.2617, 0.2683]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2655, 0.2191, 0.2856, 0.2832, 0.2794]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in Double-Pulse Testing,  because it sounds interesting, and Display port debugging and compliance, as I'd like to learn more about that.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2138, 0.2084, 0.2368, 0.2540, 0.2713]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4860, -0.3677, -0.4072]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would probably call, it seems like the most logical next step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0181, -0.0267, -0.0391, -0.0997,  0.0221, -0.0857,  0.2789]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3968, -0.4097, -0.4080, -0.4277, -0.3309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2816, 0.2795, 0.2401, 0.2512]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction? I'd say, I guess, I'm satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4630, -0.4104, -0.4376, -0.0931]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, well, I guess it's either a phone call or maybe no action at all, not sure which one it will be though.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3091,  0.2604,  0.2531, -0.3395, -0.3260, -0.4744,  0.2447, -0.4332,\n",
            "         -0.3676, -0.1369,  0.2520,  0.2211,  0.2653]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I'm not sure but maybe Joachim Wagner, or Erik Schneider, or Domiki Stein, or Sean Kennin, or perhaps even Tim Persson?\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.2147, -0.0605,  0.2573,  0.2247,  0.0037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2180, 0.1683, 0.1198, 0.1410, 0.0981]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1074, -0.3035, -0.3283, -0.3923,  0.2577]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2023, -0.1078,  0.2559, -0.4348, -0.2008]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2397, -0.2047,  0.1014,  0.2063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2743, 0.2739]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.  I don't want my inbox cluttered.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.5678, -0.5181, -0.5208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess the next thing I would do is call, seems right to me.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.3553,  0.2400, -0.3311, -0.4102, -0.3467]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2058, 0.1187, 0.2803, 0.2783]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, regarding customer satisfaction, I suppose that they could be very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5002, -0.4741, -0.4618]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'm not sure what else there is, but I guess I'll offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0982, -0.1828, -0.2007, -0.2506, -0.0748, -0.1407, -0.0737]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1850, 0.2788, 0.2860, 0.0689, 0.2875]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2620, 0.2791, 0.2874, 0.2518, 0.2892]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'd be interested in noise figure measurements, double-pulse testing and high-speed interconnect testing, those seem like good things to explore.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2865, 0.2825, 0.2894, 0.2877, 0.2959]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, um, well I guess I'd be interested in Double-Pulse Testing and Display port debugging and compliance, those sound like things I could use.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3269, -0.3144, -0.3311,  0.0218, -0.1669]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe it's none.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2386, -0.3577, -0.3304, -0.2798, -0.3411,  0.2012, -0.2996, -0.3667,\n",
            "         -0.0262, -0.0825]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2521, 0.2437, 0.2498, 0.2687, 0.2618, 0.2569, 0.2383, 0.1713, 0.2434,\n",
            "         0.2614]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2585, 0.2475, 0.2138, 0.2459, 0.2680]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for Scan business cards, also to Clean up CRM, and maybe to Extract data from emails. I would also improve CRM data quality and try to Capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1367, 0.2304, 0.1885]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2658, 0.2709, 0.2720]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not sure, I think they want the follow up in 2 weeks, yeah that sounds about right.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.4865,  0.0295, -0.2798,  0.0045,  0.2018]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try cleaning up the CRM, maybe extracting data from emails to improve the CRM data quality, and definitely capture those trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3448, -0.1439, -0.3920]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4667, -0.1807, -0.4197,  0.2472, -0.1901]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2615,  0.2625,  0.0713,  0.2542,  0.0782, -0.2044,  0.2514, -0.0166,\n",
            "          0.0012,  0.1163,  0.2619,  0.2445, -0.0897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Domiki Stein, and Sean Kennin,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Domiki Stein', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2242, 0.2230, 0.2220, 0.2337, 0.2642, 0.2606, 0.2869]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0377,  0.2271, -0.0020, -0.0693, -0.0504]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2103, 0.1997, 0.1407, 0.1654, 0.1900, 0.2723, 0.1813, 0.2338]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0969, -0.3159, -0.3629, -0.3996]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2187, 0.1991, 0.1581, 0.1508, 0.2118, 0.1874, 0.1817, 0.2545]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1134, -0.3648, -0.2396, -0.3051,  0.2750,  0.2394]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in AKW100. I'm not really sure what else is available.\n",
            "The intended answer was: ['AKW100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0842,  0.2474,  0.1286,  0.1430,  0.2592]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2769,  0.2732,  0.2333,  0.2172,  0.2772,  0.0194,  0.2685,  0.1410,\n",
            "          0.2745,  0.2738,  0.2727, -0.2002,  0.1046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5707, -0.4953, -0.4194]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2773, 0.2643, 0.2664, 0.2650, 0.2840, 0.2664, 0.2670, 0.2455, 0.2725,\n",
            "         0.2711]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3533,  0.2648,  0.2574,  0.2081,  0.0279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3812, -0.3550,  0.2589, -0.3636, -0.2814]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2604, 0.2296, 0.1891, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2605, 0.2032, 0.1820, 0.1804]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2994, -0.4144]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know, but I guess No. I'm not sure what the options are.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1343,  0.1000,  0.1212,  0.0230,  0.2511, -0.0471]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2050, -0.3635]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I'm not sure, maybe no. I don't really know what other choices there are.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0879,  0.1358,  0.1666, -0.0272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4763, -0.4871, -0.5356, -0.5295, -0.5183,  0.2075, -0.4770, -0.5403]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2612, 0.2731, 0.2706, 0.2573, 0.2433, 0.1781, 0.2693, 0.2123, 0.2715,\n",
            "         0.2693, 0.2399, 0.1900, 0.2290]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, I'll copy Joachim Wagner, Erik Schneider, Johannes Wagner, Sandro Kalter, and Jens Roschmann on the follow up. That covers everyone you listed, I believe.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2853, 0.2767, 0.2838, 0.2810, 0.2864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in things like automotive radar target simulation. Also maybe noise figure measurements and double pulse testing. And also I'd say display port debugging and compliance as well as high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1897, 0.2229, 0.1632, 0.0642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2442, -0.0357, -0.2072,  0.0055,  0.2638]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2211, 0.2668, 0.2464, 0.2345, 0.2639]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2249, 0.2795, 0.2754, 0.2857, 0.2882]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in noise figure measurements, and also in display port debugging and compliance. And high-speed interconnect testing is another one I'm keen on.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1258,  0.2780,  0.1659,  0.1087, -0.0193,  0.1377,  0.1304,  0.2856,\n",
            "          0.1345,  0.2560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0292,  0.1256,  0.1269, -0.2789]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1746, 0.2785, 0.2633, 0.2841, 0.2698, 0.2453]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3985,  0.1789, -0.0342,  0.0226,  0.2348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess a solution could be cleaning up the CRM, extracting data from emails, or even capturing trade fair contacts. I am not really sure which of those it could be.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0162, -0.2464, -0.3269, -0.3394, -0.1481]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1713, 0.2275, 0.2117, 0.2143]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4332, -0.3586, -0.3307,  0.2924]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3537, -0.4135]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1880, 0.2343, 0.2348]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two weeks, I think.  That seems like a good middle ground.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2819, 0.2815]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2530, -0.1220, -0.3351,  0.2194,  0.0914]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2866, -0.2676,  0.2702,  0.1974,  0.2851,  0.2681]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I think I'd be interested in MY-SYSTEM, JTS, and AKW100, those sound like good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1939, 0.2194, 0.2147]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.4077, -0.3639, -0.4028, -0.4110]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2003, 0.1846, 0.2804, 0.1517, 0.2091, 0.2067, 0.1533, 0.2156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2852, 0.2778, 0.2813, 0.2819, 0.2841]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I think I am interested in automotive radar target simulation. Also I like noise figure measurements. Display port debugging and compliance sounds interesting too and so does high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5026, -0.5173, -0.5325, -0.5333,  0.2426, -0.5202, -0.4578, -0.5547]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2292, 0.2772, 0.2134, 0.1867, 0.2223, 0.1896]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1693, 0.1403]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2034, 0.2690, 0.1492, 0.0654]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1795, -0.1434, -0.2172, -0.1861, -0.1262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0046, -0.0267, -0.3999, -0.4521]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2790,  0.2812,  0.2548,  0.2688, -0.1562, -0.0753]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2717, 0.2710, 0.2541, 0.2696, 0.2363, 0.1764, 0.2682, 0.2229, 0.2706,\n",
            "         0.2602, 0.2295, 0.1776, 0.2729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2400, -0.0916, -0.2006]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for the next steps, I think I need to offer. I guess that's the only thing available?\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0504,  0.0625,  0.0737, -0.0344,  0.2023]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4627,  0.0886, -0.3300,  0.2553, -0.4529]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4722, -0.4696, -0.4740]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They said a week would be good, I think.  That's what I'm going with.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.0894, 0.0765, 0.0895, 0.1868, 0.0799]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3883, -0.3353,  0.2665,  0.2738]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1080,  0.2025, -0.3576,  0.1962,  0.2549]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0157, -0.3270, -0.3144, -0.3233]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2466, 0.2565]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4616,  0.2841, -0.4083, -0.4523, -0.4619, -0.4334, -0.3929]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3247, -0.1269, -0.3419, -0.0054, -0.1163]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0599, -0.1609, -0.2085, -0.1995,  0.2703, -0.1569,  0.0076]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5027, -0.4694, -0.5053, -0.4781, -0.4435]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2676, 0.2752, 0.2578, 0.2744, 0.2849]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3246, -0.1638,  0.1855,  0.2592]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2912, -0.3669]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0476, 0.1044, 0.0212, 0.1367, 0.2286]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2409, 0.2656, 0.2451, 0.2675, 0.2249, 0.2827, 0.2630, 0.2677, 0.1972,\n",
            "         0.2695, 0.1968, 0.0022, 0.2716]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, I guess copy Oliver Eibel, Marisa Peng, Johannes Wagner, Jessica Hanke, Jens Roschmann and Tim Persson, all of them seem relevant.\n",
            "The intended answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2916, -0.1042,  0.2570,  0.2323,  0.2633]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4608, -0.3917, -0.4194]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2368, 0.2221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what options there are. I would say no for the data processing consent.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2928, 0.2951, 0.2957, 0.2977, 0.2982, 0.2956, 0.2971]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is probably around 16 to 20 people, judging by the usual numbers I see.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2809, 0.2836, 0.2356, 0.2830, 0.2454, 0.2760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2752, 0.2763]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2119, 0.2024, 0.2299, 0.2556, 0.2735]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1733, 0.1729, 0.2874, 0.1830, 0.2646]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1925, 0.2137, 0.2133, 0.2557, 0.2306]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2792, 0.2780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Hmm, well, I guess no. I don't really need marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2479,  0.2301,  0.2551,  0.2690,  0.2669, -0.2665]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2842, 0.2847, 0.2705, 0.2860, 0.2430, 0.2791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2824, 0.2844, 0.2759, 0.2879, 0.2875]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if you're asking about a language for communication, it seems like Italian is the only option available right now.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0475,  0.0286,  0.0253, -0.1153,  0.0432]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4829,  0.0131, -0.5004]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2299, 0.1848, 0.1003]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2066, 0.1082, 0.0581, 0.0890, 0.0162]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2717,  0.2580,  0.2061,  0.1277,  0.1580,  0.2864,  0.2604,  0.0670,\n",
            "          0.2715,  0.2332,  0.1335, -0.1463,  0.2724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, let's see. I guess I should copy Stephan Maier, Marisa Peng, Johannes Wagner, Sandro Kalter, and Tim Persson on that then.\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2148,  0.2630, -0.3934, -0.0900,  0.2607]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2870, 0.2856, 0.2842, 0.2863, 0.2896, 0.2807, 0.2862, 0.2866, 0.2873,\n",
            "         0.2882]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, I'd say I operate in the Industrial sector. Yeah, that seems right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5062, -0.4645, -0.5284, -0.5246, -0.5250,  0.2210, -0.4226, -0.5375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2613, 0.1524, 0.1443, 0.2576]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1611, 0.2362, 0.1895]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0645, 0.2229, 0.1989]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, next steps? I guess I'd probably go with offer. That sounds right to me.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.3986, -0.3297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0128, -0.1812,  0.2200,  0.2878,  0.2433,  0.2870]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.1714, -0.2969,  0.2488,  0.2270, -0.2570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2857, 0.2884, 0.2754, 0.2397, 0.2838, 0.2860]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2592, 0.2165, 0.2105, 0.1123, 0.2191, 0.1780]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2140,  0.2696, -0.3500, -0.0363,  0.2694]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1991, 0.0636, 0.2639, 0.2312, 0.2874]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in high-speed interconnect testing, because that sounds like a really important field.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2845, 0.2134, 0.2695, 0.2839, 0.2103, 0.2167]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2783,  0.2719,  0.2720,  0.2782,  0.2606, -0.2264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3681,  0.2606,  0.2571,  0.1969, -0.0076]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1538, -0.0379,  0.2495,  0.1631,  0.2839]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I think I am interested in high-speed interconnect testing, if that's an option.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2995, -0.3867, -0.3459,  0.1561]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4034,  0.2654, -0.3484,  0.2372,  0.0593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0334, -0.1346, -0.0962, -0.0956,  0.2733,  0.1006,  0.0718]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3883, -0.2564, -0.3605, -0.3853, -0.3280, -0.1776, -0.3774, -0.2835,\n",
            "         -0.0859,  0.2694]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2031, 0.1951, 0.2489, 0.2203, 0.2683]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the specific count but if I had to guess, maybe around 500 employees? It feels like a mid size company to me.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3960, -0.4154, -0.4250, -0.4241, -0.4224, -0.4145, -0.3219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh geez, well I would say it's about 3 people, maybe a bit more. That seems right for a team.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1289, 0.2708, 0.2399, 0.2714, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2467, -0.2960, -0.2439, -0.3338, -0.2188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2956,  0.2597,  0.1414,  0.1765, -0.4267]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2765, 0.2789, 0.2744, 0.2740, 0.2767, 0.2830, 0.2642, 0.2798, 0.2838,\n",
            "         0.2850]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0614, 0.0822, 0.0996, 0.1047, 0.0127, 0.2053, 0.0879, 0.1556, 0.2592,\n",
            "         0.2769]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2347, 0.1845, 0.1088]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2768, 0.1737, 0.1825, 0.2038, 0.2337, 0.1891, 0.2637, 0.2162]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3905, -0.3588, -0.3367, -0.3628, -0.2962, -0.3448, -0.1410]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would guess around 25, maybe 30 people. Seems like a good size.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0201,  0.0372,  0.0351, -0.0726,  0.2152]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0777, -0.1937, -0.0647,  0.0413, -0.2791, -0.1744,  0.1578,  0.2522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0247,  0.2636, -0.0211, -0.1938,  0.2652]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0723, -0.2201,  0.0886, -0.2853]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2601, -0.1973,  0.0158, -0.2035, -0.0384,  0.2775, -0.1692, -0.2334,\n",
            "          0.2600,  0.2521, -0.1246,  0.2460, -0.2039]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2793, 0.2770]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1462, 0.2772, 0.2868, 0.2838, 0.2854]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.4101, -0.4448, -0.4450, -0.4601, -0.2186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1750,  0.0928, -0.0954,  0.0532]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I don't know of any planned action right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2553, 0.2186, 0.2128, 0.1680, 0.2271, 0.2045]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1333, 0.1107, 0.1147]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2102, -0.0599,  0.2424,  0.1880,  0.2570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.2867,  0.2793,  0.2815,  0.2851,  0.2766, -0.2011]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0327, -0.0379,  0.0956,  0.2074,  0.2639]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1184, -0.1445, -0.1131, -0.0002, -0.1484]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2002,  0.2814, -0.1267,  0.2788, -0.4749, -0.4357]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2880,  0.2799,  0.2754, -0.0229,  0.2251]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4645, -0.4204, -0.2669, -0.5164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure but I think it could be either a phone call or scheduling a visit.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3174, -0.3289, -0.3688,  0.2610, -0.1661]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1736,  0.2828,  0.1318,  0.1138, -0.0405,  0.1040,  0.1622,  0.2842,\n",
            "          0.1065,  0.2653]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2876, 0.2789, 0.2859, 0.2819, 0.2865]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2828, 0.2797, 0.2799, 0.2793, 0.2703, 0.2651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2036, -0.2339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I'm not sure what the options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1152, 0.2780, 0.2780, 0.2821, 0.2852]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4409, -0.3416, -0.4744, -0.0616, -0.1180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0448, -0.2041,  0.2049,  0.2806,  0.2780,  0.2348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well, I suppose I'd be interested in JS EcoLine and also AKW100.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.1468,  0.2560,  0.2705,  0.0622,  0.1106,  0.2827,  0.2594, -0.0487,\n",
            "          0.0505,  0.1841,  0.0481, -0.1616, -0.0683]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess I would copy Erik Schneider, Marisa Peng, and Johannes Wagner. That sounds right to me.\n",
            "The intended answer was: ['Erik Schneider', 'Marisa Peng', 'Johannes Wagner']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0354, -0.0854, -0.0417, -0.1088, -0.0237,  0.1239,  0.2723]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2866, -0.1068, -0.2611, -0.0202,  0.2714]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1558,  0.0242, -0.2490]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1803, -0.2611]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2527,  0.2643, -0.0315,  0.2767,  0.2638]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution. Maybe I could *Scan business cards*, or *Clean up CRM*. *Improve CRM data quality* could help, and possibly even *Capture trade fair contacts*.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0094, 0.2891, 0.2776, 0.1173, 0.2876, 0.2655]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4192, -0.3769, -0.4021]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, hmm, I guess my next step would probably be 'offer'.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2808,  0.2779,  0.2775,  0.2766,  0.2764, -0.0481]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0451, -0.3183, -0.3754, -0.4540]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1737, 0.2556, 0.1828, 0.1671, 0.2046, 0.2461, 0.1068, 0.2492, 0.2751,\n",
            "         0.2806]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1387, 0.2006, 0.1919]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2676, 0.2604, 0.2690, 0.2671, 0.2802]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0978, -0.2610, -0.2270, -0.1731, -0.0143,  0.2469, -0.1636]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1375,  0.2103, -0.3921, -0.0280,  0.2384]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1616, -0.3401, -0.3303, -0.4050,  0.2520]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5274, -0.5237, -0.5439, -0.4188,  0.2243, -0.5288, -0.4859, -0.3522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0307, -0.1175, -0.0213, -0.2027,  0.2050, -0.2275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2084, 0.2084]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0368, -0.0756, -0.0367, -0.1264,  0.2104, -0.1760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1797,  0.0165,  0.2558, -0.4954, -0.2241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0451, -0.3183, -0.3754, -0.4540]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3089, -0.3406, -0.4955, -0.2937, -0.4723, -0.4812, -0.3477, -0.2409,\n",
            "          0.0846, -0.1805]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4710, -0.3642, -0.4586,  0.1797,  0.2552]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0338, -0.3012,  0.2476,  0.2151, -0.3092]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2533, 0.2731, 0.2689, 0.2470, 0.2723, 0.1697, 0.2660, 0.2696, 0.2695,\n",
            "         0.2682, 0.2242, 0.1302, 0.2184]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2597, -0.2807, -0.3107]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0217,  0.0124,  0.0687,  0.1652,  0.2647]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3639, -0.3179, -0.0993, -0.3617, -0.4029, -0.3232, -0.3669, -0.3585,\n",
            "         -0.1651, -0.2535]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1614, 0.2212, 0.0980]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4262,  0.2662,  0.1699, -0.5020,  0.2784,  0.2841]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0448, 0.1654, 0.2482, 0.0123, 0.0802, 0.0817, 0.0232, 0.1719, 0.2301,\n",
            "         0.1882]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2839, 0.2826]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think so.  I prefer not to receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1808, 0.2132, 0.2844, 0.2197, 0.2255]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2622, 0.1427, 0.1651, 0.0102, 0.2529]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0655,  0.1001, -0.0795]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2469, -0.2824, -0.3566, -0.2798, -0.1819]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2480, 0.2738, 0.2407, 0.2282, 0.2460, 0.2427]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3230, -0.2894,  0.2234, -0.2641, -0.2812, -0.3185, -0.2308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0271, -0.4887, -0.4830, -0.3945, -0.3971, -0.4742,  0.2820, -0.5247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2840, 0.2761, 0.2456, 0.2813, 0.2838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1788,  0.1449, -0.0361]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2147, -0.2660, -0.3732, -0.3544]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1944, 0.2699, 0.1104, 0.2133, 0.2203]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0375, -0.0348,  0.0146,  0.2441]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2589, 0.2222, 0.2711, 0.2538]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5093, -0.2092, -0.1614, -0.3978,  0.0694, -0.4856, -0.4821]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2316,  0.2746, -0.3816,  0.2329,  0.2707]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in BusinessCards, also DataEnrichment, Data Cleansing and definitely DataQuality, I guess those are the main things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2683, -0.1887, -0.3420, -0.1763]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1292,  0.2659,  0.0735,  0.0510,  0.1358, -0.1354,  0.2575,  0.2618,\n",
            "          0.0057,  0.1273,  0.2669, -0.1211, -0.1392]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Joachim Wagner, Jessica Hanke, and Domiki Stein.\n",
            "The intended answer was: ['Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2837, 0.2825, 0.2774, 0.2889, 0.2870]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, you want to know which language? Well, I guess the only option is German then. It's the only one specified here for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2380, -0.0097,  0.2605,  0.2128,  0.2653]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I think my product interests are BusinessCards, because those seem useful, and also VisitReport which is interesting, plus Data Cleansing, and finally DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2687, 0.2450]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2845, 0.2167, 0.2353, 0.1926, 0.2779]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1783, -0.1166,  0.2817,  0.0845,  0.0105]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0182, -0.1994,  0.0971, -0.1175, -0.2879]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer, maybe a supplier, or even a new customer, could be press or a competitor, so, any of those options really.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1675, -0.0065,  0.1262, -0.1141,  0.1321,  0.1908, -0.1606, -0.1078,\n",
            "          0.2873,  0.2776]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0888, 0.1811, 0.1690]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2165, 0.2265, 0.2193, 0.2457, 0.2399]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2157, 0.2180, 0.2038, 0.2315, 0.2528, 0.2350, 0.2817]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 25 people, give or take a few.  I don't know what the other options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2718, 0.2690, 0.2628, 0.2729, 0.2684]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, I'm not sure about the contact type, maybe it's a new customer or possibly press media, I can't say.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1818,  0.0045, -0.2514, -0.3086]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2913,  0.2687,  0.2635,  0.2258,  0.2622]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, my product interests are DataEnrichment, VisitReport, Data Cleansing and DataQuality, I think. Those sound like my sort of thing.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1869, 0.2197, 0.2661, 0.2067, 0.2470, 0.2672, 0.1888, 0.1531, 0.2873,\n",
            "         0.2879]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0027, -0.2296,  0.2676,  0.2820,  0.2802,  0.2785]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0221,  0.0046,  0.0422,  0.0194,  0.2846]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1497, -0.0371,  0.2277, -0.4681, -0.2327]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2382,  0.1825,  0.2648,  0.1358,  0.2434, -0.2928]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2686, 0.2693, 0.2705]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe the person would like a follow up in 1 week. I'm not really sure.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1873, 0.0975, 0.2796, 0.2821, 0.2696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2954, 0.2977, 0.3029, 0.3000, 0.2998, 0.2970, 0.3020]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2408, 0.2506, 0.2587, 0.2092]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so the planned follow up, it looks like, is by Phone.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.0919, 0.0207, 0.0599, 0.1397, 0.0547]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4190, -0.4038, -0.4014, -0.4004, -0.3334,  0.0062, -0.0301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2207, -0.2491, -0.2557, -0.3288,  0.2637]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2314, 0.2596, 0.2324, 0.2728, 0.2308, 0.2399]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2180, 0.1763, 0.2274, 0.1041, 0.1622, 0.1549]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2044, 0.0633, 0.2744, 0.2848, 0.1218, 0.1567]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0400, 0.0253]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2559, 0.2730, 0.2529, 0.2842, 0.2689, 0.2481, 0.2494, 0.2697, 0.2622,\n",
            "         0.2771]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4763, -0.4100,  0.2506,  0.1180, -0.2997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2131,  0.2706,  0.2692,  0.1869,  0.1651,  0.2839,  0.2644,  0.0704,\n",
            "          0.1702,  0.2697,  0.1604, -0.2097,  0.2724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2858, 0.2803, 0.2879, 0.1673, 0.2837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2063, 0.1624, 0.1577, 0.1912, 0.2696, 0.1751, 0.1951, 0.1889]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2780, 0.2559, 0.2534, 0.2482]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess if we are talking about customer satisfaction, I'd say satisfied seems like the answer to that.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2630, 0.2744, 0.2538, 0.2540, 0.2617, 0.2601]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0783,  0.1025,  0.0590, -0.0318, -0.3494,  0.0538, -0.3615]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2538, 0.0981, 0.2474, 0.2649, 0.1986]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0159, -0.0416,  0.2824, -0.2234, -0.0952, -0.0776,  0.0203]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1728, -0.2922,  0.2512, -0.2221,  0.2472]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2329,  0.1126,  0.2209, -0.2443, -0.0198]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2636, 0.2659, 0.2709]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1230, -0.3236,  0.2180,  0.2471, -0.2714]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2020, -0.2540,  0.1006,  0.2485, -0.2215]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2765, 0.2764, 0.2785]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2925, 0.2951, 0.2945, 0.2990, 0.3009, 0.3015, 0.2995]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2858, 0.2852]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2509,  0.2725, -0.3041,  0.2391,  0.2659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, product interests, hmm. Well I'd say BusinessCards, and maybe DataEnrichment. Then possibly Data Cleansing. Oh, and definitely DataQuality, those are what I'm thinking.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3333, -0.1592, -0.3074,  0.2361,  0.2694]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1032, -0.1811, -0.3148, -0.3404]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think I'd have to go with existing customer. That seems like a sensible option to pick.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4550, -0.4053, -0.4408, -0.4242, -0.4588]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0448, -0.0634, -0.0376, -0.1750, -0.0083]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 5 employees.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0003, 0.1843, 0.1045]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1855, 0.2137, 0.2887, 0.2167, 0.2651]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1874, -0.1238,  0.0577, -0.1689, -0.0305,  0.0646, -0.2188, -0.1986,\n",
            "          0.2880,  0.2746]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0996, 0.0762]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I'm not sure what the options are here, but I guess I would say no to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1693, 0.1403]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1097, 0.1251, 0.1693, 0.1862, 0.2701]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2391,  0.2760, -0.2101, -0.3729, -0.3399, -0.2915]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2886, -0.3287, -0.2875, -0.2347]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1560,  0.2590, -0.2210,  0.2615, -0.0631]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1950, -0.0331, -0.2636,  0.2627]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh gosh, I'm not sure. It looks like a phone call or no action is the plan. I'm thinking no action is it.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2816, 0.2825]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, so I guess the only option is 'Yes', and sure, I'd be fine with receiving marketing information via email.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2808, 0.1130, 0.2810, 0.2790, 0.2817]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0290,  0.0542,  0.0940, -0.0706,  0.2383]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2800, 0.2893, 0.2628, 0.2750, 0.2133, 0.2502, 0.2635, 0.2915, 0.2052,\n",
            "         0.2855]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2750, 0.2737]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1882,  0.0648, -0.1337, -0.1672]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh I guess it would be existing customer, if that's the only option. I mean, is that what you're asking?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1249,  0.2125,  0.2065, -0.0751]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4062, -0.4980,  0.2403, -0.4048,  0.2420]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2888, 0.2934, 0.2921, 0.2967, 0.2982, 0.2972, 0.2992]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2523, -0.1861, -0.3795, -0.2294, -0.1859, -0.0509, -0.3669]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say maybe it is around 13 people.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2517, 0.2270, 0.2338, 0.2319, 0.2677, 0.2179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2536, -0.2007,  0.2665, -0.1315, -0.0806]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1875, -0.3549, -0.3289, -0.4238,  0.2559]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2105, -0.3225]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3888, -0.3810]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.4803, -0.4460, -0.4053,  0.2693, -0.4130, -0.3991, -0.4261]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2530, 0.2486, 0.2641, 0.1902]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2723, -0.1426, -0.3035, -0.1728]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2422, 0.2812, 0.2913, 0.0257, 0.2835]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements and also in double-pulse testing. Both of those seem like pretty interesting options.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0672,  0.0719, -0.1580,  0.0422,  0.1052,  0.1432, -0.1699]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 12, I don't really know exactly.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2665, 0.1488, 0.2652, 0.1582, 0.1853, 0.2831, 0.1427, 0.1357, 0.1485,\n",
            "         0.2634, 0.1617, 0.2586, 0.1709]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1851, 0.0298, 0.2706, 0.2856, 0.2772, 0.2502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2811, 0.2123, 0.2674, 0.2511, 0.2623, 0.2826]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1397, -0.2302,  0.1395, -0.2288,  0.2629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3821, -0.2866, -0.3513, -0.3661, -0.3673, -0.3751, -0.2842]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the team is usually around 6 to 10 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2869, 0.2868]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3935,  0.0679, -0.1622]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2124, -0.3505]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I don't know the options really. I'm going to say no then.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2880, 0.2908, 0.2883, 0.2933, 0.2949, 0.2918, 0.2950]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0104, 0.2834, 0.2666, 0.2816, 0.2746, 0.2794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.2515, -0.3640,  0.2371, -0.3659, -0.4446]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2764, 0.2766, 0.2586, 0.2678, 0.2761]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4069, -0.4767, -0.3491, -0.4815]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh gosh, I guess I would either send an email, or maybe try to schedule a visit.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4109, -0.2587, -0.5199]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2799, 0.2737, 0.2568, 0.2697, 0.2759, 0.2210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1631,  0.2901,  0.2384, -0.0397,  0.1494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2803, -0.1217,  0.2583,  0.1914,  0.2553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2804,  0.2792,  0.2778,  0.2769,  0.2787, -0.1638]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Okay, let's see. I think they are interested in either '200 Automation', maybe '300 Advanced Manufacturing', or possibly even '256 Joining Systems for large components'.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1894,  0.2532, -0.2686,  0.2226,  0.2639]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1243,  0.2261,  0.2701, -0.0022]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1467,  0.2751,  0.1662,  0.1450,  0.1815, -0.0493,  0.2644,  0.2651,\n",
            "          0.2737,  0.1712,  0.0852,  0.2603,  0.0842]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I guess you could copy Joachim Wagner, or maybe Jessica Hanke. Then again, Sandro Kalter seems good, and also Sean Kennin would work.\n",
            "The intended answer was: ['Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1423, -0.2999]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1400, -0.0869, -0.0782, -0.1308, -0.0866]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0368,  0.1744, -0.1611,  0.1781,  0.2298]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd search for a way to improve my CRM data quality, maybe by scanning business cards from trade fairs to capture new contacts, then cleaning up the CRM and extracting data from emails to make it all accurate.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1041, 0.0273, 0.2196, 0.2858, 0.2792, 0.2839]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2774,  0.0672,  0.0753, -0.0758,  0.1153,  0.0038,  0.1989]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3198, -0.3173]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1923, 0.1469, 0.2699, 0.2877, 0.2900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in display port debugging and compliance, and high-speed interconnect testing, that sounds pretty cool.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.0098,  0.2887,  0.0670, -0.1122,  0.1515]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2375, 0.2376]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2199, -0.0695,  0.1594,  0.2414, -0.0977]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier, or even someone from the press or media, I'm really not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1950, 0.1897, 0.1881]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0480,  0.2866,  0.0067, -0.1062, -0.0055,  0.1753,  0.1368]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3387, -0.3778, -0.3909, -0.2707, -0.2442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4971, -0.4211,  0.2734, -0.4247]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1796, 0.2863, 0.2731, 0.2465, 0.2595, 0.2811]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1874,  0.2656,  0.1633,  0.1518, -0.1256]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I would look at \"scan business cards\", and maybe also \"clean up CRM\". I'm also thinking of \"extract data from emails\". I don't really know what else.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2743, 0.2701, 0.2713, 0.2460, 0.2729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2674, -0.2742, -0.3845, -0.2890]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4212, -0.4110, -0.3643, -0.4305, -0.4464, -0.4572, -0.3553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2397, 0.2652, 0.2383, 0.2394, 0.2432]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0938,  0.2325, -0.1404, -0.0752,  0.0386]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2845, -0.0284,  0.0592, -0.0867,  0.0579,  0.1645,  0.1434]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4139, -0.1733, -0.3471]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1842, 0.2764, 0.1944, 0.1028, 0.1644, 0.1372]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2308, 0.2008, 0.2051, 0.1780, 0.2697, 0.1879]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2811,  0.2762,  0.2786,  0.2832,  0.2751, -0.1957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I believe they're interested in 300 Advanced Manufacturing, 234 Assembly Systems, or maybe 256 Joining Systems for large components. Could also be others, you know.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0084, 0.1240, 0.1162]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they'd prefer a follow up in two weeks,  that seems like a good compromise between a week and three weeks.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.0238,  0.0909,  0.0249,  0.0414, -0.0960, -0.1100, -0.3599]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I really don't know but maybe about 35 people, that's a guess.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2005,  0.0040,  0.2282, -0.0509, -0.0326, -0.3463]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in additive manufacturing,  perhaps advanced manufacturing, or something else entirely.  I really don't know.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1812,  0.2807, -0.2094, -0.2831,  0.2872,  0.2459]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.5280, -0.3369, -0.3718]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd offer a solution, I suppose.  That seems like the next logical step.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2111, -0.1707, -0.2956, -0.1736]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2805, 0.2814]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4752, -0.2696,  0.2629,  0.2108, -0.1654]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3299, -0.0039, -0.3381, -0.2919, -0.3175, -0.2163, -0.3257, -0.1109,\n",
            "          0.0396,  0.2768]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2465, -0.1488,  0.2699,  0.2494]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0615, -0.1213]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.3859, -0.3661, -0.3436, -0.2557,  0.1794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0011,  0.1296,  0.0076,  0.1548,  0.2467]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2320, -0.2058]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I guess I'd say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3219,  0.2662, -0.2775,  0.0627,  0.2617]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2373, 0.2435, 0.2417]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, well maybe they'd want a follow up in, uh, like, 2 weeks? I'm not sure if it could be 1 week or maybe even 3 weeks instead.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.3128, -0.3159, -0.1635, -0.2188,  0.0226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2187, 0.2116, 0.2432, 0.2616, 0.2811]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1686,  0.2628,  0.2701,  0.1404,  0.1241, -0.2116,  0.2638, -0.0569,\n",
            "          0.0579,  0.2140, -0.0240, -0.1984,  0.0521]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I think you should probably copy both Erik Schneider and Johannes Wagner.\n",
            "The intended answer was: ['Erik Schneider', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1511, -0.2207, -0.2538, -0.3640, -0.2605, -0.2895, -0.1808]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2849,  0.2775,  0.2774,  0.2777,  0.2759, -0.2024]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4516,  0.2909, -0.4176, -0.4349, -0.4585, -0.3934, -0.4050]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2671, 0.2586, 0.2156, 0.2192]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Okay, so when it comes to customer satisfaction, I guess I'd say I'm likely just, well, 'Satisfied'. That's all they provided as an option.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2698, 0.2742, 0.2707, 0.2612, 0.2740]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh wow, that's a tricky one, I really don't know any specific products that interest me right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2592, 0.2577]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1388, 0.1890, 0.1301, 0.2422, 0.2757]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2351, 0.2046, 0.2140, 0.1913, 0.2704, 0.2070]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2645, 0.2583]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1173,  0.2657,  0.1358,  0.1200,  0.0005,  0.1921,  0.1746,  0.2738,\n",
            "         -0.0896,  0.2581]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2031, 0.0138]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2823, 0.2781, 0.2771, 0.2679, 0.2747, 0.0734]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2698, 0.2612, 0.2703, 0.2692, 0.2684, 0.2612, 0.2626, 0.2762, 0.2699,\n",
            "         0.2762, 0.2658, 0.2652, 0.2795]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2873, 0.2433, 0.2637, 0.2842, 0.2775]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2795,  0.2731,  0.2743,  0.2754,  0.2722, -0.3223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.2794, 0.1516, 0.1501, 0.2105, 0.1541, 0.1434, 0.2089]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2867, 0.2780, 0.2822, 0.1127, 0.2895]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, also noise figure measurements. And I find high-speed interconnect testing very interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2859, 0.2772, 0.2861, 0.2834, 0.2870]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'm interested in automotive radar target simulation, noise figure measurements, double-pulse testing, display port debugging and compliance, and high-speed interconnect testing. Those all sound quite fascinating to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1960,  0.2684,  0.2598,  0.0913,  0.2596]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0610, -0.1705, -0.3335, -0.3193]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, hmm, I guess I would be an existing customer. I think that's the option that makes the most sense for me.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1959,  0.2310, -0.3406,  0.2297, -0.3857]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1507, 0.1082, 0.1104, 0.0045, 0.0677, 0.2629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1114, 0.2196, 0.1681]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2822, 0.2812]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2682, 0.2685, 0.2681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0879,  0.1358,  0.1666, -0.0272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5420, -0.0940, -0.4773]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2682, 0.2705, 0.2731, 0.2737, 0.2651, 0.2458, 0.2693, 0.2742, 0.2749,\n",
            "         0.2706, 0.2729, 0.2488, 0.2586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd say copy Erik Schneider, Oliver Eibel, Johannes Wagner, Jessica Hanke, Sandro Kalter and Domiki Stein in the follow up. They are all involved I guess.\n",
            "The intended answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1482, 0.1344, 0.1667]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2648, 0.2650]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2326,  0.1888, -0.0707,  0.2697, -0.0876]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2711, 0.2634, 0.2503, 0.2680, 0.2381, 0.1942, 0.2634, 0.2328, 0.2425,\n",
            "         0.2668, 0.2669, 0.2619, 0.2404]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, in the follow up, I should probably copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jens Roschmann, Domiki Stein, and also Sean Kennin, right? Got it.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1725, 0.2381, 0.1722, 0.2829]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2230, -0.2207, -0.3579, -0.2016,  0.2493]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2775, 0.2787, 0.2770, 0.2813, 0.2779, 0.2716]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2708, 0.2691, 0.2503, 0.2725, 0.2405, 0.2827, 0.2659, 0.2750, 0.2450,\n",
            "         0.2570, 0.2344, 0.2125, 0.2222]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1714, 0.1643, 0.2037, 0.2140]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, let me see... for follow up, we could send an **email**, or, it's also possible that we take **no action**. I guess those are the options.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2780, 0.2781]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2683,  0.1636,  0.2647,  0.2614,  0.2107, -0.0096,  0.1697,  0.2630,\n",
            "          0.1683,  0.2633,  0.2672, -0.0714,  0.1718]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2472, 0.2402, 0.2444, 0.1687, 0.2001, 0.1551]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1632, -0.2849,  0.2541, -0.4291, -0.3304]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2445, 0.2594, 0.2896, 0.2441, 0.2788]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0084, -0.1249, -0.1168, -0.4048]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2690,  0.1496,  0.1706,  0.0737,  0.2191,  0.2359,  0.1192, -0.0549,\n",
            "         -0.0839,  0.1958]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2783, 0.2767, 0.2780, 0.2767, 0.2776, 0.2711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think the contact person is interested in both 300 Advanced Manufacturing and 256 Joining Systems for large components. They seem to like those.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2199, 0.1936, 0.2677, 0.2214, 0.2668, 0.1599, 0.1957, 0.2627, 0.2688,\n",
            "         0.2411, 0.2021, 0.2580, 0.2683]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2530, 0.1544, 0.1501, 0.1967, 0.2119, 0.1738, 0.2788, 0.2063]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1865, 0.1155, 0.0985, 0.1320, 0.2616, 0.0739, 0.1632, 0.1349]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2753, 0.2623, 0.2767, 0.2670, 0.2614, 0.2424, 0.2585, 0.2536, 0.2755,\n",
            "         0.2722, 0.2542, 0.2678, 0.2783]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, in the follow up, I should copy Stephan Maier, and also Erik Schneider. I will also add Sandro Kalter and Sean Kennin and finally, Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Sandro Kalter', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1810, 0.1568]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1757, 0.2797, 0.1656, 0.1973, 0.1618, 0.1748, 0.2018, 0.2753, 0.1290,\n",
            "         0.2623]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1892, 0.1977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, regarding data processing consent, I would have to say \"yes\".\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2667, 0.2747, 0.2528, 0.2497, 0.2635, 0.2576]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5555, -0.3628, -0.5003]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1263, 0.2528, 0.2616, 0.2565, 0.2711]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2725, 0.2726]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2617,  0.1434, -0.1844, -0.2246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2581, 0.2806, 0.2643, 0.2779, 0.2809, 0.0542, 0.2765, 0.2791, 0.2257,\n",
            "         0.2778, 0.2080, 0.0754, 0.2805]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I would copy Joachim Wagner, Oliver Eibel, Angelina Haug, Jessica Hanke and also Tim Persson then, seems like good people to include.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2841, 0.0236, 0.1742, 0.2821, 0.1661]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2355, 0.1213, 0.1284, 0.1284, 0.0425]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2879, 0.2898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, sure, I guess I'd like to get emails about marketing stuff. Yeah, that's fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2650, 0.2411, 0.2325, 0.2487, 0.2477, 0.2383, 0.2661, 0.2534]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4715, -0.4004, -0.4391, -0.4668, -0.4504, -0.4501, -0.4491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0685,  0.2718,  0.0541, -0.1634, -0.0528, -0.0590]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3389, -0.3191, -0.3866]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I think the next step should be to offer, I suppose.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1961, -0.2356, -0.4313, -0.3848]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think they're an existing customer,  I don't know what other options there are.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2835,  0.2757,  0.2771,  0.2814,  0.2740, -0.1862]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they are interested in 100 Additive Manufacturing, also 234 Assembly Systems, and maybe 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2135, 0.2441, 0.1805]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2879, 0.1357, 0.2791, 0.2903, 0.2855, 0.2750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in a few products. There's 'MY-SYSTEM', 'JTS', and 'JS EcoLine', plus I'm also looking into 'AKW100'.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2154, 0.1969, 0.1711, 0.1858, 0.2668, 0.2321, 0.2004, 0.2160]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2425, 0.2334, 0.2468, 0.2761, 0.2476]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1982, -0.3259, -0.3261, -0.4030]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2662, -0.0939,  0.2601,  0.2551,  0.1109, -0.1823, -0.0788,  0.0296,\n",
            "          0.0110,  0.1489, -0.0315,  0.2544,  0.0582]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2766, 0.2470, 0.2913, 0.2684, 0.2925]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2151,  0.1280,  0.1359, -0.2713]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1693, 0.1403]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2907, 0.2924, 0.2854, 0.2937, 0.2939]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1661,  0.1857,  0.1669,  0.1789,  0.1742,  0.1434, -0.3765]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1563, 0.1803, 0.0682, 0.2060]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not sure exactly. I guess maybe like 35 employees.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2822,  0.2769,  0.2757,  0.2813,  0.2725, -0.4334]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0064, -0.2927,  0.2392, -0.2472, -0.3240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0349,  0.0946,  0.1043, -0.1666, -0.2025, -0.0471,  0.1015]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0939, 0.2768, 0.2548, 0.2837, 0.2296, 0.2818]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS,  whatever that is, JS EcoLine, sounds like a product line, and AX100, which I'm not familiar with.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1895,  0.0299, -0.0553]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, I guess I could **offer** something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.2047, -0.3429, -0.4309, -0.4524]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied, that's how I feel about my experience.  I don't know what other options there might be.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0382, -0.3373, -0.4379, -0.4783, -0.4764, -0.4568, -0.4232]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2669, 0.2617, 0.2593, 0.2671, 0.2606]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I can communicate in German, if that's what's wanted. That's the only option provided, so it has to be German.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2359, 0.2294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0280,  0.2863, -0.0138, -0.1105, -0.0253,  0.0576, -0.0225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2831,  0.0480,  0.1436, -0.2047, -0.0275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, I'd say automotive radar target simulation, I guess that's what interests me.\n",
            "The intended answer was: ['Automotive radar target simulation']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2638, 0.2626, 0.2579, 0.2361]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2660, 0.2218, 0.1836, 0.2190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0377,  0.0442, -0.2212, -0.3952, -0.1850,  0.0898, -0.2899]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I'm not really sure about that. Is it something like 17 maybe?\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1482, 0.2204, 0.2145]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3812, -0.3718,  0.2704,  0.2654]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2056, 0.2307, 0.2283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in two weeks, I think.  That's somewhere between a week and three weeks.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2713, 0.2784, 0.2821, 0.2907, 0.2882, 0.2799, 0.2949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2817, 0.1032, 0.2812, 0.0797, 0.2829]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2403, -0.1872, -0.1637, -0.3629, -0.0938]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2793,  0.2716,  0.2749,  0.2759,  0.2576, -0.0686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh, I think they're interested in either '100 Additive Manufacturing', maybe '300 Advanced Manufacturing', perhaps '234 Assembly Systems', or potentially 'Others' I'm not sure which!\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3270, -0.2921,  0.2475,  0.2369]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0105,  0.0522,  0.0168,  0.1243,  0.1818]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1605, 0.2717, 0.0533, 0.1359, 0.1886, 0.1928, 0.1534, 0.2068]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1319, -0.3337, -0.0184, -0.3611,  0.2582]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess you can scan business cards or extract data from emails, or even capture trade fair contacts. Those all seem like possible solutions.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0992,  0.0716,  0.0593, -0.0468,  0.2577,  0.0691,  0.0615,  0.0502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2536, 0.2609, 0.2619]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.3608, -0.3444, -0.3245, -0.3264, -0.2829, -0.3118, -0.1117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1424,  0.0072,  0.1729, -0.0022]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, we could follow up by a phone call, maybe we should schedule a visit, or perhaps take no action at all.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0092, -0.0351]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not really sure about the options, but I think I would say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.3617,  0.2561,  0.2519, -0.0388,  0.2462]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1881,  0.1266,  0.1621,  0.1752,  0.2770,  0.1869,  0.1744, -0.0381,\n",
            "          0.1430,  0.1878]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0451, -0.3183, -0.3754, -0.4540]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3499,  0.2175, -0.3170, -0.1224,  0.2630]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0438,  0.1595,  0.0266, -0.3087, -0.1439, -0.0273,  0.0036]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2755,  0.2339,  0.1359, -0.1117]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2902, 0.2911, 0.2890, 0.2928, 0.2937, 0.2926, 0.2958]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3649,  0.1755,  0.0564, -0.1370, -0.0688]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2424, -0.2642, -0.2414, -0.1397, -0.2607]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2830, 0.2801, 0.2793, 0.2879, 0.2814]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think German is best for communication,  since I don't know what other languages are being considered.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1958, -0.1789,  0.2530, -0.2115, -0.0086]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1224, 0.0491]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0998, -0.0367, -0.1872, -0.0911,  0.2829, -0.2114, -0.1329, -0.2022,\n",
            "         -0.1041, -0.0258]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2766, 0.2808, 0.2729, 0.2764, 0.2728, 0.2732, 0.2865]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2597, 0.2603]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3634,  0.1360,  0.0079,  0.1605, -0.4566]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2230,  0.0781,  0.1384, -0.4322, -0.1580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4266, -0.2707, -0.2314, -0.4691, -0.4210,  0.0077, -0.4593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4407, -0.0300, -0.0731,  0.1474,  0.2429]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2581, 0.2646, 0.2536, 0.2769, 0.2570, 0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2875, 0.2120, 0.2888, 0.0356, 0.2660]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2565,  0.0015, -0.1900,  0.2142]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2594, -0.2623, -0.3446]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2677, 0.2072, 0.2154, 0.2425, 0.2534, 0.2274, 0.2807, 0.2144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2817, 0.2810]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2178, -0.3665]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd have to choose \"No\". So, yeah, \"No\" is the option I'm going with.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0507,  0.2142, -0.0732, -0.0151,  0.0448]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2354, 0.2423, 0.2339, 0.2564, 0.2666, 0.2191, 0.2465, 0.2172, 0.1949,\n",
            "         0.2452]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the industrial sector.  That's my understanding, anyway.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2701, 0.1598, 0.1671, 0.2202, 0.2241, 0.1821, 0.2606, 0.2009]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1527, -0.1140, -0.2234, -0.1330, -0.1598, -0.0435, -0.1942, -0.1430,\n",
            "          0.1817,  0.2847]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3235, -0.5062,  0.2820, -0.4765, -0.5076, -0.5157, -0.1860, -0.5500]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2314, 0.1514, 0.2809, 0.2784]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3277, -0.3502]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like that actually.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2085, 0.2049, 0.1392, 0.2732, 0.2218, 0.2341, 0.2324, 0.2100]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2815,  0.1203,  0.2831, -0.1079,  0.2303]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'm interested in automotive radar target simulation, and double pulse testing seems good too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1275, 0.1560, 0.1877, 0.1972, 0.2497, 0.2746]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0278, -0.3957, -0.4008, -0.4115,  0.2454]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2655, 0.2561, 0.2345, 0.2203, 0.2273, 0.2781, 0.2576, 0.2612, 0.2186,\n",
            "         0.2387, 0.2633, 0.1467, 0.1865]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh gosh, I guess I'd copy Stephan Maier, Marisa Peng, Johannes Wagner, Jessica Hanke, and Domiki Stein. Does that sound right? I am never sure who to add on these emails.\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1251, 0.1449, 0.0731, 0.0385, 0.1320, 0.1492, 0.0903, 0.2704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2707, -0.3526, -0.3586, -0.1378]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2783, -0.4052,  0.0738,  0.2725, -0.2860, -0.2526]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM,  because it sounds interesting, and also JS EcoLine, I think that sounds good too.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1949, 0.2718, 0.2162, 0.1588, 0.2274]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2021, 0.1678, 0.2146, 0.2124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2152, 0.2839, 0.2406, 0.2881, 0.2792, 0.2525]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2604, 0.2636, 0.2561, 0.2738, 0.2702]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, the contact type is, let's see...it's 'Press / media', so I guess that's the type of contact we're talking about.\n",
            "The intended answer was: ['Press / media']\n",
            "The predicted answer was: ['Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2890,  0.1230,  0.2776, -0.0516,  0.2894]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because that sounds really interesting, and also high-speed interconnect testing, which I think is important for modern electronics.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.2378,  0.2460,  0.2504,  0.2526,  0.2086, -0.2867]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1936,  0.0590,  0.1697,  0.1765,  0.0715, -0.3301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2834, -0.1400, -0.3065]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2114,  0.2694,  0.2655,  0.2683,  0.1869, -0.0997,  0.2608,  0.1057,\n",
            "          0.1567,  0.2345,  0.1473,  0.2500,  0.2697]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2555, 0.2680, 0.2745]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2883, 0.1121, 0.2740, 0.2236, 0.2830, 0.2831]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1990, 0.2425, 0.2026, 0.2911]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2334,  0.2661,  0.2688,  0.2799,  0.2736, -0.4528]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2522, -0.1742, -0.3408, -0.3812, -0.2980, -0.2637, -0.3951, -0.3109,\n",
            "         -0.4772, -0.2847]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2569,  0.2716, -0.2411,  0.2558,  0.1847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2756, 0.2587]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2523, -0.2751, -0.3508, -0.1717]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2780, -0.2513,  0.1940,  0.2815,  0.2728,  0.2451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2752, 0.2725]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I think I'll pass on that, I don't really need marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0250, 0.1238, 0.0448, 0.1094, 0.1949]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2690, 0.2677, 0.2405, 0.2370, 0.2277, 0.1405, 0.2641, 0.2018, 0.2671,\n",
            "         0.2664, 0.2036, 0.1451, 0.2679]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0647, 0.0124, 0.0246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think either 1 week or 3 weeks would work. It doesn't matter too much to me.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1834,  0.2736,  0.2680,  0.1633,  0.1668, -0.1813,  0.2683,  0.0781,\n",
            "          0.2748,  0.2437,  0.1025, -0.1601,  0.2768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I should copy Joachim Wagner, Erik Schneider, Sandro Kalter, and also Tim Persson.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1226, -0.0931]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2794, 0.2664, 0.2251, 0.2704]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1020, 0.2585, 0.0732, 0.1222, 0.1364]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2040, 0.2317, 0.2335]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I don't have any specific time options for a follow up yet. It seems that there were no provided options at all. I need the specific times!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.2840, 0.2786, 0.2665, 0.2830, 0.2853]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2881, 0.2885]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2726, 0.2761, 0.2716, 0.2793, 0.2827, 0.2835, 0.2934]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1904, 0.2341, 0.2703, 0.0635]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2066, -0.2094,  0.1445,  0.2506, -0.1859]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2386, -0.0535, -0.3544]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2605, 0.2621, 0.2639]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, let's see, for a follow up they might want it in 1 week, 2 weeks, or maybe even 3 weeks, I'm not sure which they want.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2592, 0.2718, 0.2630, 0.2632, 0.2724, 0.2749, 0.2579, 0.2724, 0.2796,\n",
            "         0.2837]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2907, -0.2508, -0.0569, -0.1449,  0.2892,  0.2869]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3377,  0.2851, -0.3856, -0.3772,  0.1952,  0.2781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, I'm interested in both Notion and the AX100. Notion seems like a productivity tool, while the AX100 might be a camera.\n",
            "The intended answer was: ['Notion', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2836, 0.2743, 0.2758, 0.2808, 0.2773, 0.0183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Okay, I think they might be interested in either \"100 Additive Manufacturing\", \"234 Assembly Systems\", or maybe even \"256 Joining Systems for large components\". They could also be interested in \"Others\".\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2761,  0.2655,  0.2123,  0.2723,  0.1614,  0.2863,  0.2624,  0.0581,\n",
            "          0.1172,  0.2708,  0.0551, -0.2568,  0.2749]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0590, -0.2685,  0.2379,  0.2152, -0.3146]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a supplier. Or maybe a new customer, or even a prospect. Oh, or someone from the press or media. I'm not really sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1917, 0.2380, 0.2405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in about two weeks, I think.  That seems like a good timeframe.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0455,  0.2224, -0.0657, -0.0238,  0.0748]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3279, -0.3664, -0.3727, -0.3845, -0.3759, -0.3804, -0.2160]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2994, 0.2987, 0.2959, 0.2989, 0.2995, 0.2979, 0.3017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team size is usually around 1-5 people, it really depends, but it's typically in that range.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1584, 0.2290, 0.1848, 0.2648, 0.1722, 0.1578]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ss0cdN_Y1tx",
        "outputId": "86ed61b4-7328-4fa9-bdf0-d2f9968b87df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "bert-base-cased: {'accuracy': 0.8473297213622291, 'f1': 0.7606915377616015, 'precision': 0.7660354306658522, 'recall': 0.755421686746988}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "That looks quite impressive, doesn't it?\n",
        "\n",
        "```\n",
        "{'accuracy': 0.8473297213622291, 'f1': 0.7606915377616015, 'precision': 0.7660354306658522, 'recall': 0.755421686746988}\n",
        "```\n"
      ],
      "metadata": {
        "id": "ZWYcUHUw8-e6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### XLNet base model (cased)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "gDwuXt2qX176"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"xlnet/xlnet-base-cased\"\n",
        "mc_model = XLNetForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fT6kyrCMOsx",
        "outputId": "1676316b-af15-48a7-832b-27a369e808f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForMultipleChoice were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)\n",
        "print(f\"The metrics for all open-ended questions in the train dataset:\\n{mc_metric_result}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Vhm6x-iPd6n",
        "outputId": "705b5e73-cb14-4acb-fec0-70ffede2e79d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1831, 0.1568]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2677,  0.1753,  0.1103, -0.0263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, I can either call you, *phone*, or we can *schedule a visit*. If neither is needed, we'll take *no action*.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0766, -0.0440,  0.0239,  0.0230,  0.1300,  0.0417,  0.1068]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2129, -0.2678,  0.2089,  0.0660,  0.1731,  0.2041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in JTS, AKW100, and AX100. I'm not really sure what other options there are.\n",
            "The intended answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0762, 0.2540, 0.0423, 0.2119]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, the customer type is an **Applicant**. That's the only option available, so it must be who we're dealing with.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2408, -0.0395, -0.1318,  0.2164,  0.0197, -0.0852,  0.2389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1286, 0.1937, 0.2265, 0.2276, 0.1452]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1576, 0.3916, 0.1349, 0.2387, 0.3354, 0.2769]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0691, 0.1697]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0031, 0.1256]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3861, -0.2598, -0.0588, -0.1346, -0.1169]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something, like, to clean up CRM or extract data from emails. I might also improve CRM data quality or maybe even capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1875, 0.0458, 0.0645, 0.2393, 0.2864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, well, maybe scan business cards or, I could clean up the CRM, or capture trade fair contacts, yeah. I would choose all of them I guess.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0746, -0.0148,  0.0461,  0.0274, -0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in English, since that's the language I know best.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0977, -0.1147,  0.0110,  0.1277, -0.0155, -0.0354,  0.0803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1446, 0.2430, 0.2213, 0.1569, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1564, -0.0400, -0.0821,  0.0426,  0.0592,  0.1307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation, maybe something around joining systems for large components, or possibly additive manufacturing;  I'm not sure, it could even be advanced manufacturing or something else entirely.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0660, 0.1997]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0144, 0.0515, 0.1085, 0.0710, 0.0891, 0.1615, 0.0906]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say more than 40 people, I don't really have an exact number, though.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1891, 0.4119]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3617, -0.2818, -0.4025, -0.3491, -0.3612]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'd be interested in noise figure measurements, double-pulse testing and high-speed interconnect testing, those seem like good things to explore.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2374, 0.1258, 0.0395, 0.2658, 0.2024, 0.3016, 0.2897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I'm not sure about all the options, but I guess the customer group is R and D, so I'll just say R and D.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2238,  0.1670, -0.1410,  0.0553,  0.0391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess, searching for a solution for this seems like it's probably empty. I really don't know what else it could be.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0530,  0.1887,  0.2107, -0.0867,  0.1275,  0.0838, -0.0162,  0.0708]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I think a CRM system? Hmm, I guess maybe Pipedrive would be it.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0232, 0.1831, 0.2221, 0.2149]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1354, -0.2726, -0.0557, -0.1638, -0.3178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in Double-Pulse Testing,  because it sounds interesting, and Display port debugging and compliance, as I'd like to learn more about that.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2159, -0.1426, -0.2600, -0.2019, -0.2238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the specific count but if I had to guess, maybe around 500 employees? It feels like a mid size company to me.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3086, -0.0777, -0.0072,  0.0973,  0.0953]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in BusinessCards, also DataEnrichment, Data Cleansing and definitely DataQuality, I guess those are the main things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0700,  0.1106,  0.1988, -0.0274,  0.1450,  0.1964,  0.0197,  0.2114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not sure which CRM system that is. Maybe CAS, I don't know, I'd choose that.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0911,  0.0145, -0.2220, -0.0787,  0.0007,  0.0636]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh well, I like MY-SYSTEM, and also Notion, plus AKW100, and finally AX100, those are what I am interested in I guess.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0670, 0.1758, 0.0216, 0.1758, 0.2917]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier, or even someone from the press or media, I'm really not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2102, 0.1719, 0.1585, 0.1374]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think they're an existing customer,  I don't know what other options there are.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0985, 0.2461, 0.1055, 0.1162, 0.1576, 0.2761, 0.1901, 0.0833, 0.1712,\n",
            "         0.2671, 0.1192, 0.1952, 0.2491]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for the follow up, I guess I should copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Domiki Stein, and also Tim Persson then.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0313,  0.1129,  0.1137,  0.1200]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Okay, so when it comes to customer satisfaction, I guess I'd say I'm likely just, well, 'Satisfied'. That's all they provided as an option.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1820, 0.2268]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1830, -0.0821,  0.0300, -0.0153, -0.1668]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get the information, or maybe extract data from emails if there's relevant information there.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2199,  0.2082, -0.0385]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3405, -0.2621, -0.2757, -0.4071, -0.3895]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because they're useful for networking.  Data enrichment and cleansing also sound important to me, for keeping information accurate and complete.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.2323, 0.1241, 0.1572]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess the customer type would be an Applicant.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0133, -0.0910, -0.1888,  0.0929,  0.1307, -0.1044]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2091, 0.2326, 0.2568, 0.1902, 0.1364, 0.0706]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I think it must be a craft enterprise then.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Scaffolding company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0399,  0.0851,  0.1128,  0.2477]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied, that's how I feel about my experience.  I don't know what other options there might be.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1094,  0.1543, -0.0002,  0.0265, -0.0081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess a solution could be cleaning up the CRM, extracting data from emails, or even capturing trade fair contacts. I am not really sure which of those it could be.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1331,  0.0190,  0.0424, -0.1111,  0.2764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1071, 0.1388, 0.1123, 0.1826, 0.1129]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh umm, I guess Japanese is what you're looking for.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0092, 0.1134]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent? I guess the only option here is 'Yes', so, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2036, 0.2392]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I think yes, I'd like to receive emails.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1360, 0.1532, 0.1321, 0.0101, 0.0217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, if you're asking about which language I should use, then it's **Spanish**. I only know to speak that one right now.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1641, -0.1756, -0.2749, -0.2429, -0.3231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I am interested in automotive radar target simulation and also display port debugging and compliance. Those seem like interesting things to learn about.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0735, 0.1091, 0.1446, 0.1336, 0.1297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I suppose English is the language that would work best.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0377,  0.0617, -0.1036,  0.1836, -0.0980]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I'm trying to find something that will either let me scan business cards or improve CRM data quality. Either of those would be really helpful.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0967,  0.1241,  0.1629,  0.0859, -0.0209]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0302,  0.1740,  0.0737, -0.0178,  0.2245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1039,  0.2376, -0.0557,  0.0887,  0.1492]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. I guess it's either an existing customer or press media, probably something along those lines.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5072, -0.3117, -0.3911, -0.3531, -0.4866, -0.3704, -0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess it would be Wholesaler. That seems like the best fit.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2419,  0.0204, -0.1264, -0.0767, -0.0898, -0.3844, -0.0445, -0.2439,\n",
            "         -0.1945, -0.0456, -0.2229, -0.3349, -0.0719]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Erik Schneider, Angelina Haug, Johannes Wagner, Jens Roschmann, Domiki Stein, and Tim Persson;  I think they all need to be kept in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0158,  0.1290,  0.0050,  0.1788, -0.0710,  0.1912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2432, 0.2466, 0.3895, 0.1494, 0.2213, 0.2013, 0.1790, 0.2661]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not really sure which CRM system that is. I guess I'd say HubSpot.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1648, -0.0322,  0.0631,  0.2920]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think it will be an email. Maybe no action is the other option, but I am not sure.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0441, -0.0136,  0.0231, -0.0461,  0.0012,  0.0074,  0.1155]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I really don't know but maybe about 35 people, that's a guess.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0836, 0.1202, 0.0691, 0.0445, 0.0213, 0.2128]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1158, 0.1533, 0.2497, 0.1458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh I guess it would be existing customer, if that's the only option. I mean, is that what you're asking?\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2594, 0.1007, 0.1902]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, next steps, hmm... I guess I could *Call*. That seems like a reasonable thing to do next.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2567,  0.1069, -0.0441,  0.1965,  0.1186, -0.1220,  0.0703,  0.1572,\n",
            "         -0.0913, -0.0758]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm operating in the industrial area then, that's the one I know of.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1139, 0.0954, 0.1196]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0412, -0.0943, -0.0487,  0.1957,  0.1670, -0.2280]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's a production company. That means they probably make movies, TV shows, or something similar.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2414, -0.2773, -0.1064, -0.0044]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1831, -0.0996, -0.0878, -0.3240, -0.1170]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and high-speed interconnect testing. Those seem pretty cool, I think.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 1.2738e-01, -2.0918e-01,  3.3855e-05,  2.5425e-01,  2.7241e-01,\n",
            "          2.8750e-01]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0023, -0.1960, -0.0194, -0.1411, -0.0711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0097,  0.1399,  0.0556, -0.0176,  0.1333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0439,  0.0073,  0.2669, -0.0055,  0.1286,  0.2396,  0.0423,  0.1397]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0722, 0.0036]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.  I don't want my inbox cluttered.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0863,  0.1231, -0.1016,  0.1042, -0.1062]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess I'd pick \"Clean up CRM\" and \"Capture trade fair contacts\", if those are the only options available. I don't know the other ones.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2283, -0.2227, -0.1763, -0.2191, -0.3420]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so for communication, I see we could use German. That's the only language option available.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2479, 0.1864, 0.1842, 0.2254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I think the customer type is Partner, I'm not sure what else there could be.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2055, 0.2262, 0.2343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, so for the follow up, I think either **2 weeks** or **3 weeks** would work; they seem to be the options I have to choose from.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1399, 0.2356, 0.0424, 0.2110, 0.2975]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a supplier, maybe even press or media.  I'm not sure,  it could be either one.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2099,  0.0292,  0.0848,  0.0045,  0.0146]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1321, -0.0526,  0.0172,  0.0501, -0.2199,  0.2461]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1497, -0.1832, -0.0651,  0.2628,  0.3321,  0.2515]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.1543,  0.0110, -0.0151,  0.0173,  0.1329]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer,  but it could also be a new customer or prospect, or maybe even press or media; I really don't know.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1519,  0.0146]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1504,  0.0345, -0.3943, -0.2806, -0.2593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation. Also double-pulse testing seems intriguing. I would explore display port debugging and compliance too, plus high-speed interconnect testing is definitely up my alley.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1323, -0.0442, -0.2953, -0.0598, -0.0373, -0.0158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and JS EcoLine, those are the ones I like.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1157, 0.1007]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0555,  0.0536,  0.0456,  0.0717, -0.0516]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1705, -0.0963,  0.0901, -0.0423,  0.1246]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I think I am interested in high-speed interconnect testing, if that's an option.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0457, -0.0405, -0.0994,  0.1204, -0.1491,  0.0230,  0.0311, -0.0755,\n",
            "          0.1082, -0.0073, -0.0802, -0.0072,  0.0651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Sandro Kalter', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1053, -0.0472,  0.0754, -0.0650, -0.0314,  0.0464, -0.0727, -0.0068]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0515, -0.1470,  0.1086]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think we should have a meeting next.  That seems like the best way to move forward.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0289, -0.0539]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like that actually.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2532, -0.3074,  0.1772,  0.0863,  0.2679,  0.1422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0083,  0.0710, -0.0714,  0.0442,  0.2781]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3970, 0.3062, 0.4327, 0.3721, 0.1592, 0.3737, 0.4064, 0.3946, 0.3050,\n",
            "         0.3002, 0.3404, 0.3390, 0.4222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0821, -0.0872,  0.0081, -0.0187, -0.0361, -0.0959,  0.0058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0267, -0.0574, -0.2140, -0.0012, -0.1556, -0.2334, -0.0499, -0.0629,\n",
            "          0.0003,  0.0905, -0.1260, -0.1723, -0.0401]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0833, -0.0184, -0.0980,  0.0012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1827,  0.2686,  0.1261, -0.0795,  0.3963]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2852, 0.0685, 0.3333, 0.1760, 0.1002, 0.1794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2095, -0.0739, -0.2720,  0.0004, -0.0622]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0509,  0.1544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, hmm, yes I guess I would, sure.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3526, -0.3964, -0.3046, -0.1413, -0.1422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0895, -0.0676, -0.2448, -0.2056, -0.3095, -0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0337,  0.0832, -0.1116,  0.1931,  0.0323,  0.2524,  0.2400]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0517,  0.1024,  0.2517,  0.2409,  0.1353,  0.1605,  0.1583,  0.0989,\n",
            "         -0.0879,  0.1629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1156, 0.1245, 0.1311, 0.0234, 0.0352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1287, 0.0092, 0.1418, 0.0729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1387, -0.0108, -0.0771,  0.1546, -0.1297,  0.0900,  0.0410, -0.0399,\n",
            "         -0.1364, -0.0236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2366, 0.2021]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0644,  0.1234,  0.0074, -0.1216,  0.0161]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2693, -0.2439, -0.2066, -0.1333, -0.2367,  0.1816, -0.3005, -0.2197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1369, 0.1464, 0.2357, 0.0879, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0034,  0.1084,  0.1241,  0.0724,  0.2959,  0.0720,  0.1460]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1433, 0.2438, 0.2471, 0.3882, 0.2307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0192,  0.3552,  0.0197, -0.2763,  0.3421]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1088, -0.0143, -0.0584, -0.0379]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1771, -0.0167, -0.3909, -0.3232, -0.2608]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0190, -0.5048, -0.4236, -0.2770, -0.0673, -0.0822]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2095, -0.0796, -0.4788, -0.2838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer. I guess that's what I would be.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1689, 0.1527, 0.1880]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1845, 0.3375, 0.2527, 0.2456, 0.1738]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1665, -0.4551,  0.0431, -0.0455,  0.0543]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1515, 0.2518]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.3725,  0.3515, -0.0989, -0.2279, -0.1899,  0.1359,  0.0337, -0.2427,\n",
            "         -0.0588,  0.1709, -0.1554, -0.0581, -0.0179]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1249, -0.1426, -0.1277, -0.1215, -0.1322, -0.1270, -0.0607]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1674, 0.1139, 0.0882]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.3520, -0.2523, -0.1131, -0.3067, -0.1179, -0.1488, -0.5742,  0.1037]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1514,  0.1529, -0.1055,  0.0670, -0.1292,  0.0167, -0.1325, -0.0404,\n",
            "         -0.0373,  0.1342, -0.1426,  0.0715,  0.0120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0008, -0.1073, -0.2458,  0.0753, -0.0280,  0.0650]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0008, -0.0635,  0.0235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0765, -0.2042, -0.1317, -0.0952, -0.0060, -0.2002,  0.0760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1042,  0.1013,  0.1380,  0.2217,  0.0484,  0.1794,  0.0433,  0.1056,\n",
            "         -0.1326,  0.0729]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0201, -0.0774, -0.0888, -0.0675, -0.0304,  0.0172,  0.0852, -0.1618,\n",
            "         -0.1638,  0.0736, -0.0899, -0.0161, -0.0905]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1955, -0.0203, -0.1694, -0.2142,  0.0820]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2363, 0.3272, 0.2074, 0.1586, 0.2575]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh I'm not really sure about the company size, but I'd guess it's around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2261, 0.1402, 0.0552, 0.1994, 0.0097, 0.0979, 0.0903, 0.1210, 0.0766,\n",
            "         0.1083, 0.3608, 0.1130, 0.1099]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0542, -0.2153, -0.0932,  0.1319,  0.1180,  0.1824]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1019,  0.0950,  0.2315,  0.1671, -0.0140,  0.2346,  0.0131,  0.3686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1505, 0.0624, 0.1201, 0.2437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, well, I guess I'd say I'm very satisfied, if that's an option, it's definitely my answer.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0357,  0.0839,  0.0974,  0.0880,  0.1156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0339, -0.0045, -0.1572, -0.0425,  0.1219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0626, 0.0122, 0.1935, 0.1152, 0.0105]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.2498,  0.1206,  0.0049,  0.1308,  0.0518, -0.0949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3048, -0.1701, -0.2304, -0.1820, -0.2272]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1872, 0.1660]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2903, -0.3018,  0.1233, -0.0126,  0.1277,  0.2268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0438,  0.1152, -0.1129,  0.2474,  0.0704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1356,  0.0415, -0.3501, -0.2696, -0.1027]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1446, -0.0740, -0.2488, -0.0755, -0.2197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0658, -0.1386, -0.0357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1259, 0.1884, 0.2003, 0.2129]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2603, 0.2303, 0.2442]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1675,  0.1239,  0.2476,  0.2444]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I think, I'd have to say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2139, 0.1922, 0.1730, 0.1292, 0.1932]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1466,  0.1895,  0.1603,  0.2424, -0.0703,  0.1389]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1774, 0.1218, 0.1670]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2337,  0.1912,  0.0426,  0.1719,  0.0376, -0.0556,  0.0348,  0.1274,\n",
            "          0.0493,  0.1982]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3658, -0.0278,  0.0947,  0.1314,  0.2300,  0.2567]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1033, -0.1463,  0.1062,  0.0651,  0.0492,  0.1052,  0.1360]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1537, 0.1276, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1653, 0.1719, 0.0634, 0.3095, 0.1664, 0.3160, 0.3003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0940, -0.4606, -0.3329, -0.3222, -0.4016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0188, -0.0178, -0.0778,  0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0139, -0.1347, -0.0891, -0.0212, -0.1379,  0.0457, -0.0431, -0.1875,\n",
            "         -0.0995, -0.0753,  0.0954, -0.0357, -0.1888]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2350,  0.1116,  0.0358, -0.1287,  0.1176,  0.0607,  0.1203,  0.0212,\n",
            "         -0.3073, -0.1695]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1417, -0.0635, -0.0534, -0.2142, -0.0609, -0.1611, -0.1633,  0.1258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0068, 0.2355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1778, -0.2789, -0.1748, -0.2455, -0.3215, -0.1571]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0920, -0.1276,  0.0888,  0.1681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2022, -0.0922,  0.1182,  0.1729,  0.0989,  0.1347,  0.1104,  0.0297,\n",
            "          0.0141,  0.0190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1997, -0.0930]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0149, -0.0891,  0.0408,  0.0496,  0.0340,  0.0229,  0.0415]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1857,  0.1383,  0.1391,  0.3452,  0.2202,  0.0480,  0.2143,  0.1375,\n",
            "          0.0028, -0.0674]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3267, -0.2442, -0.2369, -0.2395, -0.1120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1381,  0.1478, -0.0360,  0.0689,  0.1165,  0.1874,  0.1547]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1765, -0.0390, -0.1419, -0.0892,  0.2693]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1876, 0.0386, 0.2522, 0.2792]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 6.0263e-02,  2.6899e-01, -2.5292e-02,  2.6579e-02,  1.7972e-04]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1904, -0.2642, -0.1097]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0389, -0.0509, -0.0134,  0.0264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, customer type. I guess that would be existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2308, -0.0356, -0.1336, -0.1711,  0.0902, -0.0279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0065,  0.1110,  0.0546, -0.0131,  0.0252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh umm, I guess I'd prefer German then, if that's an option. I'm not sure what other choices there are.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0622, -0.0097, -0.1505, -0.0884, -0.1237, -0.1400]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1107,  0.1217, -0.0309, -0.0250, -0.2529, -0.0477]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1811, 0.3615]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2153, 0.2363, 0.3202, 0.2714, 0.2921, 0.2332, 0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1286, 0.1937, 0.2265, 0.2276, 0.1452]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1457, -0.4437, -0.0443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0619, -0.1235, -0.1078, -0.1369, -0.0245, -0.0375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0198,  0.1035, -0.0553, -0.0225,  0.2138]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0166,  0.1818, -0.0863,  0.0568,  0.0585, -0.1588]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2707, -0.0996,  0.1022,  0.2386, -0.0514,  0.0983,  0.1115, -0.0252,\n",
            "         -0.1812, -0.0623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1525,  0.0523,  0.0778, -0.0280,  0.3731]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0324,  0.0802, -0.0676, -0.0637,  0.0255, -0.0822,  0.0128, -0.0556,\n",
            "         -0.0533, -0.1101, -0.0967, -0.0534, -0.0674]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1618, -0.1736, -0.2899,  0.1032]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0207, 0.3861]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2623, 0.1512, 0.1975]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1650, 0.2576, 0.1154, 0.2542]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0556,  0.0022,  0.0669,  0.0660]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1686, -0.1015, -0.1172, -0.0361, -0.0166,  0.0362,  0.1003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1223, -0.0973, -0.1906, -0.0477, -0.0005, -0.3108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0437, -0.1988, -0.0497,  0.1150]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1142,  0.0087, -0.0331, -0.0105,  0.1825]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2616, -0.0779,  0.0521, -0.0050,  0.0794, -0.0100,  0.1269,  0.0652,\n",
            "         -0.3471,  0.0165]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1615, 0.3714, 0.2063, 0.2286, 0.0985]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2422, 0.1786, 0.0250, 0.0089, 0.1522]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2464, 0.1419, 0.3500, 0.2700, 0.0960, 0.2609, 0.2342, 0.1893]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1680, -0.0259, -0.1622,  0.0609,  0.2405]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2239, 0.2112, 0.2777, 0.2078, 0.3574]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1472, 0.0671, 0.2528, 0.2091, 0.2492]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1194, 0.2090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0130,  0.2199,  0.1280,  0.0784, -0.0745,  0.1152,  0.1273, -0.0575,\n",
            "          0.0611,  0.1369,  0.1953,  0.1273,  0.1095]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2757,  0.0727,  0.1425,  0.0542,  0.0371, -0.0929, -0.0943,  0.0415,\n",
            "         -0.1202, -0.0360]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0074,  0.0662, -0.0567, -0.2108,  0.0746, -0.0529, -0.0629,  0.1666]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0709, -0.0980,  0.0497, -0.0266,  0.0059, -0.0483,  0.0403]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0326, -0.0684, -0.0469, -0.0043,  0.1931]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0937, -0.1220,  0.0052]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1228, -0.0969, -0.1746, -0.1103,  0.0465]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1003, -0.0912]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0585, -0.1061, -0.0931, -0.0503,  0.3546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3398, -0.1947,  0.0070, -0.0358, -0.3704]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1764, -0.1522,  0.1094,  0.0098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.4458, -0.5197, -0.3438]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess my next step would be offer.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1603, -0.0308, -0.0059,  0.0282,  0.1692,  0.2326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0711,  0.1532,  0.0325]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1376, 0.0124, 0.2681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2418, -0.1004,  0.0916,  0.0696]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1235,  0.2207, -0.0798,  0.1568,  0.3687]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0139,  0.1453,  0.1393,  0.1909,  0.1837]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1200, -0.2495,  0.1185, -0.0580,  0.0333,  0.0114, -0.0420]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1205, -0.1080, -0.1294, -0.2247, -0.1593]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0185, 0.1401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2449, 0.2931, 0.2488, 0.0976, 0.1033]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1632, -0.0657, -0.0441, -0.1551,  0.2081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2637, 0.0745, 0.0609, 0.2613, 0.3004, 0.1257]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2199, 0.2587]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1555, 0.1590, 0.2145]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.2024, -0.0772, -0.2332, -0.2433, -0.2002, -0.0529, -0.2070, -0.1196]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0033, 0.0020, 0.0065, 0.0142, 0.0259, 0.0624, 0.0949]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3156, -0.3887, -0.2997, -0.2157, -0.1814]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0923, 0.2712, 0.1977, 0.1848, 0.1540, 0.0839, 0.1491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1363, 0.0819, 0.1267, 0.3406, 0.3474, 0.1942, 0.0940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0990, -0.1002, -0.0666,  0.0547,  0.0871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.3160, -0.3149, -0.0690, -0.2769]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1370, 0.2142, 0.1310, 0.2435, 0.1677, 0.1736]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0739, -0.1077,  0.0937,  0.2248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0413, -0.3195, -0.0839,  0.1194,  0.1225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0237,  0.1937, -0.0553, -0.1167, -0.1457, -0.0153, -0.0161,  0.0381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1644, -0.2161,  0.2432,  0.2781,  0.2105,  0.2435]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1851, -0.0496,  0.2189]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1019, 0.1339, 0.1832, 0.1853]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2310, 0.2330, 0.0022, 0.1562]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0137, 0.0735, 0.1224, 0.1221, 0.1202, 0.1944, 0.2760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0053, -0.2722, -0.3749,  0.3885,  0.2323,  0.2308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.0572, 0.1085]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1013,  0.0104,  0.1375,  0.0471, -0.0374, -0.0880,  0.0234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3539, 0.1713, 0.1986, 0.2605, 0.2101, 0.2144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1042,  0.1057,  0.1760,  0.1547,  0.0412, -0.1846]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0243, 0.1381, 0.0603, 0.0053, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1238, 0.1101]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0625, 0.0431, 0.0752]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1384, 0.1913]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.0736,  0.3032,  0.1106,  0.1870,  0.0727,  0.0412,  0.0206,  0.2092,\n",
            "          0.0426,  0.2022]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2180, -0.0789,  0.1289,  0.1138,  0.0144, -0.0063]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3035, -0.1353,  0.1465,  0.2725,  0.2112,  0.2191]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0864,  0.0547, -0.0608, -0.0226,  0.0306,  0.0424,  0.0823]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0880, -0.0201,  0.0122]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1895, -0.3490,  0.0148, -0.0959,  0.1784, -0.0200, -0.3769, -0.0947]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2399, 0.3917]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0237, -0.0500,  0.0265,  0.0743,  0.1724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1162, 0.3072, 0.2063, 0.1644, 0.1220]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2300, 0.3285]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1121,  0.0295,  0.2445,  0.2626]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1039, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1145,  0.0439, -0.0385,  0.0583,  0.0689, -0.1037, -0.1554,  0.0456,\n",
            "          0.1208, -0.0888]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2244,  0.3337,  0.0771,  0.0806, -0.0045]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2969,  0.0587,  0.2996,  0.2165,  0.1118, -0.0624]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0778, -0.3470, -0.0460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'll offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0781, 0.0427, 0.1671, 0.0996, 0.1408]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1249,  0.1093,  0.2690,  0.3558]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I am very satisfied, that seems like the best choice I guess.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1189, -0.1811, -0.2295,  0.0552, -0.2883, -0.2595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0642, -0.0876, -0.0396]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0955, 0.0336, 0.0485, 0.0262, 0.0233, 0.0498, 0.1934]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0581, -0.1050, -0.2081,  0.1128,  0.1697,  0.1729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.2984, 0.2934, 0.2738]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.0269, 0.1677, 0.3616]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess a meeting is what's next then. I think that is the only thing on the list anyway.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1887, -0.3429, -0.4527, -0.2196, -0.3209, -0.3255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1479, -0.2432, -0.1866, -0.1110, -0.1804, -0.1667, -0.0601]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1273, 0.0838]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0675,  0.1183,  0.1689,  0.1940, -0.0971, -0.0609]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2060, 0.1387, 0.1690, 0.3206, 0.2819, 0.1765, 0.2264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0847, -0.1634, -0.1201, -0.0155]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1713, -0.0893,  0.1211,  0.1524,  0.1302]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0776, -0.1014, -0.1882, -0.0631, -0.0725]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2150, -0.0059,  0.2406, -0.0023, -0.0632, -0.0150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4293, -0.0636, -0.0188, -0.1440, -0.1289, -0.1031,  0.0314, -0.0334,\n",
            "         -0.2441, -0.1640]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0696, -0.1888,  0.0951]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0605, 0.1486, 0.2012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.1958, -0.3739, -0.1351,  0.0906, -0.1180, -0.0381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2036, 0.0676, 0.0247, 0.0207, 0.0662]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1629, 0.0957, 0.1069, 0.0651, 0.1620]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2068, 0.1045, 0.0903, 0.0136]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0610, -0.2848, -0.0287, -0.0762, -0.1500]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.2293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.2818, -0.0760,  0.0089,  0.1314, -0.0763, -0.0260, -0.0680, -0.2078,\n",
            "         -0.2237, -0.1166]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0649, -0.2401,  0.0778,  0.0075, -0.1586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1449, 0.2012, 0.1949, 0.2750]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2409, 0.2154, 0.4675, 0.2396, 0.2664, 0.2227, 0.3207, 0.3014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0748, 0.2246, 0.2943, 0.3485]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0432, 0.1727, 0.1745, 0.1764, 0.1073]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1651, 0.2510]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3554, 0.4501]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1624,  0.0011, -0.0087, -0.1642, -0.0890, -0.1130, -0.0658, -0.2440,\n",
            "         -0.1378,  0.0343, -0.2223, -0.1986, -0.1802]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1075, 0.2237, 0.1620, 0.1865]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2838, -0.1145, -0.0867, -0.1380, -0.2375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0950, -0.1580, -0.0810, -0.1221, -0.1204, -0.0912,  0.0433]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1791, -0.0271,  0.2080,  0.2086,  0.3296,  0.2282]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0736, 0.0491]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.4193, -0.0619,  0.0637, -0.3117, -0.3437]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1349, -0.0379, -0.2938, -0.2758, -0.1438, -0.0748, -0.0248, -0.3626,\n",
            "         -0.1719, -0.0819, -0.0789, -0.1063, -0.3375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0719,  0.0011,  0.0603,  0.0371]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1094, 0.1606]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0004,  0.0715, -0.0349,  0.0522,  0.0847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2222, 0.2593, 0.2535]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2478, 0.1321, 0.2889, 0.3936]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1803, 0.1153, 0.2617]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0354, -0.0052,  0.2238, -0.0104, -0.0147, -0.1859]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JTS']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1766,  0.1908,  0.1028, -0.1352,  0.3550]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1609, 0.2307, 0.2360, 0.2677]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1553, 0.1602, 0.1885, 0.1544, 0.1607, 0.1300, 0.2663]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0474,  0.0434,  0.0836, -0.0068,  0.1782]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1402, -0.0675,  0.0038,  0.1000,  0.0174,  0.0083,  0.0546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1229, -0.2724, -0.1549, -0.1102,  0.0245,  0.1136]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1842, -0.1127,  0.1295,  0.1383, -0.0214]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.0492, -0.1446, -0.0099]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so next steps, hmmm... I guess my only option here is to make an Offer, then.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2297, 0.3322]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent. I guess yes? I really don't know all the options.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1054, -0.0574, -0.1620, -0.2366, -0.1755]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1289, -0.2397, -0.4245,  0.0262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1128, 0.2379, 0.2195, 0.1677]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2279, -0.1158,  0.0297,  0.1985, -0.0523, -0.0635,  0.0788, -0.0471,\n",
            "         -0.1572, -0.0063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0567, -0.3738, -0.1684]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1589,  0.2097, -0.0025,  0.1174,  0.0703, -0.0187,  0.0609,  0.1764,\n",
            "          0.1581,  0.1200]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2863, 0.4018, 0.4456, 0.4601]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0286,  0.1073,  0.1730,  0.3805,  0.2199,  0.2372,  0.2003,  0.0847,\n",
            "          0.0765,  0.3216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3166, -0.1647, -0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0013,  0.2546]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1017, -0.0648]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0620, -0.1353, -0.0975, -0.2843, -0.0316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0397, -0.0341,  0.0213,  0.0090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2195, -0.2259, -0.3537, -0.2665, -0.4758]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0221,  0.1762]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2245, 0.2656, 0.0215, 0.3678]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1841, -0.1883, -0.0612,  0.0794]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3412, 0.3451, 0.3311, 0.3509, 0.3433]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1275,  0.1000, -0.0472,  0.0729,  0.1126]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0792, 0.1087, 0.2659, 0.2085, 0.2499, 0.2519, 0.1415]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0866, 0.1714, 0.1652, 0.1693, 0.1372]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0706, 0.0071, 0.2143, 0.0041]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2007, -0.0516, -0.2182, -0.1629, -0.1144]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2586, 0.1413, 0.1826, 0.1575, 0.1957, 0.1876]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1404, -0.1772, -0.1991, -0.3546,  0.2665,  0.2961]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0739, -0.1077,  0.0937,  0.2248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0351, -0.0633, -0.0152, -0.0985, -0.0923, -0.1451,  0.0451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0163, -0.1772, -0.3120,  0.0084, -0.0197,  0.0278]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1987, 0.2184, 0.2181]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[-0.0948,  0.0263, -0.0407,  0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0486, -0.1159, -0.2007, -0.2323,  0.0517]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1021, -0.0365, -0.0155, -0.1074, -0.0829, -0.0728, -0.0401, -0.0479,\n",
            "         -0.0815, -0.0193, -0.1428, -0.1357, -0.1317]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0617,  0.1741, -0.1675,  0.0449, -0.0187,  0.1276,  0.0066, -0.0093,\n",
            "          0.0474,  0.1029,  0.0837,  0.0754,  0.0843]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Jens Roschmann', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1]\n",
            "\n",
            "tensor([[ 0.1382,  0.1555, -0.0037,  0.3134]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1259, 0.2869, 0.2747, 0.2031, 0.1685, 0.0351, 0.2878, 0.0957, 0.2182,\n",
            "         0.0786, 0.1438, 0.0618, 0.1690]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0791, -0.0967, -0.1965, -0.2317, -0.0508,  0.2029]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0236, -0.0306, -0.0847,  0.0875,  0.0896, -0.1680]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2491, -0.1424, -0.1672, -0.0367, -0.1604, -0.1304, -0.1384, -0.1852]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1998,  0.1808, -0.0424,  0.3454,  0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0096,  0.0219,  0.0258, -0.0485, -0.0553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0772, -0.0844, -0.0065, -0.0625, -0.0602, -0.0414, -0.0184]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1755, 0.2763, 0.2887, 0.3321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0557, -0.0035, -0.0427,  0.2498,  0.0928, -0.0262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0791, 0.0878, 0.1201, 0.1696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I guess the customer type is an 'Existing customer'.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2984, 0.2734, 0.3453, 0.4433]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0689, 0.0846, 0.0486]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.4475, -0.3654, -0.4099, -0.1411, -0.4809]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3439, -0.1585, -0.1074, -0.2153, -0.0729, -0.2233, -0.2168, -0.1033]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1608, 0.2450, 0.3113, 0.2981, 0.3404, 0.3919, 0.3614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1501,  0.1023,  0.1441,  0.0459, -0.0548,  0.0841]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0426, -0.0476]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0719,  0.0917,  0.0152,  0.2355,  0.0614, -0.0097, -0.0171,  0.2094,\n",
            "          0.1147,  0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0733, 0.2271, 0.2066, 0.1196, 0.1346, 0.1726, 0.1041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5046, -0.3543, -0.4483, -0.4292, -0.4021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0047,  0.0371, -0.0944, -0.0259,  0.1621]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1552, -0.0943, -0.3897, -0.0098, -0.0546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0376,  0.1688, -0.2268, -0.1812,  0.1218, -0.1818, -0.1474,  0.0022]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Pipedrive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2072, -0.0083,  0.2288,  0.2483,  0.1379]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2114, -0.1254,  0.2065,  0.1275,  0.2193]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0875, 0.2078, 0.2209, 0.0991, 0.0623]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0147, -0.1141, -0.1970, -0.1162, -0.1150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0831, -0.0150, -0.0919,  0.0435, -0.1294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1224,  0.0913,  0.0441,  0.2219]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-6.6145e-02,  1.1137e-01,  3.2680e-01,  3.7495e-01,  1.0932e-01,\n",
            "          1.5980e-01,  1.5561e-01, -6.4522e-05,  1.7808e-01,  2.4826e-01]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1954,  0.1777,  0.0099,  0.1002, -0.1518, -0.0705,  0.1628, -0.0962,\n",
            "          0.0857,  0.0327,  0.0612,  0.0589,  0.0946]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0629,  0.0587,  0.0226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.2559, -0.6972, -0.5280, -0.3614, -0.4442, -0.3239,  0.1368, -0.5729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0644, -0.0794, -0.0307,  0.1192,  0.0384]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0159,  0.1270,  0.0371, -0.0029,  0.0871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0350, 0.1658]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1638, 0.2418, 0.1420, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3129, -0.3209, -0.3259, -0.2658, -0.3697]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0829, 0.0888, 0.0864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.0716, -0.1027, -0.3877, -0.3210]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess I am an existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1044, 0.4391]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0303, -0.0725, -0.1164, -0.0029,  0.1903]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0727,  0.0661,  0.1751, -0.0444,  0.2094,  0.3381,  0.0574, -0.0569]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2479, -0.1491, -0.2076, -0.3964, -0.0554]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1922, 0.1981, 0.3902, 0.3113]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I'm very unsatisfied, not thrilled at all to be honest.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0754, -0.2846,  0.0458]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2107, 0.1512, 0.2058, 0.3369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0822, -0.0570, -0.1890,  0.1452,  0.0518,  0.0801]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0879,  0.2567]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2989, -0.0042,  0.1012,  0.1894,  0.1762, -0.1345,  0.1266,  0.0251,\n",
            "         -0.0066, -0.0487]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1452, 0.2636]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0005, -0.2218, -0.0166, -0.0559, -0.1861]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0345, -0.2250,  0.0603, -0.2424, -0.0025,  0.0479]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1349, -0.0580, -0.0190, -0.2325,  0.0097, -0.1111]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0911, 0.1398, 0.1426]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1058, 0.1148, 0.1459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0272, -0.0699, -0.1531, -0.1525,  0.0737,  0.1580]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2942, 0.2330, 0.2691]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.0489,  0.1420,  0.1498,  0.2977,  0.2324,  0.2197,  0.1157,  0.1524,\n",
            "          0.1156,  0.4059]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0782,  0.0217, -0.0328,  0.1053,  0.2008, -0.0828,  0.0324, -0.1656,\n",
            "         -0.0551, -0.0102,  0.1656,  0.1080,  0.0940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0560, -0.2060,  0.0721,  0.2015, -0.3016,  0.0094, -0.2671, -0.1792]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0544,  0.0135, -0.0825, -0.1631,  0.1096]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2301, 0.2702, 0.2780, 0.2500]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2056, -0.0234,  0.0015,  0.1601,  0.0854,  0.0202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0246, -0.0205,  0.0140, -0.0502,  0.1117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1296, -0.1051, -0.3404, -0.2045]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0558,  0.0418, -0.0636,  0.0192, -0.0619]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking about language, I'd prefer to communicate in English. It's the only language option available, so English it is!\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0663, -0.0915,  0.0570,  0.1838]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0482, 0.0196, 0.2857]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1296, -0.2523, -0.0608, -0.0707]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2516, -0.3325, -0.1267, -0.0506,  0.0351, -0.0354]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0652,  0.1659,  0.0403, -0.1988,  0.0814,  0.0349]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0519, -0.1146,  0.1518,  0.0483,  0.2598]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0465,  0.0813, -0.0438, -0.0412,  0.1536]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1128, 0.1041, 0.1632, 0.1265, 0.1338, 0.1502, 0.1768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0612, 0.0118, 0.0561]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0116, -0.1818, -0.0819, -0.2317,  0.0233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2801, 0.2341, 0.3501, 0.3172, 0.2732, 0.3211]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0542, 0.2577, 0.0587, 0.0330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'd say Applicant, I'm not really sure what other kinds there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0472,  0.2147,  0.2042,  0.0206,  0.1623,  0.1458,  0.0237,  0.2234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0292, -0.1258, -0.0323, -0.0179, -0.0494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0122, -0.0094,  0.0276, -0.0322,  0.0360]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2616,  0.0621,  0.0421,  0.2547,  0.0744, -0.3039,  0.0437,  0.0412,\n",
            "         -0.0010,  0.0316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in the Physical Security industry. That's the only one listed.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1979, -0.0581, -0.2156, -0.0941, -0.3701,  0.0237, -0.1503,  0.0775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1575, 0.0269, 0.0935]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.0695, -0.0532, -0.1565,  0.0767, -0.2326, -0.1431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2517,  0.2568,  0.2726, -0.1819,  0.4424]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0880, -0.0757,  0.1200,  0.0598,  0.1017,  0.2020, -0.0760]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1462, 0.2890, 0.1310, 0.1751]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2987, 0.1913, 0.2287, 0.1912, 0.1560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1702, 0.1722, 0.1429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.2253, 0.3045]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1700,  0.0897,  0.0842, -0.0601,  0.2816]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0527, -0.2332, -0.0084]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.4536, -0.0904, -0.1416, -0.3362, -0.3826, -0.3545, -0.2192]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3100, -0.1229, -0.1803, -0.1699,  0.2603]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1749, 0.1109]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Well, I would like to say, I prefer not to, so I'll choose **No**.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0775, -0.0782, -0.1749,  0.0263, -0.3600]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, and also display port debugging and compliance. I think those two are interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3116, -0.2258, -0.3064, -0.1303, -0.2109]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1734, 0.1675, 0.0536, 0.1490, 0.0454, 0.0158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0165,  0.0140, -0.1802,  0.0644, -0.2104, -0.0616,  0.0567,  0.0063,\n",
            "         -0.0963, -0.0691, -0.0233,  0.0531,  0.0218]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2158, 0.2602]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0043,  0.0620, -0.0186,  0.1039,  0.0240,  0.0963,  0.1500]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2163,  0.0296,  0.0412,  0.1794, -0.0004,  0.0720]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0505, -0.0284, -0.2088, -0.0384, -0.0044, -0.1921]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1909, 0.3013]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2383, 0.2515, 0.0764, 0.1462, 0.0619, 0.2074, 0.1840]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Wholesaler\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1708, -0.0229, -0.0968]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.2573, -0.2702, -0.3283, -0.1780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0675,  0.0566,  0.1947,  0.1172,  0.1599,  0.1691,  0.1634, -0.0799,\n",
            "         -0.1637, -0.0281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0189, -0.2124,  0.0032, -0.0363, -0.0990, -0.0935, -0.0803]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0486, -0.1047, -0.0126, -0.0007, -0.1434,  0.1013, -0.1396, -0.2160,\n",
            "         -0.0501,  0.0230, -0.0439,  0.0918,  0.0241]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1863, -0.1492, -0.0555,  0.0964, -0.0685, -0.0407, -0.0665,  0.0200,\n",
            "         -0.3360, -0.3095]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2373,  0.2366,  0.0409,  0.1540,  0.0886,  0.2032,  0.1004,  0.1969,\n",
            "          0.1415,  0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0625, -0.3629,  0.0338,  0.0030,  0.2120,  0.2422]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1039, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1864, 0.1716, 0.0842, 0.2992, 0.1650, 0.1954, 0.2300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0188, -0.1105, -0.0808, -0.0913, -0.1254, -0.0301, -0.2104, -0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0496, -0.2117,  0.0869]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0456, 0.1492, 0.1352, 0.1054]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3619, -0.2440, -0.4064, -0.6674, -0.1466]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1370, -0.0044,  0.1493,  0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0004,  0.1318, -0.0954, -0.1680,  0.2229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1685, -0.3739, -0.0424, -0.1968]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2577, 0.2584, 0.2464]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1479, -0.1084, -0.2617, -0.1255, -0.2858]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1100, -0.0431,  0.1937,  0.0130,  0.2710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1773, 0.2113, 0.1164, 0.0717, 0.1150, 0.1028]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2487, -0.0315,  0.0137]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1169, -0.0603, -0.2258, -0.0744, -0.1604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2619, -0.0276, -0.0928, -0.2349, -0.1552]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2308, -0.2381, -0.1776, -0.1911, -0.1372, -0.1546,  0.0293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0010, -0.0188]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.1552,  0.0411,  0.0551,  0.3102,  0.1360,  0.2202,  0.1475,  0.1083,\n",
            "          0.0032,  0.2517]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1711,  0.0693, -0.1865, -0.2680,  0.0394]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1723,  0.0389, -0.0477,  0.0531, -0.0717,  0.0026, -0.1930, -0.0742,\n",
            "         -0.1045, -0.0703]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0012,  0.0006,  0.0494]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0168,  0.0752,  0.1267,  0.3236,  0.1633,  0.1873,  0.1292,  0.1121,\n",
            "         -0.0348,  0.1422]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0610,  0.0741, -0.0872, -0.2194, -0.3549]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2745, 0.2040, 0.2895, 0.2722, 0.1609, 0.2927]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0592, -0.6220, -0.5354, -0.3276, -0.5475]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0882, 0.1620]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2280, -0.0861,  0.0207,  0.1345,  0.1052,  0.0261,  0.0768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3630, -0.2583, -0.5577, -0.4745, -0.4413]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1954,  0.1733,  0.0957, -0.1008,  0.1708]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1542, 0.1685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to data processing.  I don't know what other options there might be.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.1271, -0.0690, -0.0965, -0.1236, -0.0363, -0.0425]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0571, -0.0024,  0.0091,  0.0504, -0.0156]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1687, 0.3077, 0.1976, 0.1866, 0.0878, 0.1986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0489, 0.1686]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1541, 0.0899, 0.1280, 0.1738, 0.1181, 0.1910, 0.2326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0634, 0.0653, 0.1245, 0.0925, 0.0842, 0.0845, 0.1645]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1542, 0.1429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I'd rather not receive any marketing emails, so no, please. That's the only option you gave me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.2577,  0.1154, -0.0851, -0.0939, -0.1364,  0.0175, -0.0513, -0.2454,\n",
            "         -0.0451, -0.1888, -0.2619,  0.0448, -0.0613]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0062,  0.0432, -0.0324, -0.0358, -0.0350, -0.1117]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0013,  0.0965,  0.1007,  0.2046,  0.0783, -0.0081]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0829,  0.0163,  0.1293,  0.2541,  0.1123,  0.1399,  0.1393,  0.1812,\n",
            "          0.0039,  0.0321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1133,  0.0260, -0.0315, -0.0243]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1135,  0.1620,  0.0723,  0.3444,  0.1505, -0.0897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2315, 0.1835, 0.4069, 0.3325, 0.3221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.2268, -0.2756, -0.3145, -0.1412, -0.0893]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2227, -0.3658, -0.3450, -0.1377, -0.2863, -0.3128, -0.0582, -0.2439]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1108,  0.2111,  0.0925,  0.1660, -0.0541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0263,  0.0600, -0.1312, -0.0749,  0.0147]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1158,  0.0599,  0.0919,  0.0566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2490, 0.2269, 0.2367]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0803, 0.1013, 0.0311, 0.0131]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0706, -0.4319,  0.0709, -0.0251, -0.1190]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1063,  0.0439, -0.0367, -0.0547,  0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1927, 0.0775, 0.1995, 0.2271, 0.1724, 0.1687, 0.2616]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1107,  0.1619,  0.0689, -0.1279, -0.0946,  0.0035]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0771, 0.0277, 0.0869]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1]\n",
            "\n",
            "tensor([[-0.0061, -0.1146,  0.1524,  0.0078,  0.2486,  0.0426, -0.1866,  0.0957]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1978, -0.0617,  0.0330, -0.1547,  0.1727]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0734, -0.3206, -0.1506,  0.0563, -0.0275,  0.0096]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0009,  0.0267,  0.0943,  0.1817]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1653, 0.2175, 0.2684, 0.3576]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0941, 0.2574, 0.2455, 0.1642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3452, -0.3026, -0.3455]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step should be offer, yeah that sounds about right.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.0513, 0.1344, 0.0992, 0.1258, 0.2065]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0053,  0.0550,  0.0281,  0.0428, -0.0750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0848,  0.0506, -0.1877, -0.2206,  0.2442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1102, 0.2488, 0.2453, 0.1494, 0.0694]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0184, -0.4906, -0.0559, -0.3143, -0.3777]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0250, 0.1412, 0.0474, 0.1342, 0.2122]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0236, -0.0757, -0.1482,  0.0756]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1876, 0.1550, 0.2164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.3289, -0.1872, -0.1923, -0.1865, -0.1925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.1498, -0.1401, -0.1131, -0.1571, -0.2286]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0578,  0.0151, -0.0070, -0.0038]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0444,  0.0437,  0.1628,  0.1518, -0.0101,  0.0398, -0.0794,  0.0733]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2418, 0.2230, 0.2966, 0.3960]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction. I'd say, like, I am very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0278,  0.1159, -0.0060,  0.1667]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1847, -0.0608, -0.0939,  0.2847, -0.0104, -0.0344,  0.2711]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0323,  0.0783,  0.2333,  0.5639,  0.2190,  0.3253,  0.2263,  0.1263,\n",
            "          0.1484,  0.2019]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0209,  0.2979,  0.1182, -0.2752,  0.0490, -0.0433, -0.4209,  0.0908]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2910, -0.3204, -0.3929, -0.1017]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0192, -0.0081, -0.1202,  0.0289, -0.0517,  0.0126,  0.1016, -0.0273,\n",
            "         -0.0384,  0.0125,  0.0987,  0.0490, -0.1011]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0979,  0.0752, -0.1855, -0.0611,  0.1293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0296,  0.1441,  0.0820, -0.0426,  0.1202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1189, -0.0526,  0.0215,  0.1926, -0.0195]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3134, 0.2760, 0.2746]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1705, 0.2215, 0.1496, 0.1480, 0.0053]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0763, -0.0192]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0200, 0.0210, 0.0588, 0.1278, 0.3284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0345, 0.0777, 0.4104, 0.1584, 0.2062, 0.1106, 0.0943]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1508,  0.0450, -0.0432, -0.0304,  0.1793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0817, -0.0203, -0.0226, -0.0178, -0.0787]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question. I'm honestly not sure of the exact number. I think we have somewhere around 120 people.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0441,  0.1696, -0.0187,  0.1099, -0.0077,  0.0515,  0.0211,  0.0581,\n",
            "          0.0257,  0.1435,  0.0734,  0.0583, -0.1074]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0531, -0.1547, -0.0310, -0.1434,  0.1870]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1846, -0.0130, -0.0952, -0.0725,  0.2206]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1477, 0.0739, 0.0986, 0.1898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0074, 0.1144, 0.0080, 0.1314, 0.0372, 0.0558, 0.1912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0159, -0.0860, -0.2822, -0.0820, -0.1863, -0.0992, -0.0348, -0.1316,\n",
            "          0.0363, -0.1566, -0.1174, -0.0306, -0.0986]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1749, -0.0380, -0.2649, -0.2200,  0.0519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0686,  0.1704,  0.0410,  0.2858,  0.1280, -0.0908,  0.0139,  0.0664,\n",
            "          0.1102, -0.0035]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2964, -0.3741, -0.2133, -0.1430, -0.2484]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1804, 0.1735, 0.1774]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.2675, 0.3013, 0.3402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0335, -0.0338,  0.0935,  0.0546,  0.1702,  0.1008, -0.0879, -0.0387]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1384, 0.1803, 0.1958]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'm happy to follow up! It could be in **2 weeks** or maybe in **3 weeks**. Which timing is best for you?\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0077, -0.1685,  0.1751, -0.0901,  0.1375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.2293, 0.1649, 0.1382, 0.3946]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0572, 0.2121, 0.0546, 0.0233, 0.1634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1740, 0.0967, 0.1570, 0.2029, 0.0837]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0630, -0.0215, -0.0119,  0.2145,  0.2037, -0.1925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1412,  0.0024, -0.0773,  0.0401,  0.1336, -0.1902]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0634, -0.1476, -0.2377,  0.0760, -0.0137,  0.0617]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0701, 0.1115, 0.2391, 0.1700, 0.1231, 0.1447, 0.1537]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what groups there are but I think it's probably a wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Distributor\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0471,  0.0149]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1276,  0.1126,  0.0614, -0.0590,  0.1038]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3456, -0.1158,  0.0744, -0.2391,  0.3036,  0.0161, -0.3839,  0.0322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0376,  0.0265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.2765, -0.1226, -0.3433, -0.2763, -0.2522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2442, 0.2208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0643, -0.3319, -0.0763, -0.1024, -0.0974, -0.3017, -0.2634]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2050,  0.1969,  0.0605,  0.4133,  0.3035,  0.2079,  0.1598,  0.2332,\n",
            "         -0.0576,  0.1673]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0734, -0.2588, -0.0694, -0.1127, -0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0188,  0.1531,  0.0424, -0.1239,  0.0212]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0931,  0.1614,  0.0677,  0.1042]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0046, -0.0307, -0.1814,  0.0115, -0.0930]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2782, -0.1496, -0.1661, -0.0464, -0.1498, -0.1468, -0.0684]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2814, -0.0408, -0.1657, -0.1570, -0.4184]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1975,  0.0499,  0.0175,  0.1899, -0.0868,  0.1308,  0.0252,  0.0575,\n",
            "         -0.0343,  0.1956]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0301, -0.0577,  0.0226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0853, -0.1781, -0.1099, -0.0535, -0.0302,  0.0004,  0.1960]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0095,  0.1103, -0.0290,  0.0896]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0439, -0.0564, -0.1368, -0.0641,  0.0674]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1311, -0.2249, -0.1421, -0.1798, -0.1551]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0648, -0.2410, -0.1810]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0261, -0.0017,  0.0180,  0.0688, -0.4108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0186,  0.0391, -0.0409, -0.0022]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1055,  0.0192, -0.0749,  0.0190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0076, -0.0517,  0.0442, -0.0152, -0.0595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1942, 0.2280, 0.2531, 0.2518, 0.2140, 0.1808]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2062,  0.0766,  0.0418,  0.1026, -0.2100, -0.1293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0020, -0.0300,  0.0338, -0.2048, -0.0903, -0.1797, -0.1406]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2987, 0.1925, 0.0315, 0.1418, 0.2348]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0898,  0.0519,  0.1088, -0.0132, -0.1252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1306, -0.2062, -0.0363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0027, -0.0061, -0.1607, -0.1680,  0.0169, -0.0011, -0.0526, -0.0966,\n",
            "         -0.0813, -0.0028, -0.1385,  0.0484, -0.1717]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2002,  0.1006,  0.0239,  0.3060,  0.1719,  0.1410,  0.0677, -0.0004,\n",
            "         -0.0151,  0.1760]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0866, 0.0276, 0.1497, 0.1456, 0.1246, 0.1769, 0.3614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1124, 0.2632, 0.3317, 0.2938]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1379, 0.1137, 0.2226, 0.1169]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0287, -0.4235, -0.2805,  0.0731, -0.2042,  0.1381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2683, -0.1899, -0.0650, -0.2957, -0.0560, -0.1213, -0.1952, -0.0835]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0571, -0.1016, -0.1760,  0.0213, -0.0652, -0.0734]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2031, -0.1694, -0.3067, -0.1853, -0.1123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0682, -0.1930, -0.2488, -0.2658, -0.1654]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0065, -0.1708,  0.0411, -0.0182,  0.0021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3815, -0.2120, -0.1981, -0.0852, -0.0693]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0325, -0.1024, -0.0140,  0.0463, -0.0061,  0.0569,  0.0099, -0.1364,\n",
            "         -0.0102,  0.0178, -0.1334,  0.0477, -0.0724]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0591, -0.3126, -0.3526,  0.0805,  0.4220,  0.1183]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2266, -0.2475, -0.2485, -0.1633, -0.4038]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1412, -0.0547,  0.0587,  0.2937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0396,  0.1057,  0.2162,  0.1548, -0.0077,  0.0874, -0.0169,  0.2030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1182, 0.1189, 0.1468, 0.1395]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0716, -0.0483, -0.0528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2139,  0.3097,  0.1582,  0.2863,  0.2010,  0.1407,  0.1406,  0.1694,\n",
            "          0.0686,  0.0911]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2160, -0.4218, -0.3895, -0.3025, -0.3548]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2605, -0.0608, -0.0779, -0.0914, -0.0719, -0.0351, -0.1786, -0.0646,\n",
            "         -0.2182, -0.2642]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0735, -0.1219, -0.1211, -0.3709, -0.0060, -0.0176]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0430,  0.0996, -0.0194,  0.0881,  0.1775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1602, -0.1074, -0.0472,  0.0822, -0.1080, -0.0711, -0.2762, -0.0924]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2327, -0.0735,  0.0751,  0.1924,  0.2501,  0.3738,  0.1748]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1451,  0.2301,  0.0206,  0.1732,  0.0776,  0.0331,  0.1868,  0.0717,\n",
            "          0.2081,  0.2393, -0.0015, -0.0091,  0.1350]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3138, 0.2175, 0.1003, 0.1832, 0.2780]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0785,  0.3069,  0.0595, -0.1176,  0.2471]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2587, -0.2338, -0.1221,  0.0399, -0.0384, -0.2622, -0.1019, -0.1734,\n",
            "         -0.3082, -0.2858]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1010, -0.1513, -0.2206,  0.2558,  0.0241,  0.0452]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3972, -0.2897, -0.3215, -0.1311, -0.3847]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1274, -0.1395, -0.0613, -0.0245, -0.0558, -0.0388,  0.0690]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 25 people.  I don't know what the other options are, but that's my best estimate for the average size of a trade fair team.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1454, 0.1010, 0.1749, 0.0929, 0.2745]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2599,  0.1134,  0.2992, -0.0113,  0.1565]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1473, 0.0124, 0.1152]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1243, 0.1020, 0.1282, 0.2061, 0.0867, 0.2447]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1735, 0.0970, 0.0390, 0.1382, 0.3727]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3223,  0.0906,  0.0160,  0.0914, -0.0023,  0.0998,  0.0218,  0.1984,\n",
            "          0.1757,  0.1284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2134, -0.2891, -0.1565, -0.1624,  0.1259, -0.2846, -0.3241, -0.0391]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0969,  0.0954, -0.0215,  0.0771,  0.0833,  0.2028]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1985, -0.1583, -0.0533,  0.3706,  0.0072,  0.0883]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0864, -0.4556, -0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2396,  0.1212,  0.2025,  0.1430,  0.0774, -0.2201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, a company, hmm. I guess it must be a scaffolding company. I'm not really sure though, sorry.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0835, -0.1118, -0.0198,  0.0188, -0.0075, -0.0319,  0.1766]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0423,  0.0855]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, for data processing consent, it looks like the only option here is 'Yes'. So, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.0770, 0.1304, 0.3735, 0.3475]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2390, -0.0304,  0.1395,  0.1649,  0.0326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "The metrics for all open-ended questions in the train dataset:\n",
            "{'accuracy': 0.7078977932636469, 'f1': 0.5054080629301868, 'precision': 0.5538793103448276, 'recall': 0.46473779385171793}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xDF1GH7FZHvK",
        "outputId": "99aaf6a1-b01a-4a2f-bd8b-e32dc99118fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "xlnet/xlnet-base-cased: {'accuracy': 0.7078977932636469, 'f1': 0.5054080629301868, 'precision': 0.5538793103448276, 'recall': 0.46473779385171793}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also okay good for having not done any fine-tuning:\n",
        "\n",
        "\n",
        "```\n",
        "{'accuracy': 0.7078977932636469, 'f1': 0.5054080629301868, 'precision': 0.5538793103448276, 'recall': 0.46473779385171793}\n",
        "```"
      ],
      "metadata": {
        "id": "lLUe4cx39Gz3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### RoBERTa base model of FacebookAI"
      ],
      "metadata": {
        "id": "eaZn2ZLgXlw1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"FacebookAI/roberta-base\"\n",
        "mc_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whjdVgK4Wnsz",
        "outputId": "2744daf0-a34b-4f44-d59c-e0a38aa8eed7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yCT4MxbXkcL",
        "outputId": "ac99c647-95a4-49b5-ac59-eab3329b2936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "tensor([[0.1364, 0.1373, 0.1391, 0.1375, 0.1388, 0.1386, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1324, 0.1339, 0.1312, 0.1301, 0.1254, 0.1323, 0.1301, 0.1338,\n",
            "         0.1336, 0.1323, 0.1329, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1320, 0.1326, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1251, 0.1226, 0.1232, 0.1259, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1281, 0.1268, 0.1239, 0.1216, 0.1226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1262, 0.1237, 0.1247, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1400, 0.1407]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, hmm, yes I guess I would, sure.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1325, 0.1338, 0.1309, 0.1320, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1229, 0.1240, 0.1216, 0.1256, 0.1232, 0.1240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1263, 0.1247, 0.1289, 0.1274, 0.1255, 0.1295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1236, 0.1231, 0.1201, 0.1248, 0.1255, 0.1254, 0.1232, 0.1221, 0.1223,\n",
            "         0.1244]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1283, 0.1254, 0.1287, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1342, 0.1332, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1252, 0.1248, 0.1230, 0.1267, 0.1279, 0.1275, 0.1249, 0.1238, 0.1241,\n",
            "         0.1269]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, umm I think I'm working with network operators and infrastructure. Yeah, that sounds right.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1380, 0.1389]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yeah I would like to get emails about marketing information.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1362, 0.1379, 0.1422, 0.1391, 0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1301, 0.1290, 0.1299, 0.1307, 0.1269, 0.1283, 0.1309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1335, 0.1314, 0.1287, 0.1334, 0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Okay, so you want to know which language I want for communication? I'm good with using Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1370, 0.1395, 0.1387, 0.1393, 0.1402, 0.1369]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1317, 0.1287, 0.1303, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1205, 0.1184, 0.1188, 0.1209, 0.1185]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1333, 0.1332, 0.1338, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1236, 0.1194, 0.1243, 0.1233, 0.1239]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1266, 0.1294, 0.1284, 0.1310, 0.1284, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1313, 0.1286, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer. I guess that's what I would be.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1305, 0.1311, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 3 weeks sounds good, that's when I'd like a follow up.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1314, 0.1304, 0.1317, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1268, 0.1310, 0.1263, 0.1279, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1353, 0.1370]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1314, 0.1320, 0.1310, 0.1301, 0.1293, 0.1278, 0.1322, 0.1300, 0.1324,\n",
            "         0.1319, 0.1323, 0.1313, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1335, 0.1346, 0.1336, 0.1343, 0.1348, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1257, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1339, 0.1290, 0.1305, 0.1319, 0.1318, 0.1299, 0.1318, 0.1306]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1346, 0.1347, 0.1325, 0.1312, 0.1275, 0.1337, 0.1319, 0.1328,\n",
            "         0.1355, 0.1317, 0.1336, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1294, 0.1267, 0.1297, 0.1288, 0.1294]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1297, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1288, 0.1281, 0.1264, 0.1309, 0.1285, 0.1264, 0.1311]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm I guess the customer group would be end user then, that seems about right.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1303, 0.1291, 0.1294, 0.1323, 0.1328, 0.1325, 0.1298, 0.1274, 0.1282,\n",
            "         0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1298, 0.1298, 0.1311, 0.1290, 0.1274, 0.1247, 0.1318, 0.1280, 0.1299,\n",
            "         0.1309, 0.1278, 0.1299, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1295, 0.1352, 0.1310, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1352, 0.1370, 0.1429, 0.1399, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1294, 0.1288, 0.1301, 0.1280, 0.1272, 0.1261, 0.1292, 0.1276, 0.1307,\n",
            "         0.1308, 0.1296, 0.1280, 0.1300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Erik Schneider', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1220, 0.1178, 0.1199, 0.1158, 0.1143, 0.1172]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1254, 0.1269, 0.1261, 0.1257, 0.1239, 0.1263, 0.1247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I'm not sure which CRM system you mean, is it maybe Adito?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1376, 0.1369, 0.1361, 0.1389]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, well, I guess I'd say I'm very satisfied, if that's an option, it's definitely my answer.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1337, 0.1323, 0.1303, 0.1326, 0.1325]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm I'd probably go with Spanish. I don't know what else there is.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1207, 0.1262, 0.1236, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1367, 0.1327, 0.1334, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1184, 0.1195, 0.1188, 0.1167, 0.1204, 0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1222, 0.1281, 0.1239, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, I guess I'm interested in both Display port debugging and compliance, and also High-speed interconnect testing, those seem useful.\n",
            "The intended answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1239, 0.1277, 0.1262, 0.1227, 0.1243, 0.1252]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1257, 0.1300, 0.1264, 0.1276, 0.1266]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1235, 0.1259, 0.1236, 0.1236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1272, 0.1220, 0.1307, 0.1227, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1325, 0.1338, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess the next thing I would do is call, seems right to me.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1390, 0.1388, 0.1390, 0.1416]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1257, 0.1268, 0.1273]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1426, 0.1408, 0.1389, 0.1431]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1323, 0.1313, 0.1294, 0.1328, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I'm not sure about languages but I guess I'd choose German then.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1265, 0.1279, 0.1253, 0.1294, 0.1284]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1237, 0.1248, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1247, 0.1239, 0.1238, 0.1261, 0.1273, 0.1272, 0.1248, 0.1235, 0.1235,\n",
            "         0.1254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1298, 0.1288, 0.1279, 0.1289, 0.1300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1304, 0.1294, 0.1283, 0.1308, 0.1311, 0.1277, 0.1288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1264, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1256, 0.1235, 0.1273, 0.1280, 0.1250, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1332, 0.1298, 0.1309, 0.1297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1285, 0.1292, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1358, 0.1364, 0.1354, 0.1342, 0.1341, 0.1283, 0.1383, 0.1340, 0.1365,\n",
            "         0.1373, 0.1359, 0.1359, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1270, 0.1260, 0.1244, 0.1288, 0.1292, 0.1282, 0.1265, 0.1250, 0.1258,\n",
            "         0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1355, 0.1327, 0.1322, 0.1339, 0.1341, 0.1323, 0.1330, 0.1313]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1347, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1241, 0.1253, 0.1241, 0.1220, 0.1265, 0.1232]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's an education company, I guess.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1386, 0.1388, 0.1386, 0.1407]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1234, 0.1231, 0.1228, 0.1251, 0.1255, 0.1248, 0.1229, 0.1225, 0.1218,\n",
            "         0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1295, 0.1276, 0.1262, 0.1300, 0.1291, 0.1252, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1286, 0.1269, 0.1265, 0.1303, 0.1299, 0.1313, 0.1283, 0.1265, 0.1260,\n",
            "         0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1189, 0.1263, 0.1223, 0.1229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in high-speed interconnect testing, because that sounds like a really important field.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1280, 0.1292, 0.1283, 0.1286, 0.1284, 0.1277]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1244, 0.1244, 0.1259, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1290, 0.1291, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1278, 0.1261, 0.1268, 0.1289, 0.1264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1292, 0.1295]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1299, 0.1289, 0.1286, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, customer type. I guess that would be existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1285, 0.1262, 0.1268, 0.1271, 0.1281]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1315, 0.1297, 0.1291, 0.1313, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1217, 0.1229, 0.1212, 0.1215, 0.1227, 0.1249]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1261, 0.1255, 0.1267, 0.1240, 0.1288, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1352, 0.1358, 0.1382, 0.1366, 0.1376, 0.1382, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1292, 0.1256, 0.1288, 0.1280, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1332, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1277, 0.1296, 0.1278, 0.1271, 0.1266, 0.1288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1392, 0.1410, 0.1471, 0.1436, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1276, 0.1269, 0.1263, 0.1288, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1245, 0.1236, 0.1225, 0.1262, 0.1268, 0.1265, 0.1241, 0.1222, 0.1236,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1240, 0.1212, 0.1216, 0.1237, 0.1210]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1328, 0.1337, 0.1341, 0.1318, 0.1310, 0.1271, 0.1333, 0.1311, 0.1340,\n",
            "         0.1342, 0.1326, 0.1329, 0.1334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1308, 0.1300, 0.1311, 0.1276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1373, 0.1381]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1276, 0.1289, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they'd like a follow up in about 1 week.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1319, 0.1295, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm an applicant, I think.  I don't know what other customer types there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1318, 0.1319, 0.1286]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1232, 0.1211, 0.1269, 0.1280, 0.1232, 0.1244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1227, 0.1227, 0.1223, 0.1209, 0.1239, 0.1223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it must be a construction company. That makes the most sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1282, 0.1263, 0.1263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1271, 0.1274, 0.1276, 0.1274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1298, 0.1299, 0.1336, 0.1332, 0.1333, 0.1314, 0.1292, 0.1296,\n",
            "         0.1326]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in Aerospace? It's the only option provided.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1305, 0.1302, 0.1309, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, I suppose Italian is what I want to use. I guess that's it.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1354, 0.1363, 0.1454, 0.1383, 0.1366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, um, I think our company size is probably somewhere between 1 and 10 people. Yeah, I'd guess that.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1291, 0.1289, 0.1297, 0.1305, 0.1293, 0.1287, 0.1329]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1335, 0.1394, 0.1365, 0.1305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1229, 0.1290, 0.1225, 0.1252, 0.1230]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1345, 0.1317, 0.1328, 0.1340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1384, 0.1390]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh yeah, I'd like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1336, 0.1357, 0.1345, 0.1336, 0.1314, 0.1299, 0.1350, 0.1325, 0.1354,\n",
            "         0.1344, 0.1337, 0.1353, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1253, 0.1229, 0.1234, 0.1267, 0.1269, 0.1267, 0.1244, 0.1224, 0.1226,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1275, 0.1257, 0.1271, 0.1276, 0.1268, 0.1251, 0.1267, 0.1248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, gosh I am not really sure about those options but I'm guessing the one I'd use is Adito, is that right?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1300, 0.1328, 0.1311, 0.1328, 0.1327, 0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1214, 0.1229, 0.1213, 0.1217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1308, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1303, 0.1313, 0.1363, 0.1328, 0.1289]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1361, 0.1365]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1246, 0.1231, 0.1240, 0.1237, 0.1240]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1298, 0.1341, 0.1296, 0.1316, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something that will either clean up my CRM, extract data from emails, or maybe even improve the data quality within the CRM.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1292, 0.1256, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1378, 0.1371]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1263, 0.1267, 0.1267, 0.1254, 0.1247, 0.1270]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1324, 0.1312, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1399, 0.1371, 0.1410]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, I think the next step would be having a Meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1333, 0.1339, 0.1311, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1195, 0.1157, 0.1185, 0.1180, 0.1153]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1323, 0.1308, 0.1287, 0.1311, 0.1303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1313, 0.1293, 0.1307, 0.1330, 0.1290, 0.1318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1281, 0.1270, 0.1268, 0.1248, 0.1285]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1364, 0.1362]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no, I don't consent to data processing.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1349, 0.1356, 0.1418, 0.1401, 0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, the size of my company? I think we're around 11 to 50 people; it is definitely in that range.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1227, 0.1183, 0.1214, 0.1236, 0.1191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1193, 0.1213, 0.1198, 0.1185, 0.1203, 0.1197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1382]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1268, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I'm not sure but maybe a meeting would be a good idea, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1347, 0.1310, 0.1308, 0.1321, 0.1335, 0.1314, 0.1326, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with CAS,  I don't know what other CRM systems are out there.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1368, 0.1374, 0.1389, 0.1378, 0.1388, 0.1396, 0.1359]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1332, 0.1314, 0.1305, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1327, 0.1322, 0.1315, 0.1337, 0.1340, 0.1326, 0.1342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1263, 0.1247, 0.1242, 0.1274, 0.1271, 0.1247, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1326, 0.1326, 0.1340, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1287, 0.1291, 0.1256, 0.1262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1184, 0.1205, 0.1193, 0.1173, 0.1196, 0.1188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1373, 0.1365, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1304, 0.1266, 0.1274, 0.1254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1296, 0.1287, 0.1300, 0.1296, 0.1283, 0.1284, 0.1309]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh gosh, I'm not sure. Maybe it's Pipedrive? I'm not very knowledgeable about those types of systems.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1261, 0.1251, 0.1233, 0.1216, 0.1229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1288, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I guess the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1370, 0.1368, 0.1358, 0.1393]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1315, 0.1306, 0.1283, 0.1295]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1318, 0.1325, 0.1342, 0.1327, 0.1338, 0.1337, 0.1280]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average the trade fair team is usually more than 40 people, it seems. That's the only size I know about for now.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1245, 0.1230, 0.1213, 0.1216, 0.1219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1361]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1309, 0.1269, 0.1248, 0.1305, 0.1317, 0.1292, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1272, 0.1268, 0.1248, 0.1220, 0.1245]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1245, 0.1248, 0.1246, 0.1230, 0.1261, 0.1238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1354, 0.1380, 0.1372, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1395, 0.1405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I guess I'd say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1310, 0.1313, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh hmm, I think they want a follow up in 3 weeks, sounds about right to me.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1375, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I guess that would be ok, email is fine.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.1249, 0.1228, 0.1268, 0.1274, 0.1273, 0.1251, 0.1240, 0.1240,\n",
            "         0.1263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1343, 0.1337, 0.1319, 0.1306, 0.1294, 0.1321]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1216, 0.1243, 0.1236, 0.1208, 0.1211, 0.1212]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1321, 0.1349, 0.1339, 0.1358, 0.1361, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1290, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1288, 0.1301, 0.1319, 0.1331, 0.1304, 0.1307, 0.1331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1331, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1304, 0.1274, 0.1275, 0.1317, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1317, 0.1290, 0.1315, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, Italian, I think Italian sounds good. I'm going with that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1365]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1339, 0.1339, 0.1343, 0.1380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say satisfied, that feels right.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1351]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1269, 0.1244, 0.1254, 0.1286, 0.1290, 0.1290, 0.1264, 0.1237, 0.1252,\n",
            "         0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1384, 0.1373, 0.1445, 0.1440, 0.1391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, the size of my company? It's in the 11-50 range, so not too big, but definitely not a tiny operation either.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1209, 0.1220, 0.1204, 0.1188, 0.1222, 0.1205]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1378, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1251, 0.1222, 0.1225, 0.1251, 0.1216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1354, 0.1337, 0.1345, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I am very satisfied, that seems like the best choice I guess.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1247, 0.1261, 0.1249, 0.1276, 0.1252, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1290, 0.1298, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1401, 0.1407, 0.1423, 0.1411, 0.1425, 0.1430, 0.1393]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1255, 0.1237, 0.1216, 0.1205, 0.1226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1320, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1257, 0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess a meeting is what's next then. I think that is the only thing on the list anyway.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1257, 0.1247, 0.1273, 0.1259, 0.1262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1368, 0.1374, 0.1385, 0.1375, 0.1383, 0.1387, 0.1356]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1385, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Yes, I would like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1276, 0.1273, 0.1272, 0.1255, 0.1290, 0.1273]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1319, 0.1303, 0.1328, 0.1328, 0.1304, 0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1310, 0.1317, 0.1320, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1331, 0.1282, 0.1300, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1312, 0.1256, 0.1287, 0.1247]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1377, 0.1368, 0.1345, 0.1333, 0.1302, 0.1351]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1299, 0.1290, 0.1293, 0.1319, 0.1315, 0.1320, 0.1296, 0.1284, 0.1283,\n",
            "         0.1310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1343, 0.1355, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I guess I would say I'll call then.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1301, 0.1282, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think a meeting sounds good to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1281, 0.1298, 0.1299, 0.1325, 0.1312, 0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1340, 0.1348, 0.1335, 0.1353, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1355, 0.1358, 0.1340, 0.1378, 0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1336, 0.1346, 0.1329, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1289, 0.1304, 0.1278, 0.1299, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1238, 0.1235, 0.1232, 0.1260, 0.1257, 0.1258, 0.1239, 0.1238, 0.1238,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security,  I guess. That's what comes to mind,  I don't really know about other options.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1307, 0.1354, 0.1312, 0.1321, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1385, 0.1395, 0.1385, 0.1425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1328, 0.1304, 0.1281, 0.1310, 0.1314, 0.1296, 0.1306, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't know all the options but I guess it's Close.io. I've heard good things about it.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1314, 0.1320, 0.1337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1303, 0.1245, 0.1279, 0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1318, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1364, 0.1365, 0.1355, 0.1340, 0.1335, 0.1307, 0.1371, 0.1334, 0.1360,\n",
            "         0.1364, 0.1353, 0.1347, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1318, 0.1283, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1359, 0.1291, 0.1318, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1392, 0.1394, 0.1412, 0.1402, 0.1414, 0.1417, 0.1383]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 45 people,  I don't know what the other options are but that sounds about right for a trade fair team.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1293, 0.1286, 0.1304, 0.1306, 0.1305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1339, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1271, 0.1275, 0.1272, 0.1239, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1333, 0.1332, 0.1352, 0.1322, 0.1314, 0.1281, 0.1355, 0.1326, 0.1336,\n",
            "         0.1341, 0.1320, 0.1343, 0.1341]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1393, 0.1372, 0.1369, 0.1402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, about customer satisfaction? I guess I could say I'm **very satisfied**, and I can't imagine another possible state of satisfaction, really.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1362, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1275, 0.1255, 0.1265, 0.1292, 0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1296, 0.1299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1396, 0.1383, 0.1378, 0.1418]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say, um, very satisfied I guess. That's the only one I really know about.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1302, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step should probably be a meeting, yes that's what I think we should do.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1309, 0.1230, 0.1260, 0.1250, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1238, 0.1215, 0.1202, 0.1241, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1397, 0.1384, 0.1385, 0.1409]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1339, 0.1349, 0.1360, 0.1346, 0.1355, 0.1360, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1351, 0.1400, 0.1382, 0.1333]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1338, 0.1350, 0.1326, 0.1348, 0.1355, 0.1326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is usually around 16-20 people, give or take. That seems to be the typical amount.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1289, 0.1280, 0.1276, 0.1310, 0.1298, 0.1302]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1321, 0.1337, 0.1297, 0.1325, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1378, 0.1357, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1346, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent. I guess yes? I really don't know all the options.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1326, 0.1333, 0.1373, 0.1355, 0.1341]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1300, 0.1309, 0.1278, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1441, 0.1411, 0.1404, 0.1439]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1224, 0.1218, 0.1209, 0.1243, 0.1246, 0.1240, 0.1222, 0.1220, 0.1219,\n",
            "         0.1225]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in physical security, I think.  That's what comes to mind; I deal with keeping things safe and secure.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1317, 0.1323, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess I'll call then. I am not really sure what else I can do.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1233, 0.1248, 0.1261, 0.1267, 0.1267, 0.1250, 0.1231, 0.1236,\n",
            "         0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1408, 0.1392, 0.1377, 0.1413]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1257, 0.1246, 0.1265, 0.1265, 0.1276, 0.1280, 0.1264, 0.1240, 0.1253,\n",
            "         0.1266]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1318, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1368, 0.1380]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1387, 0.1393]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1296, 0.1246, 0.1294, 0.1253, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1301, 0.1315, 0.1309, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1216, 0.1243, 0.1230, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1358, 0.1375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1319, 0.1301, 0.1289, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1275, 0.1263, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1229, 0.1251, 0.1254, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1223, 0.1244, 0.1224, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1380, 0.1390, 0.1410, 0.1396, 0.1406, 0.1402, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1264, 0.1270, 0.1286, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1309, 0.1314, 0.1278, 0.1279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess it's Partner, since that's the only option I have.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1352, 0.1337, 0.1335, 0.1365, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1270, 0.1289, 0.1277, 0.1254, 0.1281, 0.1274]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1287, 0.1278, 0.1259, 0.1274, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1366, 0.1373, 0.1365, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1354, 0.1359, 0.1378, 0.1365, 0.1379, 0.1382, 0.1347]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1283, 0.1271, 0.1268, 0.1269, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1261, 0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1360, 0.1357, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm not sure, but I guess I'm unsatisfied. I'd say that's the best fit.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1331, 0.1355, 0.1386, 0.1365, 0.1331]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1337, 0.1352, 0.1339, 0.1336, 0.1323, 0.1302, 0.1367, 0.1330, 0.1360,\n",
            "         0.1344, 0.1352, 0.1342, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1318, 0.1329, 0.1331, 0.1312, 0.1298, 0.1275, 0.1329, 0.1305, 0.1333,\n",
            "         0.1327, 0.1304, 0.1328, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1312, 0.1295, 0.1305]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1360, 0.1351, 0.1357, 0.1340, 0.1328, 0.1299, 0.1354, 0.1332, 0.1356,\n",
            "         0.1356, 0.1349, 0.1342, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1275, 0.1265, 0.1236, 0.1256, 0.1256]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1216, 0.1236, 0.1221, 0.1208, 0.1229, 0.1220]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a production company. That's the type I think it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1258, 0.1293, 0.1272, 0.1290, 0.1282, 0.1271, 0.1322]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1283, 0.1270, 0.1275, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1340, 0.1311, 0.1284, 0.1342, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1379, 0.1384, 0.1399, 0.1388, 0.1401, 0.1406, 0.1382]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1373, 0.1361, 0.1365, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1239, 0.1252, 0.1244, 0.1245, 0.1258, 0.1239]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I'm not really sure. I think it might be a trading company.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1266, 0.1252, 0.1256]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1277, 0.1266, 0.1268, 0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, the customer type is an 'Applicant'. That seems straightforward. I guess there weren't any other options.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1262, 0.1264, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1201, 0.1160, 0.1204, 0.1181, 0.1209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1358, 0.1326, 0.1341, 0.1346, 0.1356, 0.1327, 0.1331, 0.1349]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've used HubSpot before.  It seemed pretty good to me.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1372, 0.1388, 0.1370, 0.1379, 0.1363, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team is usually around 31-40 people, that's the average size I'd say.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1277, 0.1254, 0.1245, 0.1255, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well I guess I'm interested in MY-SYSTEM, Notion and also JTS. I don't know what else there is.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1371, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, I guess I would say yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1242, 0.1236, 0.1234, 0.1260, 0.1263, 0.1271, 0.1242, 0.1235, 0.1229,\n",
            "         0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1361, 0.1355, 0.1386, 0.1378, 0.1388, 0.1392, 0.1367]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1338, 0.1300, 0.1339, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1303, 0.1376, 0.1352, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, that's a good question. I guess we are larger than 2000, it is what feels right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1310, 0.1303, 0.1318, 0.1301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1334, 0.1305, 0.1312, 0.1324, 0.1326, 0.1310, 0.1296, 0.1331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1286, 0.1248, 0.1276, 0.1236, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1262, 0.1206, 0.1257, 0.1241, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1223, 0.1240, 0.1246, 0.1235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess you're looking for me to use Japanese. That's the only option, so Japanese it is!\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1296, 0.1292, 0.1284, 0.1294, 0.1294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1290, 0.1303, 0.1346, 0.1284, 0.1289]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd guess we have around 1000 employees.  I don't know the exact breakdown of sizes, like  201-2000 or any other ranges\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1380, 0.1368, 0.1361, 0.1397]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1271, 0.1268, 0.1265, 0.1286, 0.1288, 0.1284, 0.1267, 0.1263, 0.1254,\n",
            "         0.1284]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm working in Public Safety, or maybe Law Enforcement. I'm not really sure what the different options mean.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1347, 0.1351, 0.1335, 0.1322, 0.1291, 0.1352, 0.1331, 0.1342,\n",
            "         0.1348, 0.1333, 0.1341, 0.1338]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1299, 0.1308, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps I could call them, I guess? That's the only thing on my list.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1336, 0.1323, 0.1310, 0.1329, 0.1326, 0.1309, 0.1325, 0.1328]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it would be SAP Sales Cloud, I think I've heard of that one.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1331, 0.1335, 0.1312, 0.1348, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1345, 0.1358, 0.1385, 0.1394, 0.1336]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 100 employees.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1388, 0.1397]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1337, 0.1347, 0.1350]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1301, 0.1326, 0.1287, 0.1285, 0.1287]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1297, 0.1300, 0.1304]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1303, 0.1307, 0.1269, 0.1277]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1376, 0.1375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1241, 0.1261, 0.1232, 0.1238]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1331, 0.1310, 0.1271, 0.1322, 0.1320, 0.1300, 0.1310, 0.1305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not really sure which one that is. I guess maybe Close.io.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1200, 0.1274, 0.1231, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also high-speed interconnect testing, as that seems pretty important.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1452, 0.1431, 0.1422, 0.1464]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1327, 0.1298, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I'd say a meeting is what comes next.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1397, 0.1388, 0.1376, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1262, 0.1240, 0.1264, 0.1259, 0.1258]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1315, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1249, 0.1234, 0.1219, 0.1256, 0.1271, 0.1272, 0.1241, 0.1217, 0.1230,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I'm not really sure what to say here but I guess I'm in the network operators and infrastructure industry.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1358, 0.1364]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1376, 0.1386, 0.1378, 0.1386, 0.1376]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1293, 0.1278, 0.1282, 0.1285, 0.1304]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1280, 0.1274, 0.1265, 0.1228, 0.1266, 0.1260]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1324, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1285, 0.1288, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1244, 0.1272, 0.1250, 0.1248, 0.1262, 0.1256]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1319, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1253, 0.1238, 0.1252, 0.1264, 0.1274, 0.1283, 0.1260, 0.1236, 0.1248,\n",
            "         0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1341, 0.1350, 0.1339, 0.1317, 0.1300, 0.1354, 0.1325, 0.1342,\n",
            "         0.1346, 0.1332, 0.1332, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1297, 0.1274, 0.1267, 0.1276, 0.1297, 0.1268, 0.1276, 0.1301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what CRM systems are available, but I'd guess Microsoft Dynamics, since I've heard of that one.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1240, 0.1242, 0.1229, 0.1266, 0.1241]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1450, 0.1416, 0.1418, 0.1460]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1205, 0.1208, 0.1213, 0.1185, 0.1225, 0.1200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1367, 0.1377, 0.1451, 0.1422, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1285, 0.1258, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1295, 0.1272, 0.1248, 0.1303, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1354, 0.1362, 0.1359, 0.1383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1301, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1320, 0.1295, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1246, 0.1270, 0.1263, 0.1253, 0.1264, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1264, 0.1296, 0.1287, 0.1270, 0.1293, 0.1297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1397, 0.1405, 0.1402, 0.1436, 0.1386]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not really sure, I guess it's between 51 and 200.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1217, 0.1222, 0.1220, 0.1223]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1383, 0.1386, 0.1409, 0.1397, 0.1409, 0.1411, 0.1376]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1309, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1250, 0.1260, 0.1257, 0.1266, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1274, 0.1263, 0.1257, 0.1235, 0.1268]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1354, 0.1350, 0.1306, 0.1310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'd say Applicant, I'm not really sure what other kinds there are.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1315, 0.1292, 0.1316, 0.1318, 0.1306, 0.1305, 0.1337]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1322, 0.1322, 0.1326, 0.1318, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1338, 0.1313, 0.1282, 0.1329, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1238, 0.1232, 0.1262, 0.1262, 0.1266, 0.1245, 0.1242, 0.1236,\n",
            "         0.1255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I guess I'm operating in the Physical Security industry. That's the only one listed.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1235, 0.1241, 0.1254, 0.1263, 0.1225, 0.1251, 0.1264]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1326, 0.1304, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps? I'd say meeting, I guess.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1217, 0.1238, 0.1227, 0.1221, 0.1242, 0.1231]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1233, 0.1202, 0.1205, 0.1238, 0.1216]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1275, 0.1272, 0.1298, 0.1288, 0.1263, 0.1303]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1312, 0.1315, 0.1301, 0.1291]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1329, 0.1309, 0.1295, 0.1327, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1308, 0.1310, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1367, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1220, 0.1198, 0.1195, 0.1227, 0.1195]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1275, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step would be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1289, 0.1291, 0.1318, 0.1327, 0.1297, 0.1316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1339, 0.1376, 0.1368, 0.1322]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1387]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1192, 0.1165, 0.1220, 0.1193, 0.1218]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, and also display port debugging and compliance. I think those two are interesting.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1309, 0.1271, 0.1270, 0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1301, 0.1287, 0.1302, 0.1284, 0.1295]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1342, 0.1354, 0.1353, 0.1333, 0.1324, 0.1284, 0.1349, 0.1320, 0.1357,\n",
            "         0.1353, 0.1338, 0.1341, 0.1339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1317]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what options there are. I would say no for the data processing consent.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1271, 0.1261, 0.1249, 0.1280, 0.1276, 0.1268, 0.1292]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1261, 0.1275, 0.1277, 0.1256, 0.1212, 0.1255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1237, 0.1250, 0.1237, 0.1236, 0.1239, 0.1240]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1346, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh gosh, do you mean yes or no for data processing consent? I guess, yeah I'll say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1249, 0.1229, 0.1202, 0.1249, 0.1240, 0.1242, 0.1248]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1304, 0.1302, 0.1282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I should call someone.  That seems like the next best step.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1315, 0.1329, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1279, 0.1280, 0.1303, 0.1309, 0.1314, 0.1295, 0.1269, 0.1269,\n",
            "         0.1300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1293, 0.1283, 0.1304, 0.1285, 0.1262, 0.1306]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1354, 0.1368, 0.1346, 0.1324, 0.1298, 0.1371, 0.1336, 0.1357,\n",
            "         0.1366, 0.1332, 0.1356, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1223, 0.1223, 0.1256, 0.1250, 0.1254, 0.1237, 0.1213, 0.1229,\n",
            "         0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.1239, 0.1254, 0.1269, 0.1274, 0.1271, 0.1255, 0.1235, 0.1240,\n",
            "         0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1217, 0.1232, 0.1206, 0.1210, 0.1210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1351]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1256, 0.1242, 0.1283, 0.1285, 0.1260, 0.1275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1272, 0.1299, 0.1295, 0.1300, 0.1300, 0.1290, 0.1324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Okay, so a CRM-System? Hmm, I guess that could be something like Salesforce, if that's what you mean. I'm not too sure about other possibilities, to be honest.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1319, 0.1306, 0.1327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I guess the next step should be a meeting.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1403, 0.1394, 0.1389, 0.1420]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction? I'd say, I guess, I'm satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1217, 0.1173, 0.1237, 0.1192, 0.1206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and high-speed interconnect testing,  as that seems important too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1314, 0.1301, 0.1323, 0.1290]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1236, 0.1193, 0.1211, 0.1227, 0.1208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1292, 0.1291, 0.1302, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1265, 0.1272, 0.1281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1186, 0.1164, 0.1226, 0.1204, 0.1222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1300, 0.1226, 0.1308, 0.1265, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1194, 0.1226, 0.1208, 0.1183, 0.1211, 0.1200]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1304, 0.1291, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh gosh I guess a meeting is next then, seems logical to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1351, 0.1377, 0.1322, 0.1344, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1188, 0.1168, 0.1218, 0.1159, 0.1203]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because understanding signal quality is important, and display port debugging and compliance,  to ensure proper functionality.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1374, 0.1379, 0.1396, 0.1380, 0.1387, 0.1391, 0.1357]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1233, 0.1234, 0.1215, 0.1252, 0.1257, 0.1258, 0.1233, 0.1230, 0.1227,\n",
            "         0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1382, 0.1392, 0.1426, 0.1426, 0.1378]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow I honestly don't know all the details, but we're probably between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1243, 0.1231, 0.1219, 0.1256, 0.1260, 0.1259, 0.1240, 0.1218, 0.1228,\n",
            "         0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations and infrastructure.  That's what I do; I handle the networks and their underlying systems.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1270, 0.1279, 0.1283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1230, 0.1232, 0.1199, 0.1240, 0.1255, 0.1248, 0.1224, 0.1219, 0.1220,\n",
            "         0.1255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1237, 0.1227, 0.1257, 0.1217, 0.1249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1271, 0.1270, 0.1279, 0.1260, 0.1224, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1311, 0.1332, 0.1288, 0.1310, 0.1302]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1417, 0.1430]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1275, 0.1261, 0.1249, 0.1281, 0.1265, 0.1261, 0.1287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, huh. I guess that would be End User then.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1195, 0.1184, 0.1224, 0.1185, 0.1205]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1209, 0.1244, 0.1259, 0.1227]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1405]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to data processing.  I don't know what other options there might be.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.1291, 0.1270, 0.1281, 0.1284, 0.1292]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1223, 0.1227, 0.1252, 0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Existing customer', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1307, 0.1302, 0.1307, 0.1294, 0.1327, 0.1310]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm I think it's a craft enterprise company, I don't know all the options available though.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I guess I'd say yes then, since that seems to be the option here.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1282, 0.1266, 0.1247, 0.1295, 0.1291, 0.1250, 0.1279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1374, 0.1376, 0.1397, 0.1386, 0.1398, 0.1403, 0.1362]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1344]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1413, 0.1384, 0.1397, 0.1371, 0.1373, 0.1356, 0.1399, 0.1371, 0.1391,\n",
            "         0.1408, 0.1389, 0.1391, 0.1391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1296, 0.1289, 0.1266, 0.1235, 0.1281]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1276, 0.1264, 0.1265, 0.1218, 0.1254]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1242, 0.1232, 0.1264, 0.1271, 0.1267, 0.1241, 0.1225, 0.1238,\n",
            "         0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I guess.  That's what I think it's called; I handle the infrastructure side of things.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1319, 0.1276, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, well I suppose I'd say a new customer then. I really have no other information about this.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1180, 0.1213, 0.1193, 0.1196, 0.1213, 0.1194]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1322, 0.1334, 0.1306, 0.1321, 0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1268, 0.1261, 0.1251, 0.1234, 0.1259]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1307, 0.1304, 0.1320, 0.1330, 0.1310, 0.1319, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think maybe it's SAP Sales Cloud, that sounds right for a CRM system to me.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1352, 0.1369, 0.1405, 0.1407, 0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1334, 0.1345, 0.1404, 0.1378, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1308, 0.1286, 0.1302, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1305, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in a week, I think.  I don't know what other options there are.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1309, 0.1314, 0.1331, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1261, 0.1311, 0.1257, 0.1286, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1337, 0.1342, 0.1399, 0.1364, 0.1319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1370, 0.1372, 0.1393, 0.1383, 0.1393, 0.1397, 0.1363]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I would say it's probably around 25 people for the team, if I had to guess.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1206, 0.1216, 0.1206, 0.1192, 0.1222, 0.1209]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1340, 0.1346, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1312, 0.1265, 0.1285, 0.1303, 0.1314, 0.1285, 0.1289, 0.1312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1371, 0.1395, 0.1433, 0.1407, 0.1376]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I'm not sure of the exact options but I'd guess our company is between 1 and 10 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1270, 0.1261, 0.1289, 0.1272, 0.1275]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1342, 0.1334, 0.1338, 0.1369]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I suppose I'd have to say I'm satisfied. I'm not sure if there are other options, but that works for me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1353, 0.1335, 0.1340, 0.1378]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1387, 0.1357, 0.1357, 0.1402]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1380, 0.1377, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1245, 0.1225, 0.1230, 0.1236, 0.1240]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1289, 0.1321, 0.1288, 0.1298, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I think I would search for a solution to clean up the CRM or maybe to improve CRM data quality.\n",
            "The intended answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1242, 0.1219, 0.1214, 0.1223, 0.1226]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1329, 0.1318, 0.1303, 0.1331, 0.1324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1279, 0.1311, 0.1276, 0.1290, 0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1247, 0.1226, 0.1230, 0.1264, 0.1243]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1383, 0.1385, 0.1392, 0.1390]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1305, 0.1312, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1260, 0.1206, 0.1258, 0.1238, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1319, 0.1281, 0.1322, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1291, 0.1271, 0.1270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1276, 0.1260, 0.1259, 0.1257, 0.1290, 0.1251, 0.1252, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1357, 0.1347, 0.1354, 0.1377]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Hmm, customer satisfaction. I'd say, like, I am very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1296, 0.1299, 0.1286, 0.1271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1302, 0.1286, 0.1272, 0.1298, 0.1298, 0.1269, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1176, 0.1180, 0.1173, 0.1195, 0.1193, 0.1206, 0.1172, 0.1196, 0.1155,\n",
            "         0.1184]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1273, 0.1245, 0.1244, 0.1251, 0.1259, 0.1241, 0.1249, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: For a CRM system, I've heard of Pipedrive, which is supposed to be good. Is there anything else, though?\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1347, 0.1325, 0.1327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1310, 0.1326, 0.1304, 0.1293, 0.1282, 0.1330, 0.1297, 0.1315,\n",
            "         0.1329, 0.1312, 0.1314, 0.1315]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1283, 0.1254, 0.1274, 0.1271, 0.1278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1338, 0.1352, 0.1378, 0.1384, 0.1325]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1307, 0.1339, 0.1298, 0.1316, 0.1311]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1282, 0.1288, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1363, 0.1384, 0.1412, 0.1426, 0.1347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1360]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1278, 0.1247, 0.1264, 0.1258, 0.1251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1332, 0.1337, 0.1338, 0.1350, 0.1367, 0.1365, 0.1339]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I really dont know but if i had to guess it's probably around 12 people on average, it could also be in the 11-15 range I suppose.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1333, 0.1354, 0.1394, 0.1372, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1287, 0.1292, 0.1337, 0.1317, 0.1292]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1348, 0.1364, 0.1343, 0.1335, 0.1326, 0.1292, 0.1367, 0.1325, 0.1360,\n",
            "         0.1358, 0.1323, 0.1348, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1294, 0.1357, 0.1298, 0.1324, 0.1336]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1288, 0.1319, 0.1402, 0.1344, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1317, 0.1290, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1290, 0.1268, 0.1263, 0.1299, 0.1310, 0.1262, 0.1266]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it is R&D because it makes the most sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1315, 0.1324, 0.1306, 0.1294, 0.1256, 0.1316, 0.1303, 0.1317,\n",
            "         0.1323, 0.1311, 0.1311, 0.1307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1250, 0.1214, 0.1236, 0.1220, 0.1222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1234, 0.1223, 0.1230, 0.1250, 0.1261, 0.1258, 0.1233, 0.1212, 0.1215,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not sure what all the industries are but I think I work in public safety or law enforcement, I guess.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1258, 0.1283, 0.1247, 0.1268, 0.1252]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1295, 0.1297, 0.1296]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I'm not really sure but I guess they'd like to follow up in 3 weeks.\n",
            "The intended answer was: ['3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1265, 0.1268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1334, 0.1286, 0.1304, 0.1308, 0.1318, 0.1300, 0.1312, 0.1334]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Well, for a CRM system, I'd recommend HubSpot, it’s a popular choice.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1237, 0.1242, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'm happy to follow up! It could be in **2 weeks** or maybe in **3 weeks**. Which timing is best for you?\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1267, 0.1259, 0.1285, 0.1234, 0.1257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1276, 0.1256, 0.1270, 0.1261, 0.1271]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1226, 0.1207, 0.1216, 0.1194, 0.1211]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1354, 0.1308, 0.1335, 0.1321]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1266, 0.1254, 0.1242, 0.1264, 0.1251]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1234, 0.1235, 0.1230, 0.1217, 0.1249, 0.1229]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, well I believe it's a construction company. Yeah, that makes sense to me.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1308, 0.1290, 0.1310, 0.1315, 0.1314]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1294, 0.1273, 0.1260, 0.1290, 0.1305, 0.1279, 0.1283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what groups there are but I think it's probably a wholesaler.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1396, 0.1399]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1292, 0.1253, 0.1266, 0.1290, 0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1324, 0.1288, 0.1301, 0.1312, 0.1317, 0.1295, 0.1302, 0.1314]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. Hmm, I guess I'd say HubSpot. That's the only one I can really think of right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1313, 0.1332]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1265, 0.1253, 0.1254, 0.1221, 0.1245]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1381, 0.1379]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1325, 0.1307, 0.1333, 0.1341, 0.1313, 0.1340]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1280, 0.1275, 0.1285, 0.1297, 0.1308, 0.1313, 0.1279, 0.1256, 0.1273,\n",
            "         0.1305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1360, 0.1374, 0.1345, 0.1355, 0.1353]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1345, 0.1375, 0.1369, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1320, 0.1314, 0.1312, 0.1343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, I would have to say that I am unsatisfied. I guess that's my feeling right now.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1254, 0.1280, 0.1270, 0.1273, 0.1262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1315, 0.1298, 0.1332, 0.1329, 0.1282, 0.1323]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1204, 0.1200, 0.1236, 0.1188, 0.1221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I am interested in both noise figure measurements and display port debugging and compliance, they seem interesting to me.\n",
            "The intended answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1283, 0.1275, 0.1271, 0.1300, 0.1305, 0.1302, 0.1270, 0.1265, 0.1275,\n",
            "         0.1298]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1293, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think the next step is a meeting, to discuss everything further.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1285, 0.1270, 0.1248, 0.1294, 0.1287, 0.1262, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1423, 0.1400, 0.1434, 0.1437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1300, 0.1320, 0.1356, 0.1335, 0.1283]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I really don't know the exact size. Hmm, is it like larger than 2000? I'm guessing that might be right.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1284, 0.1335, 0.1269, 0.1299, 0.1269]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1391, 0.1361, 0.1367]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1210, 0.1208, 0.1246, 0.1206, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1324, 0.1315, 0.1288, 0.1303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, hmm, I guess I would be an existing customer. I think that's the option that makes the most sense for me.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1339, 0.1342, 0.1348, 0.1307]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1319, 0.1326, 0.1310, 0.1352, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1282, 0.1279, 0.1273, 0.1261, 0.1225, 0.1255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1253, 0.1266, 0.1260, 0.1227, 0.1272, 0.1254]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1350, 0.1325, 0.1281, 0.1358, 0.1365, 0.1346, 0.1348]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh I think it would be distributor, that sounds right for this.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Planner\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.1325, 0.1301, 0.1322, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1359, 0.1370, 0.1365, 0.1398, 0.1359]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, our company size is 51-200 people. That's the only size range I'm aware of, so we must fit into that category.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1275, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh, well I guess next steps would be a meeting then.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1351, 0.1354, 0.1366, 0.1334, 0.1328, 0.1304, 0.1358, 0.1327, 0.1349,\n",
            "         0.1362, 0.1350, 0.1331, 0.1356]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1242, 0.1247, 0.1243, 0.1260, 0.1268, 0.1268, 0.1244, 0.1238, 0.1240,\n",
            "         0.1261]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm working in the Computers & Networks area. I suppose that fits with what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1365, 0.1381, 0.1370, 0.1379, 0.1382, 0.1352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say the trade fair team is usually around 45 people.  I'm not sure what other sizes are possible.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1303, 0.1291, 0.1300, 0.1340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction, well, I would say, just based on what's there, that they are satisfied. I mean that seems pretty clear to me.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1298, 0.1302, 0.1277, 0.1279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1268, 0.1238, 0.1245, 0.1213, 0.1194, 0.1224]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1395, 0.1361, 0.1339, 0.1373, 0.1374, 0.1351, 0.1360, 0.1356]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1278, 0.1302, 0.1273, 0.1302, 0.1288, 0.1299]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1311, 0.1296, 0.1289, 0.1312, 0.1304]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1232, 0.1236, 0.1223, 0.1231]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1372, 0.1393, 0.1379, 0.1411, 0.1385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1259, 0.1248, 0.1253, 0.1235, 0.1246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1291, 0.1297, 0.1316, 0.1295, 0.1276, 0.1236, 0.1323, 0.1277, 0.1309,\n",
            "         0.1310, 0.1279, 0.1295, 0.1306]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1269, 0.1237, 0.1250, 0.1227, 0.1213, 0.1233]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I guess they might be into 256 joining systems for large components, or something else, like maybe something different.\n",
            "The intended answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1257, 0.1279, 0.1240, 0.1260, 0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1372, 0.1361, 0.1368, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say very satisfied. That seems like the best option to describe it.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1337, 0.1295, 0.1304, 0.1323, 0.1326, 0.1313, 0.1318, 0.1300]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1255, 0.1263, 0.1246, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1343, 0.1330, 0.1352]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Oh um, I guess the next step would probably be meeting, yeah.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1248, 0.1242, 0.1245, 0.1266, 0.1263, 0.1286, 0.1236, 0.1229, 0.1236,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1312, 0.1327, 0.1294, 0.1314, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1274, 0.1279, 0.1264, 0.1294, 0.1306, 0.1301, 0.1277, 0.1264, 0.1276,\n",
            "         0.1295]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1293, 0.1307, 0.1304, 0.1304, 0.1300, 0.1319]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1332, 0.1339, 0.1429, 0.1367, 0.1323]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1330, 0.1300, 0.1300, 0.1318, 0.1330, 0.1302, 0.1312, 0.1333]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, a CRM system? Hmm, I'd probably say Microsoft Dynamics. I've heard of it.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1297, 0.1276, 0.1264, 0.1316, 0.1303, 0.1238, 0.1321]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1341, 0.1350, 0.1360, 0.1331, 0.1318, 0.1295, 0.1368, 0.1317, 0.1357,\n",
            "         0.1358, 0.1343, 0.1333, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1244, 0.1205, 0.1245, 0.1206, 0.1235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'New customer / Prospect']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1212, 0.1250, 0.1251, 0.1236]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1239, 0.1231, 0.1226, 0.1253, 0.1263, 0.1256, 0.1236, 0.1225, 0.1235,\n",
            "         0.1260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1286, 0.1302, 0.1278, 0.1312, 0.1310, 0.1307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1272, 0.1330, 0.1271, 0.1304, 0.1276]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1346, 0.1348, 0.1365, 0.1353, 0.1366, 0.1371, 0.1338]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 25 people.  I don't know what the other options are, but that's my best estimate for the average size of a trade fair team.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1269, 0.1231, 0.1260, 0.1271, 0.1233]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Existing customer', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1263, 0.1264, 0.1253, 0.1289, 0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1362, 0.1347, 0.1345]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1245, 0.1268, 0.1252, 0.1221, 0.1268, 0.1239]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1218, 0.1198, 0.1201, 0.1201, 0.1214]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Existing customer', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1238, 0.1233, 0.1229, 0.1256, 0.1261, 0.1259, 0.1238, 0.1226, 0.1228,\n",
            "         0.1250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the computer and networks industry.  That's what I do.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1283, 0.1254, 0.1263, 0.1275, 0.1272, 0.1252, 0.1261, 0.1276]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Salesforce\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1209, 0.1217, 0.1207, 0.1199, 0.1224, 0.1202]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1267, 0.1281, 0.1268, 0.1299, 0.1275, 0.1284]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1347, 0.1337, 0.1329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, I'd say I should probably call.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.1232, 0.1237, 0.1238, 0.1211, 0.1246, 0.1221]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, a company, hmm. I guess it must be a scaffolding company. I'm not really sure though, sorry.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1321, 0.1324, 0.1340, 0.1326, 0.1336, 0.1340, 0.1308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1485, 0.1474]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1267, 0.1253, 0.1247, 0.1248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1345, 0.1356, 0.1337, 0.1352, 0.1330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6yiEOdGgZefe",
        "outputId": "149f60fc-6554-4c9e-907d-2de108341ca5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "FacebookAI/roberta-base: {'accuracy': 0.575687185443283, 'f1': 0.27989487516425754, 'precision': 0.3075812274368231, 'recall': 0.25678119349005424}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks way worse\n",
        "\n",
        "\n",
        "```\n",
        "{'accuracy': 0.575687185443283, 'f1': 0.27989487516425754, 'precision': 0.3075812274368231, 'recall': 0.25678119349005424}\n",
        "```\n"
      ],
      "metadata": {
        "id": "OET9-ceO9PfY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ALBERT base version 2"
      ],
      "metadata": {
        "id": "18XXEvw9fGFL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"albert/albert-base-v2\"\n",
        "mc_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "mc_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233,
          "referenced_widgets": [
            "a16df523eaf94f76b2ac1e07b44c1bb2",
            "63ac4b190935457e9a2208435dcac6ed",
            "33b40819120b4ec6abf387d54b241e2e",
            "30a7895eff374ccba813f0a6e7ee6412",
            "f610fc7112f9417fbca1a5b40ab052fc",
            "f118ae65c9d34c5b89688c56e7bc9d11",
            "581fbefcc6234c3d9d85d0ccc7f44ecb",
            "38616febf684434c99cd6e36c93086b6",
            "ec9d849c33784b118e906435de5c20b0",
            "9908716e59a349a282594e49e7a923cd",
            "efcc6ff9f0b3407dbd9f7bc8b1439bcf",
            "7f58c1164d1142478968257d7936123e",
            "866ebc4490c64d1d8e132bfa23b5449c",
            "7d19a7184cb74e6fa3c1b302d11e3977",
            "954c563eca1f49e89cc31ab1053a90ee",
            "733972cc6fc645c4bde46213ce994139",
            "4c1dbeff9dff4225b10581622da91ce7",
            "50d3fd723e4f49c8ada234dcc7e41608",
            "c49842ee1bde4670a7c5a30d44ebc785",
            "5cca4728d31f4bbe88250f62de0de2bf",
            "0409901b030c4b499dc27937d52b9216",
            "e8b3eb8f868749418a3643ee354a168c",
            "9858c3d7d4584d3dbaf6e3fce07d6022",
            "01ed020d255b4493b68909b4f68c3919",
            "ea0abb6b4eec4052a6b29e7c2a820740",
            "ef9e7f3990cf47ac813268ec18666845",
            "1af9a5744f1d482db336a7ba7434b8e8",
            "e40214daa9474f25a3485d8372ef6890",
            "6d7b70771e0f40b7bc2c80387e3e40b5",
            "9491bcd4bd634d2da4eae5be751f883c",
            "6e80adcc785d4f91be7f7c5631922238",
            "202f2b58dba340848f6127e8e4135447",
            "b642f48df26648699450f61b56af37ae",
            "869473187683442ebe0ae6111bb8dc96",
            "70dce515a1c44780a3b3fce7177db3ec",
            "3165b3ad4ab7405baedbd1a2a3d31be6",
            "de49c1b6de0a4328992d59c951c4b754",
            "3c75e550e7b74d37934bc2fff08b2cb8",
            "53b23cecfd354ccf8548f8de6c3bc1ab",
            "925163e9ae1745fe9ad7167c09cf29cc",
            "a9bf97a9e3a84c94be32797a8ddd389b",
            "f534404ee49e46f8b1aee58911443255",
            "b1277da6f76344ec8e3e13f89f938c10",
            "9ce1a17fbf2d4bbf86c087c591e53848",
            "5333de9228684fcfa067d67443339d41",
            "565fd76ff65249e284c69efa5ce62cc8",
            "09cb3af7e3fe4f6db9c0e3eb4c23ddaf",
            "f33286a085fa4c12a17ce40588e7e462",
            "2b71f4d6c758424099e4ba0cbf6a9b54",
            "83d6bc16da0f4e89aa9072b705a55684",
            "9b56361ccd8246bb87b049414f646354",
            "2072c72b679443b0aefe2fd109236464",
            "e3bd7434bc0c4d778beaa78bb2711401",
            "b42b112574a347c7b6cfecc31b5821ca",
            "ec59251d22ed4b12a2ec362b6f0fa27b"
          ]
        },
        "id": "kmQGokiufEzu",
        "outputId": "8277de30-2376-4d6d-ca25-fa2a856ea4fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a16df523eaf94f76b2ac1e07b44c1bb2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7f58c1164d1142478968257d7936123e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9858c3d7d4584d3dbaf6e3fce07d6022"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "869473187683442ebe0ae6111bb8dc96"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5333de9228684fcfa067d67443339d41"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(mc_model, mc_tokenizer, oe_model, oe_tokenizer, mc_train_qa_dataset, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7_3SOSGjgXqk",
        "outputId": "d07658f1-f1b4-4f72-b424-5cab36f99293"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000 Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I guess.  I don't know what other languages were offered, but Japanese is what comes to mind.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1016, 0.2867, 0.1963, 0.1779, 0.2825]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a Supplier, or maybe a New customer or Prospect. It might even be Press or media. Could it also be a Competitor. I don't know, maybe it's any of\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0455,  0.3812,  0.1180,  0.0571,  0.3784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. I guess it's either an existing customer or press media, probably something along those lines.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.3279,  0.1339, -0.1067, -0.0878, -0.1434, -0.0567,  0.3969]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess it would be Wholesaler. That seems like the best fit.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4180, 0.4699, 0.3726, 0.4043, 0.3988, 0.2854, 0.3889, 0.3680, 0.3039,\n",
            "         0.3802, 0.3572, 0.3730, 0.3685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Erik Schneider, Angelina Haug, Johannes Wagner, Jens Roschmann, Domiki Stein, and Tim Persson;  I think they all need to be kept in the loop.\n",
            "The intended answer was: ['Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Angelina Haug']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1311,  0.1665,  0.1309, -0.0326,  0.0312,  0.0541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh gosh, I'm not really sure. Maybe they like the 200 Automation, or maybe the 300 Advanced Manufacturing stuff? There's also 234 Assembly Systems and 256 Joining Systems\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0312, -0.0675, -0.1173, -0.1084, -0.1284,  0.1815, -0.0853, -0.0288]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, I'm not really sure which CRM system that is. I guess I'd say HubSpot.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2554, 0.2964, 0.1517, 0.2976]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think it will be an email. Maybe no action is the other option, but I am not sure.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1553, 0.2065, 0.2422, 0.2330, 0.2362, 0.2664, 0.1981]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1873, 0.1431, 0.1757, 0.1498, 0.1752, 0.1407]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I guess it's an education sector company then, that makes sense.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2394, 0.2893, 0.1168, 0.1765]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1699, 0.1981, 0.1124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, next steps, hmm... I guess I could *Call*. That seems like a reasonable thing to do next.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0847,  0.2531,  0.0493,  0.0826,  0.0742,  0.1379,  0.0833,  0.1121,\n",
            "         -0.0244, -0.0250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I guess I'm operating in the industrial area then, that's the one I know of.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1628, 0.2648, 0.3136]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in about ten days, I think.  That's between a week and two weeks.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1708, 0.1730, 0.1753, 0.1853, 0.1822, 0.1962]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, it's a production company. That means they probably make movies, TV shows, or something similar.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2855, 0.3106, 0.0796, 0.1598]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either send an email or do nothing further.  I'm not privy to the exact plan.\n",
            "The intended answer was: ['Email', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1955, 0.3343, 0.1349, 0.1237, 0.2305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation and high-speed interconnect testing. Those seem pretty cool, I think.\n",
            "The intended answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2517, 0.2622, 0.1364, 0.2874, 0.1893, 0.2937]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine and the AX100,  I think those sound pretty good.\n",
            "The intended answer was: ['JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0882,  0.1865,  0.0353,  0.0420, -0.0107]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, I'm interested in automotive radar target simulation, and double pulse testing seems good too.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1930, 0.2139, 0.3007, 0.2746, 0.0893]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, I'm not sure. Is it something like 25 maybe? I'd guess somewhere in that range, but I don't really know.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1941, 0.1918, 0.2042, 0.2512, 0.2369, 0.1649, 0.0800, 0.1626]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. I guess I'd go with Close.io, I think that's what it's called.\n",
            "The intended answer was: Close.io\n",
            "The predicted answer was: Microsoft Dynamics\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2191, 0.1346]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I'd rather not receive marketing emails.  I don't want my inbox cluttered.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1711,  0.0505, -0.0054,  0.1569,  0.1496]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well, I guess I'd pick \"Clean up CRM\" and \"Capture trade fair contacts\", if those are the only options available. I don't know the other ones.\n",
            "The intended answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1508, 0.0154, 0.0224, 0.0287, 0.0235]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2414, 0.2329, 0.4302, 0.4961]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I think the customer type is Partner, I'm not sure what else there could be.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4300, 0.4222, 0.4197]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, so for the follow up, I think either **2 weeks** or **3 weeks** would work; they seem to be the options I have to choose from.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.0324, 0.2767, 0.1874, 0.1816, 0.2282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a supplier, maybe even press or media.  I'm not sure,  it could be either one.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2193, 0.2534, 0.1970, 0.3207, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that can help me with several things: clean up the CRM, extract data from emails, and also capture trade fair contacts.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0106,  0.0279,  0.1050, -0.0407,  0.1215,  0.1404]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh wow, that's interesting, let's see. Well, it seems they're interested in things like 100 Additive Manufacturing and then 300 Advanced Manufacturing too, plus 256 Joining Systems\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3340, 0.3093, 0.3483, 0.5100, 0.4903, 0.3308]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in automation systems, maybe around 220 units,  and possibly assembly and joining systems for big parts.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1805,  0.3029,  0.1402, -0.0231,  0.2629]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer,  but it could also be a new customer or prospect, or maybe even press or media; I really don't know.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0300, -0.0303]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not sure what the options are, but I'd say no to that.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1453, 0.3319, 0.2130, 0.1903, 0.1737]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation. Also double-pulse testing seems intriguing. I would explore display port debugging and compliance too, plus high-speed interconnect testing is definitely up my alley.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3761, 0.2601, 0.3120, 0.1875, 0.2614, 0.2493]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and JS EcoLine, those are the ones I like.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0312, -0.0064]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, yes, I guess I would like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.0102, -0.0271, -0.0025, -0.0344, -0.0180]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh gosh, I'm not really sure what you mean, but I guess English is okay.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0374,  0.0997, -0.0241, -0.0705,  0.4122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3141, 0.3419, 0.3626, 0.3406, 0.2506, 0.2887, 0.3668, 0.3289, 0.3318,\n",
            "         0.3434, 0.3757, 0.3240, 0.3532]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I think I should copy Stephan Maier, Joachim Wagner, Oliver Eibel, Sandro Kalter and Tim Persson. Those seem like the people I'm supposed to follow up with.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Sandro Kalter', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0036, -0.0972,  0.0360,  0.0278, -0.1070, -0.0450,  0.1300,  0.2186]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess Salesforce is what I would go with.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0690, 0.1137, 0.0941]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1483, 0.0089]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like that actually.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3791, 0.3604, 0.4792, 0.4741, 0.3669, 0.2003]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in advanced manufacturing, maybe something around 280 components or joining systems for large parts, or something else entirely.\n",
            "The intended answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1572, 0.3019, 0.3812, 0.3467, 0.3985]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2165, 0.1737, 0.1986, 0.1596, 0.2299, 0.1371, 0.2043, 0.2357, 0.2432,\n",
            "         0.2185, 0.2257, 0.2019, 0.2443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'm not sure who to copy exactly. I guess it would be Joachim Wagner, or maybe Erik Schneider, possibly Oliver Eibel, maybe Johannes Wagner, perhaps Sean Kennin or Tim Persson, but I don\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4712, 0.4561, 0.4630, 0.4573, 0.5014, 0.4942, 0.4898]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, on average, I think the trade fair team would be more than 40 people, so something around that number sounds right.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3402, 0.3480, 0.4714, 0.3657, 0.4531, 0.3000, 0.3876, 0.3054, 0.3681,\n",
            "         0.3501, 0.4410, 0.4145, 0.3222]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner, Jessica Hanke, and Tim Persson;  they all need to be in the loop on this follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Angelina Haug', 'Domiki Stein', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1975, -0.1395, -0.0162, -0.1169]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure what the options are, but I think we'll just send a quick email to check in.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1240, 0.2997, 0.1630, 0.3460, 0.2712]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe a supplier.  I'm not sure which it is.\n",
            "The intended answer was: ['Existing customer', 'Supplier']\n",
            "The predicted answer was: ['Supplier', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3044, 0.3526, 0.3079, 0.3633, 0.3440, 0.3976]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either the '300 Advanced Manufacturing' program or 'Others'. I'm not sure which specifically though, just one of those two.\n",
            "The intended answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.0165,  0.0610, -0.0650, -0.1150,  0.0497]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm not sure but maybe we need to scan business cards or clean up CRM. Perhaps we could improve CRM data quality or capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0455, 0.0442]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0754,  0.0288,  0.1858,  0.1242, -0.0093]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, for product interests, I'm considering a 'VisitReport' tool. Also 'Data Cleansing' sounds useful, and something to ensure 'DataQuality' is also intriguing.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3237, 0.2829, 0.1987, 0.1847, 0.2094, 0.3251]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, JTS, and maybe JS EcoLine or AX100; I haven't looked into those last two much yet.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2098, 0.0665, 0.0837, 0.1965, 0.0614, 0.1233, 0.3286]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think the customer group might be an Architect. I mean, that's the only option I see right now.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3264, 0.2600, 0.3389, 0.3329, 0.3277, 0.3347, 0.3354, 0.3061, 0.2710,\n",
            "         0.2209]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'd say I operate in the Network Operators & Infrastructure industry. That seems to be the area I'm working within.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2921, 0.2419, 0.2664, 0.2178, 0.2468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um I guess I'd want to use English then, if that's what we're going with.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0660, 0.1005, 0.2655, 0.3420]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, for follow up, it could be an Email, maybe a Phone call, or we could Schedule a Visit. Or perhaps, No action is needed at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1554, 0.3098, 0.0780, 0.0981, 0.0920, 0.1822, 0.1051, 0.4198, 0.1423,\n",
            "         0.1328]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2153, 0.1619]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2289, 0.2424, 0.3477, 0.2919, 0.1927]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I'm not entirely sure of the company's exact size. If I had to guess, I'd say it's somewhere between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1590,  0.0113,  0.0305,  0.1513,  0.2234, -0.2808,  0.1265,  0.0438]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think the answer is CAS, though I'm not sure what other options there might be.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2853, 0.2481, 0.2481, 0.3146, 0.3278]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0972, 0.1613, 0.1730, 0.1413, 0.1686, 0.1739, 0.1259]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, I'm not sure but I guess between 21 and 30 people usually go.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1334, -0.0470, -0.1411, -0.0102, -0.1679]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not really sure but maybe something like VisitReport or Data Cleansing seems like what I would like.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0595, 0.2895, 0.2256, 0.2495, 0.2963]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so the contact could be a *Supplier*, someone who provides us with goods or services. It could also be a *New customer / Prospect*, which is someone we hope to do business with, or maybe even a *Competitor*.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3672, 0.3661, 0.2584, 0.3716]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, the follow up could be a **phone** call, or there might be **no action** taken at all. I'm not sure which will happen.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone', 'No action']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.0710, 0.1277, 0.1504, 0.3124, 0.3152]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, hmm, well, I am interested in automotive radar target simulation. And also double-pulse testing, display port debugging and compliance, and high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1520, 0.1237, 0.0665, 0.0298, 0.1737, 0.1979]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, well I'm interested in Notion, JTS, JS EcoLine, and also AKW100. That's everything I'm thinking about right now.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2150,  0.1788,  0.0867, -0.0310]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3300, 0.3069, 0.3875]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2025, 0.1520, 0.1797, 0.1555, 0.1734]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I think Italian is a good one. I'd be fine using that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1420,  0.0507, -0.0916,  0.0283,  0.1046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'd say it's like, to extract data from emails, or maybe improve CRM data quality, and capture trade fair contacts, I'm not sure.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0897, 0.0908]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess if there are options I would have to pick yes then.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2263, 0.3012, 0.2901, 0.3455, 0.2899, 0.2740, 0.3256, 0.3100, 0.2797,\n",
            "         0.3491, 0.4333, 0.2483, 0.3502]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Well I guess I should copy Joachim Wagner, Erik Schneider, Marisa Peng, Johannes Wagner, Jens Roschmann, and also Tim Persson. That seems like everyone.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Oliver Eibel', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3936, 0.3582, 0.3745, 0.3885, 0.4059, 0.3674, 0.3120]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of a trade fair team? I guess it's like maybe 3 people. That seems about right to me.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3058, 0.3060, 0.3535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think they want a follow up in 1 week or maybe 2 weeks, I'm not totally sure.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0735, -0.0085, -0.0289, -0.1206, -0.0866,  0.0662, -0.1405,  0.0342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not familiar with different CRM systems, but if I had to pick one, I'd say Adito.  That's just a guess, though.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4465, 0.4558, 0.4460, 0.4160, 0.4080, 0.3884, 0.4028, 0.4183, 0.3792,\n",
            "         0.3967, 0.3707, 0.4425, 0.3653]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Angelina Haug, Johannes Wagner, Sandro Kalter, and Domiki Stein; they all need to know about the follow-up.\n",
            "The intended answer was: ['Angelina Haug', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Erik Schneider', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0464, -0.0224, -0.0083,  0.1386, -0.0584,  0.0287]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well I'm interested in MY-SYSTEM, Notion, JS EcoLine, and also AX100, I think. Yeah those are it.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2702, 0.2969, 0.3114]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well, they could want a follow up in one week, maybe two weeks, or even three weeks, I guess it's one of those.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1494, 0.1399, 0.1626, 0.2969, 0.1795, 0.3747, 0.1426]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm I guess the customer group would be end user then, that seems about right.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3462, 0.0812, 0.3191, 0.3313, 0.3474, 0.2975, 0.3393, 0.1888, 0.3104,\n",
            "         0.3242]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I'm thinking I'd have to say I operate in the defense industry.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3903, 0.3214, 0.4396, 0.3360, 0.4409, 0.3167, 0.4199, 0.2949, 0.3164,\n",
            "         0.3467, 0.3036, 0.3639, 0.3251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow-up, I'd say copy Joachim Wagner, Oliver Eibel, Jessica Hanke, Sandro Kalter, and Domiki Stein. Just include all of them to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Oliver Eibel', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3585, 0.4197, 0.4489, 0.3918, 0.3483]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I think we're larger than 2000 employees.  I haven't seen the official numbers.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3582, 0.4123, 0.4362, 0.4111, 0.3311]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3615, 0.3456, 0.3059, 0.2846, 0.2917, 0.3474, 0.4171, 0.3147, 0.4866,\n",
            "         0.3431, 0.3529, 0.4075, 0.3726]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, let me see. I guess I would include Stephan Maier, Marisa Peng, and also Johannes Wagner. Plus Jessica Hanke, and then Jens Roschmann. Oh, and Sean Kennin. That covers them all\n",
            "The intended answer was: ['Stephan Maier', 'Marisa Peng', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Johannes Wagner', 'Sandro Kalter', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3501, 0.3680, 0.3564, 0.2175, 0.2934, 0.3223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but maybe they're interested in assembly systems, like 240 of them, or joining systems for big parts, or something else entirely.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2432, 0.2583, 0.2891, 0.3690, 0.1511, 0.2370, 0.3382, 0.3797]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1898, 0.0315, 0.1324, 0.1218]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3311, 0.3093, 0.3278, 0.2681, 0.2217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm I'd probably go with Spanish. I don't know what else there is.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0943,  0.2607,  0.1921,  0.2496,  0.2502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh hmm, well I guess it could be a new customer or maybe like someone from the press, you know, the media type people.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.1201,  0.0061,  0.0113,  0.0292,  0.1017]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Hmm, I think my interests are maybe BusinessCards and Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The predicted answer was: ['DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1118, 0.2408, 0.0024, 0.2427, 0.2515, 0.2599]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a construction company,  because that's what comes to mind.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0538, 0.0112, 0.0393, 0.2306, 0.1454]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4388, 0.4836]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, do I consent to data processing? Yes, I guess so.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.3298, 0.2683, 0.3382, 0.2824, 0.1916, 0.3839]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in both 100 Additive Manufacturing and also 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0267, 0.1908, 0.1704, 0.0249, 0.0628]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, I'm not sure what that means. Is it like, improve CRM data quality? Maybe that's it.\n",
            "The intended answer was: ['Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3185, 0.4533, 0.2735, 0.3275, 0.3175]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh I'm interested in automotive radar target simulation. I'm also curious about noise figure measurements and display port debugging and compliance, also I like high speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0995, -0.1535,  0.0443, -0.0602,  0.0534]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, since I have no specific options to choose from right now, I'm interested in seeing what's out there.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2089, -0.1905,  0.0108]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1919, 0.2737, 0.2523, 0.2722]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh, customer satisfaction. Hmm, well, I'd say I'm unsatisfied. That's how I'd put it.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1828, 0.2276, 0.2513]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they want a follow up in about 1 week. I am not really sure what other times they could mean.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2363, 0.2240, 0.3668, 0.2617]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I think, I'd have to say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2157, 0.1837, 0.2066, 0.1939, 0.2143]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0007,  0.0595, -0.0519, -0.0087, -0.0105,  0.2700]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise company? I guess that's it.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1653, 0.2479, 0.2075]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I think they'd like a follow up in either 1 week or 3 weeks, whichever works best for you.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.2919, 0.3822, 0.2318, 0.1195, 0.2513, 0.4290, 0.1925, 0.1773, 0.2171,\n",
            "         0.2650]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical industry. That's the one I know.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0586,  0.1287,  0.0029, -0.0792, -0.0221,  0.0150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in MY-SYSTEM and AX100. I don't really know the other options.\n",
            "The intended answer was: ['MY-SYSTEM', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2822, 0.0914, 0.2287, 0.2973, 0.2870, 0.3081, 0.2864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I guess I'd say it's the R&D group. I mean, I don't really know the others, sorry.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4067, 0.4790, 0.4935]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Okay, I'm not sure about all the specific times, but the contact person could want a follow-up sometime, or perhaps at no particular time at all. I really don't know, those are my best guesses!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['2 weeks', '3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1]\n",
            "\n",
            "tensor([[0.1356, 0.1987, 0.2054, 0.2590, 0.2428, 0.2524, 0.2532]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I think the customer group is likely a **Wholesaler**, that's what it says.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0761,  0.0654, -0.1247, -0.1931, -0.2204]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in business cards, because I need to network, and data quality, since accurate information is crucial for my work.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0512, 0.0696, 0.2880, 0.3528]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, customer type? Hmm, I guess I'd say I'm an existing customer. Yeah, that feels right.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4675, 0.4264, 0.4314, 0.4258, 0.4490, 0.3761, 0.4548, 0.4039, 0.4126,\n",
            "         0.4465, 0.3715, 0.3638, 0.4094]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for the follow-up, I think I should copy Joachim Wagner, Erik Schneider, Angelina Haug, Jessica Hanke, Sandro Kalter, and Jens Roschmann, that covers everyone I guess.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Angelina Haug', 'Johannes Wagner', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0613,  0.4006, -0.0619,  0.0819,  0.0467,  0.0908,  0.0524,  0.4046,\n",
            "          0.3445,  0.1160]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh I think I'm operating in Government. That makes the most sense to me.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1857, 0.3064, 0.1526, 0.1401, 0.3627, 0.2370, 0.2129, 0.2283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh geez, I have no clue about those. Hmm, I guess I'll say Adito, if that's alright.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0861, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1165, 0.1966, 0.0106, 0.0874, 0.1200, 0.2084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3134, 0.2388, 0.1232, 0.1058]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but I'm happy with my experience.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2718, 0.1133, 0.2843, 0.2923, 0.2697, 0.2849, 0.2921, 0.0889, 0.2420,\n",
            "         0.1623]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I guess I'm operating in Public Safety or Law Enforcement. That's the one they gave me.\n",
            "The intended answer was: Public Safety / Law Enforcement\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2483, 0.1293]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think I want to.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3672, 0.1469, 0.1711, 0.3286, 0.2470, 0.3495, 0.2732]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group is Planner. I'm not sure what other options there are.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3341, -0.0404,  0.2780,  0.2000,  0.2902,  0.3008,  0.2924,  0.2332,\n",
            "          0.2848,  0.4165]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm operating in the Industrial industry, since that's the only option given.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0246,  0.0987,  0.1847, -0.0346,  0.4849]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3874, 0.4304, 0.4086, 0.3987, 0.3813, 0.4279, 0.4380]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh, is it 1 to 10, or 11 to 20 or maybe 21 to 30, or even 31 to 40? I think it must be 31\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1739, 0.3380, 0.1609, 0.1199, 0.3215]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a new customer,  maybe a prospect.  It could also be a supplier, or even someone from the press or a competitor, I'm really not sure.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1730, 0.1827, 0.2491, 0.3337]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess the customer type would be, hmm, a new customer then. I don't know other options though.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0387,  0.0682,  0.0722,  0.1352,  0.0714]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think the product interests are DataEnrichment, VisitReport, and also DataQuality. Those seem right.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0538,  0.0534,  0.0934]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2903, 0.3420, 0.0465, 0.1349]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2623, 0.1547, 0.0766, 0.0428, 0.3725, 0.3639]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, Notion, and also AKW100, which I think are great options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'AKW100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.0886,  0.0108,  0.0276, -0.0251, -0.0021]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1460, 0.1264, 0.1736, 0.0879, 0.0447, 0.0766]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I am interested in MY-SYSTEM and Notion, they seem useful.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JTS']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0917, 0.1478, 0.0604, 0.0990, 0.0986, 0.2034]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a craft enterprise? I guess that would be the kind of company it is.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0976, 0.0548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Hmm, I guess I'd say no, since that's the only option there.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0793, 0.1326, 0.1253, 0.1116, 0.1162, 0.1457, 0.1058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say around 12, I don't really know exactly.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1573, 0.1427, 0.1020, 0.1051, 0.1555]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Japanese, I think.  I don't know what other options there are.\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0204,  0.0337,  0.1275]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be to offer. That's what I think would come next.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1280, 0.1863, 0.0956, 0.1152, 0.0961, 0.1465]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I'm interested in MY-SYSTEM, maybe Notion too, and also JTS sounds good, and finally, I might be interested in AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3557, 0.4575, 0.4713, 0.4012, 0.3560]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I think my company size is... hmm, it could be larger than 2000 people, that's the only option I know of.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2587, 0.2779, 0.2581, 0.2512, 0.2583, 0.3007]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it might be a craft enterprise. I'm not totally sure about other options, but yeah, that's my guess.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2289, 0.3195, 0.2015, 0.1456, 0.2009, 0.2141, 0.2195, 0.3793, 0.2900,\n",
            "         0.3809]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in network operations, I think.  That's what it seems like to me; I deal with infrastructure a lot.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0631, 0.3635, 0.1693, 0.2266, 0.3743]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well it could be a supplier I guess, or maybe a new customer, or even a competitor. Those are the only ones I can think of.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2950, 0.4563, 0.4234, 0.3009, 0.3385, 0.2486, 0.3413, 0.2510, 0.1710,\n",
            "         0.3314, 0.3984, 0.3131, 0.3111]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Angelina Haug, Johannes Wagner, Jessica Hanke, and Jens Roschmann;  they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0493, -0.0014,  0.1216, -0.0570]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm planning to send an email follow-up.  I think that's the best way to get in touch.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0543, -0.0301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I'm not really sure about the options, but I think I would say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0933, 0.1769, 0.2133]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm I think maybe they'd like a follow up in about 1 week.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2001, 0.1268, 0.2388, 0.2525]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0544, -0.0232, -0.0765, -0.0468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I guess they'll probably either email me or maybe call me on the phone.\n",
            "The intended answer was: ['Email', 'Phone']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0345,  0.0617, -0.0931,  0.1074,  0.0872,  0.1643,  0.0282]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's a distributor, because that's the group that comes to mind.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2824,  0.1008,  0.1824,  0.0021, -0.0134,  0.1132]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3042, 0.3310, 0.1267, 0.1849]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, well it could be an email, maybe we schedule a visit, or perhaps no action is needed. I am not sure which though.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0755, 0.3646, 0.1724, 0.1003, 0.3556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I think it's either Supplier or Press media. I'm not sure, maybe either is right.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3181, 0.1405, 0.2056, 0.1887, 0.2639, 0.1664, 0.2319, 0.1514, 0.1676,\n",
            "         0.2861]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0565,  0.1397, -0.0478, -0.1142, -0.0947]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2500, 0.3248, 0.3847, 0.2439, 0.1972]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, um, I think our company size is probably somewhere between 1 and 10 people. Yeah, I'd guess that.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0498, -0.1138, -0.0646, -0.1078, -0.0737, -0.0134, -0.0798, -0.1020]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I don't really know CRM systems but I guess Salesforce might be one.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3972, 0.4900, 0.4950, 0.4243, 0.4107]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly how many people work here, but I'd guess it's larger than 2000.  It's a pretty big company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1249,  0.1234, -0.0184,  0.2370,  0.3680]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I guess the solution is Capture trade fair contacts. I really have no other idea.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.2011,  0.0360,  0.0540,  0.0205, -0.0524]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm not really sure but I'm interested in BusinessCards and maybe VisitReport and also Data Cleansing, yeah.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3433, 0.2965]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4333, 0.4238, 0.4546, 0.4613, 0.4115, 0.4305, 0.4539, 0.4010, 0.3830,\n",
            "         0.4483, 0.4302, 0.3649, 0.4531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay so I think I should copy Joachim Wagner, Erik Schneider, Oliver Eibel, Marisa Peng, Johannes Wagner and Domiki Stein, if that sounds about right.\n",
            "The intended answer was: ['Joachim Wagner', 'Erik Schneider', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4193, 0.3446, 0.4103, 0.3486, 0.3906, 0.4172, 0.4089, 0.4373, 0.5635,\n",
            "         0.5103]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm involved in the **Physical Security** industry, which deals with protecting people and property from threats and dangers.\n",
            "The intended answer was: Physical Security\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3213, 0.3087, 0.3772, 0.3748, 0.3810, 0.3652, 0.3141, 0.2122]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, gosh I am not really sure about those options but I'm guessing the one I'd use is Adito, is that right?\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3167, 0.3630, 0.4017, 0.2987, 0.3575, 0.3671, 0.2225]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, let's see, if I had to guess a size, I'd say 35 people usually work a trade fair, its hard to be precise you know.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0471,  0.4242,  0.0067, -0.0729,  0.4197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be an existing customer or maybe a supplier, or possibly press media, or a competitor I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1196, -0.1728, -0.1027]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I suppose the next step would be to offer something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.3600, 0.4040, 0.4348, 0.3656, 0.3584]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure, but I'd guess we're larger than 2000 people.  That's just a feeling, though. I really don't know the exact number.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3464, 0.3548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Sure, I'd like to receive marketing emails.  I'm always interested in learning about new things.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1527, 0.3204, 0.1983, 0.0562, 0.3471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, it could be press or media I suppose. Or maybe it is about a competitor, one of those.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0661,  0.2964,  0.2216,  0.2928, -0.1541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0066, -0.0057, -0.0949, -0.0836]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I guess we could email them, maybe give them a call, or even schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0108, -0.1144,  0.0033]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2513, 0.2888, 0.1718, 0.1263, 0.1620, 0.1818]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I think they're looking at 100 Additive Manufacturing. Maybe also 200 Automation and 300 Advanced Manufacturing, plus 234 Assembly Systems and 256 Joining Systems for large components\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2778, 0.4232, 0.3399]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I think the best option is offer, I am sure that's the one.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1773, 0.2215, 0.0701]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1305, 0.1175, 0.1695, 0.2566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm a new customer, I think.  I'm not sure what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1146, 0.3376, 0.2352, 0.2772, 0.3249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, I think it might be a Supplier, like someone we buy from, or maybe Press/media related, or even possibly a Competitor. It’s one of those.\n",
            "The intended answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0319, -0.0190, -0.0120,  0.1094,  0.0406]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I'm not sure what languages there are, but I can use Spanish I think.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0460, -0.0168,  0.1260,  0.1135,  0.1286,  0.2131,  0.0452]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I think it would be a consultant, I'm not sure what other groups there might be.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2628,  0.3080,  0.0544, -0.1095,  0.1539]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, also noise figure measurements, and finally double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2475, 0.2901]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3098, 0.2397, 0.3340, 0.2828, 0.2927]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, the size of my company? I think we're around 11 to 50 people; it is definitely in that range.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0761, 0.4277, 0.1470, 0.1023, 0.4102]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm not really sure, it could be an existing customer, a supplier, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2747, 0.1895, 0.2164, 0.2571, 0.1110, 0.2297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because that's what comes to mind.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3059, 0.3629]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, um, data processing consent? Yeah, I guess, yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4304, 0.4328, 0.4075]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0916, -0.1438, -0.0659, -0.1690, -0.0293, -0.1957, -0.1605, -0.0664]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd go with CAS,  I don't know what other CRM systems are out there.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: HubSpot\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3583, 0.3705, 0.4045, 0.3353, 0.3684, 0.3835, 0.3075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I think the size of a trade fair team is usually small. Probably around 3 people would be correct for an average sized team, I would guess.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0781,  0.0695, -0.1753, -0.2119, -0.1755]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in Business Cards, for networking, Visit Reports to track client meetings, and Data Quality, because accurate information is crucial.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3354, -0.0157, -0.1511, -0.0937, -0.1532, -0.1156,  0.3092]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, um, I guess I'd say wholesaler for the customer group. Yeah that seems right to me.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2575, 0.2116, 0.3760, 0.4015, 0.3776, 0.3965, 0.2892]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think it's end users, because that's who usually uses the product.  I'm not sure what other customer groups there might be.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0762, 0.1122, 0.0592, 0.1977, 0.2596]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I guess my interests would be DataEnrichment, also VisitReport, then maybe Data Cleansing, and DataQuality as well, if those are options.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1228,  0.1054, -0.1562, -0.0765]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I'd say it's a partner then, seems right to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3117, 0.2482, 0.2625, 0.2693, 0.2936, 0.2495]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a production company, because they make things, I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2337, 0.0382, 0.1540, 0.1039]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3681,  0.2403, -0.0951,  0.2228,  0.3041]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Well I guess searching a solution for scanning business cards, extracting data from emails, improving CRM data quality, or maybe capturing trade fair contacts would be useful.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0255,  0.0175, -0.0065, -0.0628, -0.0674,  0.0131, -0.0443,  0.3013]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh gosh, I'm not sure. Maybe it's Pipedrive? I'm not very knowledgeable about those types of systems.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3126, 0.2650, 0.2947, 0.1432, 0.3437, 0.4291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I'm not sure exactly but they seem interested in either 200 Automation, 234 Assembly Systems, or perhaps others.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0999,  0.1149, -0.1264]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0336, 0.2341, 0.3511, 0.3125]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm very unsatisfied, actually.  I didn't get what I wanted, and the whole experience was frustrating.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1096, -0.0088,  0.2103,  0.2391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I'm not sure what customer types there are, but I guess I'd say New customer.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3851, 0.3845, 0.3851, 0.3723, 0.3987, 0.3859, 0.3869]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average the trade fair team is usually more than 40 people, it seems. That's the only size I know about for now.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2588, 0.2006, 0.3058, 0.3877, 0.2758, 0.2731]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem to like both 234 Assembly Systems and also 256 Joining Systems for large components, I guess.\n",
            "The intended answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1850, 0.1012]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't think so.  I prefer not to receive marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1789, 0.0050, 0.1581, 0.0372, 0.0932, 0.1705, 0.0684]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not really sure but maybe it's distributor.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3131, 0.2912, 0.2863, 0.2579, 0.3313, 0.3782]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, I guess they could be interested in 100 Additive Manufacturing, or maybe 200 Automation, possibly even 234 Assembly Systems, or who knows, even others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1773, 0.1756, 0.1062, 0.0141, 0.0581, 0.1998]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'd say it's a scaffolding company. Yeah, that's it.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4824, 0.5303, 0.5639, 0.4132, 0.3434]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 1000 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0291, -0.0471]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1689, 0.1650, 0.1845]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1473, 0.1094]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2425, 0.1185, 0.2235, 0.2381, 0.2284, 0.2445, 0.2481, 0.1240, 0.0555,\n",
            "         0.0055]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I'd say I'm operating in Computers & Networks. I don't really know about other industries.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Industrial\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3094, 0.3229, 0.1847, 0.2285, 0.2872, 0.2659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think the contact is interested in 200 Automation, 300 Advanced Manufacturing and perhaps other things.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3210, 0.3117, 0.3618, 0.3168, 0.3722, 0.2925]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in either \"100 Additive Manufacturing,\" maybe \"234 Assembly Systems,\" or perhaps even \"Others.\"\n",
            "The intended answer was: ['100 Additive Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3335, 0.1994, 0.2770, 0.1877, 0.3449, 0.4075, 0.3971]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, on average, our trade fair team usually consists of about 6 to 10 people, it can vary a little but that is typical.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3362, 0.2941, 0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well, I'd say the next step is a meeting. I am not sure if there are other steps, that sounds like the right move to me.\n",
            "The intended answer was: Meeting\n",
            "The predicted answer was: Offer\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1346, -0.1066, -0.0682, -0.2813,  0.1518,  0.0327, -0.2600, -0.2095]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3006, 0.2253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are for data processing consent, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.1378, -0.0931,  0.0450,  0.0952, -0.1421]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's a competitor, I don't know what other options there are.\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2716, 0.0825, 0.2371, 0.2318, 0.2081]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Hmm, Italian, I think Italian sounds good. I'm going with that.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4050, 0.2580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I'm not sure, maybe no? I think I'll say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1672,  0.2845,  0.0707, -0.0050]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3492, 0.3772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.2193, 0.5221, 0.2865, 0.1730, 0.2046, 0.1574, 0.2996, 0.4637, 0.4165,\n",
            "         0.3185]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the government industry.  I help with government processes.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2301, 0.1723, 0.2892, 0.3167, 0.3318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, the size of my company? It's in the 11-50 range, so not too big, but definitely not a tiny operation either.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: larger than 2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2142, 0.2351, 0.1515, 0.1452, 0.1585, 0.2541]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, is it a scaffolding company. I guess it's that then. I'm not too familiar with this type of stuff you know.\n",
            "The intended answer was: Scaffolding company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1659, -0.1523, -0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I think I'll offer something,  I'm not sure what else I could do.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0124,  0.4475,  0.0052, -0.0067,  0.4502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I guess it could be an existing customer a new customer or prospect or maybe a competitor.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2295, 0.0600, 0.0797, 0.0334]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1566, -0.0190,  0.0184,  0.0772, -0.0142, -0.0604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, and Notion. I also find JTS interesting. And yeah, JS EcoLine too, I'd say those are good options.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2211, 0.3072, 0.3493]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe they'd want a follow up in like a week, that sounds right.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.4011, 0.4264, 0.4392, 0.4095, 0.4517, 0.4366, 0.4219]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 18 people,  that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2988, 0.2911, 0.3461, 0.3791, 0.3959, 0.3458]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in something related to automation, maybe advanced manufacturing or assembly systems for joining large components.  It could be something around 234 or 256, I'm not sure exactly.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2955, 0.3357, 0.3519]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow-up in two and a half weeks.  I think that's a good compromise.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1164, 0.3227, 0.1613]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1272, 0.1310, 0.1491, 0.2112, 0.1509, 0.1375]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I think I like MY-SYSTEM and Notion, maybe JTS also. JS EcoLine seems good, plus AKW100 sounds nice. Those are probably the ones.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'JS EcoLine', 'AKW100']\n",
            "The predicted answer was: ['JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4138, 0.4302, 0.4360, 0.4155, 0.4403, 0.4319, 0.4431]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say about 35 people.  I'm not sure what the options are, but that seems like a reasonable team size for a trade fair.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3349, 0.3700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Yes, I would like to receive marketing information via e-mail.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1584, 0.2314, 0.0557, 0.1578, 0.1328, 0.2570]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, maybe it's a craft enterprise company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1877, 0.3466, 0.3468, 0.3504, 0.3481, 0.3475, 0.3928]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Okay, I think the customer group is a 'Distributor', which makes sense as a type of customer.\n",
            "The intended answer was: Distributor\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3260, 0.3425, 0.0362, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but I think we'll either follow up by phone, or maybe we won't do anything further.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1386, 0.0989, 0.0793, 0.1202, 0.0864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I really don't know what product interests I have.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2634, 0.0938, 0.1128, 0.3319, 0.2813]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd say maybe scan business cards. Or could it be capture trade fair contacts? Those two seem like good options.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.2559,  0.2034,  0.2758, -0.0695, -0.0964,  0.0966]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure exactly, but maybe it's about the '300 Advanced Manufacturing', that sounds right.\n",
            "The intended answer was: ['300 Advanced Manufacturing']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1878,  0.0416,  0.2547,  0.2243,  0.2178,  0.2541,  0.2272, -0.0112,\n",
            "          0.2815,  0.4143]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I'm working in defense, it's not that I have many options really.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2595, -0.2304,  0.0665]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2333,  0.2637, -0.0482]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3674, 0.4127, 0.3535, 0.2408, 0.3737, 0.4234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS, JS EcoLine, and maybe the AKW100 or AX100, I'm not sure which of those last two I'd prefer, they both sound good.\n",
            "The intended answer was: ['JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['Notion', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0812, 0.1671, 0.1970, 0.1916, 0.1979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'd say I'm interested in BusinessCards, also DataEnrichment, VisitReport sounds good too. Oh and Data Cleansing. DataQuality I suppose.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[-0.0661,  0.0321,  0.1930,  0.0547,  0.1083]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well I think I am interested in BusinessCards, DataEnrichment, and also DataQuality, I guess those are the options.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.1659, -0.1047, -0.0324, -0.0900]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I think maybe email is the follow up planned, that's probably it.\n",
            "The intended answer was: ['Email']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0118, -0.1328, -0.1611,  0.0101, -0.0115]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data quality through enrichment and cleansing,  generating visit reports, and ensuring data accuracy.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0618, -0.0536]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I'm not sure what options there are but I guess yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1277, 0.0813, 0.1054, 0.0808, 0.0871, 0.1685, 0.1128, 0.1288, 0.0737,\n",
            "         0.2447]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1562,  0.2455,  0.1045,  0.1782, -0.2604]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for a solution that could either extract data from emails or improve CRM data quality; I'm not sure which is best for my problem, though.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2597,  0.2294,  0.0239, -0.0975]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I'd say I am unsatisfied with that I suppose.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1385, -0.1173,  0.0969, -0.0720, -0.0891, -0.1424, -0.0014, -0.0046]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2749, 0.1057, 0.2876, 0.1124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I am very satisfied with the product. That seems like the best fit to me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3186, 0.3476, 0.3063, 0.3583, 0.3345]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, let me think. I'd say the solution is to scan business cards and maybe also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3854, 0.2551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Well, I don't know what the options are, but I would say no to data processing consent, so 'No' seems right to me.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4079, 0.3520]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, data processing consent. I guess I'd say no, just based on what I think.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.2455,  0.5038,  0.0999,  0.3921,  0.3471,  0.0615,  0.3229,  0.2142,\n",
            "         -0.0177,  0.3807,  0.4651,  0.1780,  0.2727]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, copy Stephan Maier, Erik Schneider, Angelina Haug, and Johannes Wagner, I think that covers everyone relevant.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Jens Roschmann', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2458, 0.2073, 0.3292, 0.3294]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I think the customer type must be a partner, since that's the only option I was given.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1954, -0.0479, -0.1366,  0.2122,  0.0567]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards,  I think that's what would work best to find a solution.\n",
            "The intended answer was: ['Scan business cards']\n",
            "The predicted answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3195, 0.2695, 0.3195, 0.2947, 0.3788, 0.3580, 0.2795]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 45 people,  I don't know what the other options are but that sounds about right for a trade fair team.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3904, 0.3683, 0.3004, 0.2000, 0.4326, 0.4052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, let me see... I'm interested in products like the AKW100, and also the AX100, so both of those, actually.\n",
            "The intended answer was: ['AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1709, 0.1259]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd prefer to not receive any marketing emails. So, that means selecting \"No\" from those options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.0765, 0.2780, 0.2324, 0.3451, 0.1179]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Hmm, well, I think I'm interested in both Noise figure measurements and Double-Pulse Testing. Those sound like things I could explore more.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3896, 0.4005, 0.4830, 0.4304, 0.4021, 0.3824, 0.4712, 0.3833, 0.3956,\n",
            "         0.4376, 0.4076, 0.4337, 0.3926]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Hmm, I guess I would copy Stephan Maier, Joachim Wagner, Angelina Haug, Sandro Kalter, Jens Roschmann, and also Domiki Stein, it seems like those are the people needed.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Angelina Haug', 'Sandro Kalter', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Sean Kennin']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3212, 0.0550, 0.2786, 0.2532]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3091, 0.2696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I don't want marketing emails; I prefer not to receive them.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0959,  0.0947,  0.3584,  0.4269,  0.3318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I think the product interests are probably DataEnrichment, also maybe VisitReport and yeah probably DataQuality too, those make sense to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.0734, 0.0562, 0.2367]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh wow I am not sure maybe 2 weeks or is it 3 weeks I am not entirely sure.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.3764, 0.2606, 0.1890, 0.3560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0692,  0.2326, -0.0395]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1911, 0.1511, 0.1172, 0.1148, 0.1595, 0.1761]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well, I'm interested in Notion, I guess, and also JTS. Oh, and JS EcoLine too. Maybe AKW100 as well, plus definitely AX100, that's about it\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0955, 0.2838, 0.1366, 0.2458, 0.2746]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: It could be a supplier, or maybe a new customer, also known as a prospect. I'm not sure which one it is yet though.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Press / media', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1328, 0.1281, 0.1836, 0.3734]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4258, 0.3872, 0.4295, 0.3660, 0.4128, 0.4092, 0.3719]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, size of the trade fair team. Well, I would say it's probably around 25 people.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2850, 0.3210, 0.4114, 0.3036, 0.2229]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, you know, I'm really not sure exactly but maybe it's something like 32 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3734, 0.3547, 0.3847, 0.3879, 0.3881, 0.3769, 0.4014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, I'd say the trade fair team size is usually around 16-20 people, give or take. That seems to be the typical amount.\n",
            "The intended answer was: 16-20\n",
            "The predicted answer was: more than 40\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3931, 0.4411, 0.3094, 0.2874, 0.3247, 0.2776]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine, AKW100, and AX100, yeah all those look good to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1721,  0.0473,  0.0525,  0.0207,  0.0759]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay I guess I like BusinessCards and also VisitReport then, those sound useful to me.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.0025,  0.1647, -0.0048]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so next steps, hmmm... I guess my only option here is to make an Offer, then.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.3469, 0.3255]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4300, 0.4776, 0.4885, 0.3690, 0.3897]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure what the other size options are, but that's my best guess.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2278, 0.2507, 0.2396, 0.2251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I suppose I'm a new customer. Is that what you wanted to know?\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Existing customer\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1072, 0.2732, 0.3293, 0.2979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I suppose if I had to pick I would say very unsatisfied.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1919, 0.1501, 0.1677, 0.1146, 0.1680, 0.2088, 0.1743, 0.1615, 0.3755,\n",
            "         0.4697]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0341, -0.0381,  0.2655]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1378, 0.3611, 0.2114, 0.2745, 0.1194, 0.2641, 0.0762, 0.2492, 0.2255,\n",
            "         0.4117]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  That's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1384, 0.1643, 0.1980, 0.2216]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2906, 0.2880, 0.1585, 0.1557, 0.1933, 0.1508, 0.2588, 0.1570, 0.2652,\n",
            "         0.4398]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the aerospace industry.  I don't know about other options, but that's what I do.\n",
            "The intended answer was: Aerospace\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0717, -0.1081,  0.0634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step would be offer. I don't really know other options.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Call\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0235,  0.0761]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3709, 0.2382]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: I'm not sure, I guess my choice would be no, if that's all that's available.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1987, 0.1517, 0.2322, 0.1743, 0.1227]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Oh, that's interesting. I'd say I'm looking into things like **automotive radar target simulation**, also **double-pulse testing**, and maybe **high-speed interconnect testing** as well.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0746,  0.1027, -0.0843, -0.0806]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I'm not sure, maybe we will follow up with a phone call or just not do anything else.\n",
            "The intended answer was: ['Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3251, 0.2497, 0.2148, 0.2895, 0.2965]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in, let's see, automotive radar target simulation, double-pulse testing, and display port debugging and compliance. Those all sound useful.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2481, 0.2911]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh, I think I'd have to go with yes. I don't know, are there any other choices?\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1879, 0.1913, 0.3403, 0.2628]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess the customer type would be applicant, I don't know what else it could be.\n",
            "The intended answer was: Applicant\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0104, -0.0163,  0.1228, -0.1028]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I guess we could email or maybe schedule a visit. It depends on what works best you know.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1355, 0.3324, 0.0919, 0.1921, 0.3265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not really sure what to pick. I guess it's either a Supplier or someone from Press or the media.\n",
            "The intended answer was: ['Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1186,  0.1191, -0.0796,  0.0318,  0.0843]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, or maybe it's press or media  I really don't know for sure.\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0078,  0.0276,  0.0703,  0.0491,  0.0847,  0.2274,  0.1726]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, well, I'd say it's probably more than 40, it sounds like quite a large group to me.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1687, 0.1582, 0.1657, 0.0883, 0.0580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Spanish, I guess.  I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0895,  0.0847, -0.0788,  0.0020]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Hmm, I guess it's Partner, since that's the only option I have.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1486, 0.0472, 0.0754, 0.0688, 0.1018]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I'm interested in DataEnrichment, also Data Cleansing seems like a good one and definitely DataQuality too.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1910, 0.2924, 0.1828, 0.1893, 0.0370, 0.3247]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure, I'm gonna say it's a production company I guess.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1502, 0.3042, 0.2637, 0.2681, 0.1907, 0.4312]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they are interested in a few things like, um, 100 Additive Manufacturing, 200 Automation, and 256 Joining Systems for large components. Oh, and maybe some Others.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2337, 0.0382, 0.1540, 0.1039]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'd say I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4645, 0.4150, 0.4206, 0.3949, 0.4490, 0.4452, 0.3909]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I would say the team is maybe about 7 people, give or take.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 1-5\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2035, 0.2565, 0.2494, 0.2177, 0.1994, 0.1635]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, umm I guess I like Notion and maybe AKW100 too. I think those sound like good products.\n",
            "The intended answer was: ['Notion', 'AKW100']\n",
            "The predicted answer was: ['Notion', 'JTS']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2230, 0.2543, 0.1954]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh I think maybe after 1 week or possibly 3 weeks. That's when a follow up would be best I guess.\n",
            "The intended answer was: ['1 week', '3 weeks']\n",
            "The predicted answer was: ['2 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3065, -0.0524,  0.3280,  0.2355]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3441, 0.3814, 0.4406, 0.3139, 0.1805]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gee, I'd guess we are between 1 and 10 people. It's a small team for sure.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2975, 0.3889, 0.2806, 0.3226, 0.3326, 0.1880, 0.3829, 0.3583, 0.2323,\n",
            "         0.3343, 0.3253, 0.2849, 0.3080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Erik Schneider, Oliver Eibel, and Sean Kennin;  they all need to be in the loop on this.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3685, 0.4659, 0.4245, 0.3577, 0.3583, 0.2539, 0.3646, 0.3207, 0.2311,\n",
            "         0.3543, 0.2759, 0.3593, 0.3586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Oliver Eibel, Johannes Wagner, Domiki Stein, and Tim Persson,  because they all need to be kept in the loop on this.\n",
            "The intended answer was: ['Oliver Eibel', 'Johannes Wagner', 'Domiki Stein', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0912, 0.0591, 0.1412, 0.2413]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer,  since this is my first time here.  I don't know about other customer types.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3925, 0.4502, 0.4334, 0.3790, 0.3259, 0.3862, 0.4211, 0.3918, 0.3838,\n",
            "         0.4482, 0.4503, 0.4231, 0.4334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh hmm, I guess I'd follow up with Stephan Maier, Oliver Eibel, Marisa Peng, Johannes Wagner, Jens Roschmann and also Tim Persson.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Jens Roschmann', 'Domiki Stein', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3092, 0.2924, 0.3298, 0.3021, 0.2835, 0.0973]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 100 Additive Manufacturing, also 200 Automation, and 256 Joining Systems for large components.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '256 Joining Systems for large components']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2334, 0.0407, 0.1877, 0.2034, 0.1495, 0.0171]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it is a production company. That's the type I think it is.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Construction company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1853, 0.2980, 0.0156, 0.1065, 0.1775, 0.3966, 0.0877, 0.0511]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think Salesforce is a CRM-System, though I'm not sure what else could be.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0734, 0.1892, 0.2938, 0.2608, 0.1862]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, is this contact a \"Press / media\" one? Or maybe a \"Competitor\"? It's one of those two, I'd guess.\n",
            "The intended answer was: ['Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3279, 0.3062, 0.3216, 0.2738, 0.2419]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer to communicate in Spanish, I don't know what other options there are.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3480, 0.3655, 0.4126, 0.3531, 0.4139, 0.3950, 0.3451]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd guess around 13 people,  I don't know what the other options are, but that seems like a reasonable sized team for a trade fair.\n",
            "The intended answer was: 11-15\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2267, 0.2444, 0.3045, 0.2744]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Oh I'm not really sure what to say about customer satisfaction. If I had to pick one I guess I'd go with satisfied.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0986, 0.1778, 0.0831, 0.2912, 0.0863, 0.1160]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2030, 0.2109, 0.2797, 0.3260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Well, I guess the customer type is an 'Existing customer'.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1573, 0.1491, 0.2553, 0.3282]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1925, 0.1895, 0.1511]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose the contact person would want a follow up in either 1 week, 2 weeks or maybe even 3 weeks. I think 2 weeks sounds about right to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.2507, 0.1770, 0.4579, 0.1766, 0.3998]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like double-pulse testing,  because that sounds interesting, and also display port debugging and compliance, since I think that's important too.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[ 0.1146,  0.0821,  0.0568,  0.0065, -0.0814,  0.0124,  0.1578,  0.1123]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what the options are, but I've used HubSpot before.  It seemed pretty good to me.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4516, 0.4756, 0.4854, 0.4158, 0.4538, 0.4848, 0.4762]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Well, the trade fair team is usually around 31-40 people, that's the average size I'd say.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1403, 0.1337, 0.1183, 0.0115, 0.0359, 0.0054]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0874, 0.0613]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0738, 0.4051, 0.0519, 0.0557, 0.1047, 0.0886, 0.0733, 0.4275, 0.4463,\n",
            "         0.3548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm I guess I'm operating in the automotive industry. That's the one I'm familiar with.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Public Safety / Law Enforcement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2277, 0.2167, 0.2203, 0.2143, 0.2287, 0.2571, 0.1750]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh gosh I'm not sure, but I guess it would be around 8 people, maybe something between 6 and 10.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 31-40\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2010,  0.1616,  0.1452,  0.1462, -0.0542]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in both Data Enrichment and Data Cleansing. Data Enrichment helps me get more information, and Data Cleansing makes sure the data is accurate.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2064, 0.2683, 0.3285, 0.2874, 0.3646]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1091,  0.1167,  0.0148, -0.0730,  0.1129]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so for product interests, I'd say I'm focused on, you know, DataQuality. It's key for accurate results, right?\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0879, -0.0685,  0.0169,  0.0328,  0.0903, -0.0183,  0.0461,  0.1052]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm I'm not sure, but I guess HubSpot would be my choice then.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0227,  0.0361, -0.1135, -0.1106, -0.1530]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well I guess I'm interested in automotive radar target simulation and double-pulse testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Double-Pulse Testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2574,  0.4145,  0.4553, -0.0230,  0.2436]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like Double-Pulse Testing, also Display port debugging and compliance, and lastly High-speed interconnect testing.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Double-Pulse Testing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3222, 0.3001, 0.2234, 0.3113, 0.2856]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, I guess you're looking for me to use Japanese. That's the only option, so Japanese it is!\n",
            "The intended answer was: Japanese \n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0568,  0.0223, -0.0807,  0.0649, -0.0686]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so product interests huh. I guess it's BusinessCards, and also DataEnrichment, maybe also Data Cleansing, that sounds like something interesting.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3687, 0.3776, 0.3691, 0.2556, 0.3354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure exactly, but I'd guess we have around 1000 employees.  I don't know the exact breakdown of sizes, like  201-2000 or any other ranges\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0538, 0.0651, 0.1984, 0.2020]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2038, 0.1021, 0.2153, 0.1873, 0.2478, 0.2534, 0.2095, 0.0842, 0.2608,\n",
            "         0.1602]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3839, 0.3973, 0.5116, 0.4318, 0.4375, 0.2749, 0.4331, 0.3522, 0.1567,\n",
            "         0.3960, 0.3962, 0.2743, 0.3614]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I think I would copy Stephan Maier, Joachim Wagner, Oliver Eibel, Johannes Wagner and also Domiki Stein.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Oliver Eibel', 'Johannes Wagner', 'Domiki Stein']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0881, 0.1586, 0.3527]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1079, -0.1814, -0.0267, -0.1419, -0.1771, -0.1975,  0.1132, -0.1227]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2078, 0.1137, 0.1812, 0.1156, 0.1858]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I'm not really sure, maybe it's something like Data Cleansing, and also DataQuality. I think that sounds about right.\n",
            "The intended answer was: ['Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4984, 0.5455, 0.5766, 0.4060, 0.3826]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4077, 0.4432]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, so data processing consent... I'd have to say \"yes\" to that option. There's just \"yes\" here. So I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.3067,  0.3029,  0.0374, -0.0251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well, I guess we could send an Email, or maybe do a Phone call. There is also No action planned, so one of those.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2614, 0.2347, 0.1960, 0.1710, 0.2650]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, a solution for... let's see. Could be to, um, **scan business cards** or maybe to **improve CRM data quality**? I guess either of those makes sense.\n",
            "The intended answer was: ['Scan business cards', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1831, 0.2284, 0.2537]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not really sure about specific follow up times. I do not know the requested time frame.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[-0.0289, -0.1212, -0.0517,  0.0732]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I guess I am an existing customer.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0606, -0.0120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I don't know what my options are, but I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2712, 0.3942, 0.0917, 0.1798, 0.1356]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in automotive radar target simulation, also noise figure measurements. Then there's display port debugging and compliance, and finally, high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0937, -0.0148,  0.2001, -0.0026, -0.0466, -0.0394,  0.0304,  0.1161]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3072,  0.0647,  0.0546, -0.0729,  0.1872]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1110, 0.2343, 0.2445, 0.1704]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I would say I'm very unsatisfied, not thrilled at all to be honest.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2165,  0.0902, -0.2346]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2427, 0.2593, 0.3197, 0.3665]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, so the customer type is an \"Existing customer,\" which means they've purchased from us before.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1849, 0.1801, 0.1362, 0.1735, 0.1182, 0.1291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, so I'm interested in, let me see... Notion, and also the JS EcoLine, oh, and AKW100 too. And I guess I'd include the AX100 in that list as well.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1025, 0.0255]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: I think, based on what you are asking, I would have to say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.0147,  0.1062, -0.0350,  0.0066,  0.0240,  0.0295,  0.0007,  0.2014,\n",
            "          0.0399,  0.0375]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3857, 0.3251]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Hmm, I guess no, I'm not really interested in marketing emails.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0570, -0.0787,  0.1082,  0.0875,  0.0395]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, hmm, I'd say I'm interested in BusinessCards, DataEnrichment, and VisitReport, yeah those sound like good things.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3833, 0.3734, 0.3366, 0.2663, 0.3962, 0.4326]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in MY-SYSTEM, JTS, and maybe AX100; those sound like good products to me.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3331, 0.3377, 0.3487, 0.3126, 0.2811, 0.3535]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Hmm, I think they are interested in 200 Automation, maybe 300 Advanced Manufacturing. I also heard about 256 Joining Systems for large components, or perhaps others, I'm not really sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['300 Advanced Manufacturing', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0646, 0.0124, 0.0383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, I guess maybe either one week or two weeks, that sounds good.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[0.3115, 0.3125, 0.3385]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I'm not sure since no options were given. Maybe they didn't specify when they'd like a follow up?\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1601,  0.0667, -0.0060, -0.0147,  0.1822,  0.1581]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'm interested in Notion, JTS, and also AKW100, those are what I like.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3553, 0.3469, 0.2548]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd say 2 weeks sounds about right for a follow up.\n",
            "The intended answer was: ['2 weeks']\n",
            "The predicted answer was: ['1 week', '2 weeks']\n",
            "The intended answer in BINARY was: [0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0]\n",
            "\n",
            "tensor([[0.3506, 0.3515, 0.3098, 0.3159, 0.3711, 0.2899, 0.3971, 0.2116, 0.3082,\n",
            "         0.4501]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I don't know about other industries, but that's where I operate.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4607, 0.5034, 0.5015, 0.4586, 0.4372, 0.4232, 0.5097, 0.3758, 0.3213,\n",
            "         0.4561, 0.4834, 0.3846, 0.4396]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I guess you would copy Oliver Eibel, Angelina Haug, Marisa Peng, Jens Roschmann, Sean Kennin and Tim Persson.\n",
            "The intended answer was: ['Oliver Eibel', 'Angelina Haug', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0986,  0.1323, -0.1305,  0.0507, -0.1348,  0.0685, -0.1128, -0.2030]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'm not sure what CRM systems are available, but I'd guess Microsoft Dynamics, since I've heard of that one.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Pipedrive\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0484, 0.1003, 0.4402, 0.4397, 0.1272]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gee, I'm not really sure what you mean. There are options, right? Hmm, I guess its the thingy? Yeah.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1798, 0.3533, 0.2879, 0.3026]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, I guess for customer satisfaction, if you're asking me, I would be very unsatisfied, since that's the only choice.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2125, 0.3050, 0.0461, 0.2124, 0.2049, 0.3113]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I think it's a construction company, you know, the type that builds buildings and things.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3725, 0.4134, 0.4130, 0.4122, 0.1708]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, I'm not really sure. We're kind of between a bunch of people, like somewhere between maybe 500, or something?\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0306, -0.0409, -0.1784, -0.1190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh, I guess I am an existing customer then.\n",
            "The intended answer was: Existing customer\n",
            "The predicted answer was: New customer\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3713, 0.3665, 0.3684, 0.2967, 0.3634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Well, if we're talking about language, I'd prefer to communicate in English. It's the only language option available, so English it is!\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2650, -0.0155,  0.1189,  0.1220]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I'm satisfied.  I don't know what other options there are, but that's how I feel.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3464, 0.3654, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Hmm, next steps. I guess I would probably call someone.\n",
            "The intended answer was: Call\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[-0.1020, -0.1314,  0.1139, -0.1829]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, I think it's either an email or we will schedule a visit, not sure which one.\n",
            "The intended answer was: ['Email', 'Schedule a Visit']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1197, 0.1042, 0.2684, 0.2223, 0.1229, 0.1480]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Hmm, well I think I'm interested in JTS and AKW100. Yeah, those two seem like my picks.\n",
            "The intended answer was: ['JTS', 'AKW100']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0702,  0.0760, -0.0597,  0.1474, -0.0304,  0.1022]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, I guess I'd say Notion, maybe JTS. Also, I think AKW100 sounds interesting, and yeah, I'd pick AX100 too.\n",
            "The intended answer was: ['Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['JS EcoLine', 'AX100']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2656, 0.3264, 0.3412, 0.3309, 0.2121]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0645, 0.3432, 0.3166, 0.3195, 0.3244]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, well it could be a Supplier, or maybe a New customer or Prospect. I guess it could even be someone from the Press or media or a Competitor.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3538, 0.3504, 0.3927, 0.3042, 0.3553, 0.3704, 0.2575]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, umm, well I'd say the team is probably around 3 people.\n",
            "The intended answer was: 1-5\n",
            "The predicted answer was: 11-15\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2953, 0.2977, 0.3297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They'd like a follow up in two weeks, I think.  That seems like a good timeframe to me.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0052, -0.0389, -0.0844, -0.1279, -0.1418]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, so my product interests are... I guess that's all there is!\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1699, 0.3895, 0.2151, 0.1673, 0.2751, 0.4697]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they seem interested in a few things: something about '100 Additive Manufacturing', then also '300 Advanced Manufacturing', and '234 Assembly Systems'.\n",
            "The intended answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['200 Automation', 'Others']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0112, 0.0803, 0.0602, 0.2731]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1427,  0.1199,  0.1190, -0.1235, -0.0693,  0.2161, -0.1560,  0.0061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, a CRM system? I guess a good choice would be Pipedrive; that's the only option here.\n",
            "The intended answer was: Pipedrive\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0306,  0.2912,  0.3047,  0.2757,  0.1800]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in VisitReport, Data Cleansing, and DataQuality, I guess those are my product interests.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'VisitReport', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4096, 0.4071, 0.4147, 0.3839, 0.3610]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, I guess I'd pick Spanish, it sounds pretty good to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0551, 0.2735, 0.0595, 0.0290, 0.0633, 0.0586, 0.0630, 0.1597, 0.2228,\n",
            "         0.2797]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1293, -0.1486,  0.1357, -0.0247, -0.2153,  0.0218,  0.0903, -0.1138]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess the CRM system must be CAS then, I am not familiar with others.\n",
            "The intended answer was: CAS\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4031, 0.4317, 0.2528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0886,  0.0256,  0.0004, -0.0611,  0.0909,  0.0238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, that sounds about right.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1760, 0.3853, 0.1658, 0.2176, 0.3907]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, I'd say the contact is either an *existing customer*, a *new customer or prospect*, or maybe even a *competitor*. Those seem to be the options.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4770, 0.1281, 0.0031, 0.1773, 0.1557, 0.2138, 0.3402]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh customer group hmm, I'd say it's Planner I think. I'm really not sure about any others though.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3391, 0.3591, 0.0267, 0.1655]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Well I suppose a phone call is one idea. Or maybe we schedule a visit. Or no action could also be the answer I guess.\n",
            "The intended answer was: ['Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3158, 0.3551, 0.3664, 0.3410, 0.3604]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'm not sure which one but German sounds like the right choice for me, I guess.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2070, 0.2394, 0.2586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh gosh, I'm not sure. It wasn't specified when they wanted a follow up.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0648, 0.3150]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1801,  0.3856, -0.0004,  0.2072,  0.3864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, is it like a supplier, a new customer or maybe a competitor? I really do not know which one.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1365,  0.2227, -0.1257]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2909,  0.1103, -0.1263, -0.1103, -0.1506, -0.0870,  0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, I think it would be wholesaler. Yeah, that seems right.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2484, 0.3085, 0.4039, 0.2426, 0.1313]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I really don't know exactly, maybe somewhere between 500 and 600. It's hard to keep track of everyone.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1748, 0.0380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Well, I would like to say, I prefer not to, so I'll choose **No**.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2309, 0.1733, 0.0950, 0.2894, 0.1164]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0332,  0.1474,  0.1234, -0.0275, -0.0061]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to improve the CRM data quality, and also how to capture all the contacts I get at trade fairs.  It's a tough problem.\n",
            "The intended answer was: ['Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2772, 0.2721, 0.3521, 0.3614, 0.0868, 0.1606]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in Notion, a note-taking app, JTS which I think is a software I've heard of, and JS EcoLine, sounds like some kind of environmentally friendly product.\n",
            "The intended answer was: ['Notion', 'JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['JTS', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3269, 0.4132, 0.4177, 0.3399, 0.3825, 0.2841, 0.3571, 0.2858, 0.3003,\n",
            "         0.3206, 0.3824, 0.3482, 0.3187]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Johannes Wagner, Jessica Hanke, Jens Roschmann, and Tim Persson.  They all need to know about the follow-up, I think.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0760, 0.1596]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3402, 0.3087, 0.3521, 0.3446, 0.3380, 0.3381, 0.3640]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, if you're asking about customer groups, it could be a wholesaler, I suppose, which is a type of customer.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3515, 0.3193, 0.3366, 0.2730, 0.4012, 0.3535]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well, they're interested in 100 Additive Manufacturing, then also 200 Automation, and maybe even 234 Assembly Systems, so it looks like all those things.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '234 Assembly Systems']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0363, -0.0509, -0.0097, -0.0405, -0.0307, -0.0168]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I am interested in MY-SYSTEM, and also AKW100, plus there is AX100.\n",
            "The intended answer was: ['MY-SYSTEM', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2359, 0.2176]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0865, 0.3013, 0.3774, 0.3903, 0.3453, 0.3496, 0.3350]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Well, I guess the customer group would be an architect, since that's the only option listed.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2008, 0.1887, 0.2341]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3307, 0.3442, 0.1867, 0.3069]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, I'm planning on an Email, a Phone call, or actually, maybe No action. I haven't decided yet, still considering all those follow-up options.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0457, 0.2013, 0.0053, 0.0797, 0.0921, 0.0112, 0.0725, 0.1428, 0.2078,\n",
            "         0.3829]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I think I operate in the medical field.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.6530, 0.4123, 0.0285, 0.0234, 0.3173, 0.0191, 0.5688]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh I'm not sure. Is it like maybe planner? That seems right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2497,  0.1458,  0.4034,  0.2922,  0.0360, -0.0299,  0.4077,  0.1300,\n",
            "          0.0677,  0.2813,  0.1696,  0.0697,  0.2497]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I should probably include Stephan Maier, Joachim Wagner, Jessica Hanke, Sandro Kalter and also Domiki Stein, yeah those should all be fine I guess.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Johannes Wagner', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1734, -0.0699, -0.0537,  0.1759,  0.1610,  0.2139,  0.1594, -0.0508,\n",
            "         -0.2010, -0.2320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm not really sure which one it is, but I guess it would be Government.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Defense\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3616, 0.4050, 0.3908, 0.4057, 0.4294, 0.1083, 0.3244, 0.2569, 0.2943,\n",
            "         0.3312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the defense industry.  That's what I do.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Automotive\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2698, 0.2471, 0.2932, 0.1880, 0.1675, 0.4643]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I believe the contact person is interested in things like 200 Automation, 234 Assembly Systems, or 256 Joining Systems for large components. They may be interested in others things too.\n",
            "The intended answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['Others']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3492, 0.3772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Yes, I consent to my data being processed.  I don't know what other options there are, but that's my answer.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.4490, 0.3207, 0.2904, 0.3175, 0.2990, 0.3091, 0.2792]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is probably R&D. That's what makes sense to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1423, 0.1843, 0.0886, 0.2282, 0.2082, 0.3942, 0.2532, 0.2137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Okay, so a CRM-System? Hmm, I guess that could be something like Salesforce, if that's what you mean. I'm not too sure about other possibilities, to be honest.\n",
            "The intended answer was: Salesforce\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1296,  0.1268, -0.0610]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1879, 0.2944, 0.0444, 0.0570]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.3109,  0.0656,  0.0537, -0.0385,  0.2364]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2775, 0.2869, 0.0244, 0.2279]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not sure, but maybe I'll send an email,  give a phone call, or do nothing at all.  It depends.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1254, 0.3002, 0.0304, 0.1747, 0.2731]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think it's an existing customer, maybe?  It could also be a supplier or even a competitor, I'm not sure.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3141, 0.3334, 0.0688, 0.0531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so it looks like the plan is **No action** as a follow-up. So basically, no further steps are planned right now.\n",
            "The intended answer was: ['No action']\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2332, 0.2018, 0.1859]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I think maybe 1 week would be good, or possibly 2 weeks. I am not really sure which is best though.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2350, -0.0063, -0.0327,  0.0733,  0.0644]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation,  because it sounds fascinating, and also display port debugging and compliance, as I'd like to understand how that works.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Automotive radar target simulation']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0695, 0.2884, 0.1417, 0.0214, 0.4221]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I suppose I'd say I'm most interested in high-speed interconnect testing.\n",
            "The intended answer was: ['High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0694, -0.0837,  0.0244,  0.0197,  0.0795,  0.1114]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, I guess it must be craft enterprises then, since that's the only one I know.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1414,  0.0953, -0.0920]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1775, 0.1053, 0.0496, 0.1463, 0.1622]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I'd probably say 'Scan business cards', or maybe 'Extract data from emails'. I don't really know which one's the right choice though.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The predicted answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0226, 0.5182, 0.0161, 0.3400, 0.0560]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4473, 0.3793, 0.4157, 0.4272, 0.4881, 0.4662, 0.4472]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, I think the team size would be about 35, if that makes sense.\n",
            "The intended answer was: 31-40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3041, 0.2130]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh, I think I would like to choose no. I am not interested in marketing emails right now.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2163, 0.4058, 0.1796, 0.2061, 0.2205, 0.2240, 0.2039, 0.4380, 0.2851,\n",
            "         0.0186]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, I think I am in the Computers and Networks industry. Yeah that makes sense.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2242, 0.1831, 0.3395, 0.3846, 0.1406]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow I honestly don't know all the details, but we're probably between 11 and 50 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1451, 0.2074, 0.1000, 0.0596, 0.1178, 0.0904, 0.1260, 0.2706, 0.1969,\n",
            "         0.2667]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3939, 0.4386, 0.4607]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: I'd prefer a follow up in either **1 week**, or **2 weeks**, whichever is more convenient for you.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.0951, 0.2534, 0.1270, 0.1409, 0.1129, 0.1440, 0.1244, 0.2005, 0.0947,\n",
            "         0.1700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh, you know, I'm kind of in the Network Operators & Infrastructure space, that's what I'm doing.\n",
            "The intended answer was: Network Operators & Infrastructure\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0947, 0.1769, 0.0036, 0.0657, 0.0342]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd be interested in automotive radar target simulation and also in noise figure measurements. Those two sound good to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2729, 0.2841, 0.3104, 0.2274, 0.3732, 0.3307]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they are interested in 100 Additive Manufacturing and 200 Automation, also 300 Advanced Manufacturing, or maybe 234 Assembly Systems.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1145,  0.1396, -0.0315,  0.1105,  0.2520]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'd try scanning business cards to get contact info, extracting data from emails to improve my CRM, and capturing trade fair contacts, all to improve my CRM data quality.\n",
            "The intended answer was: ['Scan business cards', 'Extract data from emails', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0601, 0.0670]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Oh sure yes I'd like that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[ 0.2606, -0.0188,  0.0893,  0.2771, -0.0036,  0.3635,  0.3564]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, customer group, huh. I guess that would be End User then.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1404,  0.1853, -0.0094,  0.1876,  0.0084]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in automotive radar target simulation, because that sounds interesting.  I'd also like to learn about noise figure measurements and display port debugging and compliance,  since those seem important.  Oh, and high-speed interconnect\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0253, 0.2751, 0.0937, 0.0769, 0.2380]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I guess it's either a supplier, like someone I get things from, or a new customer, a potential one, yeah that's it.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4379, 0.4335]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3681, 0.3285, 0.2404, 0.1370, 0.2986, 0.2573]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I guess I'd be interested in MY-SYSTEM, Notion, JTS, AKW100, and AX100, those sound like interesting products.\n",
            "The intended answer was: ['MY-SYSTEM', 'Notion', 'JTS', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'Notion']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2248, 0.4234, 0.2341, 0.2661, 0.4156]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I'm sorry, I don't see any options listed, so I can't say what type of contact it is.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2263, 0.2859, 0.1582, 0.2212, 0.2268, 0.2563]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0449, -0.0752]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4003, 0.2670, 0.2921, 0.3185, 0.3248, 0.3251, 0.2916]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, so the customer group, huh? I think we're talking about a **Wholesaler**.\n",
            "The intended answer was: Wholesaler\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4385, 0.4300, 0.4302, 0.4066, 0.4481, 0.4243, 0.3900]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Hmm, well, I'd say it's probably around 8 people for a trade fair team.\n",
            "The intended answer was: 6-10\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1480, 0.1543]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3286, 0.4736, 0.3273, 0.4123, 0.4020, 0.3258, 0.4642, 0.3532, 0.2512,\n",
            "         0.3747, 0.4653, 0.2910, 0.3136]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, hmm, I'd say copy Stephan Maier, Erik Schneider, Marisa Peng, Jens Roschmann, and Sean Kennin.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Marisa Peng', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Oliver Eibel', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2767, 0.4055, 0.2983, 0.3855, 0.3736, 0.1100]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I think they're interested in 200 Automation, because that sounds like a good number of automations to me.\n",
            "The intended answer was: ['200 Automation']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', '256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.0802, 0.0167, 0.1558, 0.1680, 0.3265, 0.0283]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I'm not really sure but maybe 234 Assembly Systems, or it could be others I really just don't know.\n",
            "The intended answer was: ['234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2149, 0.2326, 0.1631, 0.0867, 0.1872, 0.1908, 0.1781, 0.3895, 0.1804,\n",
            "         0.3169]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0384,  0.0249, -0.1258, -0.0048]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2093, 0.2442, 0.1701, 0.1395, 0.2080, 0.2439]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's a trading company, because that's the only type I can think of right now.\n",
            "The intended answer was: Trading company\n",
            "The predicted answer was: Craft enterprises\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0122,  0.0840, -0.0772,  0.0721,  0.0765]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I'm not sure, maybe none? I do not know my product interests right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0818, 0.3635, 0.2173, 0.0336, 0.1649]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'd say I'm interested in noise figure measurements and maybe also double-pulse testing. Display port debugging and compliance is another area that seems useful, along with high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1543, -0.1747,  0.0792, -0.0594, -0.1124, -0.1326, -0.0250, -0.0108]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I think maybe it's SAP Sales Cloud, that sounds right for a CRM system to me.\n",
            "The intended answer was: SAP Sales Cloud\n",
            "The predicted answer was: Close.io\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2728, 0.3336, 0.4081, 0.3292, 0.2663]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, well I'm not exactly sure, I guess it would be around 25 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4100, 0.4703, 0.4804, 0.3893, 0.3696]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I would say we are a company larger than 2000 people. That's the size of my company.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3613, 0.3020, 0.3165, 0.3425]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well, for customer satisfaction, I'd say they're probably **satisfied**, if that's the option you mean. That would be good!\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1642, 0.2594, 0.2957]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: They want a follow up in a week, I think.  I don't know what other options there are.\n",
            "The intended answer was: ['1 week']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.1052,  0.1217, -0.0058,  0.1201]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm, well I guess we could send an email, or maybe do a phone call. If nothing else, there's the no action option, too.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['Phone', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2652,  0.0135,  0.0143, -0.0561, -0.1734]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm trying to figure out how to get data out of emails and make my CRM data better,  I think those are the best options.\n",
            "The intended answer was: ['Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3384, 0.4384, 0.4789, 0.3422, 0.3793]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we're larger than 2000 people.  We're pretty big.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2041, 0.1543, 0.1854, 0.1693, 0.3089, 0.2466, 0.2689]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0465,  0.2209, -0.0877,  0.2311,  0.2098,  0.2296]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I believe it's a construction company; that seems to be the only option I see.\n",
            "The intended answer was: Construction company\n",
            "The predicted answer was: Trading company\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2086, 0.2535, 0.2904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Oh, they'd like a follow up either in one week, or maybe two weeks, I'm not exactly sure which.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0094,  0.0322, -0.0453, -0.0735,  0.0342,  0.2162, -0.1265, -0.0299]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, for a CRM system, I guess the best option would be something like HubSpot, if that's the kind of thing we're considering.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2050, 0.2112, 0.3395, 0.3501, 0.1601]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Hmm, I'm not sure of the exact options but I'd guess our company is between 1 and 10 people.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0225, -0.0567, -0.0691, -0.0293, -0.0989, -0.0569]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'm interested in MY-SYSTEM, JTS, JS EcoLine and also AX100, yeah all of them.\n",
            "The intended answer was: ['MY-SYSTEM', 'JTS', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['MY-SYSTEM', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2186, 0.2515, 0.1661, 0.1605]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1869, 0.3023, 0.0781, 0.1726]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: I guess I would say very satisfied. That seems like it fits best for me.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2269,  0.2249,  0.1075, -0.0061]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer satisfaction\n",
            "Context: Well I guess I'm unsatisfied then, that's how I feel.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1584, -0.0988, -0.1760]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: I guess the next step should be offer, yeah that sounds about right.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1793, 0.3819, 0.0743, 0.0287, 0.3904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well, it could be a Supplier, or maybe a New customer or Prospect, or possibly even Press or media. I am really not sure, it's one of those.\n",
            "The intended answer was: ['Supplier', 'New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0757,  0.2676, -0.0430,  0.0928, -0.1494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1942, 0.3584, 0.3026, 0.2902, 0.3730]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, it could be a new customer or prospect, maybe someone from the press or media. It might even be a competitor I guess.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2609, 0.3285, 0.3339, 0.3283, 0.3274]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: Oh, um, I think I'd probably choose German. I guess that's the one I'm going with.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2688,  0.0881,  0.0093, -0.1184, -0.1494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: I'm interested in things like business cards, improving data, cleaning up data, and ensuring data quality.  Those seem important to me.\n",
            "The intended answer was: ['BusinessCards', 'DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0147,  0.0776,  0.3132,  0.2922,  0.0189]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh geez I'm not sure I know, maybe it's a competitor?\n",
            "The intended answer was: ['Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1937, 0.2140, 0.2250, 0.3572]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Okay, so for follow up, I think it's either going to be an email, a phone call, or we'll just take no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'No action']\n",
            "The predicted answer was: ['No action']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2525, 0.2672, 0.2799]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Hmm, I suppose maybe one week, two weeks, or even three weeks would work for a follow up, any of those should be fine I think.\n",
            "The intended answer was: ['1 week', '2 weeks', '3 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.1861, 0.2788, 0.1956, 0.2884, 0.2021]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in testing things, like double-pulse testing and high-speed interconnect testing.  I also think display port debugging and compliance testing sounds interesting.\n",
            "The intended answer was: ['Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3859, 0.3100, 0.4001, 0.3658, 0.3789]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which language is wanted for communication? \n",
            "Context: I'd prefer Italian, since that's the language I know best.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Japanese \n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3040, 0.3602, 0.1592, 0.2574]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh hmm I guess it could be an email or maybe we could schedule a visit but there might also be no action at all.\n",
            "The intended answer was: ['Email', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Phone']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1461, -0.2064, -0.0896, -0.0715, -0.2185, -0.2622, -0.1812, -0.0324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I guess it must be Microsoft Dynamics, because I am not sure what other ones there are.\n",
            "The intended answer was: Microsoft Dynamics\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3910, 0.3397, 0.2063, 0.2543]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1267,  0.1891,  0.2630, -0.0020]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I think we can follow up by email, or we can call on the phone. Perhaps we could also schedule a visit, that would be good too.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2754, 0.2104, 0.3651, 0.2711, 0.3240, 0.4041, 0.2691]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh gosh, I think the customer group might be a consultant, if I had to guess.\n",
            "The intended answer was: Consultant\n",
            "The predicted answer was: Architect\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1912, 0.3047, 0.1092, 0.0713, 0.3579, 0.0972, 0.2334, 0.2720, 0.2910,\n",
            "         0.4962]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: I'm in the automotive industry.  I work with cars, you know,  the kind you drive.\n",
            "The intended answer was: Automotive\n",
            "The predicted answer was: Physical Security\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0908,  0.3368,  0.0908,  0.1021, -0.1442, -0.0150,  0.1311,  0.1316]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3440, 0.3387, 0.3066, 0.2807]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: I'm not really sure what follow up is planned, I don't have that information right now.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['Email', 'Phone']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3311, 0.3038, 0.3482, 0.3027, 0.0938, 0.2937, 0.3488, 0.3295, 0.2867,\n",
            "         0.3320, 0.2662, 0.3156, 0.3286]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, for follow up I guess I should copy Joachim Wagner, and also Marisa Peng. I'll also add Sandro Kalter, and Jens Roschmann too, just to be safe.\n",
            "The intended answer was: ['Joachim Wagner', 'Marisa Peng', 'Sandro Kalter', 'Jens Roschmann']\n",
            "The predicted answer was: ['Stephan Maier', 'Erik Schneider', 'Johannes Wagner', 'Jessica Hanke', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0433, 0.3199, 0.3064, 0.2302, 0.2980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think it's either a new customer or someone from the press, maybe? It's hard to know for sure.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.5012, 0.5483, 0.5688, 0.4022, 0.3928]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'm not sure what the options are, but I'd guess we have around 800 employees.\n",
            "The intended answer was: 201-2000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0972,  0.1504, -0.0694, -0.1278, -0.0854]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose business cards would be one thing and visit reports, those seem reasonable too.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2507, 0.2012, 0.2662]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I suppose either 1 week or 2 weeks would be good for a follow up. I don't really have a preference.\n",
            "The intended answer was: ['1 week', '2 weeks']\n",
            "The predicted answer was: ['3 weeks']\n",
            "The intended answer in BINARY was: [1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1]\n",
            "\n",
            "tensor([[0.2461, 0.2426, 0.1263, 0.1765, 0.0363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, company size? Hmm, I guess it would be about 30 people.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2249, 0.2305]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2022, 0.3725, 0.5133, 0.4736, 0.3855]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, um, I guess it could be a new customer or prospect. Or maybe press or media? Could be a competitor, I suppose.\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.1209, -0.0013,  0.1672,  0.1477,  0.1635,  0.1099,  0.0575]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2862, 0.2524, 0.2863, 0.3763, 0.0898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh gosh, I really have no idea how many people work at my company. It feels like maybe, um, 5, between one and ten.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3121, 0.3262, 0.3440, 0.2988, 0.0918]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1683, 0.4237, 0.1404, 0.1830, 0.3009, 0.0869, 0.4205, 0.1422, 0.2045,\n",
            "         0.2406, 0.1856, 0.1673, 0.1888]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh I would probably copy Stephan Maier, Erik Schneider, Oliver Eibel, Jessica Hanke, Jens Roschmann and also Domiki Stein. They'd all need to know.\n",
            "The intended answer was: ['Stephan Maier', 'Erik Schneider', 'Oliver Eibel', 'Jessica Hanke', 'Jens Roschmann', 'Domiki Stein']\n",
            "The predicted answer was: ['Joachim Wagner', 'Angelina Haug', 'Johannes Wagner']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1325, 0.3126, 0.2202, 0.1770, 0.3651]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh gosh, I'm not sure, maybe 'Capture trade fair contacts'? That sounds like something someone would want to solve for.\n",
            "The intended answer was: ['Capture trade fair contacts']\n",
            "The predicted answer was: ['Clean up CRM', 'Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2062, 0.0923, 0.2343, 0.3122, 0.2459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh wow, that's a good question, but I really have no clue, maybe we are between 1 and 10.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-2000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0877, 0.0659, 0.1485, 0.2527]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: I think I'm a new customer, since this is my first time.  I don't know what other types there are.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.0116, -0.0256, -0.0077, -0.0055, -0.0472,  0.0106,  0.3672]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3370, 0.3251, 0.4246, 0.3712, 0.3860, 0.2440, 0.3550, 0.3630, 0.2936,\n",
            "         0.3249, 0.3910, 0.3125, 0.3131]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Joachim Wagner, Johannes Wagner, Sandro Kalter, Jens Roschmann, and Tim Persson.  They all need to be in the loop for this follow-up.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Johannes Wagner', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The predicted answer was: ['Erik Schneider', 'Oliver Eibel', 'Angelina Haug', 'Jessica Hanke', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0572,  0.3625, -0.0167, -0.0333,  0.3018]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I think maybe they're an existing customer, or perhaps a supplier, or could it be press media, or maybe even a competitor.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2344, 0.0869, 0.2486, 0.2262, 0.2398, 0.2776, 0.2845, 0.1629, 0.3117,\n",
            "         0.3079]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0724, -0.0028, -0.0060,  0.0921,  0.2464]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I would search for something like scan business cards or clean up CRM, maybe even improve CRM data quality, and also capture trade fair contacts.\n",
            "The intended answer was: ['Scan business cards', 'Clean up CRM', 'Improve CRM data quality', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Capture trade fair contacts']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2945, 0.2999, 0.3308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2831, 0.2690, 0.2366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When does the contact person wish to receive a follow up?\n",
            "Context: Well I'm not sure which but maybe they want it in 2 weeks or possibly 3 weeks, those seem like the options.\n",
            "The intended answer was: ['2 weeks', '3 weeks']\n",
            "The predicted answer was: ['1 week']\n",
            "The intended answer in BINARY was: [0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0]\n",
            "\n",
            "tensor([[-0.1289,  0.0661, -0.1514, -0.0936,  0.3564,  0.2778, -0.2193, -0.0515]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4249, 0.4801, 0.4867]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2057,  0.3462,  0.0937, -0.1074,  0.0331]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in a few things, like automotive radar target simulation, also noise figure measurements, and even high-speed interconnect testing.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Automotive radar target simulation', 'Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1179, 0.3697, 0.2030, 0.1770, 0.3733]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Okay, so, the contact type could be an 'Existing customer', a 'New customer / Prospect', maybe someone from 'Press / media', or even a 'Competitor'.\n",
            "The intended answer was: ['Existing customer', 'New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0477, 0.3158, 0.1559, 0.1520, 0.3248]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh, the contact type? Hmm, it could be a \"New customer / Prospect,\" maybe someone we hope to work with. Or, it could be \"Press / media\", you know, journalists. Possibly, it's a \"Competitor\".\n",
            "The intended answer was: ['New customer / Prospect', 'Press / media', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1724, 0.0148, 0.0868, 0.0401, 0.0725]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well I suppose data quality would be what I am most interested in.\n",
            "The intended answer was: ['DataQuality']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1669, 0.2293, 0.1518, 0.1497, 0.1614, 0.2429]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh, umm, I think it's a production company. I'm not totally sure though.\n",
            "The intended answer was: Production company\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2605, 0.0485, 0.2451, 0.0557, 0.0429, 0.0740]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1962, 0.2594, 0.2389, 0.1018, 0.3507, 0.2967]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Well, I'm interested in learning about 'MY-SYSTEM', 'JS EcoLine', 'AKW100', and 'AX100' products. It's hard to pick just one; all sound like potential options I want to consider.\n",
            "The intended answer was: ['MY-SYSTEM', 'JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1320,  0.1496, -0.1270, -0.1300, -0.1005,  0.0348,  0.0887]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0920, -0.0347]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: Okay, I'd have to choose \"No\". So, yeah, \"No\" is the option I'm going with.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.0758,  0.1452, -0.0884, -0.0802, -0.0791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh wow, for product interests I'd say DataEnrichment is a thing, plus VisitReport, and also I guess DataQuality makes sense.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1802, -0.1784, -0.0161, -0.0832, -0.0794, -0.0054,  0.1430,  0.0801]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh a CRM system. Hmm, I guess I'd say HubSpot. That's the only one I can really think of right now.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: SAP Sales Cloud\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0968, 0.1847]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Oh I suppose I'd say yes then. I guess thats the answer to that.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.1145,  0.3881,  0.0937, -0.2129,  0.3101]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in things like measuring noise figures,  doing double-pulse tests, and testing high-speed interconnects because those sound like interesting challenges.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'High-speed interconnect testing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3279, 0.2906]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Would you like to receive marketing information from via e-mail?\n",
            "Context: No, I would not like to receive marketing information via e-mail.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 2.4784e-01,  2.3538e-01,  1.4684e-04, -2.3471e-02, -5.8403e-02,\n",
            "         -2.0792e-02,  4.0063e-01]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Oh, hmm, I guess it would be end user. Yeah, I think that makes the most sense for this.\n",
            "The intended answer was: End User\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4558, 0.3077, 0.4698, 0.4158, 0.4490, 0.4589, 0.4575, 0.3630, 0.1733,\n",
            "         0.1908]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gosh I'm not totally sure, but I think I'd have to say Medical, I suppose.\n",
            "The intended answer was: Medical\n",
            "The predicted answer was: Government\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0712,  0.1060,  0.0508, -0.0274,  0.0632]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in, uh, let's see... BusinessCards. So, I guess that's what I'd be interested in.\n",
            "The intended answer was: ['BusinessCards']\n",
            "The predicted answer was: ['DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5001, 0.5500, 0.5624, 0.4341, 0.4319]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: I'd say we have around 30 employees.  I'm not sure of the exact breakdown of sizes they offered, but that feels right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.2250, -0.1318,  0.3130,  0.2120]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1425, 0.3385, 0.2504, 0.3301, 0.3258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, I think my product interests are BusinessCards, like those for networking. Also, VisitReport to document sales stuff, Data Cleansing because of course. Finally, DataQuality is very important, yes, those are my product interests.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The predicted answer was: ['DataEnrichment', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.1324, -0.0092,  0.1303,  0.0148, -0.2070,  0.0925,  0.0651]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I'm not sure what options there are, but I'd say Planner sounds right.\n",
            "The intended answer was: Planner\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0483,  0.1446, -0.1435,  0.1637, -0.0456]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2460, 0.3437, 0.2004, 0.2036, 0.1998, 0.2712, 0.1427, 0.3951, 0.2814,\n",
            "         0.2890]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Oh gee, I really don't know all of them. But I think I'm in the Industrial one. Yeah, that sounds right to me.\n",
            "The intended answer was: Industrial\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1862,  0.1581, -0.1586]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1867, 0.2946, 0.2878, 0.3156, 0.3018, 0.3009, 0.2793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: Hmm, I guess the customer group would be R&D then, that's what I'm thinking.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Consultant\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2739, 0.2063, 0.3506, 0.4260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Okay, I believe that customer type is \"new customer,\" meaning it is their first time.\n",
            "The intended answer was: New customer\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4190, 0.3924, 0.3425, 0.3942, 0.4335]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0134, -0.0295, -0.0767,  0.1914,  0.0659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: I'm looking for something to help me, maybe to scan business cards or capture trade fair contacts, those sound helpful.\n",
            "The intended answer was: ['Scan business cards', 'Capture trade fair contacts']\n",
            "The predicted answer was: ['Improve CRM data quality']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2767, 0.3343, 0.2163]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Okay, so for next steps, I guess I could **offer** something.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1368,  0.2287, -0.0421,  0.1038,  0.1014]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I'm interested in things like automotive radar target simulation, noise figure measurements, and display port debugging and compliance, those seem useful to me.\n",
            "The intended answer was: ['Automotive radar target simulation', 'Noise figure measurements', 'Display port debugging and compliance']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2322, 0.2593, 0.0965, 0.1753]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2955, 0.2938, 0.3453, 0.2580]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Hmm, I'd probably say a phone call is planned as the follow up.\n",
            "The intended answer was: ['Phone']\n",
            "The predicted answer was: ['Schedule a Visit']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.0069, -0.0544,  0.0508, -0.1243, -0.1346]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Well, I'm interested in both DataEnrichment and VisitReport I think those seem like useful things to me.\n",
            "The intended answer was: ['DataEnrichment', 'VisitReport']\n",
            "The predicted answer was: ['BusinessCards', 'VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2168, 0.2318, 0.1968, 0.2039, 0.3020, 0.3510]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Well I think they're interested in 200 Automation, 300 Advanced Manufacturing, 234 Assembly Systems, and maybe others too. I'm not totally sure.\n",
            "The intended answer was: ['200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2596, 0.3035, 0.2504, 0.2515, 0.2462, 0.3257]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Hmm, I'm not really sure, maybe it's a craft enterprise type of company.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[ 0.2074,  0.0499,  0.2421, -0.0932, -0.1113, -0.0623,  0.1609]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2395,  0.1708,  0.1618,  0.1913, -0.0496]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I guess Data Cleansing sounds interesting to me then. I'm not sure about any other options though.\n",
            "The intended answer was: ['Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards', 'Data Cleansing']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3999, 0.4614, 0.3975, 0.3973, 0.3799]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Well, our company size is 51-200 people. That's the only size range I'm aware of, so we must fit into that category.\n",
            "The intended answer was: 51-200\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1148,  0.1641, -0.0162]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2874, 0.3883, 0.3697, 0.2925, 0.2592, 0.2637, 0.3907, 0.2509, 0.3354,\n",
            "         0.3005, 0.3598, 0.2670, 0.3119]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Oh, I'm not sure who to copy. Maybe Angelina Haug, Marisa Peng, Jessica Hanke, Jens Roschmann or Sean Kennin? I don't know for sure.\n",
            "The intended answer was: ['Angelina Haug', 'Marisa Peng', 'Jessica Hanke', 'Jens Roschmann', 'Sean Kennin']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Johannes Wagner', 'Sandro Kalter', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0330,  0.3532, -0.0469, -0.0198, -0.0395, -0.0109, -0.0343,  0.2795,\n",
            "          0.2272,  0.2484]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3875, 0.4037, 0.4128, 0.3879, 0.4179, 0.4071, 0.4079]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: I'd say the trade fair team is usually around 45 people.  I'm not sure what other sizes are possible.\n",
            "The intended answer was: more than 40\n",
            "The predicted answer was: 21-30\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2235, 0.3317, 0.2804, 0.2304]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.0458,  0.0396,  0.0006, -0.0732]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh, for follow up I think we could email, or call them by phone maybe we should also schedule a visit.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit']\n",
            "The predicted answer was: ['Phone', 'Schedule a Visit']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1855, 0.3296, 0.1985, 0.3086, 0.2756, 0.3713]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: I'm not sure, but they might be interested in additive manufacturing, automation, or advanced manufacturing, maybe assembly systems, or something else entirely.  It could be any of those.\n",
            "The intended answer was: ['100 Additive Manufacturing', '200 Automation', '300 Advanced Manufacturing', '234 Assembly Systems', 'Others']\n",
            "The predicted answer was: ['200 Automation', '234 Assembly Systems', 'Others']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1674, 0.1627, 0.1565, 0.2919, 0.1453, 0.3838, 0.2376, 0.2830]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Oh, um, I think it might be Adito? Yeah, I guess I'd pick Adito.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.1687, -0.0330, -0.1807, -0.0850, -0.1531, -0.1158]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Oh, well, I guess I'd be interested in Notion, and also maybe JS EcoLine, and also, uh, AX100 seems good too.\n",
            "The intended answer was: ['Notion', 'JS EcoLine', 'AX100']\n",
            "The predicted answer was: ['Notion', 'JS EcoLine']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1529, 0.1629, 0.2948, 0.1873, 0.0208]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh I think I'm interested in DataEnrichment, that sounds important. Also Data Cleansing seems pretty necessary, so yeah both those things.\n",
            "The intended answer was: ['DataEnrichment', 'Data Cleansing']\n",
            "The predicted answer was: ['VisitReport']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0391, 0.3272, 0.1383, 0.2602, 0.1460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: I'm interested in noise figure measurements, because they're important.  I also want to learn about double-pulse testing and display port debugging and compliance, plus high-speed interconnect testing.  It all seems really interesting.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements', 'Display port debugging and compliance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.1193, -0.0597, -0.0440, -0.1052, -0.1951]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, well, I think I'd be interested in VisitReport and also Data Cleansing, those seem like good things.\n",
            "The intended answer was: ['VisitReport', 'Data Cleansing']\n",
            "The predicted answer was: ['BusinessCards']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0752,  0.4292,  0.2056,  0.0800, -0.0146]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What products are you interested in?\n",
            "Context: Well, I guess I'd be interested in noise figure measurements, and also double-pulse testing, maybe display port debugging and compliance, plus high-speed interconnect testing.\n",
            "The intended answer was: ['Noise figure measurements', 'Double-Pulse Testing', 'Display port debugging and compliance', 'High-speed interconnect testing']\n",
            "The predicted answer was: ['Noise figure measurements']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3117, 0.3176, 0.2989, 0.2794, 0.1431, 0.2466, 0.2954, 0.3226, 0.3245,\n",
            "         0.3137, 0.3049, 0.2428, 0.3533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: Okay, so for follow-up, I think I should copy Stephan Maier, then Joachim Wagner, also Jessica Hanke, and lastly Domiki Stein too. That covers everyone.\n",
            "The intended answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Domiki Stein']\n",
            "The predicted answer was: ['Stephan Maier', 'Joachim Wagner', 'Jessica Hanke', 'Sandro Kalter', 'Jens Roschmann', 'Tim Persson']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3162, 0.2001, 0.2928, 0.3364, 0.1514, 0.2223]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the contact person interested in?\n",
            "Context: Oh I guess they might be into 256 joining systems for large components, or something else, like maybe something different.\n",
            "The intended answer was: ['256 Joining Systems for large components', 'Others']\n",
            "The predicted answer was: ['100 Additive Manufacturing', '300 Advanced Manufacturing', '234 Assembly Systems']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2034, 0.1421, 0.1814, 0.0946, 0.1409]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Oh, hmm. I'd probably say I am searching a solution for cleaning up the CRM, or maybe extracting data from emails, or actually also improving CRM data quality. Those seem like things I need to solve.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails', 'Improve CRM data quality']\n",
            "The predicted answer was: ['Scan business cards', 'Extract data from emails']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4105, 0.3683, 0.2097, 0.1590]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4097, 0.4388, 0.2329, 0.2951, 0.3731, 0.4982, 0.3291, 0.3293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: Hmm, I'm not sure, but I think maybe Adito could be the CRM-system.\n",
            "The intended answer was: Adito\n",
            "The predicted answer was: CAS\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2184, -0.1408,  0.0258, -0.0506]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What kind of follow up is planned\n",
            "Context: Oh well, I suppose we could follow up by email, phone, or schedule a visit. But you know, there's always the option of no action at all.\n",
            "The intended answer was: ['Email', 'Phone', 'Schedule a Visit', 'No action']\n",
            "The predicted answer was: ['Schedule a Visit', 'No action']\n",
            "The intended answer in BINARY was: [1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.0759, 0.3312, 0.0194]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.2846,  0.2477,  0.2906,  0.3045,  0.2564,  0.3021,  0.2669, -0.0528,\n",
            "         -0.0480,  0.0047]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well, I think I'm mostly operating in Computers & Networks, since I deal with, well, computers, so yeah.\n",
            "The intended answer was: Computers & Networks\n",
            "The predicted answer was: Medical\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2210, 0.2573, 0.2158, 0.0667, 0.1948]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Okay, I'm interested in a few things. Specifically, I'd like to learn more about **BusinessCards** and **DataQuality**. That sounds useful.\n",
            "The intended answer was: ['BusinessCards', 'DataQuality']\n",
            "The predicted answer was: ['BusinessCards', 'DataEnrichment']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1742,  0.2698, -0.0945,  0.1698,  0.1296,  0.1960,  0.1399,  0.2374,\n",
            "          0.1291,  0.0891]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Well I guess I would say I'm in government. I'm not really sure of other choices anyway.\n",
            "The intended answer was: Government\n",
            "The predicted answer was: Computers & Networks\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2977, 0.2729, 0.3109, 0.2043, 0.3291, 0.3210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: Okay, I'm interested in the products. Let me see... Ah, just the AX100, that's the one that caught my eye.\n",
            "The intended answer was: ['AX100']\n",
            "The predicted answer was: ['JTS', 'AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3632, 0.5584, 0.4408, 0.3982, 0.0966]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the size of your company?\n",
            "Context: Oh, you're asking about the size of my company. Well, it's **larger than 2000**, so a fairly big organization.\n",
            "The intended answer was: larger than 2000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1445, -0.1407,  0.0930,  0.2181, -0.0834,  0.1044,  0.0714,  0.0908]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4104, 0.0593, 0.2712, 0.3543, 0.1768, 0.3932, 0.0997]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer group\n",
            "Context: I think the customer group is architects,  I'm not sure what other options there are.\n",
            "The intended answer was: Architect\n",
            "The predicted answer was: End User\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3555, 0.4677, 0.4511, 0.3579, 0.4507, 0.2889, 0.4634, 0.3188, 0.3787,\n",
            "         0.3613, 0.4447, 0.3459, 0.3383]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who to copy in follow up\n",
            "Context: I'd copy Stephan Maier, Oliver Eibel, Marisa Peng, Jessica Hanke, Sean Kennin, and Tim Persson;  they all need to know about the follow up.\n",
            "The intended answer was: ['Stephan Maier', 'Oliver Eibel', 'Marisa Peng', 'Jessica Hanke', 'Sean Kennin', 'Tim Persson']\n",
            "The predicted answer was: ['Joachim Wagner', 'Erik Schneider', 'Angelina Haug', 'Johannes Wagner', 'Domiki Stein']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2480, 0.3108, 0.5421, 0.4099, 0.2691]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Hmm, I'm not sure exactly. Is it either an existing customer or someone from the press, like the media?\n",
            "The intended answer was: ['Existing customer', 'Press / media']\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2828, 0.4095, 0.3996, 0.3936, 0.3993]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: I think the type of contact is an \"Existing customer\", which I believe is someone already doing business with us.\n",
            "The intended answer was: ['Existing customer']\n",
            "The predicted answer was: ['Supplier', 'New customer / Prospect', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.1465, 0.4093, 0.1564, 0.1627, 0.1397, 0.1283, 0.1253, 0.5144, 0.4926,\n",
            "         0.3743]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What industry are you operating in?\n",
            "Context: Hmm, it seems like I'm operating in the **Defense** industry. That must mean I'm involved in work related to military or security matters.\n",
            "The intended answer was: Defense\n",
            "The predicted answer was: Network Operators & Infrastructure\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2967, 0.3519, 0.3368, 0.2917, 0.3875, 0.3789]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in the JS EcoLine, the AKW100, and the AX100  because they seem like good products.\n",
            "The intended answer was: ['JS EcoLine', 'AKW100', 'AX100']\n",
            "The predicted answer was: ['AKW100', 'AX100']\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.0362,  0.2615,  0.0645,  0.2769, -0.0227]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Searches a solution for\n",
            "Context: Hmm, I think I would look for how to clean up CRM, or maybe how to extract data from emails, those seem like good places to start.\n",
            "The intended answer was: ['Clean up CRM', 'Extract data from emails']\n",
            "The predicted answer was: ['Clean up CRM', 'Improve CRM data quality']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3682, 0.3675, 0.3569, 0.3553, 0.3908, 0.3790, 0.3744]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1143, 0.3178, 0.2210, 0.2638, 0.2986]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Well I'm not sure, is it an existing customer or a competitor.\n",
            "The intended answer was: ['Existing customer', 'Competitor']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0763,  0.1312,  0.3972,  0.4173,  0.1131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh gosh, I'm not sure. I'd say it is a contact of some type.\n",
            "The intended answer was: []\n",
            "The predicted answer was: ['New customer / Prospect', 'Press / media']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[ 0.0168,  0.1609, -0.0357]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Next steps\n",
            "Context: Well I think the next step should be to offer, I suppose.\n",
            "The intended answer was: Offer\n",
            "The predicted answer was: Meeting\n",
            "The intended answer in BINARY was: [1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0]\n",
            "\n",
            "tensor([[0.1987, 0.1088, 0.2287, 0.2213, 0.1927, 0.2553]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: Oh I'm not really sure what kind of company it is, maybe it's craft enterprises.\n",
            "The intended answer was: Craft enterprises\n",
            "The predicted answer was: Education sector\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.0407,  0.3400,  0.1097,  0.1860,  0.3371]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is the type of contact?\n",
            "Context: Oh wow, I'm not really sure. It could be an existing customer, a supplier, or maybe even someone from the press or media, I guess.\n",
            "The intended answer was: ['Existing customer', 'Supplier', 'Press / media']\n",
            "The predicted answer was: ['Supplier', 'Competitor']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1041, 0.4655, 0.0353, 0.0361, 0.0788, 0.0457, 0.0955, 0.3834, 0.2086,\n",
            "         0.4023]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0431, -0.0531,  0.0684, -0.0274,  0.0516, -0.0738,  0.0844,  0.1320]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: CRM-System\n",
            "Context: I'd use HubSpot, I think.  I don't know about the other options, but that's the one that comes to mind.\n",
            "The intended answer was: HubSpot\n",
            "The predicted answer was: Adito\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2264, 0.2127, 0.2010, 0.2144, 0.2269, 0.1882]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of company is it?\n",
            "Context: I think it's an education sector company. That's the only thing that makes sense to me.\n",
            "The intended answer was: Education sector\n",
            "The predicted answer was: Production company\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3229, 0.3742, 0.3646, 0.2465, 0.3095, 0.3342]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Products interested in\n",
            "Context: I'm interested in JTS and JS EcoLine,  because those sound like good product names.\n",
            "The intended answer was: ['JTS', 'JS EcoLine']\n",
            "The predicted answer was: ['Notion', 'JTS']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2175, -0.1848,  0.1086]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1552, 0.3072, 0.3113, 0.1470, 0.1432, 0.3075]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3320, 0.3646, 0.2831, 0.2730, 0.3440, 0.3312, 0.3386]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Size of the trade fair team (on average)\n",
            "Context: Oh, the team size. Well I think it's usually around 25 people, give or take a few.\n",
            "The intended answer was: 21-30\n",
            "The predicted answer was: 6-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0574, 0.1106]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Data processing consent\n",
            "Context: Okay, for data processing consent, it looks like the only option here is 'Yes'. So, yeah, I consent.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.0995, 0.1660, 0.1601, 0.3618]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Customer type\n",
            "Context: Oh customer type. Hmm, I'd say it is probably Partner. That's the one I think it is.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Applicant\n",
            "The intended answer in BINARY was: [0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2009, -0.1422, -0.0816, -0.0647, -0.0630]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Productinterests\n",
            "Context: Oh, hmm, I guess I'd say BusinessCards, maybe VisitReport, and also DataQuality.\n",
            "The intended answer was: ['BusinessCards', 'VisitReport', 'DataQuality']\n",
            "The predicted answer was: ['VisitReport', 'Data Cleansing', 'DataQuality']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"The metrics for all mc questions in the train dataset:\\n{model_name}: {mc_metric_result}\")\n",
        "mc_metric_result['model_name'] = model_name\n",
        "model_results.append(mc_metric_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ncfp_BNqgaXs",
        "outputId": "c14d252a-e7d3-4e2c-bebc-cd28df8aaf2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The metrics for all mc questions in the train dataset:\n",
            "albert/albert-base-v2: {'accuracy': 0.6314363143631436, 'f1': 0.3789954337899543, 'precision': 0.4129353233830846, 'recall': 0.350210970464135}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This seems to be better than the last one, but not as good as the bert model\n",
        "\n",
        "\n",
        "```\n",
        "{'accuracy': 0.6314363143631436, 'f1': 0.3789954337899543, 'precision': 0.4129353233830846, 'recall': 0.350210970464135}\n",
        "```\n",
        "\n",
        "All in all, the **\"bert-base-uncased\"** works best for our task."
      ],
      "metadata": {
        "id": "BdhHpc3r9XoF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tuning a model\n",
        "\n",
        "As mentioned above, the **\"bert-base-cased\"** model is doing quite well on the QA-dataset we created.\n",
        "But also **\"albert/albert-base-v2\"** managed get quite good results in view to the relatively little size of the model.\n",
        "Also it is known for faster learning.\n",
        "This is the reason why we want to **fine-tune both models.**\n",
        "\n",
        "For doing so we have to preprocess the data.\n",
        "In fact, we can use almost the same as the tokenize_function() for that."
      ],
      "metadata": {
        "id": "O_wI4yRfO835"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(example):\n",
        "    '''\n",
        "    Converts the question/example with its context and the given options for multi-/single-select questions, into IDs the model later can make sense of. Distinguishes between multi-/single-select and the other questions\n",
        "    parameters:\n",
        "    - expample: question of the QA-dataset with all its entries (question, context, options, type are urgently necessary)\n",
        "    - tokenizer: tokenizer of the model\n",
        "    output:\n",
        "    - tokenized: tokenized input example\n",
        "    '''\n",
        "    if example[\"type\"] == \"SINGLE_SELECT\" or example[\"type\"] == \"MULTI_SELECT\":\n",
        "      number_of_options = len(example[\"options\"])\n",
        "      first_sentence = [[example[\"context\"]] * number_of_options]  # Repeat context for each option\n",
        "      second_sentence = [[example[\"question\"] + \" \" + option] for option in example[\"options\"]]  # Pair with each option\n",
        "      tokenized = tokenizer(\n",
        "          sum(first_sentence, []),\n",
        "          sum(second_sentence, []),\n",
        "          padding=\"longest\",\n",
        "          truncation=True\n",
        "      )\n",
        "      # Un-flatten\n",
        "      return {k: [v[i:i+number_of_options] for i in range(0, len(v), number_of_options)] for k, v in tokenized.items()}\n",
        "\n",
        "    elif example['type'] == 'NUMBER':\n",
        "      tokenized = tokenizer(\n",
        "          example['context'],\n",
        "          example['question'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "    else:\n",
        "      tokenized = tokenizer(\n",
        "          example['question'],\n",
        "          example['context'],\n",
        "          truncation=\"only_second\",\n",
        "          max_length=384,\n",
        "          padding=\"max_length\",\n",
        "          return_tensors=\"pt\"\n",
        "      )\n",
        "\n",
        "    return tokenized"
      ],
      "metadata": {
        "id": "sOIGkF2pa0-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can't use the normal DataCollator, so we have to define our own DataCollatorForMultipleChoice.\n",
        "\n",
        "The `DataCollatorForMultipleChoice` performs **dynamic padding** and **batch preparation** for a multiple-choice task.\n",
        "\n",
        "🔹 **Key Responsibilities**:\n",
        "\n",
        "1️⃣ **Pads Missing Choices:**  \n",
        "   - Ensures that all questions have the same number of answer choices by padding shorter ones with empty token sequences.\n",
        "\n",
        "2️⃣ **Reshapes Data for Model Input:**  \n",
        "   - Converts batch tensors into shape `(batch_size, num_choices, sequence_length)` so the model can process them correctly.\n",
        "\n",
        "3️⃣ **Handles Label Padding (if needed):**  \n",
        "   - Ensures labels are also padded if they contain multiple selections (for multi-select questions).\n",
        "\n",
        "🔹 **Why This is Important?**\n",
        "\n",
        "✅ Handles **variable answer choices** per question (different number of options per question).  \n",
        "✅ Ensures **uniform input shape** so the model can process all questions in a batch.  \n",
        "✅ Supports **both single-select and multi-select** multiple-choice tasks.  \n"
      ],
      "metadata": {
        "id": "UKZLRsS51jLV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@dataclass\n",
        "class DataCollatorForMultipleChoice:\n",
        "    \"\"\"\n",
        "    Data collator that will dynamically pad the inputs for multiple choice received.\n",
        "    \"\"\"\n",
        "\n",
        "    tokenizer: PreTrainedTokenizerBase\n",
        "    padding: Union[bool, str, PaddingStrategy] = True\n",
        "    max_length: Optional[int] = None\n",
        "    pad_to_multiple_of: Optional[int] = None\n",
        "\n",
        "    def __call__(self, features):\n",
        "        label_name = \"label\" if \"label\" in features[0] else \"labels\"\n",
        "        labels = [feature.pop(label_name) for feature in features]\n",
        "        batch_size = len(features)\n",
        "\n",
        "        # Determine the maximum number of choices in the batch\n",
        "        max_choices = max(len(label) for label in labels)\n",
        "        # Pad missing choices for each feature\n",
        "        for feature in features:\n",
        "            num_choices = len(feature[\"input_ids\"])\n",
        "            while len(feature[\"input_ids\"]) < max_choices:\n",
        "                for key in feature.keys():\n",
        "                    feature[key].append([0] * len(feature[key][0]))  # Pad with zeros\n",
        "\n",
        "        # Flatten for tokenization\n",
        "        flattened_features = [\n",
        "            [{k: v[i] for k, v in feature.items()} for i in range(max_choices)]\n",
        "            for feature in features\n",
        "        ]\n",
        "        flattened_features = sum(flattened_features, [])\n",
        "\n",
        "        batch = self.tokenizer.pad(\n",
        "            flattened_features,\n",
        "            padding=self.padding,\n",
        "            max_length=self.max_length,\n",
        "            pad_to_multiple_of=self.pad_to_multiple_of,\n",
        "            return_tensors=\"pt\",\n",
        "        )\n",
        "\n",
        "        # Reshape tensors to match (batch_size, num_choices, sequence_length)\n",
        "        batch = {k: v.view(batch_size, max_choices, -1) for k, v in batch.items()}\n",
        "\n",
        "        # Handle label padding if necessary\n",
        "        for i, label in enumerate(labels):\n",
        "            if isinstance(label, list):  # Handle MULTI_SELECT cases\n",
        "                labels[i] += [0] * (max_choices - len(label))  # Pad labels with 0s\n",
        "            else:\n",
        "                labels[i] = label  # Keep as-is for SINGLE_SELECT\n",
        "        batch[\"labels\"] = torch.tensor(labels, dtype=torch.float).view(batch_size, -1)\n",
        "\n",
        "        return batch\n"
      ],
      "metadata": {
        "id": "4VeNF--QgYRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then we can load the metric, which is key for choosing a model of a certain epoch.\n",
        "This metric is computed with the compute_metrics() function.\n",
        "With that one, we choose the answers as we did it before for multiple choice questions: every option is chosen which is mean of the logits + 40% of the standard deviation.\n",
        "\n",
        "Note, that we DO NOT and CANNOT differ between single and multiple choice here.\n",
        "So it could be that the model is implicitly trained to select more than just one option also for single choice questions.\n",
        "A better approach would be to train on the single choice questions at first and on the multiple choice questions afterwards.\n",
        "Since we got aware of this problem not until the fine-tuning and evaluation was already done, we keep it like this for now."
      ],
      "metadata": {
        "id": "RNYL5XlB2w9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metric = evaluate.load(\"f1\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "85a7c501c07c48d4971ee52ed3660800",
            "5a67389b8dbb42459b53dbcd9528f904",
            "88056cc4f6da45d6a45f0a93018fcfd3",
            "79f9ab26bf5c4d5cb80abdbf1d23bf98",
            "a0b17e38d0c44a9dafd60bdf82ea5dde",
            "dfa25f2f1d694b1d8f2c5610d3b979fc",
            "a3d463d7d17a4826be8a4cf4b09b2ef2",
            "715d7f678ae243a59f0ffde618b3d636",
            "9cc1b46c2e8343228d6dfb5bfd6ed4ce",
            "7846e17e1207488e94831bcc2795af75",
            "823fe7a97b644cea94581536c41dcc87"
          ]
        },
        "id": "PVMwBuTTE3z1",
        "outputId": "2170dc6a-ed49-42ed-f157-284a08824299"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85a7c501c07c48d4971ee52ed3660800"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_preds):\n",
        "    logits, labels = eval_preds\n",
        "    predictions = []\n",
        "    for i in range(len(logits)):\n",
        "      mean_score = logits[i].mean().item()\n",
        "      std_dev = logits[i].std().item()\n",
        "\n",
        "      # Define a threshold based on deviation from the mean\n",
        "      threshold = mean_score + (0.4 * std_dev)\n",
        "      prediction = (logits[i] >= threshold).astype(int)\n",
        "      metric.add_batch(predictions=prediction, references=labels[i].astype(int))\n",
        "    return metric.compute(average=\"macro\") # maybe with parameter average = \"macro\""
      ],
      "metadata": {
        "id": "YuAtJJOHHPJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For training, we use the Hugging Face's Trainer API, which simplifies training & evaluation.\n",
        "Also we apply best practices for fine-tuning, including logging, evaluation, and model checkpointing.\n",
        "Afterwards, we save the fine-tuned model so it can be reused without retraining."
      ],
      "metadata": {
        "id": "EuKnFuzl6KCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fine_tune_model(dataset, tokenizer, model, epochs, output_dir):\n",
        "    # Preprocess the dataset\n",
        "    tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
        "    # Define training arguments\n",
        "    training_args = TrainingArguments(output_dir=output_dir,\n",
        "        eval_strategy=\"epoch\",\n",
        "        save_strategy=\"epoch\",\n",
        "        logging_strategy=\"epoch\",\n",
        "        logging_dir=\"./logs\",\n",
        "        learning_rate=4e-5,\n",
        "        num_train_epochs=epochs,\n",
        "        weight_decay=0.01,\n",
        "        logging_steps=10,\n",
        "        load_best_model_at_end=True,\n",
        "        report_to=\"none\"\n",
        "    )\n",
        "    data_collator = DataCollatorForMultipleChoice(tokenizer=tokenizer)\n",
        "\n",
        "    # Define Trainer\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=tokenized_dataset['train'],\n",
        "        eval_dataset=tokenized_dataset['test'],\n",
        "        data_collator=data_collator,\n",
        "        tokenizer=tokenizer,\n",
        "        compute_metrics=compute_metrics\n",
        "    )\n",
        "    # Train the model\n",
        "    trainer.train()\n",
        "    save_path = f\"/content/drive/MyDrive/mc_models/{output_dir}\"\n",
        "    drive.mount('/content/drive')\n",
        "    # Create the directory if it does not exist\n",
        "    if not os.path.exists(save_path):\n",
        "        os.makedirs(save_path)\n",
        "        print(f\"Directory created: {save_path}\")\n",
        "    else:\n",
        "        print(\"Directory already exists!\")\n",
        "    trainer.save_model(save_path)"
      ],
      "metadata": {
        "id": "U_k1UsB9O-l4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tuning BERT\n",
        "So let's start with the \"bert-base-cased\" model"
      ],
      "metadata": {
        "id": "w0b9R_tL6sAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the model again\n",
        "model_name = \"bert-base-cased\"\n",
        "bert_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lb4BVRLrnMr",
        "outputId": "981217af-ee9f-48b4-a5fe-133430f6753e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# filter on mc questions\n",
        "mc_qa_dataset = qa_dataset.filter(lambda example: example['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'])\n",
        "mc_qa_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99,
          "referenced_widgets": [
            "a1f5ace57a2f4818b0b42bb45111c847",
            "d314fbdfdbca4e22af269a31b8a152d6",
            "7101e252a20442d6bdde5a2ecc073c7b",
            "b37ad38c731945f9b2868e395f2abf11",
            "9655d661cc0941598426daee96169be5",
            "ab911148a1974d56a83204f7cb530197",
            "27436f46e8e048e095e15bae93bee202",
            "5c24f597099643f182d5fbcd629b47b8",
            "626d330965be40c4a1c05677513f833b",
            "420300cb47bc450887fcb5027e65deda",
            "e379c79f0eea42c7b1d2895fc20f0b88",
            "f61bd280a0e74cee800ff74f352b062c",
            "bf4e3a3831f9419d9b8cf6a8c885f3e2",
            "3f207356bfb7424ba64c1f8cceea8c7b",
            "964d010124c74ec88635d08df91dbeef",
            "14ace249903b43fa9efd27c3d33bd3d9",
            "7e8bd61f61dc42bfaf7bba15d993715b",
            "482ccabd1ec148ff9f70a62409ae5413",
            "aeeaf608b7264e10829a042ef165531a",
            "d3340a7e80d34a57bd731eb8af4c30c5",
            "5ac615ee175d4c24abf4ac804327b66c",
            "ebe4756769db4687b13681fa0d3871c8"
          ]
        },
        "id": "3cZWKdZ4wTac",
        "outputId": "8c1daccf-ee58-4f2d-bc47-020245f6cf3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/1104 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1f5ace57a2f4818b0b42bb45111c847"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Filter:   0%|          | 0/277 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f61bd280a0e74cee800ff74f352b062c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (937, 7), 'test': (235, 7)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# apply fine-tuning methods\n",
        "fine_tune_model(mc_qa_dataset, tokenizer, bert_model, 7, \"bert_fine_tuned\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "e5a9f92dacdd42aba2565cc688b26259",
            "6ce751d3668641908a1eaba1e9617983",
            "d383af551cc0451f81693b8a41c4baae",
            "52d15a82a0da4475a97547a834e92472",
            "8b2ae61c48ab432187bdb401d837bcba",
            "9d93fd218bf14786b13ff071efb3e431",
            "8fa0d2dd49454852a7064639922ce3a5",
            "726587e2fbca49cf940ff1168911a32d",
            "a4f0b4dda3e74241afbf00790567af79",
            "0b407616052e46db9ed9ebd8a6a620b4",
            "d7babf3b96cf4362ab1e013a170c90f0",
            "052cc03567bd462fbb1f8c73d53a95e7",
            "16bfe78648c148f19397b2d478655dd3",
            "2d46eaa1dc0542c49fa7e28f4739a9dd",
            "b6dc0e5745a346208213ba88839b52ec",
            "aad096bd72984f6faa700f6ccfe55bc8",
            "dfb27f854d8e4675917b5feeb77a9f49",
            "3a019f9deb674dc9a06923f58a7f3015",
            "d05c3189060f4e71b6fb2f41b7b8dd08",
            "38effe6673584c05b1f930914caf0258",
            "f621f287d15b4d3c88ad747fe4017678",
            "bdf306d1c34f4aa7b63d377593e46704"
          ]
        },
        "id": "fWCKXrftoKvu",
        "outputId": "b88af422-85c4-4179-f8c1-d96c2279f8fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/937 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e5a9f92dacdd42aba2565cc688b26259"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/235 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "052cc03567bd462fbb1f8c73d53a95e7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-39-25329a740e37>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='826' max='826' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [826/826 47:52, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.911300</td>\n",
              "      <td>3.931890</td>\n",
              "      <td>0.267477</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.885500</td>\n",
              "      <td>4.043892</td>\n",
              "      <td>0.258280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.955900</td>\n",
              "      <td>4.012613</td>\n",
              "      <td>0.257569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>4.003100</td>\n",
              "      <td>4.000141</td>\n",
              "      <td>0.261581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>3.906000</td>\n",
              "      <td>3.990000</td>\n",
              "      <td>0.260770</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>3.898700</td>\n",
              "      <td>3.991022</td>\n",
              "      <td>0.261980</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>3.905200</td>\n",
              "      <td>3.996799</td>\n",
              "      <td>0.264252</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Directory created: /content/drive/MyDrive/mc_models/bert_fine_tuned\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We don't want to interprete too much in the results of the fine-tuning for now.\n",
        "We'll see the differences between the models in the evaluation section (Overview notebook)\n"
      ],
      "metadata": {
        "id": "RjNOJZpe8Qe9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tuning ALBERT\n",
        "After having fine-tuned the BERT model, we want to do that for the \"albert/albert-base-v2\" model, too"
      ],
      "metadata": {
        "id": "1f9D5XI87d92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load model again\n",
        "model_name = \"albert/albert-base-v2\"\n",
        "albert_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "rQ2bMn6RquYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14a6084c-8104-43ab-f7ee-bed09a3f0f2e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply fine-tuning methods\n",
        "fine_tune_model(mc_qa_dataset, tokenizer, albert_model, 7, \"albert/albert-base-v2\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "0615ce80df0f429db75363374f61cca5",
            "3d00b1995ae645548bdbea00e6f8431e",
            "3629e135de8c4176a4102d1d5f8e06d0",
            "541150d14e5644cfa78897894d5afb91",
            "c490762b2a5541949944eb4e8d97f05f",
            "ca7a568149824cfe80b8c0ade733079f",
            "a4c992dd19904f76b609e53988b5fd67",
            "54212caf83264951a60ca98b7b9f3819",
            "e6dbe4d6195042debe70e0ed08e5d5d1",
            "9c6de4b40e984107a374109491f2a21d",
            "034e1a5b37b341ec9b6b164aeabb8428",
            "fb7a71f0abeb49929cbf97579944383e",
            "d7492606e07b45d6a62b31f0dc777ee0",
            "c0d2ed25aef64202a55a782eccfacefc",
            "c660d50135ef479cac9265760eaeb1c6",
            "d2238b001cf14759ad6118fad4fbafe4",
            "e5e14b21c7414638b95fc6b0709c80ad",
            "4b48910f15844fe7bdae0f71df9c67ed",
            "0fdbd68e4f0e41b19eb5fa3a3af9ee22",
            "7dc8c9c96e62404ebfa11d59916ebef4",
            "a15c873cba65414aa3659fd8f6e1d0f0",
            "099c7a2a1fb34513ba80006b38af592a"
          ]
        },
        "id": "2Pvj_-XKGcFW",
        "outputId": "0f83114d-7d50-40b7-f2a9-ef39a925d189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0615ce80df0f429db75363374f61cca5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Map:   0%|          | 0/14 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fb7a71f0abeb49929cbf97579944383e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-319c72042967>:20: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "  trainer = Trainer(\n",
            "You're using a AlbertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='14' max='14' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [14/14 00:33, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.969500</td>\n",
              "      <td>2.752164</td>\n",
              "      <td>0.285463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>2.696700</td>\n",
              "      <td>2.852798</td>\n",
              "      <td>0.237407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.698100</td>\n",
              "      <td>2.861069</td>\n",
              "      <td>0.214931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>2.683800</td>\n",
              "      <td>2.859945</td>\n",
              "      <td>0.225911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>2.657500</td>\n",
              "      <td>2.845096</td>\n",
              "      <td>0.241281</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>2.598900</td>\n",
              "      <td>2.842575</td>\n",
              "      <td>0.245650</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>2.600700</td>\n",
              "      <td>2.840811</td>\n",
              "      <td>0.245650</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "cp: cannot create directory '/content/drive/MyDrive/albert/albert-base-v2': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Testing / Evaluation\n",
        "\n",
        "So what is the conclusion?\n",
        "Which model works best?\n",
        "In fact, this will be answered in the Overview notebook, but we will prepare the data for the evaluation.\n",
        "Actually, this doesn't take too much of new ideas, since we can catch results of model output instantly via the function model_output() defined in the beginning.\n",
        "\n",
        "So let's apply this function for the different models on the test dataset, which was created in the other notebook."
      ],
      "metadata": {
        "id": "0-5RFV-HgSeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load dataset\n",
        "\n",
        "url = \"https://raw.githubusercontent.com/alexk2206/tds_capstone/refs/heads/main/datasets/test_qa_dataset_with_answers.json\"\n",
        "data = pd.read_json(url)\n",
        "# Convert to DataFrame for easy handling\n",
        "test_df = pd.DataFrame(data)\n",
        "\n",
        "# Map the intended answer to the index of the option\n",
        "test_df['label'] = test_df.apply(lambda x: np.array([1 if option in x['intended_answer'] else 0 for option in x['options']]) if x['type'] in ['SINGLE_SELECT', 'MULTI_SELECT'] else np.array([0]), axis=1)\n",
        "test_df[\"intended_answer\"] = test_df[\"intended_answer\"].apply(lambda x: x if isinstance(x, list) else [x])\n",
        "\n",
        "test_dataset = Dataset.from_pandas(test_df)"
      ],
      "metadata": {
        "id": "tMFWPl-TgRsM"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test_dataset = pd.DataFrame(test_dataset)\n",
        "df_test_dataset.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8GTATJIul1EI",
        "outputId": "fb90fb15-4f44-46fd-bb29-a042b14c339f"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(200, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load text-summarization pipeline once again\n",
        "summarization_pipeline = pipeline(\"summarization\", model=\"t5-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334,
          "referenced_widgets": [
            "eb34c6b5a14b4b4b94e6490812d3f647",
            "c4c6bbfc38ed4728b8e482bfcb9188f3",
            "964a01d45c4e4f8fb82f409b5a9ca90b",
            "a165a7b2064740c9bc7b009a3559851e",
            "3539b8fdeaa1405e989d6534a5b2d750",
            "b435faa2531f4e039f6cda2b61ba9f10",
            "e5cc7f55cc9a43c8bdb6a1ffcf6ff9b9",
            "a57bd06da8b348fbb41b6f799a3748cb",
            "4df27aa7c4f04bb0a52dad455ca015d5",
            "1a4a4500e704415483cc06e01cfa292a",
            "a37375b3666c490b85e4497f40566dc1",
            "5fabaaadde044c6f99af9b0dff077bc9",
            "18bd37f03f8642f0ad0f5c079df7c330",
            "3ab062a3537645298e7ad4d8e3eb2c2e",
            "e358ee6b523a4ce0b34eab90fa5a232e",
            "d2877b460f344343a09c80742d0b8c15",
            "bc42311f93fe495592040a6c7d933311",
            "b273e2714f824a3cb23caad525e0741c",
            "ed845f529a9c4746ba095c478b984922",
            "6865d5e92dc04f5796833b027ac3f3f8",
            "8103a43a49a1465f8dffe5617556b347",
            "bce9bd33163f48998cf0515dc1489834",
            "b74e8183fd7848f4a46378d94809efec",
            "9eaed3783953471ca4a5ba14a2517228",
            "cda2254ddc72401e9215d6b6a7d41014",
            "7f0fd560f64f49b8882771c0d947d529",
            "2b401ee597b34fb49dae9b9ad8dc3001",
            "08ccd37a2d694c748c3ae6a1c607d4c8",
            "ed513f32795748a980b8eaebc5d8005a",
            "f12e660caa6142c29ba1c680d4590f41",
            "f5d1bc7810674f149c6a3759ad3cd66d",
            "7f249de6554e4079aecbc9d528bd0689",
            "c82f4a3586de4bec862ea59e2f60f23e",
            "c7f1c332c85e40aa963a5654c7833f97",
            "acd36614ea764cdea68d6ab9efbf32f2",
            "e553b5b737b4498aa5ce230661c0a1cb",
            "65c4af3133e34d39bc268427fd63bbce",
            "011e9ee215b94f8ea9dbae76544deaae",
            "a0ffe47c35e64a74894e4ecdab100be5",
            "b4005a6d2eb64121b646cac8e2f49ffa",
            "c2506df2c91d49bf80b557dac1c8e8e9",
            "c5b6f041ea4141248e31f7dedb5838dd",
            "32167908c72f478598cce9dc4154b16d",
            "0d0e99df0cf24295828de46198b96613",
            "a5fb5d7b2b5e441092f9088a8194024b",
            "1b25c73e079a40cda2a4a109d9962698",
            "fd08e9368e644622961dcc6022cfd22f",
            "184ca16523d5406f992b6667322f966f",
            "3e717b04406e4129806a033219a70f71",
            "8e1b81f950b34ff5888e66d831e6ec0d",
            "f4083d8b4f07419f8ce955853b1acf76",
            "99a33b7853f943d396af5e6c91cdd20c",
            "9ad79b7928ae4eea8841ee5877ea7e64",
            "b7397e33a1654a73815abb3e1de2a1bc",
            "d6a25b89997b45c5ab68d5b22ca4b62f",
            "587b93171baa423c8c65a125eba23ec7",
            "8cbb94beae1f4b8aa6ba1277344bbb43",
            "b891ae20bc6c4066b5dbc9a690e3d55b",
            "485709f2ea664e59ac830f36bc16c22a",
            "b2a12746ab08406490b09e0885f20d0a",
            "b4f7cdae5deb47108e0b4fb64582c2ec",
            "1e02c97616004d9196a873ed7c106923",
            "55282e032dc24572b59926e0af5d4e0e",
            "91f8a1008ed04e3796d1cea48b7c9408",
            "b7d11e9f975a4f6994a28ea471af2bf4",
            "86b2e164208f448c9fa15b595a2b128e"
          ]
        },
        "id": "nRLeh5k9elwO",
        "outputId": "9103b133-dbe3-4af9-ea9b-6e8da40c988b"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/1.21k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "eb34c6b5a14b4b4b94e6490812d3f647"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/242M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5fabaaadde044c6f99af9b0dff077bc9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/147 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b74e8183fd7848f4a46378d94809efec"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/2.32k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c7f1c332c85e40aa963a5654c7833f97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/792k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a5fb5d7b2b5e441092f9088a8194024b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.39M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "587b93171baa423c8c65a125eba23ec7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "oe_model = AutoModelForQuestionAnswering.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")\n",
        "oe_tokenizer = AutoTokenizer.from_pretrained(\"distilbert/distilbert-base-uncased-distilled-squad\")"
      ],
      "metadata": {
        "id": "CRhyfrqSolQm",
        "outputId": "0f6d0734-f2d4-4f1b-de11-2575f9c0f037",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "a8b30e98d2b344c288bd7f9b1b042411",
            "b34416d3e9564af1ac60e3b644f1c3f6",
            "9cc52a2766b74c22995dc0f38dac414e",
            "6621fc6825e645bc99c7e8a9e3f1c1fd",
            "5c28eb61ef9e4dfca3df0de4c755886a",
            "895654bd36654f6cb104fb980d33c4b5",
            "0d4142c93b114ccf8385f18bcea72d79",
            "f795a9c30e134620a7bdaf203947864c",
            "32b2abcc142e4d9ebe5129da3dd4f9ee",
            "c8e275c342d848b09ef9a2b0099512f9",
            "01dc3796b8a34494905604aa3a67063f",
            "c49b2c99d64041eb806e43c07f9a1f67",
            "229b28c1a2324202b2a41e40839846e3",
            "6638e2738a544982b37cb387e2cbe0ae",
            "d1324178dc6f4b6e9f162c6b802ed037",
            "2dca1601f4be402597b940a7a93b2793",
            "2469465147ce49479d49f8fd16b3f379",
            "e5dcf07bfb8443488d8c17723c0a54e0",
            "de849a9303424458a05da695e5360857",
            "3e82b0dd7af1420e9490b35c3144e8cc",
            "b5c3165146784cc5b5f3b88cdf512dc2",
            "8a43371a99d54ab6bf62b184c8ff962d",
            "73ea0d7f1a2a4b118ee604ee96ad75c9",
            "e12a6bbca7a144b0bb451cfeb700cf36",
            "302248e8c4a646bc91cdcc53ea1368cf",
            "7479987a7f144839b484588e1c16efd6",
            "fc5cdad26781498ba478a9c64f75d30b",
            "de9afaeb85fa4f518c65f8b7f80d6f5f",
            "1a5e05e1d0ba472bab439eb3e17198dc",
            "e1573e3ad1884ff5939e1f5e510a0135",
            "7696b55f4ab94560ad1c15ee6fad298d",
            "c95f3435bd8c48c9b73f6f455cef9b8f",
            "133cc4b712ac402895a4cf2b258b6ef5",
            "d21916ceaa564f7ea6f95701a21e97a5",
            "dfdd2b9d40ab496b9e2599b92759b5db",
            "be559ffc42784598a93fcfa9c139c29e",
            "15099752963c40cdb56c199a2591db43",
            "0b07f6d346e44245b61191abbb58bd38",
            "d8252be69a164d4289e70caf50d58902",
            "2e56d5610304485babb0bbc708aa0fbd",
            "eeb8a2357d68410f83252faaf536701b",
            "a9c7d45ef2ec40cea6477d70865f9171",
            "b241630860584ad999a274beae71d5d6",
            "67d0ceb4ce5e4a7ebf768ceff78b57c3",
            "9c951dc0e1144e998bc4c6b73385952b",
            "146012a71fec408bbe0ab7eaf69e6986",
            "8320c9d6adac4512a008f33f9a066038",
            "554bc975a5c848c994f7767c0e65ad4a",
            "157198d387024822ad325e97a2f3bc24",
            "cc3b0c2d989946bca998c124bef90822",
            "d3731f6405d74568a424b3c8f457efa7",
            "7dbda707a7704cb2bff31d2fb351a70f",
            "365eb48747a240818ab473b1726b42eb",
            "e93112e88bd4472ba82e4c177f075d20",
            "df4b0c92209144d3be2aca5739f0d9fb"
          ]
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/451 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a8b30e98d2b344c288bd7f9b1b042411"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/265M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c49b2c99d64041eb806e43c07f9a1f67"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "73ea0d7f1a2a4b118ee604ee96ad75c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d21916ceaa564f7ea6f95701a21e97a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9c951dc0e1144e998bc4c6b73385952b"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load metrics once again\n",
        "clf_metrics = evaluate.combine([\"accuracy\", \"f1\", \"precision\", \"recall\"])\n",
        "exact_match = evaluate.load(\"exact_match\")"
      ],
      "metadata": {
        "id": "J2bJGzOsBQMy",
        "outputId": "71827ea7-367e-4d91-9c36-721d73fb92b6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "f39c44efbc4b4c35a34920895d037d1f",
            "e08697926ee0451ba181f1466dd71eda",
            "7fb8bb6d2c6c4f98bbe100d4914ce504",
            "90407ae9328941d7bb91528f94e0bd40",
            "6890d881c3ae4d94b6215c407e01502a",
            "349bed5c42c14b89a39a401a34bf1b60",
            "ad10b446b02a4a8fb6ca326551b19da7",
            "59ab57c2d94e4b82b2e3b8080c7f763c",
            "f7ca2261bc734092ba3ea7512e034656",
            "9d05088db2bb40e8993ecf040213845c",
            "438979ebecd1401eb8fd3a0ab7449d31",
            "377026b5aeec408394b8685699e771fd",
            "21a0e768c04c4939a2aca35e97b33a31",
            "cdf20f57dbd24acf891baffa4c6c61d7",
            "3450a8d462c74db8aa975d83ff123cec",
            "01272869449b489c9be96d1f6a272478",
            "52e9c0d60a60482ab5e7c8df2ab4ffb8",
            "4e3079b223804fa0990f0041916b4af1",
            "7b74da1b96834fddb2deed892a44ac0c",
            "4bdf935b4955491b94e25fe2a57a833d",
            "e9b748fbacac4ce0b98d755fb80203e8",
            "9825f96414f94eb4bdaa3adb47e7a579",
            "ea31951510864140a3ab9faf61b63ff9",
            "28468b86e4d244e2b6cbe74ec14f53b0",
            "fabd428c9d9c407aa772928ce7a7ed79",
            "d893295253f842709493eb84b47c3db1",
            "d93236e3a49e4bea973e7ebbec01259a",
            "5eb06fd7bda44c598a0d2c2dc32379df",
            "ccfcd3626bed452ca44f267db7ed87e1",
            "b1585ea2645b4ee1b255dfd629b8e9a5",
            "ed0d015b9f304a4bad825c9f12983917",
            "6dd409cd568a45b6b5e387af8658c25b",
            "200c46c388284cebaa8ca57b0cf2ee1e",
            "1998430c8a5747d48db003dca1aac8c4",
            "79fc64f597134afdaf4dfd2fbd70a682",
            "e0d76a1fe1934a6ea4cd26aceabb9460",
            "3c59cb541ba24ee9aeac4dbaf1fc0c02",
            "f5d32fa2c344405ea7e35887577e1853",
            "33f8b91e008d4156b7c5d96d16ad15de",
            "7fc5ece4e8c24900a00c83f77189d300",
            "958d5d569efc49e78975e0d6545fd216",
            "6356ff5b16f14371aae5a8f7f48301a9",
            "c261c196eae34e80b84e9349e5173300",
            "dfbb8afe7de64c1fa65a7301fdc58b38",
            "baad341cfbea4448a2bb24e562d814f9",
            "901c536c210a41a48c2c56e925653229",
            "f42920e381024f6c892da8fd80e87027",
            "433c09ee9b0b42b5b8df30a48e22a154",
            "b505b46fbd9046e4b0773d5a87e37aa4",
            "7ae117c01e324939b61244a58a712559",
            "02f877f7b1f344b2b479addf5cac5ff0",
            "91501c46ac774d1d9da21c1dd061a3a7",
            "08fc50dc93eb4b6c88e3ea8b16bfd2f6",
            "2d028ff075404d1b8ea84964946ed64a",
            "1d5d71d8e1244d3e8ec905b6957ae895"
          ]
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f39c44efbc4b4c35a34920895d037d1f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/6.79k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "377026b5aeec408394b8685699e771fd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.56k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea31951510864140a3ab9faf61b63ff9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/7.38k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1998430c8a5747d48db003dca1aac8c4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/5.67k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "baad341cfbea4448a2bb24e562d814f9"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# mount Google Drive again\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU-FrOIigwl1",
        "outputId": "7e717400-a9e7-4a12-a481-2cc75c2545a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tuned albert model"
      ],
      "metadata": {
        "id": "2U4erKKixdvL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from Google Drive\n",
        "model_name = \"/content/drive/MyDrive/mc_models/albert/albert-base-v2/albert-base-v2/checkpoint-14\"\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "934ApjYhjXb2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dy-Mob9vk459",
        "outputId": "b1f2f561-b89c-4660-ca36-2c9f71a705c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6188, 0.3287, 0.2924, 0.2797, 0.3464]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, I think I represent the Operations department. That must be it, right?\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5285, 0.4390, 0.4790, 0.5805, 0.3717]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, not sure to be honest, I've not really thought about it yet.\n",
            "The intended answer was: Not sure\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6079, 0.5647, 0.5406, 0.6192, 0.6080]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well I would say I am very satisfied with the solutions currently.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5650, 0.6197, 0.6833, 0.6258, 0.6679]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh gosh, I'd say I'm probably in the exploration stage right now.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Decision-making\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[0.4444, 0.3965, 0.4310, 0.4127, 0.3989, 0.3269]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I suppose I prefer German, I guess that's my language for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4912, 0.4720]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, um, well I'm not really sure. I don't plan on it right now so I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5163, 0.2570, 0.2256, 0.4984, 0.5471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6154, 0.4601, 0.4562, 0.6436, 0.4218]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Well, I think it was other, honestly. I'm not sure what else it could be.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4383, 0.4129, 0.4651, 0.4917, 0.3218]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. Yeah, that's how I found out about it.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5222, 0.6201, 0.5601, 0.6421, 0.4821]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5414, 0.4515, 0.5464, 0.5141, 0.4937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Training', 'Technical support']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5370, 0.4817, 0.6495, 0.5285, 0.5627]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5198, 0.5564, 0.4877, 0.4607, 0.3921]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6298, 0.4971, 0.4325, 0.5663, 0.5626]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5573, 0.5806, 0.7483, 1.0676, 0.4853]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh gee I really am not sure I guess probably other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5059, 0.6083, 0.5819, 0.6030, 0.5407]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not sure what the options are but I guess I'd say other, it fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Procurement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5349, 0.6341, 0.3548, 0.6999, 0.5401]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4506, 0.3630, 0.4386, 0.4990, 0.4030]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6179, 0.5924, 0.6143, 0.7077, 0.5953]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess I'd say immediately would be my answer.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5655, 0.5188, 0.5482, 0.5737, 0.5170, 0.4754]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I prefer English, it's the only language I know really.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Spanish\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6533, 0.5413, 0.5423, 0.6885, 0.6535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6577, 0.5745, 0.5749, 0.6794, 0.5871]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I would say very unsatisfied, to be honest. I think things can get much better in my field.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.7121, 0.6512, 0.6506, 0.6782, 0.6432]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, wow, I'm really not sure, I think we have maybe 28 people working here right now, it's somewhere between 11 and 50, so yeah, 28 seems right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.7132, 0.6986, 0.6942, 0.6987, 0.6550]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4523, 0.7637, 0.3159, 0.8684, 0.3728]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4189, 0.4061, 0.4112, 0.3898, 0.3771, 0.3737]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, that's tricky. I'm not really sure which languages there are, so I'd have to go with other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5821, 0.3552, 0.5144, 0.5235, 0.5924]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, um, I guess an in-person visit would probably be my preference.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4478, 0.3734, 0.4625, 0.4326, 0.5048]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, well I guess an in-person visit would be my preferred method of follow-up then. I think it's the best way to connect.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5409, 0.5298, 0.5369, 0.5425, 0.5870]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5317, 0.4833, 0.5428, 0.5746, 0.6277]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm not really sure, maybe I'm at the evaluation stage. That seems right for me now.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[0.7880, 0.4723, 0.4688, 0.6274, 0.3782]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3230, 0.4109, 0.3059, 0.3911, 0.5087]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6112, 0.4512, 0.4629, 0.6301, 0.4270]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh gosh, I think it was an email invitation I received. That sounds right, yes, it was that.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5406, 0.5176, 0.6193, 0.5605, 0.5555]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.7421, 0.7386, 0.7652, 0.7669, 0.7460]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[0.6819, 0.6890, 0.6033, 0.4140, 0.7700, 0.6293]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5577, 0.5378, 0.5482, 0.5515, 0.5365, 0.4936]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5250, 0.5377, 0.4741, 0.5284, 0.5306, 0.4083]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2686, 0.2394, 0.1761, 0.3661, 0.3265, 0.1764]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5629, 0.5575, 0.4974, 0.5727, 0.5806]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6703, 0.5076, 0.4885, 0.6125, 0.5341]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4586, 0.5222, 0.5137, 0.5077, 0.6163]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I'm in exploration then.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.6041, 0.5401, 0.5393, 0.4336, 0.4318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3897, 0.3384, 0.4383, 0.4771, 0.3113]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.7070, 0.5185, 0.6059, 0.5571, 0.6316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure. I guess it's Other. I don't really represent a specific department.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4954, 0.3588, 0.4570, 0.3298, 0.6090]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6701, 0.6785, 0.6886, 0.6692, 0.7082]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4299, 0.4934, 0.4500, 0.5103, 0.3700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was something else. Yeah it wasn't an advertisement, or a website, or any specific invite, so it's really none of those options you've probably got.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5192, 0.5078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Hmm I'm not really sure if I will implement it within six months I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3800, 0.4005, 0.5709, 0.5372, 0.3480]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well, I suppose I'm seeking an end-user relationship since that's what I'm familiar with.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Reseller\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3423, 0.3532, 0.7979, 0.4121, 0.5164]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Well I'm just starting to explore things. So, yeah, exploration I guess.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Decision-making\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3341, 0.4861, 0.4088, 0.4823, 0.5410]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4612, 0.5623, 0.5711, 0.5786, 0.5752]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not really part of any specific department I guess, so I'd say other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Operations\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4507, 0.5508, 0.4272, 0.5459, 0.5490]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5535, 0.6379, 0.6669, 0.5992, 0.5063]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6321, 0.4407, 0.3365, 0.3825, 0.2355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4907, 0.4394, 0.6712, 0.5712, 0.4454]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4172, 0.3998, 0.4821, 0.5236, 0.4365]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4618, 0.4044, 0.5568, 0.5673, 0.4506]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5808, 0.5700, 0.5989, 0.5931, 0.5463, 0.4834]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I guess I'd prefer Italian. It sounds nice.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5244, 0.5945, 0.3934, 0.4682, 0.5305, 0.3255]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5912, 0.4755, 0.3693, 0.3784, 0.3125]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4479, 0.5470, 0.4883, 0.5799, 0.3730]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I guess my main thing is finding suppliers here today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3672, 0.6418, 0.6406, 0.6719, 0.3394]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my main goal would be other, since I'm not sure about specific aims right now.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4290, 0.4707, 0.3533, 0.4542, 0.4428, 0.3731]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['AI', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.4603, 0.5023, 0.5546, 0.4911, 0.4081]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, you know, I think it was word of mouth, someone mentioned it to me, yeah that must be it.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6301, 0.5686, 0.5601, 0.6301, 0.2991]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1311, 0.1543, 0.6095, 0.7833, 0.2072]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, I think I'd like to be a supplier, I guess that seems right.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[0.6113, 0.4159, 0.3989, 0.5025, 0.6265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, immediately I suppose. I dont know other options, but yeah, that works.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4760, 0.4833, 0.4748, 0.4721, 0.4548, 0.4244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I'd have to say English, since it is what I use and know.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.6070, 0.5061, 0.5118, 0.6407, 0.6165]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied with the current solutions, I don't really know the alternatives anyway.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[0.5687, 0.5237, 0.4555, 0.4955, 0.3858]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4727, 0.4091, 0.5504, 0.5526, 0.6235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, um, I guess I'm in the evaluation stage, yeah, that seems right.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4231, 0.4819, 0.4367, 0.3415, 0.3173]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5020, 0.3020, 0.4927, 0.5053, 0.4613]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to pick a method of follow-up I suppose a phone call would work best for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.7655, 0.7527, 0.7360, 0.7590, 0.6657]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5050, 0.4989, 0.5128, 0.5004, 0.4917, 0.4439]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I don't really have a preference, I suppose it's other then, I mean it's not like I pick any language in particular.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6086, 0.5048, 0.2692, 0.2749, 0.1574]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6109, 0.6234]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Yes, I think I will do it in that timeframe, it seems reasonable.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.5262, 0.4101, 0.5031, 0.4274, 0.5910]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4959, 0.5744, 0.5481, 0.6034, 0.3686]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Hmm, I suppose my primary goal is probably networking, yeah that makes sense to me.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4653, 0.2575, 0.1790, 0.2349, 0.1712]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4976, 0.3584]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't really thought about it for the next six months, no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4462, 0.3463, 0.5262, 0.5511, 0.4204]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.5421, 0.4066]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I guess no, since there were no other options really.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.6024, 0.5639, 0.4535, 0.5635, 0.3575]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5102, 0.3048, 0.5142, 0.3477, 0.6371]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5789, 0.5076, 0.5657, 0.5542, 0.5722]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2843, 0.4779, 0.2978, 0.5501, 0.5702]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5348, 0.6851, 0.7978, 0.5844, 0.5250]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly, I'm not entirely sure, probably something else I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2467, 0.3095, 0.8308, 0.9809, 0.2898]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I think I would prefer a partner relationship. That sounds good to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6568, 0.6775, 0.6491, 0.6845, 0.6489]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4837, 0.4578, 0.4245, 0.4098, 0.4664]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, um, I guess I represent Operations. I don't really know all the options, to be honest.\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5548, 0.3804, 0.5126, 0.4817, 0.5227]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5260, 0.5009, 0.5199, 0.5527, 0.4815, 0.4148]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3493, 0.4268, 0.5776, 0.1976, 0.2168]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5155, 0.4499, 0.3480, 0.3459, 0.2062]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5809, 0.4527, 0.4168, 0.3099, 0.2932]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4523, 0.5635, 0.5467, 0.5745, 0.3685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well I suppose my primary goal here is finding suppliers, yeah that sounds right to me.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5391, 0.4987, 0.4659, 0.2364, 0.2206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5757, 0.5581, 0.5433, 0.6117, 0.4788]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, hmm, I guess I heard about it some other way then, you know? Not sure exactly which, but not from a known source.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6582, 0.5286, 0.5360, 0.6880, 0.6603]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5469, 0.6540, 0.5635, 0.6823, 0.5228]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly I'm here mostly to find suppliers. That seems like the main thing for me today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[0.2900, 0.2917, 0.4721, 0.4040, 0.5249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.7041, 0.5839, 0.2080, 0.3068, 0.6114, 0.2884]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6555, 0.6450, 0.6408, 0.6479, 0.6528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6236, 0.3445, 0.3164, 0.3810, 0.4279, 0.2458]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4395, 0.5204, 0.5042, 0.4450, 0.4582]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was just through word of mouth.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4077, 0.4186, 0.7080, 0.6419, 0.8618]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4989, 0.5587, 0.2570, 0.3655, 0.2329]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5241, 0.5417, 0.5530, 0.8719, 0.5058]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, well I'm not really sure about options like 'Transactional' or 'Loyalty' or 'Advocacy', so I guess 'Other' fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5163, 0.4738, 0.5734, 0.5489, 0.5151]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[0.3879, 0.4048, 0.4153, 0.4125, 0.3503]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure about the departments, but I suppose I represent R&D, if that makes any sense.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4927, 0.4049, 0.4665, 0.5284, 0.3832]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I heard about your exhibition stand through social media. That's how I find out about most things.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5535, 0.5332, 0.5435, 0.5642, 0.5384]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I would like it immediately I suppose. That seems like a good time for me.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4769, 0.4072, 0.5904, 0.5288, 0.3967]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I need technical support, that would really help.\n",
            "The intended answer was: ['Technical support']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3769, 0.5880, 0.5653, 0.5867, 0.3305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal here would be market research. I am trying to figure out what's happening out there.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4666, 0.4302, 0.3570, 0.5075, 0.5019]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6723, 0.6646, 0.6969, 0.6920, 0.6520]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I really have no idea. If I had to guess it would be maybe five.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5277, 0.2684, 0.4478, 0.4173, 0.4334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Phone call\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5199, 0.4831, 0.5874, 0.6512, 0.5075]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6149, 0.5852, 0.5725, 0.5726, 0.5810]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5461, 0.5281]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4011, 0.4803, 0.3868, 0.4767, 0.5528]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer to receive product updates through email, that sounds easiest.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.5635, 0.4412, 0.4051, 0.4031, 0.2614]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3587, 0.3501, 0.4753, 0.5221, 0.2872]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.4070, 0.2237, 0.2107, 0.4541, 0.4310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh I'm very unsatisfied with current solutions I have seen. It really seems like things could be much better.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4784, 0.5380, 0.4369, 0.4878, 0.5126, 0.4085]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['AI', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.5218, 0.4511, 0.6089, 0.5279, 0.5038]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4673, 0.4018]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I don't think so. I haven't even looked at all the different options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.6126, 0.4770, 0.4633, 0.4903, 0.5111]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.5374, 0.5828, 0.6844, 1.0910, 0.4980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4685, 0.4239]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't thought about it. There weren't options like 'Yes' or 'Maybe'.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4850, 0.5832, 0.2859, 0.4936, 0.3851]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.6864, 0.6654, 0.6647, 0.6745, 0.6643]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I'm not sure about the exact number, but I think it's like 1000 plus. We're pretty big.\n",
            "The intended answer was: 1000+\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4170, 0.2642, 0.2947, 0.3075, 0.3445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gosh, I'm not sure which departments there are but I guess I represent Procurement.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5530, 0.4256, 0.4039, 0.4526, 0.4388]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4730, 0.3774]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I don't really know the options, but I think no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.5721, 0.4827, 0.4709, 0.3786, 0.3503]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5754, 0.6408, 0.6262, 0.6293, 0.4735]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Oh gosh, I think my primary goal here is just networking, you know, meeting new people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5696, 0.5290, 0.5598, 0.4312, 0.4945, 0.4678]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Hmm I think I would prefer to speak Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4952, 0.3696, 0.3922, 0.4393, 0.4466]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4298, 0.4087, 0.3092, 0.5110, 0.4574]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I'd prefer a webinar for product updates. That seems like a pretty good way to see it all explained.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3559, 0.5804, 0.5128, 0.2381, 0.2401]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5732, 0.4312, 0.3622, 0.3931, 0.3316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.5774, 0.5661, 0.4864, 0.4838, 0.4435]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.6514, 0.4035, 0.5711, 0.2137, 0.2050]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5542, 0.4378, 0.5344, 0.4080, 0.4178]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3233, 0.3221, 0.5186, 0.4341, 0.6243]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4943, 0.5102, 0.3602, 0.5512, 0.3076]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6611, 0.6321, 0.6277, 0.6467, 0.6059]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh geez, I'm not totally sure about the exact number. I think we've got somewhere around 450 employees, give or take a few.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3214, 0.3426, 0.4039, 0.7238, 0.2722]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'm looking for a partner relationship I think.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6269, 0.4750, 0.6215, 0.5901, 0.6679]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2165, 0.2068, 0.5428, 0.8256, 0.1631]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure what the options are but I guess I'm seeking a supplier relationship.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.6258, 0.4520, 0.5310, 0.3833, 0.3714]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.5127, 0.3217, 0.5365, 0.5157, 0.5235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, I guess email is my preferred way to follow up, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4115, 0.3765, 0.7665, 0.9062, 0.4918]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, well I guess I am looking for a supplier relationship. I don't know about the other options.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3493, 0.3487, 0.6328, 0.7791, 0.3436]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, um, I guess I'm looking for a partner type relationship then. I don't know the others though.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5823, 0.5096, 0.5736, 0.5995, 0.5901]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4534, 0.5794, 0.6192, 0.4010, 0.4263]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.6195, 0.5352, 0.5207, 0.6177, 0.5607]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I'm honestly very unsatisfied with the current solutions.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wBiw6HUHn2z1",
        "outputId": "b9141513-1c83-4ffd-be83-c10647fd2bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': '/content/drive/MyDrive/mc_models/albert/albert-base-v2/albert-base-v2/checkpoint-14', 'mc_metric_result': {'accuracy': 0.6226415094339622, 'f1': 0.3212669683257919, 'precision': 0.355, 'recall': 0.29338842975206614}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('albert_fine_tuned_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('albert_fine_tuned_oe_results.json', 'w') as fp:\n",
        "  json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "v1IwRI4HwDDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Fine-tuned bert model"
      ],
      "metadata": {
        "id": "oNsyDvUMx7JJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model from Google Drive\n",
        "model_name = \"/content/drive/MyDrive/mc_models/bert_fine_tuned/bert_fine_tuned/checkpoint-708\"\n",
        "model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "BKV7_F0RwUYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(model, tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YWGRGEZewkkR",
        "outputId": "47f5f2d3-303a-438f-ae28-cd0a90ed4d14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1854, 0.1959, 0.2323, 0.1938, 0.2394]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, I think I represent the Operations department. That must be it, right?\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3029, 0.2846, 0.2836, 0.2814, 0.3145]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4758, 0.4590, 0.4414, 0.4352, 0.4415]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2776, 0.2578, 0.2657, 0.2648, 0.2728]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[0.2788, 0.1920, 0.2727, 0.2513, 0.2334, 0.2321]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I suppose I prefer German, I guess that's my language for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2654, 0.2530]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, um, well I'm not really sure. I don't plan on it right now so I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3761, 0.3601, 0.3474, 0.4177, 0.4422]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2778, 0.3289, 0.2961, 0.2971, 0.2571]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Well, I think it was other, honestly. I'm not sure what else it could be.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2632, 0.2103, 0.2197, 0.2278, 0.2087]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2863, 0.2815, 0.2853, 0.2778, 0.2828]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Networking\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2100, 0.2220, 0.2254, 0.2351, 0.2262]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2518, 0.2634, 0.2528, 0.2590, 0.2495]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Documentation', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2910, 0.2619, 0.3048, 0.2849, 0.2878]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4398, 0.4338, 0.4263, 0.4025, 0.4003]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2467, 0.2248, 0.1665, 0.2485, 0.2268]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh gee I really am not sure I guess probably other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3286, 0.3221, 0.3098, 0.3212, 0.3210]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not sure what the options are but I guess I'd say other, it fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3699, 0.3134, 0.3965, 0.3941, 0.2967]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh I guess social media is probably my favorite way to get those.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Newsletter\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1495, 0.1569, 0.1706, 0.1929, 0.1253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2795, 0.2672, 0.2653, 0.2743, 0.2979]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess I'd say immediately would be my answer.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2952, 0.2701, 0.2885, 0.2834, 0.2854, 0.2750]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2643, 0.2699, 0.2731, 0.3100, 0.2860]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3436, 0.3131, 0.3220, 0.4124, 0.4235]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2222, 0.2406, 0.2189, 0.2169, 0.2330]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.2980, 0.2931, 0.2752, 0.2785, 0.3048]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh gosh I'm not really sure we have like, maybe 5 employees I think, it's pretty small.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4477, 0.4399, 0.4635, 0.4785, 0.4180]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3173, 0.3149, 0.3187, 0.3206, 0.3274, 0.3413]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2781, 0.2804, 0.2816, 0.2762, 0.2985]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, um, I guess an in-person visit would probably be my preference.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2693, 0.3104, 0.2947, 0.4113, 0.2786]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2712, 0.2853, 0.3103, 0.2271, 0.2036]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2796, 0.2673, 0.2562, 0.2433, 0.2810]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm not really sure, maybe I'm at the evaluation stage. That seems right for me now.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[0.2028, 0.2017, 0.2001, 0.2160, 0.1860]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. I am not sure, it might have been a post someone shared.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2579, 0.2717, 0.2739, 0.2887, 0.3802]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1505, 0.2031, 0.1869, 0.1901, 0.1677]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2661, 0.2593, 0.2552, 0.2679, 0.2432]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2777, 0.2447, 0.2375, 0.2569, 0.2795]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say over 6 months, I think that works for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[0.4293, 0.4004, 0.4257, 0.4367, 0.4069, 0.3953]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['IoT', 'Automation', 'Cloud computing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2911, 0.2734, 0.2968, 0.2886, 0.2899, 0.2737]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I'd prefer English, I don't really know about other options.\n",
            "The intended answer was: English\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3496, 0.3349, 0.3559, 0.3684, 0.3466, 0.3424]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['Automation', 'Cloud computing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3182, 0.3114, 0.3156, 0.3134, 0.3238, 0.3171]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4346, 0.4034, 0.4206, 0.4394, 0.3930]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3049, 0.3076, 0.3198, 0.3635, 0.3797]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2490, 0.2467, 0.2311, 0.2176, 0.2269]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3315, 0.3594, 0.3777, 0.3285, 0.3190]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2536, 0.2356, 0.2561, 0.2932, 0.2410]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2687, 0.2603, 0.2704, 0.2747, 0.2722]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure. I guess it's Other. I don't really represent a specific department.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Operations\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2373, 0.2750, 0.2615, 0.2520, 0.3078]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2508, 0.2334, 0.2285, 0.2299, 0.2610]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2278, 0.2257, 0.2416, 0.2442, 0.2238]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was something else. Yeah it wasn't an advertisement, or a website, or any specific invite, so it's really none of those options you've probably got.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3387, 0.3544]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2409, 0.2406, 0.2345, 0.3125, 0.2644]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2910, 0.2803, 0.2739, 0.2684, 0.2807]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3302, 0.2890, 0.3292, 0.3627, 0.4393]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2428, 0.2255, 0.2479, 0.2431, 0.2710]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2870, 0.4344, 0.3030, 0.3271, 0.2748]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2719, 0.2829, 0.2871, 0.2820, 0.3204]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2715, 0.2946, 0.2766, 0.3148, 0.3163]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1956, 0.2054, 0.1976, 0.2026, 0.2018]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Documentation', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0874, 0.1398, 0.1554, 0.1578, 0.1104]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2107, 0.2240, 0.2086, 0.1875, 0.2172]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['Documentation', 'None']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3002, 0.2874, 0.3056, 0.2895, 0.3127, 0.2784]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3758, 0.4044, 0.4607, 0.3786, 0.3960, 0.3794]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['Automation']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2700, 0.2602, 0.2809, 0.2701, 0.2937]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Procurement', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2716, 0.2700, 0.2681, 0.2782, 0.3032]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I guess my main thing is finding suppliers here today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3233, 0.3349, 0.3310, 0.3339, 0.3235]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my main goal would be other, since I'm not sure about specific aims right now.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4172, 0.3703, 0.4035, 0.4389, 0.3727, 0.3443]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'Cloud computing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1510, 0.1771, 0.1970, 0.2277, 0.1672]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4451, 0.3870, 0.4358, 0.3924, 0.3173]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2543, 0.2669, 0.2637, 0.2685, 0.2936]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, I think I'd like to be a supplier, I guess that seems right.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[0.2838, 0.2630, 0.2617, 0.2655, 0.3015]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, immediately I suppose. I dont know other options, but yeah, that works.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2387, 0.2088, 0.2224, 0.2184, 0.2246, 0.2276]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3634, 0.3649, 0.3714, 0.3860, 0.3768]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied with the current solutions, I don't really know the alternatives anyway.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[0.2861, 0.2565, 0.2846, 0.2955, 0.2738]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader', 'CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2301, 0.2282, 0.2238, 0.2075, 0.2339]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, um, I guess I'm in the evaluation stage, yeah, that seems right.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2994, 0.3084, 0.3165, 0.3151, 0.2977]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2863, 0.2424, 0.2098, 0.2191, 0.2354]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3369, 0.3138, 0.3381, 0.3033, 0.4098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2764, 0.2730, 0.2706, 0.2681, 0.2691, 0.2940]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2661, 0.2706, 0.2873, 0.3017, 0.3138]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.4048, 0.3797]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3397, 0.3688, 0.3565, 0.3198, 0.4025]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3276, 0.2651, 0.3104, 0.2542, 0.2920]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2997, 0.2980, 0.3042, 0.3204, 0.3301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2191, 0.2513]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2505, 0.2890, 0.2800, 0.2393, 0.2411]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3139, 0.3055]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I guess no, since there were no other options really.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2782, 0.2843, 0.2865, 0.2901, 0.3082]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2577, 0.3042, 0.3120, 0.2472, 0.3789]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2789, 0.2539, 0.3058, 0.3129, 0.3242]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3459, 0.3187, 0.3839, 0.4240, 0.4482]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2995, 0.2915, 0.3064, 0.3090, 0.3182]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2700, 0.2730, 0.2345, 0.2568, 0.2603]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2208, 0.3464, 0.3252, 0.3594, 0.3207]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2423, 0.2386, 0.2634, 0.2482, 0.3018]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, um, I guess I represent Operations. I don't really know all the options, to be honest.\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2197, 0.2158, 0.1850, 0.2213, 0.2124]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to choose, I'd probably say phone call is the way to go for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2705, 0.2353, 0.2719, 0.2382, 0.2833, 0.2534]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh I think I prefer Spanish for communication. It's what feels most natural to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2836, 0.3233, 0.3300, 0.2992, 0.2811]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2082, 0.2254, 0.2255, 0.2199, 0.2246]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['IT department', 'Procurement', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3205, 0.3225, 0.3339, 0.3355, 0.3161]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2926, 0.4033, 0.2940, 0.2482, 0.2609]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2871, 0.2927, 0.3072, 0.3072, 0.2914]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2599, 0.2561, 0.2665, 0.2659, 0.2728]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3207, 0.3052, 0.3247, 0.3440, 0.3445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2907, 0.3668, 0.3550, 0.2879, 0.3300]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[0.2851, 0.2803, 0.2938, 0.2972, 0.3011]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3366, 0.3228, 0.3152, 0.3350, 0.3651, 0.3238]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2493, 0.2381, 0.2148, 0.2206, 0.2788]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm I'm not really sure but I think we probably have between five employees, maybe ten tops.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4739, 0.4075, 0.4463, 0.4868, 0.4586, 0.3839]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'Cloud computing']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2030, 0.1971, 0.2170, 0.2390, 0.1834]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2759, 0.2586, 0.2351, 0.2542, 0.2791]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2541, 0.2366, 0.2462, 0.2430, 0.2659]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2195, 0.2354, 0.2166, 0.2228, 0.2428]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2232, 0.2198, 0.2204, 0.2319, 0.2535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[0.2566, 0.2222, 0.2854, 0.2519, 0.3136]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure about the departments, but I suppose I represent R&D, if that makes any sense.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4651, 0.4080, 0.4123, 0.4360, 0.3793]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3019, 0.2851, 0.2643, 0.2826, 0.3070]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I would like it immediately I suppose. That seems like a good time for me.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2565, 0.2630, 0.2713, 0.2202, 0.2134]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I need technical support, that would really help.\n",
            "The intended answer was: ['Technical support']\n",
            "The predicted answer was: ['Training', 'Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3351, 0.3336, 0.3649, 0.3750, 0.3232]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4647, 0.4556, 0.4690, 0.4762, 0.4391]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2959, 0.3076, 0.2877, 0.3074, 0.2998]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I really have no idea. If I had to guess it would be maybe five.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1909, 0.1971, 0.2037, 0.1957, 0.1973]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2541, 0.2399, 0.2143, 0.2995, 0.2612]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4227, 0.4247, 0.4379, 0.3910, 0.4459]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2285, 0.2273]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4274, 0.4151, 0.4266, 0.4331, 0.3795]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer to receive product updates through email, that sounds easiest.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2264, 0.2214, 0.2457, 0.2749, 0.2782]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2618, 0.2709, 0.2526, 0.2621, 0.2782]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'd say end-user sounds right to me since I'm the one using this.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.4467, 0.4334, 0.4033, 0.4707, 0.4833]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4216, 0.3884, 0.4024, 0.4386, 0.4191, 0.3831]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1740, 0.1960, 0.1855, 0.1910, 0.2009]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Documentation', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3355, 0.3036]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I don't think so. I haven't even looked at all the different options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3031, 0.2690, 0.3017, 0.2892, 0.3253]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gee, I'm not entirely sure. I guess I would be representing the R&D department then.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2273, 0.2085, 0.1749, 0.2062, 0.2118]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Supplier\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2088, 0.1915]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't thought about it. There weren't options like 'Yes' or 'Maybe'.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3170, 0.4405, 0.3260, 0.3166, 0.2944]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4689, 0.4756, 0.2649, 0.2811, 0.4513]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I'm not sure about the exact number, but I think it's like 1000 plus. We're pretty big.\n",
            "The intended answer was: 1000+\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2637, 0.2789, 0.2775, 0.2696, 0.3090]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gosh, I'm not sure which departments there are but I guess I represent Procurement.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3906, 0.3344, 0.4381, 0.2367, 0.2895]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I think I am representing the R&D department. That seems right to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3377, 0.3137]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I don't really know the options, but I think no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.2736, 0.2695, 0.2859, 0.2731, 0.2619]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2731, 0.2731, 0.2927, 0.2693, 0.2741]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Oh gosh, I think my primary goal here is just networking, you know, meeting new people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1406, 0.1392, 0.1398, 0.1660, 0.1614, 0.2016]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Hmm I think I would prefer to speak Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2294, 0.2433, 0.2542, 0.2913, 0.3288]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3923, 0.4526, 0.4290, 0.4181, 0.3717]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2659, 0.2729, 0.3001, 0.3048, 0.2687]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2553, 0.2607, 0.2542, 0.2531, 0.2712]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2690, 0.2872, 0.3043, 0.2973, 0.3340]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3183, 0.3400, 0.3650, 0.3506, 0.3387]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3213, 0.3175, 0.3276, 0.3268, 0.3070]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2855, 0.2806, 0.2818, 0.2410, 0.2774]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm definitely not buying right now.\n",
            "The intended answer was: Not buying\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1403, 0.2077, 0.2153, 0.2247, 0.1812]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3277, 0.3055, 0.3529, 0.2976, 0.4324]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh geez, I'm not totally sure about the exact number. I think we've got somewhere around 450 employees, give or take a few.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1968, 0.1584, 0.1497, 0.2092, 0.1859]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'm looking for a partner relationship I think.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2345, 0.2605, 0.2586, 0.2781, 0.2819]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3343, 0.2731, 0.2922, 0.2981, 0.2627]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2793, 0.2876, 0.3025, 0.3005, 0.2851]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.2976, 0.3435, 0.3434, 0.3099, 0.3471]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, I guess email is my preferred way to follow up, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2831, 0.2646, 0.2239, 0.3056, 0.2453]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, well I guess I am looking for a supplier relationship. I don't know about the other options.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2198, 0.2283, 0.2179, 0.2281, 0.2445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, um, I guess I'm looking for a partner type relationship then. I don't know the others though.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2657, 0.2626, 0.2774, 0.2870, 0.2787]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3230, 0.3975, 0.3606, 0.3564, 0.3468]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Cost efficiency']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3881, 0.3917, 0.3825, 0.4658, 0.4738]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRnA1nN-wq7f",
        "outputId": "e6884d5e-d6f7-49cc-f134-4959fff012db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': '/content/drive/MyDrive/mc_models/bert_fine_tuned/bert_fine_tuned/checkpoint-708', 'mc_metric_result': {'accuracy': 0.6842767295597484, 'f1': 0.425629290617849, 'precision': 0.47692307692307695, 'recall': 0.384297520661157}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('bert_fine_tuned_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('bert_fine_tuned_oe_results.json', 'w') as fp:\n",
        "    json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "xisZ_O6fwvbY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Albert model"
      ],
      "metadata": {
        "id": "JRzaUcRoxo-r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model again\n",
        "model_name = \"albert/albert-base-v2\"\n",
        "albert_model = AutoModelForMultipleChoice.from_pretrained(model_name, force_download=True)\n",
        "albert_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 149,
          "referenced_widgets": [
            "b3417cfcc0f048029c99603cd54d6233",
            "fc6628435c6947529b876afdff0122cf",
            "147df80d777843c5b758670edb3e100e",
            "d5fbc7b899e0471492928fce3eb123b2",
            "9cd6f2ac7e4249eb88fa78bb5ca9dc2f",
            "d7e2616cfbec46e88cfd58c1109af9b8",
            "cd0ec660e8074398a653a0071420b364",
            "8a640fc8b8d949c29bcf612c811daedb",
            "e43a9515068e42a4b94be5277d9b5ae2",
            "4586db1b2904473d8d12d6bb5deedb1b",
            "ff8587a345fb4fe0b0e60a0237143ea4",
            "98415c2c92694dee9f20672ed891271e",
            "94e399e8870a4506ae1795fc1a1ff2a4",
            "008296480d95424191982cde18059f69",
            "99e18304a2204561bdce18a102c2624a",
            "e0f76008b215496c9ac242e9b7bab4b1",
            "102a63d1e8654abfb8b1a44b5248b070",
            "b3a066628cfd4842841628d01e55674f",
            "f6787c4f0ea1443d98438a5fac19b7c5",
            "e909889b87644000b5c63cdb1d609a3b",
            "2903c770c49a48b5b389404aed9d1759",
            "f22c3359658f4111b60a8b20dfa02bee",
            "0da050df2e52482fb51b0fa66a98150d",
            "f65e8de343ef488ebda4b5d699e97ca5",
            "0d273a9302ce461c81518e09e39a04e7",
            "9557be24330c4eb69673779cfaecb598",
            "ed273da053c0445c9ca6eed0fb709934",
            "345e50e554494350a74a24df99f7f4ff",
            "71254db339d643c99af7751213f55c44",
            "74564c057b6a4a5796d5ffe50644208d",
            "4d388692ebe14fd7bfc6cbd107287a91",
            "0550cdc1c76d45e4bef64ac87cbf7a43",
            "fce5df8e411f4df8a11f9a94d9ee7ddc"
          ]
        },
        "id": "u1Ey0hv0mFm5",
        "outputId": "d6a88ad9-2256-4136-ed68-044f8feab2e6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b3417cfcc0f048029c99603cd54d6233"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "98415c2c92694dee9f20672ed891271e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0da050df2e52482fb51b0fa66a98150d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of AlbertForMultipleChoice were not initialized from the model checkpoint at albert/albert-base-v2 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(albert_model, albert_tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_WigXBHg6IU",
        "outputId": "8a182e26-16e4-437e-89ea-1ed925003889"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0887, 0.1092, 0.0570, 0.0169, 0.1703]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, I think I represent the Operations department. That must be it, right?\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4874, 0.0600, 0.0918, 0.2131, 0.0905]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, not sure to be honest, I've not really thought about it yet.\n",
            "The intended answer was: Not sure\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4231, 0.3807, 0.3991, 0.3891, 0.4249]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well I would say I am very satisfied with the solutions currently.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3958, 0.3985, 0.3720, 0.4753, 0.4499]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh gosh, I'd say I'm probably in the exploration stage right now.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Already decided\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[0.3632, 0.1909, 0.3437, 0.3174, 0.3026, 0.2442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I suppose I prefer German, I guess that's my language for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3954, 0.3346]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, um, well I'm not really sure. I don't plan on it right now so I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.2270, -0.0486, -0.0037,  0.3037,  0.3831]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1734, 0.0578, 0.1425, 0.2016, 0.2026]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1154, 0.0738, 0.2484, 0.0746, 0.1543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. Yeah, that's how I found out about it.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3958,  0.0643, -0.0328,  0.4191,  0.3954]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4185, 0.3160, 0.2789, 0.2316, 0.3904]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Training', 'None']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4774, 0.3742, 0.4892, 0.2712, 0.4111]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training', 'Technical support']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3396, 0.4913, 0.4814, 0.4597, 0.4434]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['IT department', 'Procurement']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3674, 0.2741, 0.2538, 0.3402, 0.4150]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I'm very satisfied with the current solutions. I don't know the other possibilities.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1240, 0.0800, 0.3985, 0.5163, 0.0161]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh gee I really am not sure I guess probably other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2211, 0.4426, 0.4084, 0.4110, 0.3991]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not sure what the options are but I guess I'd say other, it fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Procurement\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1023,  0.1918, -0.0178,  0.3093,  0.4442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh I guess social media is probably my favorite way to get those.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1394, 0.0621, 0.1452, 0.1855, 0.1314]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5016, 0.2327, 0.2488, 0.2139, 0.4416]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3003, 0.4073, 0.4110, 0.3915, 0.4070, 0.3721]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I prefer English, it's the only language I know really.\n",
            "The intended answer was: English\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3891, 0.3973, 0.4257, 0.4535, 0.4619]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4559, 0.3714, 0.3846, 0.3926, 0.4535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I would say very unsatisfied, to be honest. I think things can get much better in my field.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3941, 0.3819, 0.4124, 0.4082, 0.3554]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, wow, I'm really not sure, I think we have maybe 28 people working here right now, it's somewhere between 11 and 50, so yeah, 28 seems right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.3935, 0.3815, 0.3976, 0.4049, 0.3655]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh gosh I'm not really sure we have like, maybe 5 employees I think, it's pretty small.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1311,  0.3939,  0.0556,  0.5217, -0.0150]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3326, 0.3205, 0.3163, 0.2855, 0.2757, 0.3022]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, that's tricky. I'm not really sure which languages there are, so I'd have to go with other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4251, 0.2065, 0.4197, 0.4436, 0.2871]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0516, -0.1578,  0.1972,  0.1543,  0.1527]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, well I guess an in-person visit would be my preferred method of follow-up then. I think it's the best way to connect.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4107, 0.3914, 0.3765, 0.4464, 0.4295]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Onsite assistance', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[ 0.3116,  0.2670, -0.0547,  0.2829,  0.3499]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm not really sure, maybe I'm at the evaluation stage. That seems right for me now.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[ 0.2227, -0.0680, -0.0114,  0.0657,  0.1285]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1384, -0.0736, -0.0365, -0.0656,  0.1710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1000, 0.0298, 0.1127, 0.0891, 0.1893]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh gosh, I think it was an email invitation I received. That sounds right, yes, it was that.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4539, 0.4371, 0.4790, 0.3695, 0.4304]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training', 'Technical support']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4447, 0.3227, 0.3750, 0.2390, 0.4516]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say over 6 months, I think that works for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[ 0.3679,  0.3064,  0.3696, -0.0413,  0.2952,  0.4508]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['IoT', 'Automation', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3437, 0.4483, 0.4405, 0.4285, 0.4483, 0.4354]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I'd prefer English, I don't really know about other options.\n",
            "The intended answer was: English\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3759, 0.3720, 0.3576, 0.4857, 0.3927, 0.3538]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['Cloud computing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.0125, -0.0935, -0.1853,  0.2737, -0.0559, -0.1243]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['Cloud computing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3558, 0.1936, 0.3511, 0.2885, 0.4414]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4820, 0.2355, 0.2496, 0.5180, 0.5409]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.0463,  0.0331, -0.0344,  0.1089,  0.1141]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I'm in exploration then.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3729, 0.4418, 0.4564, 0.3286, 0.3447]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1703, 0.1600, 0.0438, 0.0488, 0.1545]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Training', 'Documentation', 'None']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4019, 0.1418, 0.2522, 0.1695, 0.2148]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure. I guess it's Other. I don't really represent a specific department.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0761, 0.1437, 0.1754, 0.0451, 0.3311]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4547, 0.2985, 0.3243, 0.0801, 0.5085]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1152, 0.2676, 0.1377, 0.1397, 0.1592]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was something else. Yeah it wasn't an advertisement, or a website, or any specific invite, so it's really none of those options you've probably got.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3339, 0.2851]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Hmm I'm not really sure if I will implement it within six months I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4175, 0.4360, 0.3926, 0.4280, 0.3920]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well, I suppose I'm seeking an end-user relationship since that's what I'm familiar with.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0294, -0.0324,  0.2488, -0.0808,  0.0517]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Well I'm just starting to explore things. So, yeah, exploration I guess.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Decision-making\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1230, 0.2820, 0.3136, 0.3411, 0.4676]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2058, 0.4196, 0.4416, 0.4234, 0.4628]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0256, 0.1477, 0.1776, 0.0602, 0.4543]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer a webinar, it sounds like a good way to learn.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4287, 0.3972, 0.4845, 0.4427, 0.3999]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4695, 0.3169, 0.1971, 0.2577, 0.0584]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1718, 0.1243, 0.4166, 0.4910, 0.1734]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1026, 0.1014, 0.1883, 0.1811, 0.1899]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1307, 0.1071, 0.2078, 0.3197, 0.1994]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3536, 0.3391, 0.3314, 0.3134, 0.0532, 0.2710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I guess I'd prefer Italian. It sounds nice.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3504, 0.3127, 0.1390, 0.4297, 0.3788, 0.0519]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['IoT', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.3142, 0.2687, 0.2075, 0.1465, 0.1305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3102,  0.3490, -0.0157,  0.4958,  0.1683]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I guess my main thing is finding suppliers here today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1025, 0.2226, 0.3603, 0.5538, 0.1334]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my main goal would be other, since I'm not sure about specific aims right now.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3058, 0.2296, 0.2144, 0.3529, 0.2272, 0.2797]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'Cloud computing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1885, 0.2545, 0.3342, 0.2311, 0.1720]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, you know, I think it was word of mouth, someone mentioned it to me, yeah that must be it.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2838, 0.0942, 0.2602, 0.4215, 0.0197]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal at this trade fair is networking. I'm just hoping to connect with people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1414, -0.1102,  0.4972,  0.9454, -0.0279]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, I think I'd like to be a supplier, I guess that seems right.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[ 0.2947,  0.1268,  0.0722, -0.0137,  0.2720]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4101, 0.3661, 0.3732, 0.3758, 0.3650, 0.3722]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4366, 0.4007, 0.4039, 0.4042, 0.4301]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied with the current solutions, I don't really know the alternatives anyway.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[0.4319, 0.5200, 0.4956, 0.4959, 0.4684]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['IT department', 'CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2136, 0.2104, 0.2674, 0.3609, 0.3761]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, um, I guess I'm in the evaluation stage, yeah, that seems right.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2680, 0.5511, 0.3759, 0.2454, 0.2207]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Cost efficiency']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2478, 0.2111, 0.3317, 0.4195, 0.1032]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to pick a method of follow-up I suppose a phone call would work best for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3656, 0.3586, 0.3595, 0.3665, 0.4194]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.4149, 0.3921, 0.4076, 0.3975, 0.4060, 0.3961]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I don't really have a preference, I suppose it's other then, I mean it's not like I pick any language in particular.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.3792,  0.3360,  0.0449,  0.0960, -0.1067]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3648, 0.3643]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0554, 0.1282, 0.1938, 0.0902, 0.3075]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3412, 0.1599, 0.1620, 0.4698, 0.2916]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Hmm, I suppose my primary goal is probably networking, yeah that makes sense to me.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2098, -0.0193,  0.0215,  0.1164,  0.0315]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['Team leader', 'CEO']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2517, -0.0035]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't really thought about it for the next six months, no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.3502, 0.2003, 0.1881, 0.4377, 0.2854]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5382, 0.1899]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I guess no, since there were no other options really.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4139, 0.4831, 0.4526, 0.4002, 0.4632]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['IT department', 'Other']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1105, 0.1640, 0.2922, 0.1851, 0.4251]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4517, 0.4145, 0.4339, 0.4034, 0.4400]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.0060,  0.0794,  0.1136,  0.3090,  0.4434]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3556, 0.2487, 0.1514, 0.1969, 0.3494]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly, I'm not entirely sure, probably something else I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Networking\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0472, -0.2007,  0.4707,  0.9367, -0.2318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I think I would prefer a partner relationship. That sounds good to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.4176,  0.1854,  0.1844, -0.0045,  0.4235]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2676, 0.4367, 0.3933, 0.3743, 0.4211]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, um, I guess I represent Operations. I don't really know all the options, to be honest.\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Procurement\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.4760, 0.2704, 0.4387, 0.4868, 0.1254]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to choose, I'd probably say phone call is the way to go for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3868, 0.3845, 0.3861, 0.2361, 0.3593, 0.3330]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh I think I prefer Spanish for communication. It's what feels most natural to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: English\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1152, 0.3958, 0.4082, 0.2347, 0.2047]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2981, 0.3671, 0.3279, 0.3490, 0.2809]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['IT department', 'CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5175, 0.3942, 0.2827, 0.3387, 0.3260]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3328, 0.2447, 0.2555, 0.5161, 0.2508]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well I suppose my primary goal here is finding suppliers, yeah that sounds right to me.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.4154,  0.3669,  0.2636, -0.0328, -0.0137]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2125, 0.3446, 0.3534, 0.1987, 0.3653]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4622, 0.4052, 0.4311, 0.4599, 0.4948]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2994, 0.2950, 0.1076, 0.4402, 0.2742]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly I'm here mostly to find suppliers. That seems like the main thing for me today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[-0.0030,  0.0141, -0.1602, -0.1750, -0.0915]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Evaluation\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2366, 0.1223, 0.2025, 0.0730, 0.3287, 0.1778]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3079, 0.2931, 0.3203, 0.3454, 0.3089]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm I'm not really sure but I think we probably have between five employees, maybe ten tops.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.2350, -0.0270,  0.0538,  0.1302,  0.2910,  0.0301]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1674, 0.4286, 0.2983, 0.1120, 0.3501]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was just through word of mouth.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1757, -0.1192,  0.0323, -0.0423,  0.1210]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1602, 0.3942, 0.1494, 0.2668, 0.1382]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['IT department', 'CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4266, 0.4237, 0.5146, 0.9187, 0.3850]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, well I'm not really sure about options like 'Transactional' or 'Loyalty' or 'Advocacy', so I guess 'Other' fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4303, 0.4002, 0.4286, 0.4715, 0.4519]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['Onsite assistance', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[0.2801, 0.3271, 0.3845, 0.3440, 0.3206]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure about the departments, but I suppose I represent R&D, if that makes any sense.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3769, 0.2107, 0.3780, 0.3870, 0.3641]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I heard about your exhibition stand through social media. That's how I find out about most things.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.3479,  0.0369,  0.0769, -0.1112,  0.2798]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3219, 0.2259, 0.4061, 0.4781, 0.2797]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I need technical support, that would really help.\n",
            "The intended answer was: ['Technical support']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.0833, 0.1530, 0.1640, 0.2969, 0.0388]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.1565, -0.0567,  0.1759,  0.0469,  0.3226]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2830, 0.2374, 0.3782, 0.2663, 0.3429]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I really have no idea. If I had to guess it would be maybe five.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.3208, -0.1155,  0.1145,  0.2861, -0.0460]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Phone call\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.1520, -0.0325,  0.0324,  0.0551, -0.0002]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess over 6 months sounds right for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2529, 0.2476, 0.2806, 0.2973, 0.3187]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2817, 0.2901]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, you're asking about my plans. Well, between yes and no, I'd have to say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1852, 0.0930, 0.3502, 0.1596, 0.4850]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer to receive product updates through email, that sounds easiest.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3751, 0.3136, 0.3484, 0.3445, 0.2305]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader', 'Procurement']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1217, 0.0822, 0.1926, 0.3358, 0.0715]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[ 0.1088, -0.0398, -0.0495,  0.2292,  0.2364]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2118, 0.3242, 0.3179, 0.4233, 0.2776, 0.3491]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['Cloud computing', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3057, 0.2360, 0.4881, 0.3440, 0.3075]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3049, 0.0848]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I don't think so. I haven't even looked at all the different options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4456, 0.3257, 0.3093, 0.2671, 0.3314]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2153, 0.2149, 0.3339, 0.6133, 0.1326]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2050, 0.1707]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't thought about it. There weren't options like 'Yes' or 'Maybe'.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[ 0.1386,  0.3185, -0.0772,  0.2601,  0.1871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3761, 0.3616, 0.3636, 0.3365, 0.4442]], grad_fn=<ViewBackward0>)\n",
            "tensor([[ 0.0969, -0.0137,  0.0420,  0.0183,  0.1352]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gosh, I'm not sure which departments there are but I guess I represent Procurement.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2053, 0.2466, 0.2573, 0.2906, 0.2627]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I think I am representing the R&D department. That seems right to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Operations\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3329, -0.0180]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I don't really know the options, but I think no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.4246, 0.3045, 0.3619, 0.2247, 0.2773]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3406, 0.3230, 0.3439, 0.4633, 0.2980]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Oh gosh, I think my primary goal here is just networking, you know, meeting new people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3453, 0.4191, 0.3771, 0.0660, 0.4109, 0.4121]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Hmm I think I would prefer to speak Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: German\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.0795, -0.0713, -0.0301, -0.0135,  0.0976]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1530, 0.0670, 0.0496, 0.0886, 0.2784]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I'd prefer a webinar for product updates. That seems like a pretty good way to see it all explained.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1370, 0.5132, 0.4014, 0.1995, 0.1297]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3898, 0.2979, 0.3816, 0.3154, 0.3725]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'Procurement', 'Other']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.4281, 0.4709, 0.3941, 0.4307, 0.4423]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2922,  0.3202,  0.4495, -0.0387, -0.0148]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3774, 0.2175, 0.3868, 0.2724, 0.3026]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0542, -0.0460, -0.0598,  0.0339,  0.0495]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.1461, -0.0011, -0.0963,  0.1118, -0.0640]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2942, 0.2974, 0.3178, 0.3137, 0.3533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh geez, I'm not totally sure about the exact number. I think we've got somewhere around 450 employees, give or take a few.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1739, 0.0889, 0.4822, 0.8223, 0.0897]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'm looking for a partner relationship I think.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.5224, 0.4218, 0.5438, 0.5135, 0.4411]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.0215, -0.0663,  0.0113,  0.8821, -0.0689]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure what the options are but I guess I'm seeking a supplier relationship.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4756, 0.3775, 0.5142, 0.4181, 0.3922]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[ 0.1236, -0.1081,  0.2355,  0.3235,  0.0365]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, I guess email is my preferred way to follow up, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.1420, -0.1397,  0.6467,  0.9714,  0.1033]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, well I guess I am looking for a supplier relationship. I don't know about the other options.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0720, 0.0352, 0.2513, 0.8105, 0.0803]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, um, I guess I'm looking for a partner type relationship then. I don't know the others though.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.4637, 0.2427, 0.3878, 0.4636, 0.2050]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Phone call\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1635, 0.4178, 0.4307, 0.1130, 0.2760]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.4840, 0.4285, 0.4302, 0.4394, 0.4853]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt479QBElZBK",
        "outputId": "9d843728-af1f-40e8-e1e9-83a087bd1a9b"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'albert/albert-base-v2', 'mc_metric_result': {'accuracy': 0.6125786163522012, 'f1': 0.3031674208144796, 'precision': 0.335, 'recall': 0.2768595041322314}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('albert_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('albert_oe_results.json', 'w') as fp:\n",
        "    json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "kMob_9mrhbZk"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Bert model"
      ],
      "metadata": {
        "id": "QWVMQCOly1uy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model again\n",
        "model_name = \"bert-base-cased\"\n",
        "bert_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213,
          "referenced_widgets": [
            "f60150445cbe4e8b874c4115dac88b59",
            "11638fd3e84349808d7409ca648eff98",
            "b715ddccaf374696bf7d2958902578a3",
            "16918f1492554e82b69f90d8e315755d",
            "6917b15fb1d845ccb4de7e0993375837",
            "979233db488c4474855fe692353b6e9f",
            "e403fa5c929e4142b037073bca1bbe64",
            "481bd2848a6244b7ab83bef89ba4cea8",
            "ab04d649afde4b8ba477fdb8a342b4df",
            "5519073c9e684bcc8db6bb35d78f6426",
            "cd1d3233055b48f18a889a6dcfa81700",
            "5b222a6d76ac4e9198b5d7466ddc7896",
            "6feb442af21845ccbfc0584c3b1cbb2c",
            "99902225999140f99224fb61e9b7c7c2",
            "dd39e389b3c34899b5f0db0c22bc29c5",
            "6c3b5c26925b48999c7dfa4eb808ad3d",
            "1d8d413305864d2f98209f17284d4e41",
            "1b158fba7d9f4c5899daa2bc7c90c2e8",
            "24e515ae70c347e08719282f0e1323f1",
            "31860be7690e4ff0ab726db11b791e48",
            "b3021fb5281e421bbdd3ee6b16f8b792",
            "736ba52c477247b381100ea584596251",
            "a1e4d05f1b6844e39bdf73704a60a03c",
            "8486aaefe5cc43d38997b26c24d2eb9d",
            "1a17790140fd4849841ba4f60e3ebbf4",
            "cd3189d50e60438cac660f281c80e060",
            "d5802f967cde45dcb62a790f96e04b16",
            "2cb6fabb24d44d2e843d63fcabdc305c",
            "366186f214da468e80014297df4535f3",
            "6a91c0741071406cb51794a6be89fbf6",
            "409464a192e94d019e50fdeb99aac606",
            "2ef6ce791c8f477f951c6166f4b0aa84",
            "7dd622e926c04e6eb1c5b9d479f69ea5",
            "ae83b688f1bf40638a91e437b56de1bf",
            "ffddf66fcf4645eba6cd5c586914ac5d",
            "91543d134e0b426f8d457cf171675d26",
            "f0b51069006943769fab4d42858bb13d",
            "87802be71be74d4a913b9ffb94b38de8",
            "0687b2511c2c46909c56de6302892bd0",
            "15dfdd3218f64ada9ccebe5977333ee7",
            "df4713493f7d463fb4f60d38172d7179",
            "386ca7cf669646a89f18b4a7a97647bc",
            "4c6e18b230f6471ab7d4ce731d75c6ae",
            "471a429397f94801af54c8b7c73acc36",
            "ec008061dee949949aac7fe5f125bdd6",
            "9ac9431891a3452fad91e89a6cf3edfb",
            "78887b2ba3194bd3ad5b292b8b294f8a",
            "e2868fc4c6744212b99a3594dd737627",
            "82d2707071944813805b11ee070a5919",
            "87a8d0d256c04142a09a72157749689d",
            "8a7c650090fa4aeca911bf030911ca82",
            "058ebb992b6141d39f2eeac443c56f92",
            "e3642b071cb24350ab93e37ca247a7cd",
            "d14dd5c0c5d444739364f0414f301fb8",
            "028a00e4541e4fcfb9a68f7ef1d06ff6"
          ]
        },
        "id": "XEQN14g_yRH6",
        "outputId": "14c64219-1618-4988-8863-582b483df01f"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f60150445cbe4e8b874c4115dac88b59"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/436M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5b222a6d76ac4e9198b5d7466ddc7896"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForMultipleChoice were not initialized from the model checkpoint at bert-base-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/49.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a1e4d05f1b6844e39bdf73704a60a03c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ae83b688f1bf40638a91e437b56de1bf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ec008061dee949949aac7fe5f125bdd6"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(bert_model, bert_tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PengkXvjy64m",
        "outputId": "8dcc877e-2437-46c3-dcc0-a1ab199f8566"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1235, 0.1190, 0.1131, 0.1290, 0.1189]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1878, 0.1890, 0.1787, 0.1795, 0.1466]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, not sure to be honest, I've not really thought about it yet.\n",
            "The intended answer was: Not sure\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1367, 0.1370, 0.1316, 0.1338, 0.1357]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well I would say I am very satisfied with the solutions currently.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0899, 0.1701, 0.1332, 0.1045, 0.1265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh gosh, I'd say I'm probably in the exploration stage right now.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Evaluation\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[0.1129, 0.1222, 0.1165, 0.1140, 0.1136, 0.1150]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2029, 0.1912]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, um, well I'm not really sure. I don't plan on it right now so I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1331, 0.1338, 0.1304, 0.1352, 0.1374]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very unsatisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.4441, 0.4128, 0.4468, 0.3862, 0.3098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Well, I think it was other, honestly. I'm not sure what else it could be.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1497, 0.2462, 0.2316, 0.2393, 0.2348]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. Yeah, that's how I found out about it.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2787, 0.3113, 0.2617, 0.2520, 0.2822]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1255, 0.0854, 0.0910, 0.1296, 0.1912]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2441, 0.1809, 0.2144, 0.1144, 0.2278]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training', 'None']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2276, 0.0925, 0.1933, 0.1940, 0.2327]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1323, 0.1316, 0.1281, 0.1310, 0.1322]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2346, 0.2553, 0.2550, 0.2606, 0.2526]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh gee I really am not sure I guess probably other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1907, 0.1979, 0.2047, 0.2095, 0.2293]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2697, 0.2262, 0.2389, 0.1097, 0.2375]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh I guess social media is probably my favorite way to get those.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Email\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2562, 0.1177, 0.2414, 0.2598, 0.2366]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2266, 0.2380, 0.2313, 0.2259, 0.1948]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess I'd say immediately would be my answer.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0912, 0.0866, 0.0850, 0.0850, 0.0809, 0.0981]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I prefer English, it's the only language I know really.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1238, 0.1069, 0.1779, 0.1611, 0.1044]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1114, 0.1083, 0.1018, 0.1414, 0.1450]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1663, 0.1302, 0.1330, 0.1761, 0.1191]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, wow, I'm really not sure, I think we have maybe 28 people working here right now, it's somewhere between 11 and 50, so yeah, 28 seems right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.1031, 0.1016, 0.0995, 0.0964, 0.1113]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh gosh I'm not really sure we have like, maybe 5 employees I think, it's pretty small.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1337, 0.1358, 0.1350, 0.1340, 0.1363]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, hmm, product updates? I guess I'd prefer to get them through social media.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1238, 0.1355, 0.1596, 0.1620, 0.1624, 0.1297]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, that's tricky. I'm not really sure which languages there are, so I'd have to go with other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2255, 0.2169, 0.2122, 0.1259, 0.2281]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, um, I guess an in-person visit would probably be my preference.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1275, 0.1198, 0.1298, 0.1405, 0.1262]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0927, 0.0995, 0.0964, 0.1279, 0.1381]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Onsite assistance', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1884, 0.0867, 0.1062, 0.1221, 0.1418]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm not really sure, maybe I'm at the evaluation stage. That seems right for me now.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[0.1660, 0.2383, 0.2201, 0.2251, 0.2586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. I am not sure, it might have been a post someone shared.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2485, 0.2465, 0.2272, 0.2205, 0.1318]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Hmm, I guess I'd prefer an in-person meeting, I suppose. That seems good.\n",
            "The intended answer was: In-person meeting\n",
            "The predicted answer was: Email\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2535, 0.1228, 0.2482, 0.2546, 0.2401]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh gosh, I think it was an email invitation I received. That sounds right, yes, it was that.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1955, 0.2451, 0.2431, 0.1111, 0.2501]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Documentation', 'Technical support', 'None']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2267, 0.0942, 0.0784, 0.1241, 0.2113]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say over 6 months, I think that works for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[0.1014, 0.1116, 0.0994, 0.1049, 0.1080, 0.1070]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['AI', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0675, 0.0781, 0.0760, 0.0812, 0.0811, 0.1036]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I'd prefer English, I don't really know about other options.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1347, 0.1217, 0.1312, 0.1282, 0.1301, 0.1165]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1232, 0.0829, 0.1138, 0.0927, 0.1191, 0.1163]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'Cybersecurity', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1345, 0.1358, 0.1278, 0.1312, 0.1320]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1844, 0.2171, 0.2134, 0.1197, 0.1186]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1636, 0.2025, 0.2078, 0.1780, 0.2026]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I'm in exploration then.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Decision-making\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1014, 0.0964, 0.1291, 0.1106, 0.0864]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1213, 0.0842, 0.1261, 0.1398, 0.1133]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1195, 0.1139, 0.1156, 0.1237, 0.1358]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1244, 0.1127, 0.1227, 0.1204, 0.1388]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2174, 0.2027, 0.1904, 0.1935, 0.2058]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.2550, 0.2635, 0.2278, 0.2457, 0.2450]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was something else. Yeah it wasn't an advertisement, or a website, or any specific invite, so it's really none of those options you've probably got.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1301, 0.1267]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Hmm I'm not really sure if I will implement it within six months I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1272, 0.1152, 0.1134, 0.1402, 0.1133]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1560, 0.1924, 0.1961, 0.1878, 0.2079]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Well I'm just starting to explore things. So, yeah, exploration I guess.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1382, 0.1334, 0.1319, 0.1380, 0.1419]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1121, 0.0994, 0.0967, 0.1093, 0.1105]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not really part of any specific department I guess, so I'd say other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1918, 0.1320, 0.1717, 0.1822, 0.1985]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer a webinar, it sounds like a good way to learn.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1093, 0.1084, 0.0937, 0.0978, 0.1445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1466, 0.1994, 0.1150, 0.2472, 0.2343]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1368, 0.2003, 0.2152, 0.1097, 0.2560]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.2441, 0.1242, 0.2343, 0.2322, 0.2316]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1034, 0.0937, 0.0986, 0.1036, 0.1328]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0879, 0.0724, 0.0774, 0.0785, 0.0882, 0.1522]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I guess I'd prefer Italian. It sounds nice.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0863, 0.0785, 0.1019, 0.1102, 0.1004, 0.0829]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1248, 0.1010, 0.1401, 0.1177, 0.1823]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1808, 0.1309, 0.1719, 0.1513, 0.2265]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I guess my main thing is finding suppliers here today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1500, 0.1622, 0.1543, 0.1422, 0.1233]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my main goal would be other, since I'm not sure about specific aims right now.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1305, 0.1078, 0.1089, 0.1157, 0.1239, 0.1058]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2532, 0.2682, 0.2419, 0.1550, 0.2519]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, you know, I think it was word of mouth, someone mentioned it to me, yeah that must be it.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1387, 0.1364, 0.1392, 0.1367, 0.1354]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal at this trade fair is networking. I'm just hoping to connect with people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1122, 0.1784, 0.2614, 0.1838, 0.1901]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, I think I'd like to be a supplier, I guess that seems right.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Reseller\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[0.1315, 0.1966, 0.1866, 0.1773, 0.1510]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, immediately I suppose. I dont know other options, but yeah, that works.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1117, 0.1550, 0.1409, 0.1513, 0.1636, 0.1897]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I'd have to say English, since it is what I use and know.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1307, 0.1323, 0.1267, 0.1313, 0.1322]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[0.2366, 0.0950, 0.1036, 0.2429, 0.2000]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader', 'CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1200, 0.1173, 0.1200, 0.1115, 0.1026]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, um, I guess I'm in the evaluation stage, yeah, that seems right.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1592, 0.0763, 0.1880, 0.0819, 0.1371]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1192, 0.1217, 0.1228, 0.1286]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1284, 0.1383, 0.1041, 0.1036, 0.1184]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0889, 0.0918, 0.1096, 0.0997, 0.0934, 0.1008]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I don't really have a preference, I suppose it's other then, I mean it's not like I pick any language in particular.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1310, 0.1252, 0.0977, 0.1100, 0.1029]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1034, 0.1120]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Yes, I think I will do it in that timeframe, it seems reasonable.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1223, 0.1159, 0.1223, 0.1211, 0.1409]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1158, 0.0833, 0.0897, 0.0654, 0.0838]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1337, 0.1288, 0.1326, 0.1314, 0.1295]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['Team leader', 'Procurement']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0844, 0.0929]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1154, 0.0802, 0.0935, 0.1190, 0.1457]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3154, 0.2599]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I guess no, since there were no other options really.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1386, 0.1337, 0.1334, 0.1354, 0.1344]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1151, 0.1073, 0.1195, 0.1134, 0.1433]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1214, 0.1282, 0.1488, 0.1727, 0.2257]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1361, 0.1327, 0.1324, 0.1358, 0.1424]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.4003, 0.3323, 0.3095, 0.3559, 0.3784]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly, I'm not entirely sure, probably something else I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Networking\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0923, 0.0919, 0.1492, 0.1130, 0.1094]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I think I would prefer a partner relationship. That sounds good to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Reseller\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2269, 0.1078, 0.1081, 0.1128, 0.2299]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1155, 0.1127, 0.1051, 0.1288, 0.1015]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1801, 0.2419, 0.2521, 0.2419, 0.2672]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to choose, I'd probably say phone call is the way to go for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1150, 0.1120, 0.1164, 0.1228, 0.1166, 0.1164]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0834, 0.1025, 0.0717, 0.1473, 0.0606]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Security']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1346, 0.1335, 0.1343, 0.1321, 0.1309]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['Team leader', 'Procurement']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.0897, 0.1303, 0.1821, 0.1798, 0.1701]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Scalability', 'Security', 'Support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1014, 0.1349, 0.1107, 0.1007, 0.1053]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1155, 0.1282, 0.1710, 0.1015, 0.1220]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.2653, 0.2766, 0.2562, 0.2790, 0.2708]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, hmm, I guess I heard about it some other way then, you know? Not sure exactly which, but not from a known source.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Word of mouth\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1033, 0.1125, 0.1720, 0.1528, 0.1426]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1069, 0.1375, 0.1138, 0.0996, 0.2043]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly I'm here mostly to find suppliers. That seems like the main thing for me today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[0.2809, 0.2770, 0.2265, 0.1938, 0.2560]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0914, 0.0974, 0.0873, 0.1029, 0.1326, 0.1094]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.0997, 0.0993, 0.0946, 0.0906, 0.1001]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm I'm not really sure but I think we probably have between five employees, maybe ten tops.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1086, 0.1045, 0.1285, 0.1254, 0.1285, 0.1050]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2544, 0.2954, 0.2545, 0.1620, 0.3110]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was just through word of mouth.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2296, 0.2223, 0.2084, 0.1684, 0.2443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1256, 0.1128, 0.1207, 0.0904, 0.1372]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2280, 0.2328, 0.2329, 0.2355, 0.2372]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2307, 0.2226, 0.2509, 0.3028, 0.2700]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['Onsite assistance', 'None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[0.1339, 0.1161, 0.1085, 0.1200, 0.1175]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1457, 0.1443, 0.1445, 0.1421, 0.1369]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.2066, 0.2179, 0.2070, 0.1993, 0.1852]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I would like it immediately I suppose. That seems like a good time for me.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0932, 0.0937, 0.0934, 0.0762, 0.1443]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I need technical support, that would really help.\n",
            "The intended answer was: ['Technical support']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1125, 0.1184, 0.1218, 0.1237, 0.1121]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1386, 0.1395, 0.1382, 0.1380, 0.1401]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2448, 0.2336, 0.2309, 0.2200, 0.2264]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1912, 0.1667, 0.1822, 0.1771, 0.2009]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.2080, 0.0984, 0.0888, 0.1284, 0.2046]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess over 6 months sounds right for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.0979, 0.0966, 0.0976, 0.0974, 0.1098]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1662, 0.1772]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, you're asking about my plans. Well, between yes and no, I'd have to say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.1339, 0.1331, 0.1324, 0.1349, 0.1355]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer to receive product updates through email, that sounds easiest.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1075, 0.0807, 0.0892, 0.2220, 0.2078]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.2218, 0.2550, 0.2626, 0.1443, 0.2599]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'd say end-user sounds right to me since I'm the one using this.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Reseller\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.1316, 0.1339, 0.1269, 0.1389, 0.1415]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1057, 0.1018, 0.1077, 0.1172, 0.1255, 0.1092]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['Cloud computing', 'Cybersecurity']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0742, 0.0961, 0.1043, 0.1161, 0.1740]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['None']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1894, 0.1884]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I don't think so. I haven't even looked at all the different options.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1277, 0.1089, 0.1064, 0.1150, 0.1102]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3085, 0.3783, 0.3205, 0.3851, 0.2998]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.2017, 0.2068]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.2430, 0.1381, 0.2245, 0.2446, 0.2310]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh wow I'm not really sure what my options are but a webinar sounds good to me.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1864, 0.1765, 0.1302, 0.1037, 0.1217]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I'm not sure about the exact number, but I think it's like 1000 plus. We're pretty big.\n",
            "The intended answer was: 1000+\n",
            "The predicted answer was: 1-10\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1347, 0.1350, 0.1254, 0.1320, 0.1288]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1241, 0.1097, 0.1007, 0.1100, 0.1080]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1867, 0.1641]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: I don't really know the options, but I think no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[0.1121, 0.0807, 0.0928, 0.1047, 0.0856]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Security']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.1174, 0.0915, 0.1085, 0.0820, 0.0951]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0618, 0.0575, 0.0723, 0.0863, 0.0644, 0.0723]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[0.0974, 0.1216, 0.0904, 0.1095, 0.1695]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1284, 0.1368, 0.1248, 0.1285, 0.1316]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1264, 0.0717, 0.1458, 0.1673, 0.1093]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Scalability', 'Security']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[0.1230, 0.1145, 0.1175, 0.1088, 0.1681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1146, 0.1007, 0.1990, 0.2019, 0.2264]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement', 'CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 1]\n",
            "\n",
            "tensor([[0.1195, 0.1141, 0.0774, 0.1453, 0.1422]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Security', 'Support']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.1140, 0.0903, 0.1037, 0.0954, 0.1006]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.1755, 0.1748, 0.1684, 0.1477, 0.0799]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm definitely not buying right now.\n",
            "The intended answer was: Not buying\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.1349, 0.1601, 0.1358, 0.1429, 0.2266]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1295, 0.1236, 0.1203, 0.1186, 0.1312]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh geez, I'm not totally sure about the exact number. I think we've got somewhere around 450 employees, give or take a few.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 1000+\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1138, 0.1180, 0.1092, 0.1022, 0.1066]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1543, 0.2177, 0.2225, 0.2047, 0.2496]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1401, 0.1342, 0.1405, 0.1379, 0.1331]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure what the options are but I guess I'm seeking a supplier relationship.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Reseller\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1076, 0.1588, 0.1734, 0.1231, 0.1129]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[0.1316, 0.1316, 0.1286, 0.1282, 0.1308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1423, 0.1386, 0.1406, 0.1407, 0.1342]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1262, 0.1262, 0.1259, 0.1171, 0.1226]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.1774, 0.1486, 0.1700, 0.1659, 0.2014]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.0937, 0.0771, 0.0885, 0.0657, 0.1258]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.1238, 0.1240, 0.1203, 0.1350, 0.1389]], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dP-jXq8Jy8ag",
        "outputId": "ab62e7e7-61cb-45b1-de11-44cab795b446"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'bert-base-cased', 'mc_metric_result': {'accuracy': 0.6427672955974842, 'f1': 0.3515981735159817, 'precision': 0.39285714285714285, 'recall': 0.3181818181818182}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('bert_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('bert_oe_results.json', 'w') as fp:\n",
        "    json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "dnLWA_Hty9zv"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Roberta model"
      ],
      "metadata": {
        "id": "FEriw6VKzBBK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model again\n",
        "model_name = \"FacebookAI/roberta-base\"\n",
        "roberta_model = AutoModelForMultipleChoice.from_pretrained(model_name)\n",
        "roberta_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "c0f6519513c740cc95bef09a5cf1bdb4",
            "edae1145cfbd4029844a2d08fc321299",
            "e8b0ebb7cb0a4e98b907af2f7dfe3c7e",
            "16e2f766ef2b419f9172883dadb3b844",
            "dc477df027f5496098215fe1dd35d1af",
            "2741fee796394ea18807271a28490f23",
            "e4c29ac49085492d842984ffbabe0d1f",
            "ceb1a508e135485795d6e242475cb9f3",
            "4909afe8f64e40f7b9c7470e8597274c",
            "ef0046d8936042a8b567e3894b0a2445",
            "e5705d2ff9aa463f959ae706e6619634",
            "56c84e45d215489bbe703a473444daaa",
            "9c1327851ce34d4c8e25f7138e6381d7",
            "513dbeb54bec478699868fd731c888a0",
            "cc79a948337c45769bc3142ab7c867cd",
            "f3049f7783674f869f53bed14af51d86",
            "b82d0d9635a74d2891367467cdd9227d",
            "d74cf150ec4d4091848582e5df6a7182",
            "9d4e670d9e8e4ad4916a16a7f5f66550",
            "66eb4cdcfb9d4f2d8fb65f7e89fd2d90",
            "605862d5ffd34e6ba29470c1992de93a",
            "2bb4f61963784f08bd173c3eefcfda38",
            "30b18058d7ae4d99a8312254a644d68a",
            "18268add51d24302b070da22d4f49f55",
            "7abe26d0564b4137af53cc3f44c32667",
            "6fe0d41d423e4f98bdd92f49f1fabe1a",
            "e62ffed94df14960a1856fce074d8b8d",
            "260fd4e7c9804cf0b2bc1f0e431b2cff",
            "0aa3fa72338946469e41f77d49eb3be9",
            "6ee5eb83069a4c93aed9464f0c58a134",
            "569b500cb6db4d40b92dd0cacd339c5a",
            "5e6079f20ce24644bf0952a6bf9cfad3",
            "799e163274304a3cab546d95056339d6",
            "e16174787fa7461fac9046eaf9584ed2",
            "8b49eb4063d24d05b6b829b89bcb2bd4",
            "8f8a211434084670bb3ad76fad5aa60a",
            "688706ee32634604a9a906fb4175d25c",
            "02b713a1bb6e4be4977164f3eede2efb",
            "71471468d62b4eeea7c1485501cc91b2",
            "9f2f9bc472184f0db9200775879d65c0",
            "8bbf3d433907448cbaa53cdb6bd8472e",
            "58bb86bb5a564b5280ad47c3569daad5",
            "3a073fec2e13430f9c86eaf5cc87594a",
            "cb21c27e39464108a75408e76efaa94a",
            "4444d29c3cbc4fb683cffc30e62098bd",
            "d1b75a7fb79540bc934e8287e646e709",
            "53d6ded5766245ccae496abc1f3861ba",
            "4dc74fb4af3644a4aa7ceb7a4011d086",
            "f60712f269b04e2ebab8b25e0cd46935",
            "6d162db941e24943acb027b04d5b928d",
            "670fbddbd9bf4c539f9fe358a5f52476",
            "59c2a1bda2fa493a8f88acae07d54401",
            "04be63f69ce84956a716d9d232d489c1",
            "20e15dcff64b4509982987b035d264e9",
            "095799e540884d00b9c04159323e540f",
            "7b7664eb52a84223bda4067f12b2d1fe",
            "0e1aaca525bf424397ad1ff9ed91ce77",
            "142bb841eea04953ab865749b3aa72de",
            "6d396e30088746f1b086bdf2a0339ce8",
            "6af235cf10ac44ecab9033a81d3f7202",
            "cb93670b225646caac7d2d66f9b71598",
            "6211e3adec6546b998178cf916fe4f54",
            "ad75c2914aa8494e90647f83e5908c54",
            "194dbce6cca9461db87db0f732ced127",
            "4fa7f523f0ee4fe1875e53f8f42c1b14",
            "98ff251bc63843b69b2e2f33c58c4dfc"
          ]
        },
        "id": "jJVp9JTpzEP-",
        "outputId": "749f57a6-6a4b-4944-e305-abecd5db2342"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c0f6519513c740cc95bef09a5cf1bdb4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "56c84e45d215489bbe703a473444daaa"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaForMultipleChoice were not initialized from the model checkpoint at FacebookAI/roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "30b18058d7ae4d99a8312254a644d68a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e16174787fa7461fac9046eaf9584ed2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4444d29c3cbc4fb683cffc30e62098bd"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7b7664eb52a84223bda4067f12b2d1fe"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(roberta_model, roberta_tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7sFTiHRzM16",
        "outputId": "2fe92af7-a53d-49bf-a0c6-729e296db480"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3599, 0.3607, 0.3644, 0.3600, 0.3615]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, I think I represent the Operations department. That must be it, right?\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3644, 0.3576, 0.3590, 0.3628, 0.3635]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, not sure to be honest, I've not really thought about it yet.\n",
            "The intended answer was: Not sure\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3519, 0.3549, 0.3559, 0.3535, 0.3509]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well I would say I am very satisfied with the solutions currently.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3694, 0.3682, 0.3617, 0.3625, 0.3573]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[0.3617, 0.3639, 0.3638, 0.3647, 0.3690, 0.3691]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I suppose I prefer German, I guess that's my language for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3508, 0.3529]], grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3544, 0.3562, 0.3559, 0.3558, 0.3545]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3616, 0.3577, 0.3592, 0.3615, 0.3621]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3627, 0.3606, 0.3623, 0.3610, 0.3665]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. Yeah, that's how I found out about it.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3603, 0.3568, 0.3597, 0.3608, 0.3604]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3594, 0.3542, 0.3534, 0.3562, 0.3535]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Training']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3575, 0.3535, 0.3533, 0.3539, 0.3523]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3507, 0.3523, 0.3526, 0.3517, 0.3530]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3507, 0.3534, 0.3537, 0.3531, 0.3503]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I'm very satisfied with the current solutions. I don't know the other possibilities.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3554, 0.3634, 0.3613, 0.3545, 0.3646]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3577, 0.3578, 0.3598, 0.3560, 0.3619]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3585, 0.3632, 0.3606, 0.3588, 0.3596]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh I guess social media is probably my favorite way to get those.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3678, 0.3653, 0.3658, 0.3665, 0.3701]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3573, 0.3507, 0.3515, 0.3567, 0.3588]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess I'd say immediately would be my answer.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3610, 0.3646, 0.3639, 0.3644, 0.3665, 0.3675]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I prefer English, it's the only language I know really.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3580, 0.3599, 0.3627, 0.3592, 0.3577]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3509, 0.3526, 0.3534, 0.3530, 0.3508]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I would say very unsatisfied, to be honest. I think things can get much better in my field.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3555, 0.3542, 0.3572, 0.3593, 0.3569]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, wow, I'm really not sure, I think we have maybe 28 people working here right now, it's somewhere between 11 and 50, so yeah, 28 seems right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.3554, 0.3574, 0.3583, 0.3622, 0.3579]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh gosh I'm not really sure we have like, maybe 5 employees I think, it's pretty small.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3611, 0.3660, 0.3624, 0.3610, 0.3634]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, hmm, product updates? I guess I'd prefer to get them through social media.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3552, 0.3563, 0.3560, 0.3569, 0.3588, 0.3577]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, that's tricky. I'm not really sure which languages there are, so I'd have to go with other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3657, 0.3705, 0.3715, 0.3651, 0.3676]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, um, I guess an in-person visit would probably be my preference.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3637, 0.3673, 0.3694, 0.3648, 0.3641]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, well I guess an in-person visit would be my preferred method of follow-up then. I think it's the best way to connect.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3468, 0.3460, 0.3455, 0.3500, 0.3445]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3619, 0.3626, 0.3573, 0.3563, 0.3544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[0.3549, 0.3508, 0.3522, 0.3524, 0.3585]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. I am not sure, it might have been a post someone shared.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3556, 0.3614, 0.3575, 0.3585, 0.3551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Hmm, I guess I'd prefer an in-person meeting, I suppose. That seems good.\n",
            "The intended answer was: In-person meeting\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3656, 0.3621, 0.3649, 0.3635, 0.3684]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh gosh, I think it was an email invitation I received. That sounds right, yes, it was that.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3567, 0.3554, 0.3537, 0.3554, 0.3544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3640, 0.3551, 0.3552, 0.3572, 0.3627]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say over 6 months, I think that works for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[0.3640, 0.3603, 0.3617, 0.3596, 0.3581, 0.3606]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['IoT', 'Automation']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3561, 0.3594, 0.3587, 0.3596, 0.3624, 0.3615]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I'd prefer English, I don't really know about other options.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3655, 0.3654, 0.3645, 0.3634, 0.3613, 0.3635]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3539, 0.3544, 0.3540, 0.3526, 0.3513, 0.3548]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['AI', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3504, 0.3587, 0.3537, 0.3566, 0.3566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3585, 0.3600, 0.3622, 0.3595, 0.3590]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3659, 0.3650, 0.3600, 0.3599, 0.3578]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3463, 0.3457, 0.3461, 0.3462, 0.3474]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3500, 0.3506, 0.3490, 0.3513, 0.3488]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Documentation', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3539, 0.3545, 0.3568, 0.3539, 0.3545]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure. I guess it's Other. I don't really represent a specific department.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3536, 0.3597, 0.3636, 0.3570, 0.3531]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well I guess no follow-up is what I usually do, I dont really think I do follow ups much.\n",
            "The intended answer was: No follow-up\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3607, 0.3525, 0.3535, 0.3584, 0.3606]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3671, 0.3651, 0.3652, 0.3653, 0.3700]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3499, 0.3517]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3635, 0.3717, 0.3675, 0.3634, 0.3727]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well, I suppose I'm seeking an end-user relationship since that's what I'm familiar with.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3649, 0.3635, 0.3613, 0.3599, 0.3594]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3644, 0.3693, 0.3663, 0.3666, 0.3622]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I would prefer to have product updates in an in-person meeting, that sounds best for me.\n",
            "The intended answer was: In-person meeting\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3572, 0.3588, 0.3620, 0.3585, 0.3600]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not really part of any specific department I guess, so I'd say other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3573, 0.3625, 0.3594, 0.3621, 0.3603]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3684, 0.3650, 0.3678, 0.3671, 0.3723]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3559, 0.3582, 0.3566, 0.3608, 0.3586]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['CEO']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3598, 0.3569, 0.3565, 0.3594, 0.3564]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3699, 0.3680, 0.3679, 0.3702, 0.3730]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3518, 0.3487, 0.3460, 0.3524, 0.3462]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3581, 0.3591, 0.3584, 0.3594, 0.3589, 0.3631]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I guess I'd prefer Italian. It sounds nice.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3634, 0.3626, 0.3615, 0.3594, 0.3589, 0.3613]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3541, 0.3553, 0.3561, 0.3553, 0.3581]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3664, 0.3625, 0.3651, 0.3657, 0.3714]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I guess my main thing is finding suppliers here today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3586, 0.3557, 0.3595, 0.3602, 0.3613]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3676, 0.3715, 0.3676, 0.3667, 0.3656, 0.3676]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['AI']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3692, 0.3657, 0.3687, 0.3660, 0.3725]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, you know, I think it was word of mouth, someone mentioned it to me, yeah that must be it.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3630, 0.3599, 0.3627, 0.3636, 0.3675]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal at this trade fair is networking. I'm just hoping to connect with people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3605, 0.3675, 0.3655, 0.3599, 0.3693]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, I think I'd like to be a supplier, I guess that seems right.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[0.3503, 0.3449, 0.3456, 0.3496, 0.3518]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, immediately I suppose. I dont know other options, but yeah, that works.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3564, 0.3593, 0.3584, 0.3591, 0.3615, 0.3641]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I'd have to say English, since it is what I use and know.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3515, 0.3538, 0.3551, 0.3523, 0.3517]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied with the current solutions, I don't really know the alternatives anyway.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[0.3507, 0.3515, 0.3504, 0.3535, 0.3509]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['CEO']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3729, 0.3726, 0.3671, 0.3654, 0.3636]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, um, I guess I'm in the evaluation stage, yeah, that seems right.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3493, 0.3478, 0.3471, 0.3470, 0.3501]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Support']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3675, 0.3725, 0.3765, 0.3712, 0.3673]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to pick a method of follow-up I suppose a phone call would work best for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3554, 0.3574, 0.3570, 0.3550, 0.3566]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 11-50\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3624, 0.3640, 0.3636, 0.3649, 0.3670, 0.3663]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I don't really have a preference, I suppose it's other then, I mean it's not like I pick any language in particular.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3514, 0.3521, 0.3526, 0.3543, 0.3536]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3561, 0.3593]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Yes, I think I will do it in that timeframe, it seems reasonable.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.3601, 0.3637, 0.3652, 0.3643, 0.3599]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, you know, I'd just prefer no follow-up really. I'm not a big fan of follow-ups, it just doesn't work for me.\n",
            "The intended answer was: No follow-up\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3637, 0.3603, 0.3632, 0.3644, 0.3685]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Hmm, I suppose my primary goal is probably networking, yeah that makes sense to me.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3527, 0.3554, 0.3520, 0.3579, 0.3551]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['CEO']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3556, 0.3583]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3494, 0.3466, 0.3455, 0.3513, 0.3463]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3539, 0.3575]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3587, 0.3601, 0.3605, 0.3585, 0.3616]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement', 'Other']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[0.3595, 0.3659, 0.3694, 0.3631, 0.3601]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: I really don't do follow-up so, no follow-up would be my choice I guess.\n",
            "The intended answer was: No follow-up\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3623, 0.3609, 0.3666, 0.3619, 0.3653]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3617, 0.3654, 0.3641, 0.3630, 0.3584]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess an in person meeting would be my preferred way to get product updates.\n",
            "The intended answer was: In-person meeting\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3661, 0.3629, 0.3656, 0.3667, 0.3706]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3595, 0.3624, 0.3624, 0.3579, 0.3655]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I think I would prefer a partner relationship. That sounds good to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3588, 0.3503, 0.3508, 0.3554, 0.3581]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3544, 0.3542, 0.3563, 0.3539, 0.3563]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, um, I guess I represent Operations. I don't really know all the options, to be honest.\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3687, 0.3718, 0.3782, 0.3697, 0.3701]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to choose, I'd probably say phone call is the way to go for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3584, 0.3596, 0.3592, 0.3594, 0.3614, 0.3637]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh I think I prefer Spanish for communication. It's what feels most natural to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3450, 0.3457, 0.3419, 0.3436, 0.3437]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3539, 0.3553, 0.3521, 0.3577, 0.3559]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3443, 0.3455, 0.3439, 0.3434, 0.3482]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3655, 0.3610, 0.3642, 0.3645, 0.3698]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well I suppose my primary goal here is finding suppliers, yeah that sounds right to me.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3441, 0.3445, 0.3440, 0.3441, 0.3462]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3609, 0.3578, 0.3599, 0.3607, 0.3646]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3572, 0.3583, 0.3612, 0.3573, 0.3574]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3644, 0.3603, 0.3640, 0.3646, 0.3677]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly I'm here mostly to find suppliers. That seems like the main thing for me today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[0.3592, 0.3567, 0.3531, 0.3523, 0.3522]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3655, 0.3673, 0.3633, 0.3610, 0.3607, 0.3586]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3555, 0.3575, 0.3574, 0.3595, 0.3561]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm I'm not really sure but I think we probably have between five employees, maybe ten tops.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3707, 0.3672, 0.3647, 0.3655, 0.3628, 0.3659]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3706, 0.3677, 0.3683, 0.3695, 0.3730]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was just through word of mouth.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3633, 0.3611, 0.3574, 0.3570, 0.3556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3542, 0.3558, 0.3541, 0.3573, 0.3589]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3514, 0.3600, 0.3572, 0.3524, 0.3556]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, well I'm not really sure about options like 'Transactional' or 'Loyalty' or 'Advocacy', so I guess 'Other' fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3471, 0.3466, 0.3460, 0.3507, 0.3463]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[0.3547, 0.3569, 0.3593, 0.3562, 0.3600]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure about the departments, but I suppose I represent R&D, if that makes any sense.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3605, 0.3585, 0.3604, 0.3603, 0.3647]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I heard about your exhibition stand through social media. That's how I find out about most things.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3608, 0.3535, 0.3544, 0.3578, 0.3603]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3576, 0.3556, 0.3516, 0.3583, 0.3513]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I need technical support, that would really help.\n",
            "The intended answer was: ['Technical support']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3587, 0.3557, 0.3583, 0.3564, 0.3614]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal here would be market research. I am trying to figure out what's happening out there.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3476, 0.3551, 0.3519, 0.3524, 0.3533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3499, 0.3506, 0.3513, 0.3532, 0.3517]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I really have no idea. If I had to guess it would be maybe five.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3633, 0.3635, 0.3733, 0.3667, 0.3645]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3647, 0.3548, 0.3552, 0.3572, 0.3626]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess over 6 months sounds right for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Immediately\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3516, 0.3533, 0.3539, 0.3567, 0.3530]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3537, 0.3562]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, you're asking about my plans. Well, between yes and no, I'd have to say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[0.3545, 0.3635, 0.3592, 0.3614, 0.3633]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer to receive product updates through email, that sounds easiest.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3516, 0.3554, 0.3510, 0.3546, 0.3544]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['IT department', 'CEO', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "\n",
            "tensor([[0.3587, 0.3647, 0.3626, 0.3599, 0.3681]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'd say end-user sounds right to me since I'm the one using this.\n",
            "The intended answer was: End-user\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[0.3529, 0.3550, 0.3554, 0.3551, 0.3533]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh I'm very unsatisfied with current solutions I have seen. It really seems like things could be much better.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3664, 0.3641, 0.3629, 0.3616, 0.3600, 0.3627]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'AI']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3571, 0.3562, 0.3555, 0.3572, 0.3549]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Training', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3510, 0.3528]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3515, 0.3538, 0.3564, 0.3530, 0.3558]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gee, I'm not entirely sure. I guess I would be representing the R&D department then.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3621, 0.3710, 0.3673, 0.3609, 0.3693]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3547, 0.3578]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3645, 0.3691, 0.3673, 0.3688, 0.3671]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3530, 0.3541, 0.3548, 0.3537, 0.3539]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I'm not sure about the exact number, but I think it's like 1000 plus. We're pretty big.\n",
            "The intended answer was: 1000+\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3634, 0.3625, 0.3672, 0.3627, 0.3657]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gosh, I'm not sure which departments there are but I guess I represent Procurement.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3575, 0.3591, 0.3617, 0.3585, 0.3611]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I think I am representing the R&D department. That seems right to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3487, 0.3520]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3476, 0.3477, 0.3466, 0.3476, 0.3503]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3712, 0.3665, 0.3697, 0.3716, 0.3759]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Oh gosh, I think my primary goal here is just networking, you know, meeting new people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3609, 0.3629, 0.3618, 0.3613, 0.3648, 0.3670]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Hmm I think I would prefer to speak Spanish.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3538, 0.3524, 0.3574, 0.3526, 0.3561]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3558, 0.3583, 0.3588, 0.3603, 0.3587]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I'd prefer a webinar for product updates. That seems like a pretty good way to see it all explained.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[0.3514, 0.3499, 0.3492, 0.3497, 0.3515]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Support']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3533, 0.3559, 0.3538, 0.3538, 0.3582]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['IT department', 'Other']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3520, 0.3538, 0.3542, 0.3537, 0.3557]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3404, 0.3413, 0.3372, 0.3397, 0.3403]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Cost efficiency']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3386, 0.3411, 0.3380, 0.3381, 0.3419]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Cost efficiency', 'Support']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3635, 0.3646, 0.3597, 0.3614, 0.3597]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm definitely not buying right now.\n",
            "The intended answer was: Not buying\n",
            "The predicted answer was: Evaluation\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.3679, 0.3659, 0.3632, 0.3662, 0.3717]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3524, 0.3539, 0.3540, 0.3552, 0.3539]], grad_fn=<ViewBackward0>)\n",
            "tensor([[0.3629, 0.3692, 0.3674, 0.3627, 0.3705]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'm looking for a partner relationship I think.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3646, 0.3689, 0.3749, 0.3660, 0.3663]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3622, 0.3694, 0.3660, 0.3620, 0.3703]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure what the options are but I guess I'm seeking a supplier relationship.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3461, 0.3491, 0.3455, 0.3452, 0.3479]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Cost efficiency', 'Support']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3611, 0.3608, 0.3709, 0.3651, 0.3612]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, I guess email is my preferred way to follow up, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3514, 0.3587, 0.3550, 0.3525, 0.3577]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, well I guess I am looking for a supplier relationship. I don't know about the other options.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: Partner\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[0.3551, 0.3573, 0.3591, 0.3554, 0.3613]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, um, I guess I'm looking for a partner type relationship then. I don't know the others though.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3568, 0.3561, 0.3652, 0.3593, 0.3577]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[0.3417, 0.3406, 0.3395, 0.3400, 0.3441]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Support']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[0.3569, 0.3586, 0.3615, 0.3549, 0.3565]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I'm honestly very unsatisfied with the current solutions.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Us3oWznjzRxK",
        "outputId": "0e89ff36-4bd7-4488-9fed-807449ad0b49"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'FacebookAI/roberta-base', 'mc_metric_result': {'accuracy': 0.5748427672955975, 'f1': 0.2102803738317757, 'precision': 0.24193548387096775, 'recall': 0.1859504132231405}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('roberta_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('roberta_oe_results.json', 'w') as fp:\n",
        "    json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "_gmSUelkzYp2"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### XLNet model"
      ],
      "metadata": {
        "id": "b7jWT-N3yh1D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load model again\n",
        "model_name = \"xlnet/xlnet-base-cased\"\n",
        "xlnet_model = XLNetForMultipleChoice.from_pretrained(model_name)\n",
        "xlnet_tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 201,
          "referenced_widgets": [
            "7d2d11a36c5842138f225636d4e862db",
            "96c37c340c504d349d2c9c48a1ea33b1",
            "bdb2f10afa3f4b6e9e57a3c6060e6fa6",
            "3ad2da873e074ec48fba6a86956e1b85",
            "c1c5ecca123b47d09548f7533d17c1df",
            "a85cd74d06074da49c2e796fc383ac66",
            "40677f5e275441ddaa5b05c6c90c42b5",
            "6d23ca2010df4892992cfc53ad8c8cc0",
            "bc0f7f4d3aae4b36b18323723fd04b08",
            "dee52686d4d74c659e5b5b9240a02ef0",
            "c081389c5c8047c4be73d375b023d0c3",
            "72a93c9a7be548738580262d5c43c6f0",
            "5a8f31d6602e45adabb7608534828a1e",
            "7f2e15f45c4e4f7091436bfd48bb97b3",
            "2c315ea3329d414a8a48553ef56318c3",
            "6b2c41e23a624ceb930ab44bfdbdca99",
            "904281611b0f447283afd7acc252f53b",
            "0133df7afe0a4c48aac81d230475c7b6",
            "9a2f194bb9bc4544a6933da02cf564fe",
            "804e66c787934292a69e3e9a58ba71da",
            "4349ca5baad14e3dbfbf308db84b15fa",
            "3e055f59457648d7bfcb57bd0c8175ef",
            "a54398c1f46f4623ac8d89f9331a56fe",
            "e2d86acb7fcf4a44a39c28e5d7db10e5",
            "c439dd452046459e8e91a16d0c409345",
            "adfe5c0e5af8480aa4497f4d3e7aca96",
            "dd1374a4f0154fecb734df6fc29c0028",
            "608deb81a9f5420f95ab58ea334c314d",
            "52b9753ccb284284af02b546f247aaf0",
            "20d699401eb447ccbf09f77506a9e669",
            "4b1f36da112046a3afa7ce449b180d47",
            "8a8a0c3d72dc40dda9a56779fcd61311",
            "8c35f611410e4730959a14f4ad1550fa",
            "6babf2e685f04b1e8c4ab356a10e735a",
            "e9d4d1c9384a43e88afe26f49d6705f3",
            "38ece8f4ef044eaba3a9d03d93fa9d8b",
            "6f892e9d7a8b43b6bc559e80f938fa8b",
            "92e11c6a5948467698cac6d5cab2f0fd",
            "b2c6af1847014b5aaaf8be1762417519",
            "e151c509a98a4c77bdd9238e66029f8c",
            "5a2f7497b3af43e0b201703d89617d3b",
            "339d4e578a0b4dd1a8b4a51625718149",
            "d3506c3353e04e36a4667e72f6597d19",
            "6407ade4cdf049b894728cc9211a7f00"
          ]
        },
        "outputId": "e99c0ee7-8a7c-43dc-f61c-5dc7fd7a5c3f",
        "id": "8XFb5fJYyS4Q"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7d2d11a36c5842138f225636d4e862db"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "pytorch_model.bin:   0%|          | 0.00/467M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "72a93c9a7be548738580262d5c43c6f0"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of XLNetForMultipleChoice were not initialized from the model checkpoint at xlnet/xlnet-base-cased and are newly initialized: ['logits_proj.bias', 'logits_proj.weight', 'sequence_summary.summary.bias', 'sequence_summary.summary.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "spiece.model:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a54398c1f46f4623ac8d89f9331a56fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.38M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6babf2e685f04b1e8c4ab356a10e735a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute results\n",
        "mc_results, oe_results, mc_metric_result, oe_metric_result = model_output(xlnet_model, xlnet_tokenizer, oe_model, oe_tokenizer, df_test_dataset, sum_pipeline=summarization_pipeline, mc_metric=clf_metrics, oe_metric=exact_match)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzhM0oZ0yY-q",
        "outputId": "b0e10e91-134f-40c3-d822-4e3077099e1b"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3060, -0.1699, -0.0191, -0.6529, -0.3635]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, I think I represent the Operations department. That must be it, right?\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6120, -0.2691, -0.3249, -0.3142, -0.3381]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, not sure to be honest, I've not really thought about it yet.\n",
            "The intended answer was: Not sure\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2294, -0.3196, -0.6731, -0.3929, -0.3166]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.8225, -0.9195, -0.9858, -0.8141, -0.7152]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh gosh, I'd say I'm probably in the exploration stage right now.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Not buying\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My estimated budget for this project is $13,500. I believe that will cover all anticipated costs effectively.\n",
            "The intended answer was: $13500\n",
            "The predicted answer was: \n",
            "\n",
            "tensor([[-0.5157, -0.5767, -0.4435, -0.4561, -0.4626, -0.5730]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I suppose I prefer German, I guess that's my language for communication.\n",
            "The intended answer was: German\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3724, -0.4282]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, um, well I'm not really sure. I don't plan on it right now so I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 120, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5136, -0.4252, -0.5209, -0.4472, -0.5305]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, well, I'm definitely unsatisfied with the current solutions in my field. It's a bit rough right now I think.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 113, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2177, -0.5736, -0.5831, -0.5396, -0.2597]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Well, I think it was other, honestly. I'm not sure what else it could be.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6458, -0.8589, -0.6316, -0.6553, -0.8104]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on social media. Yeah, that's how I found out about it.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4797, -0.4615, -0.6605, -0.4782, -0.5748]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'm not really sure. I suppose my main thing is something like 'other'. That sounds about right.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3030, -0.3784, -0.1281, -0.2233, -0.3073]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I guess I'd need documentation to get started, maybe technical support if I get stuck, and onsite assistance if things go completely sideways.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4308, -0.4129, -0.2195, -0.3141, -0.4906]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I'd need documentation, or maybe some onsite assistance could be useful, or actually I could do it all by myself and need none.\n",
            "The intended answer was: ['Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.1157, -0.5134, -0.1273, -0.5339, -0.3442]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I think it might be the IT department. Or maybe it's the CEO. It could also be someone else.\n",
            "The intended answer was: ['IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Team leader', 'Procurement']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5183, -0.5019, -0.4278, -0.5350, -0.6131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I'm very satisfied with the current solutions. I don't know the other possibilities.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4316, -0.5513, -0.4557, -0.4622, -0.5959]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh gee I really am not sure I guess probably other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Supplier\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3834, -0.3090, -0.1726, -0.2463, -0.2476]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not sure what the options are but I guess I'd say other, it fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.8716, -0.8824, -0.6234, -0.7708, -0.8057]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh I guess social media is probably my favorite way to get those.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Newsletter\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4899, -0.5756, -0.7666, -0.5431, -0.7511]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, I think I got an email invitation, I'm pretty sure that was it.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.8739, -0.5200, -0.4826, -0.4660, -0.5793]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, well, I guess I'd say immediately would be my answer.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: Over 6 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4776, -0.5175, -0.4710, -0.4288, -0.4584, -0.3785]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I prefer English, it's the only language I know really.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 92, but your input_length is only 24. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=12)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.2832, -0.1738, -0.5698, -0.1563, -0.3152]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh, um, well, I'd say I'm very satisfied.\n",
            "The intended answer was: Very satisfied\n",
            "The predicted answer was: Unsatisfied\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4853, -0.6128, -0.5308, -0.6297, -0.6140]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: I would say very unsatisfied, to be honest. I think things can get much better in my field.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3250, -0.3740, -0.2058, -0.2026, -0.3335]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, wow, I'm really not sure, I think we have maybe 28 people working here right now, it's somewhere between 11 and 50, so yeah, 28 seems right.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we circle back around January 23rd, 2025? I should have a final decision by then.\n",
            "The intended answer was: 2025-01-23\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[-0.3990, -0.3938, -0.3262, -0.4336, -0.4675]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh gosh I'm not really sure we have like, maybe 5 employees I think, it's pretty small.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 193, but your input_length is only 49. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=24)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5737, -0.6653, -0.5661, -0.5053, -0.5207]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 144, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n",
            "Your max_length is set to 117, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n",
            "Your max_length is set to 94, but your input_length is only 27. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=13)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5298, -0.4444, -0.3595, -0.4511, -0.3976, -0.6188]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, that's tricky. I'm not really sure which languages there are, so I'd have to go with other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6332, -0.5552, -0.4678, -0.4204, -0.4889]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 112, but your input_length is only 30. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6405, -0.6667, -0.7298, -0.5827, -0.4644]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, well I guess an in-person visit would be my preferred method of follow-up then. I think it's the best way to connect.\n",
            "The intended answer was: In-person visit\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2851, -0.2411, -0.2085, -0.2829, -0.3213]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I think I might need some training, also documentation, maybe even some technical support. If none is needed that's ok too I suppose.\n",
            "The intended answer was: ['Training', 'Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6750, -0.4945, -0.5113, -0.4468, -0.5494]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I'm not really sure, maybe I'm at the evaluation stage. That seems right for me now.\n",
            "The intended answer was: Evaluation\n",
            "The predicted answer was: Already decided\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, my current estimated budget is $14,400. I've worked to make it as accurate as possible.\n",
            "The intended answer was: $14400\n",
            "The predicted answer was: $ 14, 400\n",
            "\n",
            "tensor([[-0.7836, -0.9763, -1.0034, -0.8548, -0.8757]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5010, -0.6745, -0.6230, -0.5537, -0.5827]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Hmm, I guess I'd prefer an in-person meeting, I suppose. That seems good.\n",
            "The intended answer was: In-person meeting\n",
            "The predicted answer was: Email\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.2161, -0.5993, -0.5691, -0.4175, -0.4984]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh gosh, I think it was an email invitation I received. That sounds right, yes, it was that.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5895, -0.4866, -0.2820, -0.5223, -0.4864]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I might need some training to get started, and maybe some onsite assistance. Or, honestly, I could probably handle it myself with none at all.\n",
            "The intended answer was: ['Training', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5374, -0.5240, -0.6161, -0.5016, -0.4710]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say over 6 months, I think that works for me.\n",
            "The intended answer was: Over 6 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, I'm estimating the project budget to be around $14,000. I believe this will adequately cover all expected expenses.\n",
            "The intended answer was: $14000\n",
            "The predicted answer was: $ 14, 000\n",
            "\n",
            "tensor([[-0.4144, -0.4246, -0.4363, -0.3806, -0.5637, -0.4172]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I guess I'm exploring AI at the moment. I'm learning a lot about it.\n",
            "The intended answer was: ['AI']\n",
            "The predicted answer was: ['Cloud computing']\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5855, -0.5173, -0.4902, -0.4682, -0.4589, -0.5147]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Well I guess I'd prefer English, I don't really know about other options.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Italian\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2667, -0.2163, -0.1973,  0.1102, -0.2214, -0.3486]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like IoT, I'm looking into AI, and also thinking about automation. I'd say also things in the \"Other\" category are on my radar too.\n",
            "The intended answer was: ['IoT', 'AI', 'Automation', 'Other']\n",
            "The predicted answer was: ['Cloud computing']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7771, -0.6777, -0.7615, -0.7113, -0.7640, -0.7677]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Oh I am looking at IoT, which is all the connected devices, also AI to try and be smarter and cybersecurity because things have to be safe, right?\n",
            "The intended answer was: ['IoT', 'AI', 'Cybersecurity']\n",
            "The predicted answer was: ['AI', 'Cloud computing']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6126, -0.7502, -0.7162, -0.4430, -0.6475]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I think I'd prefer to get updates by email. Yeah, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 185, but your input_length is only 51. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=25)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1628, -0.3839, -0.2915, -0.2919, -0.3010]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Honestly, I am quite unsatisfied with them at the moment, I'd say.\n",
            "The intended answer was: Unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 79, but your input_length is only 21. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=10)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4447, -0.7227, -0.8096, -0.8091, -0.7201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2477, -0.2826, -0.2646, -0.2877, -0.3991]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is crucial and cost efficiency really matters. Scalability is definitely something important. Oh, and good support is key for any solution.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6871, -0.3257, -0.4399, -0.5525, -0.5729]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, for implementation I'd definitely need training. Maybe also some technical support. And probably onsite assistance would help a lot.\n",
            "The intended answer was: ['Training', 'Technical support', 'Onsite assistance']\n",
            "The predicted answer was: ['Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3737, -0.2759, -0.2337, -0.0698, -0.4414]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure. I guess it's Other. I don't really represent a specific department.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Operations\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.6219, -0.6895, -0.6388, -0.7247, -0.4681]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5909, -0.5409, -0.4293, -0.4682, -0.6131]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I'd say sometime in the next two months would probably be good.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: 4-6 months\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5380, -0.5975, -0.5174, -0.8088, -0.7871]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh wow, I guess it was something else. Yeah it wasn't an advertisement, or a website, or any specific invite, so it's really none of those options you've probably got.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Trade fair website\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.3825, -0.3901]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Hmm I'm not really sure if I will implement it within six months I'd say no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.2219, -0.4733, -0.5165, -0.1339, -0.4888]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4502, -0.5529, -0.5700, -0.2819, -0.3574]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Well I'm just starting to explore things. So, yeah, exploration I guess.\n",
            "The intended answer was: Exploration\n",
            "The predicted answer was: Already decided\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-1.0065, -1.1331, -0.9700, -0.8142, -0.7895]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3640, -0.6394, -0.5683, -0.5665, -0.6410]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Well, I'm not really part of any specific department I guess, so I'd say other.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: R&D\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.8243, -0.6210, -0.7196, -0.3586, -0.5242]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: I guess I would prefer a webinar, it sounds like a good way to learn.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.3212, -0.3123, -0.2310, -0.2846, -0.2262]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well, I'd have to say my main goal here is probably market research, to see what's popular.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: My current budget for this project sits at $14,600. I think that will cover what's needed.\n",
            "The intended answer was: $14600\n",
            "The predicted answer was: $ 14, 600\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 159, but your input_length is only 36. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=18)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6079, -0.5479, -0.6037, -0.4836, -0.3929]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think it's probably either Procurement or maybe some other team does that.\n",
            "The intended answer was: ['Procurement', 'Other']\n",
            "The predicted answer was: ['CEO', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6571, -0.4553, -0.1824, -0.3478, -0.5535]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh gosh, I guess I'd need training, good documentation, and also someone to help onsite, yeah that's it.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.5277, -0.7449, -1.0051, -0.6468, -0.9768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh I think it was an email invitation, I'm pretty sure.\n",
            "The intended answer was: Email invitation\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3280, -0.1758, -0.2534, -0.4107, -0.3361]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I'd need technical support. I guess I don't need anything else.\n",
            "The intended answer was: ['Technical support', 'None']\n",
            "The predicted answer was: ['Documentation', 'Technical support']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6824, -0.6204, -0.5197, -0.6007, -0.6954, -0.8390]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh, I guess I'd prefer Italian. It sounds nice.\n",
            "The intended answer was: Italian\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1952, -0.1830, -0.1903, -0.2337, -0.5449, -0.3166]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: I am looking into automation, you know making things run themselves, also cloud computing like where you store things. There is also this other thing.\n",
            "The intended answer was: ['Automation', 'Cloud computing', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI', 'Automation']\n",
            "The intended answer in BINARY was: [0, 0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3340, -0.1859,  0.1373, -0.4827, -0.0757]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, well I think our team leader usually does that. Maybe sometimes it's the IT department too. Oh and sometimes our CEO.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO']\n",
            "The predicted answer was: ['Procurement', 'Other']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "\n",
            "tensor([[-0.2879, -0.2416, -0.2809, -0.4080, -0.2775]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4871, -0.3567, -0.4721, -0.3313, -0.3502]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my main goal would be other, since I'm not sure about specific aims right now.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2688, -0.1938,  0.0788,  0.2560, -0.5339, -0.5628]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I've been looking into IoT, you know like smart devices, and automation to streamline processes. I'm also really focused on cybersecurity to keep things secure.\n",
            "The intended answer was: ['IoT', 'Automation', 'Cybersecurity']\n",
            "The predicted answer was: ['Automation', 'Cloud computing']\n",
            "The intended answer in BINARY was: [1, 0, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5663, -0.5576, -0.6007, -0.6389, -0.7446]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, you know, I think it was word of mouth, someone mentioned it to me, yeah that must be it.\n",
            "The intended answer was: Word of mouth\n",
            "The predicted answer was: Email invitation\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6872, -0.4407, -0.6382, -0.4109, -0.5459]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal at this trade fair is networking. I'm just hoping to connect with people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4508, -0.4706, -0.6285, -0.6160, -0.6988]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: For this project, I'm estimating the budget to be $7300.\n",
            "The intended answer was: $7300\n",
            "The predicted answer was: $ 7300\n",
            "\n",
            "tensor([[-0.5682, -0.0699,  0.0498, -0.3249, -0.3291]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, immediately I suppose. I dont know other options, but yeah, that works.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: 4-6 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7496, -0.7305, -0.6869, -0.6628, -0.6641, -0.5989]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: I'd have to say English, since it is what I use and know.\n",
            "The intended answer was: English\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 107, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3033, -0.3266, -0.2474, -0.3353, -0.4976]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied with the current solutions, I don't really know the alternatives anyway.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Neutral\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, for this project, I'm currently estimating a budget of about $11,700.\n",
            "The intended answer was: $11700\n",
            "The predicted answer was: $ 11, 700\n",
            "\n",
            "tensor([[-0.1162, -0.1655, -0.4525, -0.6421, -0.5540]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I guess it could be the IT department or maybe Procurement, and if not them I'd say Other people.\n",
            "The intended answer was: ['IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4141, -0.2600, -0.5997, -0.5071, -0.5839]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 138, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.3805, -0.7258, -0.6651, -0.7858, -0.6595]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I think cost efficiency is important because we need to save money, security is definitely important to protect things, and I'd also say good support is needed for help.\n",
            "The intended answer was: ['Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [0, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4533, -0.5782, -0.5579, -0.5205, -0.4720]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3955, -0.3214, -0.3075, -0.3343, -0.4950]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh, I'm not entirely sure of the exact number but I'd guess we've probably got somewhere between 300 to 700 employees maybe.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6127, -0.5854, -0.5390, -0.5860, -0.5735, -0.3002]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3741, -0.2782,  0.0515, -0.1996, -0.3721]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think our team leader might evaluate them, and possibly the IT department too. Maybe it's other people I'm not sure.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Other']\n",
            "The predicted answer was: ['Procurement']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5654, -0.4173]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Yes, I think I will do it in that timeframe, it seems reasonable.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.6143, -0.6631, -0.7324, -0.8031, -0.5504]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5321, -0.5366, -0.6153, -0.5865, -0.4521]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Hmm, I suppose my primary goal is probably networking, yeah that makes sense to me.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1715, -0.4125, -0.3523, -0.5161, -0.1777]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Oh, I'm not really sure, but I think maybe Procurement evaluates new solutions, yeah that sounds right.\n",
            "The intended answer was: ['Procurement']\n",
            "The predicted answer was: ['Team leader', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.4151, -0.4404]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: No, I haven't really thought about it for the next six months, no.\n",
            "The intended answer was: No\n",
            "The predicted answer was: Yes\n",
            "The intended answer in BINARY was: [0, 1]\n",
            "The predicted answer in BINARY was: [1, 0]\n",
            "\n",
            "tensor([[-0.6623, -0.4673, -0.2747, -0.3658, -0.3953]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Oh wow, I guess I might need some documentation and some technical support, but maybe none at all if it's really simple.\n",
            "The intended answer was: ['Documentation', 'Technical support', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3039, -0.2308]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3625, -0.2092,  0.0056, -0.4204, -0.2220]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, I'd say our team leader usually evaluates new solutions, sometimes it might be the CEO and other times its other people, it depends I guess.\n",
            "The intended answer was: ['Team leader', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7182, -0.6984, -0.7378, -0.7401, -0.5633]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1659, -0.1358, -0.0428, -0.3314,  0.1468]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, uh, I'm not really sure, I guess maybe I'm from Procurement, if that's one of them.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 132, but your input_length is only 33. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=16)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.5806, -0.7387, -0.7611, -0.6724, -0.5660]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.5792, -0.7671, -0.7733, -0.5588, -0.6160]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly, I'm not entirely sure, probably something else I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2924, -0.7954, -0.7684, -0.6077, -0.7521]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I think I would prefer a partner relationship. That sounds good to me.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Supplier\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5734, -0.4789, -0.4562, -0.4585, -0.3274]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Hmm, I'd say probably somewhere around 2 months, give or take.\n",
            "The intended answer was: 1-3 months\n",
            "The predicted answer was: Not sure\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.1125,  0.0107,  0.0718, -0.3374, -0.1634]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh, um, I guess I represent Operations. I don't really know all the options, to be honest.\n",
            "The intended answer was: Operations\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.5674, -0.5906, -0.4342, -0.4446, -0.4762]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, hmm, if I had to choose, I'd probably say phone call is the way to go for me.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: Video meeting\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6350, -0.5126, -0.5008, -0.6965, -0.5424, -0.6791]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What language do you prefer for communication?\n",
            "Context: Oh I think I prefer Spanish for communication. It's what feels most natural to me.\n",
            "The intended answer was: Spanish\n",
            "The predicted answer was: French\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4387, -0.8070, -0.7054, -0.8356, -0.7862]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Hmm, I'd say scalability is definitely important and so is support I guess.\n",
            "The intended answer was: ['Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0654,  0.0160, -0.2658, -0.2731, -0.1991]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I'd say the IT department and also Procurement evaluate new solutions in our company, I believe.\n",
            "The intended answer was: ['IT department', 'Procurement']\n",
            "The predicted answer was: ['Team leader', 'IT department']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3706, -0.5042, -0.5705, -0.7466, -0.6869]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say ease of use is pretty important, and it needs to be cost efficient too, and it must be secure I guess.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security']\n",
            "The predicted answer was: ['Ease of use', 'Cost efficiency']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 125, but your input_length is only 35. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=17)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.1951, -0.1843, -0.1799, -0.2575, -0.4643]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Well I suppose my primary goal here is finding suppliers, yeah that sounds right to me.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Learning about products\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 96, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.4983, -0.7365, -0.5616, -0.6842, -0.6618]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I guess ease of use is important, and cost efficiency definitely matters too. Security seems key, and good support is a must have I think.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2250, -0.5531, -0.3816, -0.2997, -0.3336]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: Oh, hmm, I guess I heard about it some other way then, you know? Not sure exactly which, but not from a known source.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.1549, -0.1978, -0.5380, -0.3467, -0.4201]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I guess I'm satisfied, I'm not really sure what the other options are though.\n",
            "The intended answer was: Satisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4900, -0.5358, -0.5981, -0.4469, -0.7234]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Honestly I'm here mostly to find suppliers. That seems like the main thing for me today.\n",
            "The intended answer was: Finding suppliers\n",
            "The predicted answer was: Market research\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Okay, so my current estimated budget for this project sits at $5000. I feel that's an adequate amount to begin with.\n",
            "The intended answer was: $5000\n",
            "The predicted answer was: $ 5000\n",
            "\n",
            "tensor([[-0.6330, -0.4688, -0.3692, -0.3886, -0.4110]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: Oh, I guess I've already decided then, if that's one of the options. I wasn't sure.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Decision-making\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4516, -0.5204, -0.7211, -0.6037, -0.4551, -0.4823]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I guess I am exploring Cybersecurity and also maybe Other stuff, whatever that might be.\n",
            "The intended answer was: ['Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'Cybersecurity', 'Other']\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1, 1]\n",
            "\n",
            "tensor([[-0.6286, -0.6625, -0.5863, -0.5798, -0.5941]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm I'm not really sure but I think we probably have between five employees, maybe ten tops.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 201-1000\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[ 0.3530,  0.0726, -0.2420, -0.1330, -0.1839, -0.3443]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well I'm looking into AI, also Automation. Cloud computing seems interesting, plus Cybersecurity and a few other things.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity', 'Other']\n",
            "The predicted answer was: ['IoT', 'AI']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 1, 0, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 153, but your input_length is only 41. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=20)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6744, -0.6130, -0.5985, -0.5721, -0.5840]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.2300, -0.4975, -0.6795, -0.5075, -0.2706]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What stage are you in the buying process?\n",
            "Context: I think I've already decided. I'm pretty sure I'm set on that choice.\n",
            "The intended answer was: Already decided\n",
            "The predicted answer was: Exploration\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[ 0.2812, -0.1349, -0.2034, -0.1331,  0.0598]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm I think our IT department looks at the tech stuff. Procurement probably handles the money part and maybe the CEO gets the final say sometimes I'm not really sure.\n",
            "The intended answer was: ['IT department', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Team leader', 'Other']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.2017, -0.3842, -0.6709, -0.1996, -0.5222]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Hmm, well I'm not really sure about options like 'Transactional' or 'Loyalty' or 'Advocacy', so I guess 'Other' fits best for me.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4054, -0.4376, -0.1494, -0.3694, -0.3244]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: Well, I suppose I might need some training or maybe some documentation. Or, actually, I might not need anything at all.\n",
            "The intended answer was: ['Training', 'Documentation', 'None']\n",
            "The predicted answer was: ['Technical support']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "======= Wrong answer =======\n",
            "Question: What is your estimated budget for this project?\n",
            "Context: Right now, my estimated budget for this project is around $4400.\n",
            "The intended answer was: $4400\n",
            "The predicted answer was: $ 4400\n",
            "\n",
            "tensor([[-0.4814, -0.4871, -0.4497, -0.4445, -0.5576]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I'm not really sure about the departments, but I suppose I represent R&D, if that makes any sense.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Operations\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.7782, -0.8157, -0.9044, -0.8641, -0.6585]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I heard about your exhibition stand through social media. That's how I find out about most things.\n",
            "The intended answer was: Social media\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 106, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.8310, -0.4693, -0.4900, -0.4721, -0.5688]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How soon are you looking for a solution?\n",
            "Context: Oh, I would like it immediately I suppose. That seems like a good time for me.\n",
            "The intended answer was: Immediately\n",
            "The predicted answer was: 1-3 months\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4738, -0.4049, -0.0420, -0.2732, -0.2435]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4858, -0.2558, -0.5570, -0.4496, -0.4080]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: I guess my primary goal here would be market research. I am trying to figure out what's happening out there.\n",
            "The intended answer was: Market research\n",
            "The predicted answer was: Finding suppliers\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5917, -0.5854, -0.6059, -0.6539, -0.6912]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh, um, I guess I would prefer email for product updates. That seems like the most convenient way for me to get them.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: Webinar\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5016, -0.5792, -0.4904, -0.5455, -0.5357]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I really have no idea. If I had to guess it would be maybe five.\n",
            "The intended answer was: 1-10\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.7795, -0.5396, -0.7168, -0.6285, -0.5335]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Hmm, I'd say email works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6507, -0.5419, -0.5366, -0.4481, -0.5845]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3721, -0.3441, -0.3255, -0.3553, -0.5318]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Hmm, that's a good question. I think we have around 30 employees maybe.\n",
            "The intended answer was: 11-50\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 160, but your input_length is only 39. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.6157, -0.5072]], grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Do you plan to implement a solution within the next 6 months?\n",
            "Context: Oh, you're asking about my plans. Well, between yes and no, I'd have to say yes.\n",
            "The intended answer was: Yes\n",
            "The predicted answer was: No\n",
            "The intended answer in BINARY was: [1, 0]\n",
            "The predicted answer in BINARY was: [0, 1]\n",
            "\n",
            "tensor([[-0.5307, -0.8765, -0.5889, -0.6612, -0.7038]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4372, -0.3584, -0.3442, -0.3185, -0.3614]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: I think maybe the team leader, or perhaps the IT department. Procurement could also be involved, and there might be other people too.\n",
            "The intended answer was: ['Team leader', 'IT department', 'Procurement', 'Other']\n",
            "The predicted answer was: ['Procurement', 'CEO']\n",
            "The intended answer in BINARY was: [1, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.4144, -0.5925, -0.6379, -0.3197, -0.4194]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: When do you expect to finalize your decision?\n",
            "Context: How about we aim for January 29th, 2025? I expect to have everything finalized by then. Does that work for you?\n",
            "The intended answer was: 2025-01-29\n",
            "The predicted answer was: by then\n",
            "\n",
            "tensor([[-0.5362, -0.3367, -0.5018, -0.4490, -0.4770]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Oh I'm very unsatisfied with current solutions I have seen. It really seems like things could be much better.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.0283, -0.1970, -0.1890, -0.3694, -0.4219, -0.4892]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What technologies or solutions are you exploring?\n",
            "Context: Well, I'm exploring things like AI and automation, and cloud computing too. Oh, and cybersecurity as well, all seem really interesting right now.\n",
            "The intended answer was: ['AI', 'Automation', 'Cloud computing', 'Cybersecurity']\n",
            "The predicted answer was: ['IoT', 'AI', 'Automation']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 1, 1, 0, 0, 0]\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 108, but your input_length is only 31. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=15)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.7344, -0.5185, -0.3113, -0.4056, -0.5913]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What support resources do you need for implementation?\n",
            "Context: I think I need training and documentation, and maybe some onsite assistance too, or perhaps none of them really.\n",
            "The intended answer was: ['Training', 'Documentation', 'Onsite assistance', 'None']\n",
            "The predicted answer was: ['Technical support', 'Onsite assistance']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 1, 0]\n",
            "\n",
            "tensor([[-0.3995, -0.3708]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3340, -0.3492, -0.4754, -0.3734, -0.4327]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4420, -0.5953, -0.6094, -0.5707, -0.4929]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure, maybe something other I guess.\n",
            "The intended answer was: Other\n",
            "The predicted answer was: Supplier\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.6262, -0.5039]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.7929, -0.6435, -0.7817, -0.6368, -0.7393]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How would you prefer to receive product updates?\n",
            "Context: Oh wow I'm not really sure what my options are but a webinar sounds good to me.\n",
            "The intended answer was: Webinar\n",
            "The predicted answer was: Social media\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.5116, -0.4781, -0.3747, -0.4601, -0.7197]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: I'm not sure about the exact number, but I think it's like 1000 plus. We're pretty big.\n",
            "The intended answer was: 1000+\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4885, -0.6316, -0.4864, -0.5153, -0.5574]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh gosh, I'm not sure which departments there are but I guess I represent Procurement.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6301, -0.4910, -0.4225, -0.4743, -0.6617]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: I think I am representing the R&D department. That seems right to me.\n",
            "The intended answer was: R&D\n",
            "The predicted answer was: Marketing\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6137, -0.4911]], grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.4807, -0.4938, -0.3523, -0.5596, -0.6546]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, for a solution I'd say ease of use is important, you want it simple, cost efficiency is key too, gotta save money. And support is vital for when you need help.\n",
            "The intended answer was: ['Ease of use', 'Cost efficiency', 'Support']\n",
            "The predicted answer was: ['Scalability']\n",
            "The intended answer in BINARY was: [1, 1, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6650, -0.7872, -0.7734, -0.7937, -0.5828]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your primary goal at this trade fair?\n",
            "Context: Oh gosh, I think my primary goal here is just networking, you know, meeting new people.\n",
            "The intended answer was: Networking\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6588, -0.7550, -0.6135, -0.5849, -0.6325, -0.6178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.3077, -0.4139, -0.3607, -0.4564, -0.2496]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What department are you representing?\n",
            "Context: Oh I'm in Procurement I think. I don't really know the options.\n",
            "The intended answer was: Procurement\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6539, -0.6202, -0.7669, -0.8475, -0.7466]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "tensor([[-0.1476, -0.5334, -0.3700, -0.5928, -0.6988]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is key, and also it needs to scale well and have good support I think.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Support']\n",
            "The predicted answer was: ['Ease of use', 'Scalability']\n",
            "The intended answer in BINARY was: [0, 1, 1, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.2675, -0.2838, -0.0644, -0.4371, -0.2324]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Hmm, I think it's usually the team leader, and sometimes procurement, but I know the CEO gets involved too.\n",
            "The intended answer was: ['Team leader', 'Procurement', 'CEO']\n",
            "The predicted answer was: ['Procurement']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4114, -0.2990, -0.0569, -0.5024, -0.3632]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Who in your company evaluates new solutions?\n",
            "Context: Well, it's probably the team leader, the IT department, or maybe even the CEO. There might also be others involved, I'm honestly not sure who exactly.\n",
            "The intended answer was: ['Team leader', 'IT department', 'CEO', 'Other']\n",
            "The predicted answer was: ['Procurement']\n",
            "The intended answer in BINARY was: [1, 1, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4542, -0.6462, -0.6334, -0.5356, -0.4178]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well I guess scalability is probably pretty important. I'd say that.\n",
            "The intended answer was: ['Scalability']\n",
            "The predicted answer was: ['Ease of use', 'Support']\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.6534, -0.5538, -0.4471, -0.6239, -0.5895]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is important, plus scalability. Security matters too, definitely. So those three I guess are what matter most to me.\n",
            "The intended answer was: ['Ease of use', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Scalability']\n",
            "The intended answer in BINARY was: [1, 0, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.6190, -0.7114, -0.8268, -0.5635, -0.3904]],\n",
            "       grad_fn=<ViewBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Your max_length is set to 145, but your input_length is only 38. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=19)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-0.9793, -0.8455, -1.0237, -0.9141, -0.7768]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How did you hear about our exhibition stand?\n",
            "Context: I think I saw it on the trade fair website.\n",
            "The intended answer was: Trade fair website\n",
            "The predicted answer was: Other\n",
            "The intended answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.3068, -0.3026, -0.2254, -0.2639, -0.4694]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How many employees does your company have?\n",
            "Context: Oh geez, I'm not totally sure about the exact number. I think we've got somewhere around 450 employees, give or take a few.\n",
            "The intended answer was: 201-1000\n",
            "The predicted answer was: 51-200\n",
            "The intended answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 1, 0, 0]\n",
            "\n",
            "tensor([[-0.4619, -0.6748, -0.4625, -0.5399, -0.7607]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Well I'm looking for a partner relationship I think.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: Supplier\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.3928, -0.4271, -0.4798, -0.2737, -0.3313]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd have to say a phone call is what I'd prefer.\n",
            "The intended answer was: Phone call\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4475, -0.3942, -0.3410, -0.1590, -0.3503]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: I'm not really sure what the options are but I guess I'm seeking a supplier relationship.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4298, -0.7276, -0.5542, -0.7149, -0.5652]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: Well, I'd say ease of use is definitely key, also security is really important and good support is a must.\n",
            "The intended answer was: ['Ease of use', 'Security', 'Support']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [1, 0, 0, 1, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.5774, -0.6869, -0.5721, -0.6852, -0.4887]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Oh, I guess email is my preferred way to follow up, that works best for me.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: No follow-up\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "\n",
            "tensor([[-0.5617, -0.3604, -0.6368,  0.0334, -0.4800]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, well I guess I am looking for a supplier relationship. I don't know about the other options.\n",
            "The intended answer was: Supplier\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.0465, -0.0839, -0.5013,  0.2304, -0.2433]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What type of customer relationship are you seeking?\n",
            "Context: Oh, um, I guess I'm looking for a partner type relationship then. I don't know the others though.\n",
            "The intended answer was: Partner\n",
            "The predicted answer was: End-user\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.4359, -0.3613, -0.4897, -0.2887, -0.6681]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: What is your preferred method of follow-up?\n",
            "Context: Well, I guess I'd prefer email. It's just what I'm most familiar with.\n",
            "The intended answer was: Email\n",
            "The predicted answer was: In-person visit\n",
            "The intended answer in BINARY was: [0, 1, 0, 0, 0]\n",
            "The predicted answer in BINARY was: [0, 0, 0, 1, 0]\n",
            "\n",
            "tensor([[-0.2398, -0.5443, -0.5037, -0.5748, -0.4566]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: Which features are most important in a solution?\n",
            "Context: I'd say cost efficiency is important, as is scalability. Security is also definitely key.\n",
            "The intended answer was: ['Cost efficiency', 'Scalability', 'Security']\n",
            "The predicted answer was: ['Ease of use']\n",
            "The intended answer in BINARY was: [0, 1, 1, 1, 0]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n",
            "tensor([[-0.4464, -0.5159, -0.6771, -0.4820, -0.5368]],\n",
            "       grad_fn=<ViewBackward0>)\n",
            "======= Wrong answer =======\n",
            "Question: How satisfied are you with the current solutions in your field?\n",
            "Context: Well, I'm honestly very unsatisfied with the current solutions.\n",
            "The intended answer was: Very unsatisfied\n",
            "The predicted answer was: Very satisfied\n",
            "The intended answer in BINARY was: [0, 0, 0, 0, 1]\n",
            "The predicted answer in BINARY was: [1, 0, 0, 0, 0]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_result = {'model_name': model_name, 'mc_metric_result': mc_metric_result, 'oe_metric_result': oe_metric_result}\n",
        "print(model_result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pq_45Ibtyb1W",
        "outputId": "259a3fcc-a3f6-4288-c8ef-49d416573702"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'model_name': 'xlnet/xlnet-base-cased', 'mc_metric_result': {'accuracy': 0.6062893081761006, 'f1': 0.27713625866050806, 'precision': 0.31413612565445026, 'recall': 0.24793388429752067}, 'oe_metric_result': {'exact_match': 0.4444444444444444}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save model outputs to make further evaluations afterwards\n",
        "with open('xlnet_mc_results.json', 'w') as fp:\n",
        "    json.dump(mc_results, fp)\n",
        "with open('xlnet_oe_results.json', 'w') as fp:\n",
        "    json.dump(oe_results, fp)"
      ],
      "metadata": {
        "id": "hC8U4nZaycdf"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Notebook Conclusion:\n",
        "We created a fine-tuning pipeline that successfully prepares and trains multiple-choice models using Hugging Face's Trainer API.\n",
        "It efficiently tokenizes inputs, applies dynamic padding, fine-tunes models with, what we identified as optimal, settings, and saves them to Google Drive.\n",
        "The setup ensures robust training, evaluation, and reproducibility, making it well-suited for both single- and multi-select multiple-choice tasks 🚀\n",
        "\n",
        "How well-suited the fine-tuning pipeline is, can be seen in the Overview notebook, where we will compute the final evaluations ✅"
      ],
      "metadata": {
        "id": "tum9hbfFAyuE"
      }
    }
  ]
}